comment_id,post_id,comment,upvotes
g8mbqkh,j9wzy1,"Guys, It doesn't, I've learned it the hard way. just download 10.1 version ( ´･･)ﾉ(.\_.\`)",8.0
g8mtmg7,j9wzy1,Newer versions of CUDA shouldn't have issues running TF built for older versions. At least for not too old versions.,1.0
g8mt4z0,j9wzy1,"No, it doesn't support yet.",1.0
g8oj1ft,j9wzy1,https://medium.com/@rexdivakar/common-problems-and-solutions-of-tensorflow-gpu-installation-fa08f0807eac?sk=14bc8d0b308155586e47c25e56969127,1.0
g8p4124,j9wzy1,[https://forums.developer.nvidia.com/t/cuda-10-2-tensorflow-2-0-getting-an-error-when-testing-tensorflow/109712](https://forums.developer.nvidia.com/t/cuda-10-2-tensorflow-2-0-getting-an-error-when-testing-tensorflow/109712),1.0
g8pknzt,j9wzy1,"I built a wheel with CUDA 11.0 successfully so you shouldn't have a problem. The pre-built wheels don't come with CUDA 11 yet I don't think  


Checkout the wheel here

 [https://github.com/davidenunes/tensorflow-wheels](https://github.com/davidenunes/tensorflow-wheels)",1.0
g8po57v,j9vtn1,I had similar situation. They will eventually respond and give you a refund. So wait.,1.0
g8mdpfd,j9tevr,Thinking about taking it in two weeks. Can report back.,6.0
g8men5x,j9tevr,good luck and hope to hear back from you.,1.0
g8nv5vo,j9tevr,"It is a good overview of the high-level API, tf.keras. The Andrew Ng and Laurence Moroney Coursera specialization is a great resource.",2.0
g8nzzxm,j9tevr,Thank you,1.0
g8ohvok,j9tevr,Noted,1.0
g8p9w9e,j9tevr,Do you have a link? Searching for it under their instructor name gives me several courses on ML/AI,1.0
g8pqts8,j9tevr,https://www.coursera.org/professional-certificates/tensorflow-in-practice#courses,1.0
g8ornl1,j9tevr,Any study group?,2.0
g8mnhzw,j9tevr,Following,1.0
g8ljxcl,j9pevj,"Nice, saving this for later.",2.0
g8lu4ph,j9kxhf,"Based on someone took the exam, and actually the exam instructions!, it is allowed to use additional libraries if the examinee needs to.


So, installing tensorflow-gpu2.0.0 beside tensorflow2.0.0 solves the problem.


Until someone else denies this detail , or confirms it, I hope it could help someone out there.",1.0
g8kh02w,j9kxhf,"Be wary, I took the exam and used colab. Could not get it to use gpu when using 2.0... You might be able to solve this, but I decided not too since I was doing it on the fly",0.0
g8kh2f2,j9kxhf,"That being said, I still had enough time to take and pass the exam. But it was stressful knowing that training could be faster",1.0
g8kh4bs,j9kxhf,""" get it to use gpu when using 2.0"" you mean your local machine?",1.0
g8kha7j,j9kxhf,"No I don't have gpu. I installed 2.0 on colab, and could not get it to use gpu. And I have colab pro",2.0
g8khqiw,j9kxhf,"Ok, that's another surprize!! So do you advise going for the Colab Pro?",0.0
g8kig4g,j9kxhf,"I’m not a huge fan of colab, but it’s easy for quick testing if that’s what you’re looking for. Also, I think you can use gpu with 2.0 in colab, but make sure you have it working before you start the test",1.0
g8kih0h,j9kxhf,You don’t need it for the exam though,1.0
g8kochb,j9kxhf,Ok I tried to get it working (Colab+ TF2.0.0+ GPU) but it was a vain attempt... Thank you very much for sharing your experience.,0.0
g8n8ut5,j9k4ow,"Not familiar with maven, is there any way to just use some of the artifacts and build a very simple java program that runs a hello world in tensorflow from eclipse? maybe convert to a gradle script?",1.0
g8hwcvf,j9414d,I have tried to get it to run. For a week. And it either ended up with a cant find nvcc or a vm_86 not defined error. So i dont think they are for now. Please if you or anybody finds any solution. Please tell me. Hahahaha. Because the entire reason for me buying the 3080 was for its cudacores. And ability to use with gan models.,5.0
g8kw42z,j9414d,"Hey /u/ephemeralkazu, did you see the comment below about the docker image? I read the description and it provides a working environment for ampere cards for using tf 1.15. I also checked the official tensorflow implementation of the new ada-stylegan2, and it does work with tensorflow 1.15, provided you are using ubuntu. I hope this works for you, good luck!",1.0
g8l0l8p,j9414d,ill check it out. and let you know what i found.,1.0
g8l340c,j9414d,so i should just build a docker env and then install this image instead of tensorflow,1.0
g8la5jm,j9414d,"Yes, that should install all the dependencies you need. Alternatively, there is also a guide there for installing the dependencies via a pip wheel, but I would stick to the docker image if possible. There is a lot less that can cause errors using that method. I would test it if I could, but I haven't bought my card yet...",1.0
g8lbbbo,j9414d,Im gonna try later. Let you know what the results are,2.0
g8lird0,j9414d,"Cool, good luck! Let me know if you run into any issues.",2.0
g8lqhkw,j9414d,Thanks !,2.0
g8i5coe,j9414d,"I would try [the docker image from NGC](https://ngc.nvidia.com/catalog/containers/nvidia:tensorflow). There's a 1.15 version which should work with Ampere cards. I'm not familiar with StyleGAN but 1.15 should be mostly compatible with 1.14.

More info: https://developer.nvidia.com/blog/accelerating-tensorflow-on-a100-gpus/",5.0
g8iba7s,j9414d,"Thanks for the tip, I'll check it out! That would be good news!",1.0
g8ir8r3,j9414d,"I managed to get it working by compiling tensorflow to cuda 11.1. This towards data science article helped with some of the problems (namely some renaming of shared objects and the such) [tensorflow 2.3 with cuda 11.1](https://towardsdatascience.com/how-to-compile-tensorflow-2-3-with-cuda-11-1-8cbecffcb8d3)

You'll need cuda 11.1 for the 8.6 compute capability the rtx 30xx have :)",1.0
g8l0yxa,j9414d,did you get stylegan2 working ?,1.0
g8m7m7l,j9414d,"I have not specifically tried style gan, but while you are building tensorflow you can specify you want v1 and it should build with latest v1. X, if style gan doesn't support that, then you may want to look at a more recent implementation of stylegan",0.0
g8hsiwt,j92l5y,Why should I use this over tensorboard?,3.0
g8k0hhs,j92l5y,"Many features are missing currently if you compare with Tensorboard. However, we will add these features such as gradients, weights graphs etc in the next few months.

The main idea is UI/charts are optimized for mobile. Therefore, you don't need a laptop to check training upgrades.

If you could use this for your projects, please let us know your thoughts/ feedback. That will help us to improve this. Thanks",2.0
g8gwiz9,j92ahm,"I'd also like to know

Also does the PyCharm plugin actually download Tensorflow?

I can see all sorts of issues with this....",1.0
g8pchy9,j92ahm,"I'll (""vaguely"") answer 1. and 3. (not sure to be allowed to answer 2.)

In this official [document](https://www.tensorflow.org/extras/cert/Setting_Up_TF_Developer_Certificate_Exam.pdf) is reported that "" During the exam, you are welcome to experiment with training models using GCP, AWS, Jupyter Notebooks or Google Colab, but you will still need to define, train and save your models within the exam environment, inside PyCharm, in order to submit it for grading"".

You can interpret it in many ways. The way I interpret it is that you are allowed to use Colab but in any case you will need to define and train a model (wherever you want) and then save it  in the exam folder. 

I know that it's a not immediate interpretation but that's what actually happened for many of us, since it's almost impossible to make the exam environment to work with gpu so you will likely find yourself running out of time, or at least you'll feel the pressure. So many of us trained models in pycharm and in colab simultaneously in order to save time.

But if you're allowed to train models wherever you want and then just put the models into the exam folder this also means that completing code is not actually mandatory. The code they offer you is then only a guide to make you able to train a model compatible with the grader.

This should (again, ""vaguely"") answer 1. and 3.

Hope it helps.",1.0
g8hmnu6,j922ve,Android or iOS?,2.0
g8hsf43,j922ve,Im looking for Android,1.0
g8hy23l,j922ve,"Have you tried the usual means of moving files around in Android? Something like FileUtils.copyFile(source_file_object, destination_file_object)?",2.0
g8m1jbf,j922ve,"Aha, nope I havent used that way. So is it possible to access assets folder?",1.0
g8msgux,j922ve,You probably want to use the AssetManager class if you want to move a file from the assets folder to another location. Here's [an example](https://stackoverflow.com/questions/4447477/how-to-copy-files-from-assets-folder-to-sdcard) of someone moving all the files in the assets folder to a location in the sd card. You can probably tweak this code to move a specific file to whatever location you need to.,2.0
g8ozzb7,j922ve,Thanks a lot! You solved my problem! xD,2.0
g8p0wyd,j922ve,Awesome :D,2.0
g8by5p4,j8hjdv,"Check out the TensorFlow probability lib, it has MAF, MADE, IAF and more",1.0
g8byd89,j8hjdv,Yes I know . But I didn’t understand how to join my actual model with MAF / IAF . Do I need to re-train the model ? Or just add the MAF layer after the latent representation and forward the encoder + MAF Layer ?,1.0
g8an3nk,j8ftoi,Thanks for sharing,2.0
g8aansq,j8cx8b,Buddy did [this](https://cdn.discordapp.com/attachments/551173792110608406/554902772730953728/it_works.png) in a course in college. I believe it was [BRISK](https://duckduckgo.com/?t=ffcm&amp;q=BRISK+descriptor&amp;ia=web). You could also check out [SIFT](https://en.wikipedia.org/wiki/Scale-invariant_feature_transform). I haven't studied or used either though so not 100%.,1.0
g8adytf,j8cx8b,"Modern object detection frameworks are probably struggling here because they're 1000x overkill for what you're trying to do.

Consider starting with the openCV corner detector and doing some geometry.

https://opencv-python-tutroals.readthedocs.io/en/latest/py_tutorials/py_feature2d/py_features_harris/py_features_harris.html

Or to do it with ML/TensorFlow grab an off the shelf small/fast image classifier. Add an output head that directly outputs the things you're trying to predict. Center location, box width, box height, and the angle (if more rotation were possible I'd say the sin/cos of the angle)=&gt; output is 5 floats.  

Then run this as a standard regression problem. 

Object detection models are only complicated because they have to be able to generate a variable number of boxes per per image. You know you always have one box, so this is easy.",1.0
g8aea6x,j8cx8b,Contours are better suited for this: https://opencv-python-tutroals.readthedocs.io/en/latest/py_tutorials/py_imgproc/py_contours/py_table_of_contents_contours/py_table_of_contents_contours.html,2.0
g8b8vrv,j8cx8b,I've been using OpenCV for this project but when I perform my findContours call it obviously will find more than just my target. The theory behind my idea was to use TF to crop to the target board to them run OpenCV to do the last bit of image analysis.,1.0
g8bsp08,j8cx8b,"If the target board takes up the majority of the image, simply take the largest contour",1.0
g894xgn,j86229,nvidia is king on machine learning . i recommend buying either a 3070 or 3080 because of the amount of tensorcores and cudacores. Amd will never get there.,-1.0
g8976n7,j86229,"I don't disagree. I mainly bought my GPU for playing games. However, now that I have it, can I use it for tensorflow?",2.0
g899xwr,j86229,"there is a way. But what I can see its extremely complicated and works only on Vega, Polaris, Fiji and Hawaii GPUs. So not on the 5500. 

I just did a quick google search. And the conclusive answer is no sorry.
This was the main reason that i switched from a 5700xt to a 3080.",2.0
g89i83v,j86229,"How In the Frick did you get one of those?

Also, what about ROCm for Tensorflow? I know there are  ROCm versions of Tensorflow ,i just don't know how well it works or with what.",2.0
g8b6ph1,j86229,Yeah that does not work on navi. And I was just lucky wasnt even trying that much.,2.0
g88z3rs,j86229,Gpu acceleration isn’t available at all on AMD gpu’s afaik. They don’t support anything like CUDA.,0.0
g88zlmk,j86229,"Well, they have OpenCL, which is pretty similar. However, no one supports it so there are a lot of 3rd party solutions. However, none are for the NAVI chipset.",2.0
g89094p,j86229,*They support anything like that for any major machine learning frameworks that I know of. Nvidia gpu’s also are better suited with deep learning due to tensor cores and being more ai oriented in general.,2.0
g8953h0,j7v4zc,"It depends on the range of your pixel intensities. You could still use `sigmoid_cross_entropy_with_logits` if you know your pixels are in [0, 1]. MSE works in general otherwise.",2.0
g895f6b,j7v4zc,"I have a range of -1 1 . I thought about using tanh as activation function in the last layer . In this case , is KL Div alone , sufficient for the loss ?",1.0
g895zp6,j7v4zc,"KL div is measuring the divergence of your latent space to multivariate normal. You likely still need a reconstruction loss, how good your decoder is at building the correct image after sampling from the latent space.",1.0
g8967dp,j7v4zc,You think about MSE ?,1.0
g896e0j,j7v4zc,MSE is a good start.,1.0
g84zgdm,j7d72k,Can the 3 people with 8k tvs please verify this?,1.0
g855ud1,j7d72k,probably not) 8K TV ... this is a very expensive pleasure),2.0
g83obci,j7bvvp,"What, exactly, stays at 0%?  How are you monitoring your GPU usage?  `nvidia-smi`?",1.0
g83os8k,j7bvvp,"task manager. But I got a new problem. The training just stops.  and i get this 

[https://imgur.com/a/NafQfqo](https://imgur.com/a/NafQfqo)",1.0
g83rhi8,j7bvvp,did you install tensorflow correctly? It seems tensorflow cannot use CUDA for some reason. Did you validate your installation?,1.0
g83rqwx,j7bvvp,tensorflow is installed. version 1.14,1.0
g83s0bj,j7bvvp,and how do i validate my installation?,1.0
g840vnn,j7bvvp,tf.test.gpu_device_name() to see if tf can see your gpu.,1.0
g843by1,j7bvvp,"its just that rtx 3080 needs cuda 11.0 . Stylegan2 uses tensorflow 1.14
tensorflow 1.14 needs cuda 10.0.

So its just not compatible.... ffs",1.0
g843hnn,j7bvvp,Makes sense.,1.0
g846fmj,j7bvvp,im going to install ubuntu and try it on ubuntu,1.0
g82uzfg,j6zcgw,"I can use it for training pretty advanced repositories like stylegan2 or ALAE with multi-GPUs as of rocm 3.8, pretty functional I must say. I have 2xVega56  


I think the biggest caveat right now is the uncertainty of rocm's support of consumer GPUs like RDNAx, apparently, AMD will add support only for CDNA compute cards and these GPUs are enterprise-class GPUs, soo, maybe Vega will be the last consumer GPUs to ever support rocm :(, if this is the case the only way is Nvidia for the average user.",3.0
g83lch5,j6zcgw,Problem for me is good number of command line Linux tools available for nvidia stuff that don't exist in the amd/rocm world also uniform scalability of nvidia (cuda) devices.,2.0
g81y7p5,j6zcgw,"I'm also curious about DirectML which seems more promising to me, though I don't have any experience with it.",0.0
g8346ys,j6zcgw,"I just read up on it.

I am.not exited though. It used DirectX which is proprietary. And therefore can not be used in proper scalable settings like cloud.",3.0
g804092,j6nn2d,What driver version? Ensure you are on a driver / CUDA version that supports your GPU.,4.0
g81ix3q,j6nn2d,"Are u on linix or windows? I had a similar issue with my 2080 and my fix was going in Nvidia GeForce amd setting GPU to always on, if you are using a dual graphics sometimes my GPU wasn't being activated and it was using my cpu for whatever reason. This was in Linux. Iv now made changes to code to ensure GPU is being selected in any tenaorflow I'm using.

Also GPU has several power modes and it was selecting power mode 0 or lowest setting, I believe I had changed it power mode 8? Which is the performance mode.",2.0
g87e4da,j6nn2d,"I'm on windows and only have one GPU.

I disabled every power saving feature, still no luck ...",1.0
g7zlhkl,j6nn2d,Did u use Same cuda version ?,1.0
g7zny9s,j6nn2d,"Yes, I used the exact same Cuda version.

I just plugged the new card in and launched my stuff. 

I then updated the GeForce Experience drivers (mine were a week old) to see if that would improve things, but nada.",1.0
g7zzt97,j6nn2d,Just to make sure: did you delte the old driver and installed the one for the rtx2060?,1.0
g8860lk,j6nn2d,I uninstalled and reinstalled everrything.,1.0
g7zmgij,j6nn2d,What how's that possible ?,1.0
g7zo4go,j6nn2d,"I wonder if it has to do with the way I use float32 and float64.  
Maybe the RTX 2060 has weaker float64 and/or float 32 performance than the GTX 1060 ... ?",1.0
g7ztayt,j6nn2d,"There is a wikipedia page with the performances of all NVIDIA GPU where you can find that.

[here](https://en.m.wikipedia.org/wiki/List_of_Nvidia_graphics_processing_units)",2.0
g816a19,j6nn2d,Can you reinstall new driver for the rtx. The new card is backward compatible with the old driver so it still runs but you wont activate the extra power? Im in the same situation which i have a gtx1060 and im looking to buy a new rtx2060 or 2070 so im curious!,1.0
g87e260,j6nn2d,"&gt;power mode

So, I uninstalled the drivers.

Booted in safe mode to remove every last bi of it and used a 3rd party tool called Driver Diplay Uninstaller.  
Reinstalled the latest drivers with the latest Cuda and so on ...

I disabled any power saving feature I could think of : still no performance increase !!!

I'm going bonkers !!!",1.0
g8bwdle,j6nn2d,Experiment with batch sizes and tf 32 imo.,1.0
g8bwh5h,j6nn2d,Also you have the extra 2 gb to increase batch sizes,1.0
g8lx5di,j6nn2d,"Excellent idea !

I got rid of the tf 64 and I'm now 60% faster than the 1060.",1.0
g8lxaa0,j6nn2d,💫👏,1.0
g80lf2y,j6njzg,"&gt;  Is there a corresponding method to frozen graph in TF2.x?

They've really focused on saved-model as the *only* method of exporting a TensorFlow model in TF2. There were too many, mostly bad, ways to do it in TF1.",1.0
g7xj7pd,j67fcf,[deleted],1.0
g80a5c1,j67fcf,the .bin file is 2mb,1.0
g7wllqd,j65lw5,"Thank you for sharing this article. As someone who runs a decentralized life tracking app, this looks really exciting. Hopefully we will get a Javascript client?",2.0
g7wtxqj,j65lw5,Thanks for your kind words. And I really hope we get a javascript client.,3.0
g7ye8vr,j65lw5,Pysyft should have one,1.0
g7yeojj,j65lw5,Yeah. It should. Pysyft is leading federated learning.,1.0
g7yflac,j65lw5,I don't know about that... 🙂,1.0
g7xgnsi,j65lw5,[deleted],2.0
g7xyf44,j65lw5,"Federated learning is where you send a model out to clients, where they train it with potentially sensitive data and send it back to the server. The server can then combine these partially trained models to create the next iteration. One example is Google's GBoard.",3.0
g82cos2,j63ybu,Can't really help but it's inference not interference,1.0
g83gwef,j63ybu,"Ouh ah thanks, yeah english not my first language but still a stupid mistake :D",1.0
g7vqgku,j60hte,Size of tf package,1.0
g7vh3eg,j60hte,Working Tensorflow 2.1 in windows 10,1.0
g7w5bit,j5tvqk,"TensorFlowJS is an option, but not a very good one.  You'll not only lose a lot of the efficiencies of using Python/GPU, but you'll also lose the resources that were built for this task (e.g., [Stable Baselines](https://stable-baselines.readthedocs.io/en/master/)).  If these things don't bother you, such as if this is just an experiment or something, then TFJS might be an interesting route.

Assuming you want to use Python, then the next best option would be to setup an interface between your Python agent and the Javascript environment.  This will be entirely dependent on your environment, but this can be facilitated in a lot of ways.  For example, you can use Python to read the state and provide actions using something like websockets if you're looking for a ""clean"" separation between the two (obviously everything can be ran locally, but implementing WS in JS is pretty straight-forward).  Or you can do something slightly more involved like grabbing images from an emulated browser and providing keystrokes as actions through a controller emulation.

I will say that I've actually been able to do something similar to what you've described in Colab (where I made an environment using JS that interacted with a Python agent), but it wasn't easy.  My work is probably dated, too, but if I can find the notebook and clean it up a bit, I'll share it.",2.0
g7w65tg,j5tvqk,"In a way, this is an experiment, just for fun. So taking the Tensorflow.js route could be interesting.

I thought about a kind of backend to work as interface between environments, but I guess the latency may slow down the training, right?

Aniways nice answer! thank you!",2.0
g7w8hp9,j5tvqk,"Yeah, the latency in the interface would certainly be the bottleneck in such an environment, but there'd be no better choice other than to really dig deep and create a more direct way to share that data.

But yeah, taking the TFJS route should work, and would be a great project to share with others if you get it working.  Being able to train an RL agent to play Mortal Kombat directly in the browser would make for an excellent portfolio piece.  I know I'd be interested in seeing what you come up with lol.",2.0
g7umsya,j5tvqk,You can use TensorflowJS,1.0
g7sopi7,j5kw10,"Here's my 2 cents...

Installing a deep learning framework like TensorFlow is the ""least painful"" part. Understanding the math/theory behind the models that you will build in TensorFlow is much more difficult. Heck, even debugging your TensorFlow code is going to be more difficult.

In addition, cross-OS software deployment is extremely non-trivial. This is why there are - almost always - separate download/install options for all three of the major OS's. 

TL;DR - skipping the installation process isn't going to make using TensorFlow or deep learning easy. In fact, even if what you're asking for is possible, you'd be skipping the easiest step.",3.0
g7spfcb,j5kw10,"AIs can understand math, but only end users can choose to run the file. It can be a separate installer or zip for each OS. Deployment is not ""the easiest step"" cuz it has to run in a machine thats very unreliable, called an end user (a Human). If you cant give an example of the kind of program I asked for, then I'll just stick with other number crunching libraries.",-2.0
g7t9qe9,j5kw10,"The issue is your asking for way more than you think. Say you had the installer, then what? These things dont come with a graphical user interface out of the box. So you would then have to start finding and editing config files, knowing where these files are is half of what installing manually does for you. 

So now you would want an installer for the backend, tensor flow and the supporting programs, and some sort of interface. Say now you have both the installer and the interface in one package. Now you need to know how it works, the math is just one example of what you might want to know, so you can use the interface. 

There is a lot that goes on with these things and it's not as easy as install and run what you have in your mind unless you build it yourself. 

If you just want something preconfigured then download docker and the images that tensor flow has uploaded. If that doesn't do what you want, then your not really sure what your asking for. Honestly if you looked into how to set up tensor flow you would see how to download it from docker.",1.0
g7tkusc,j5kw10,You can try to use pyinstaller. It can generate an executable file from a py script by bundling the packages and the script into the executable. Apparently it works with Tensorflow too.,1.0
g7u5kxw,j5kw10,What end user program works that way?,1.0
g7wowrk,j5kw10,faceswap.py is an installer for windows and installs a python environment and tensorflow,1.0
g7or76r,j4zx3d,"I just noticed that the batch size reported in the guide is 60000, while for me it is 469.  

469/60000 \* 6000 microseconds = 46.9 microseconds... 

So I guess it is the exact same as reported in the guide?  A little disheartening since I am using two GPUs that are both supposed to be better than the RX-480.",1.0
g7p1kip,j4zx3d,"Yea, skimming the guide you linked, it appears that even though it says ```batch_size=128```, it doesn't appear that this is reflected in the output posted in the guide. Instead, it looks like it was just run with no minibatches, just individual samples. Which means that your timing is correct and reflects a similar speed as the guide.

This sounds like good performance to me. Adding additional GPUs won't necessarily mean faster training times, but the ability to increase minibatch size greatly or increase model size is enabled. Additionally, regardless of the speed / power of a given GPU, you may experience a bottleneck based on how fast data can be transferred from RAM to your GPUs VRAM.",2.0
g7pn7f1,j4zx3d,"Informative reply, thank you.",1.0
g7po9br,j4zx3d,"Actually, another question - do you know how might one detect a bottle neck from limitations of RAM -&gt; VRAM?  

Thanks.",1.0
g7psydw,j4zx3d,"Yes: https://www.tensorflow.org/guide/profiler

However, this is written to profile CUDA and Nvidia performance. Not sure if it will work for AMD and rocM, or if there is another similar profiling tool / setup that exists for rocM. This would be where I would start though.",2.0
g7wlhi2,j4zx3d,Belated thanks for your reply :),1.0
g7o9qqk,j4yfe2,"I've been playing around with TensorFlow Lite and it works pretty well - end-to-end wake word detection takes about 100ms in total including pre-processing the audio to get the Spectrogram.

There's room for quite. a bit of optimisation as I'm currently using floating-point FFT and could switch to a fixed point version.

It's fairly robust - it only really get confused by words that are very close to the wake word (""Marvin"") - so words like ""Marvel"" definitely cause false positives.

GitHub repo contains the training notebooks and the firmware: [https://github.com/atomic14/diy-alexa](https://github.com/atomic14/diy-alexa)",3.0
g7ojuyr,j4vbbm,Have you considered using anaconda and letting it handle the install process?,3.0
g7ot721,j4vbbm,I read about that but I wanted to do it via pip only. And I did it!,1.0
g7nkkxl,j4vbbm,Probably try `python -m pip install tensorflow`,2.0
g7nkpy9,j4vbbm,In command prompt?,1.0
g7nkrkk,j4vbbm,Yeah!,1.0
g7nkxfy,j4vbbm,Still showing the same error,2.0
g7nly6p,j4vbbm,"My guess is that the latest tensorflow version (that you're trying to install) is not compatible with Python 3.8 32 bit. I have tensorflow 2.2 installed in Python 3.8 64 bit version so I thought it might work for you as well :)

Maybe try installing an older version of tensorflow.",1.0
g7nm88s,j4vbbm,My laptop would actually support 64 bit version of python 3.8. I tried to change it but during installation it’d only give me option to download the 32 bit version. Can you give me a link to download the 64 bit?,1.0
g7nmr0j,j4vbbm,https://www.python.org/downloads/release/python-386/,2.0
g7ot81d,j4vbbm,Thanks!,1.0
g7nmppz,j4vbbm,"[Python 3.8.6 64 bit for Windows](https://www.python.org/ftp/python/3.8.6/python-3.8.6-amd64.exe)

I do have to mention, I run Linux, not windows. But I have faced the same error, and it was definitely a compatibility issue between Python and tensorflow. You just have to find the right combination of versions ;)",1.0
g7nryxs,j4vbbm,"I downloaded it in C drive where it was recommended, but now when I write python in command prompt to check the version, it opens the windows store and tells me to download python.",2.0
g7ns7z1,j4vbbm,"You have to add the installation location of python to your system's path environment variable. Just google it, you'll find a more detailed answer of how to do it.",3.0
g7nsenu,j4vbbm,Alright. I’ll see how I can do that. Thanks for your help!,2.0
g7p387z,j4rfs0,I'd be happier if they UPDATED THEIR DEVELOPER NETWORK WEBSITE PAST AUGUST!,3.0
g7mn117,j4rfs0,What? I want one too! Someone needs to confirm this,2.0
g7nmtfw,j4rfs0,Me too !! 😭😭,1.0
g7mcamr,j4rfs0,"Get me one as well lol, TF logo is nice af",1.0
g7nrzy5,j4rfs0,"If it's like the Google Cloud Platform swag, then after you get the certification you should be given the ability to make purchases for certification unlocked swag after the cert is earned. Personally, I never got an invite code even after earning my GCP certification, so ¯\\_(ツ)_/¯",1.0
g7o3jku,j4rfs0,"AFAIK there isn't one. 

If you want hoodies and other swag you can go for the Google cloud certified professional data engineer, machine learning engineer or others. Every exam you pass gets you a code that you can pick an item from the swag shop. 

Source: certified Tensorflow and GCP Data Engineer.",1.0
g7laq1c,j4qfet,"for the record when I run rocm-smi I also see them:

    ========================ROCm System Management Interface========================
    ================================================================================
    GPU  Temp   AvgPwr  SCLK     MCLK    Fan     Perf  PwrCap  VRAM%  GPU%  
    0    60.0c  11.0W   1269Mhz  945Mhz  14.9%   auto  220.0W    0%   0%    
    1    53.0c  14.0W   1138Mhz  800Mhz  13.73%  auto  220.0W    4%   1%    
    ================================================================================
    ==============================End of ROCm SMI Log ==============================",1.0
g7lw328,j4qfet,"i can't really comment on radeon gpus, but what I can say is that I had a bit of trouble getting tensorflow to work with my **cuda installation**  

things that helped me :

* matching the gpu driver to the tensorflow version (google/reddit)
* installing specific dependencies (*may be specific to my install, buy may apply to you)*
   * `numpy==1.16.0 scipy==1.4.1` *(I did this with conda, but the* `syntax` *here is for* `pip`*)*
* installing tensorflow / keras through `pip` 
   * `pip install keras tensorflow-gpu`",1.0
g7nbflg,j4qfet,"how is your example code structured? is it expected to strain your graphics cards?

benchmark your system with gpu and cpu to make sure your gpu is doing some work.

[https://github.com/tensorflow/benchmarks/tree/master/scripts/tf\_cnn\_benchmarks](https://github.com/tensorflow/benchmarks/tree/master/scripts/tf_cnn_benchmarks)

readme explains how to run the benchmark",1.0
g7olb7j,j4qfet,"thanks for the tip - I think my issue is a little different than I originally believed, and I'm going to make a new post.",1.0
g7ogcwc,j4o9fq,"Start here:

[https://pjreddie.com/darknet/yolov1/](https://pjreddie.com/darknet/yolov1/)",1.0
g7k9nu4,j4m83g,"Here are the keras examples for generative models. If you don't need anything fancy these should work fine for what you want.

https://keras.io/examples/generative/",2.0
g7kmbgo,j4m83g,Thanks,1.0
g7kl4w3,j4m83g,Check out Refik Anadol,1.0
g7kmcuw,j4m83g,Ill check it out thanks,2.0
g7pp7bj,j4m83g,runwayml.com sounds like just the right thing for you,1.0
g7psw4u,j4m83g,I think ive heard about this. Its cloud based right?,1.0
g7t8cxr,j4m83g,"i just heard of it, and it seems like something you can use without much knowledge about whats going on in the background",1.0
g7it4jq,j4f9c0,"https://www.quora.com/Can-I-use-AMD-and-Nvidia-GPUs-together#:~:text=Now%20comes%20the%20practical%20job,and%20install%20the%20Nvidia%20drivers.",1.0
g7ivh8m,j4f9c0,cheers looks like a headache.,2.0
g7ixthp,j4f9c0,"I've done this, I am adamant that it is not worth it. I ended up consolidating around my 2080 and putting the AMD in some other box",1.0
g7jroxj,j4f9c0,How to confuse your machine 101,1.0
g7jsgyz,j4f9c0,"It is certainly possible on Linux, but on Windows, I am not sure",1.0
g7kj2vh,j4f9c0,"How to confuzzle ur machine 101. Yes it is possible, but its  quite hard. gl",1.0
g7nj0d1,j4f9c0,"You can technically do this using the virtualisation route. Refer here for more details.

https://www.linux-kvm.org/page/Main_Page

Best practice is to have a separate vm for your data science workloads.",1.0
g7gmpgq,j42uwf,"https://youtu.be/23R2eI95S30 

keeping the link more accessible. Because  link in the title is not clickable.",2.0
g7hdds1,j42uwf,Thank you,1.0
g7hpgbh,j42uwf,Concise and good. Little bit explanation on how the UI appears automatically will be appreciated.,1.0
g7hrs9p,j42uwf,thank you for the feedback :),1.0
g7edqwk,j3uabw,"## Overview

We are glad to release Spark NLP 2.6.2! This release comes with a brand new SentenceDetectorDL (SDDL) that is based on a general-purpose neural network model for sentence boundary detection with higher accuracy. In addition, we are releasing 12 new and improved BioBERT models for BertEmbeddings and BertSentenceEembeddings used for sequence and text classifications.

Spark NLP has a new and improved [Website](https://nlp.johnsnowlabs.com/) for its documentation and models. We have been moving our 330+ pretrained models and pipelines into [Models Hubs](https://nlp.johnsnowlabs.com/models) and we would appreciate your feedback! :)

As always, we would like to thank our community for their feedback, questions, and feature requests.

## New Features

* Introducing a new SentenceDetectorDL (trainable) for sentence boundary detection
* Dedicated [Models Hub](https://nlp.johnsnowlabs.com/models) for all pretrained models &amp; pipelines

## Enhancements

* Improved BioBERT models quality for BertEmbeddings (it achieves higher accuracy in sequence classification)
* Improved Sentence BioBERT models quality for BertSentenceEmbeddings (it achieves higher accuracy in text classification)
* Improve loadSavedModel in BertEmbeddings and BertSentenceEmbeddings
* Add unit test to MultiClassifierDL annotator
* Better error handling in SentimentDLApproach

## Bugfixes

* Fix BERT LaBSE model for BertSentenceEmbeddings
* Fix loadSavedModel for BertSentenceEmbeddings in Python

## Deprecations

* DeepSentenceDetector is deprecated in favor of SentenceDetectorDL

## Models

|Model|Name|Build|Lang|
|:-|:-|:-|:-|
|BertEmbeddings|`biobert_pubmed_base_cased`|2.6.2|`en`|
|BertEmbeddings|`biobert_pubmed_large_cased`|2.6.2|`en`|
|BertEmbeddings|`biobert_pmc_base_cased`|2.6.2|`en`|
|BertEmbeddings|`biobert_pubmed_pmc_base_cased`|2.6.2|`en`|
|BertEmbeddings|`biobert_clinical_base_cased`|2.6.2|`en`|
|BertEmbeddings|`biobert_discharge_base_cased`|2.6.2|`en`|
|BertSentenceEmbeddings|`sent_biobert_pubmed_base_cased`|2.6.2|`en`|
|BertSentenceEmbeddings|`sent_biobert_pubmed_large_cased`|2.6.2|`en`|
|BertSentenceEmbeddings|`sent_biobert_pmc_base_cased`|2.6.2|`en`|
|BertSentenceEmbeddings|`sent_biobert_pubmed_pmc_base_cased`|2.6.0|`en`|
|BertSentenceEmbeddings|`sent_biobert_clinical_base_cased`|2.6.2|`en`|
|BertSentenceEmbeddings|`sent_biobert_discharge_base_cased`|2.6.2|`en`|

The complete list of all 330+ models &amp; pipelines in 46+ languages is [available here](https://github.com/JohnSnowLabs/spark-nlp-models/).

## Documentation and Notebooks

* New notebook to [use SentenceDetectorDL](https://github.com/JohnSnowLabs/spark-nlp-workshop/blob/master/tutorials/Certification_Trainings/Public/9.SentenceDetectorDL.ipynb)
* Update [Model Hubs](https://nlp.johnsnowlabs.com/models) with new models in Spark NLP 2.6.2
* Update documentation for release of Spark NLP 2.6.2
* Update the entire [spark-nlp-workshop](https://github.com/JohnSnowLabs/spark-nlp-workshop) notebooks for Spark NLP 2.6.2

## Installation

**Python**

    #PyPI
    
    pip install spark-nlp==2.6.2
    
    #Conda
    
    conda install -c johnsnowlabs spark-nlp==2.6.2

**Spark**

**spark-nlp** on Apache Spark 2.4.x:

    spark-shell --packages com.johnsnowlabs.nlp:spark-nlp_2.11:2.6.2
    
    pyspark --packages com.johnsnowlabs.nlp:spark-nlp_2.11:2.6.2

**GPU**

    spark-shell --packages com.johnsnowlabs.nlp:spark-nlp-gpu_2.11:2.6.2
    
    pyspark --packages com.johnsnowlabs.nlp:spark-nlp-gpu_2.11:2.6.2

**spark-nlp** on Apache Spark 2.3.x:

    spark-shell --packages com.johnsnowlabs.nlp:spark-nlp-spark23_2.11:2.6.2
    
    pyspark --packages com.johnsnowlabs.nlp:spark-nlp-spark23_2.11:2.6.2

**GPU**

    spark-shell --packages com.johnsnowlabs.nlp:spark-nlp-spark23-gpu_2.11:2.6.2
    
    pyspark --packages com.johnsnowlabs.nlp:spark-nlp-spark23-gpu_2.11:2.6.2

**Maven**

**spark-nlp** on Apache Spark 2.4.x:

    &lt;dependency&gt;
        &lt;groupId&gt;com.johnsnowlabs.nlp&lt;/groupId&gt;
        &lt;artifactId&gt;spark-nlp_2.11&lt;/artifactId&gt;
        &lt;version&gt;2.6.2&lt;/version&gt;
    &lt;/dependency&gt;

**spark-nlp-gpu:**

    &lt;dependency&gt;
        &lt;groupId&gt;com.johnsnowlabs.nlp&lt;/groupId&gt;
        &lt;artifactId&gt;spark-nlp-gpu_2.11&lt;/artifactId&gt;
        &lt;version&gt;2.6.2&lt;/version&gt;
    &lt;/dependency&gt;

**spark-nlp** on Apache Spark 2.3.x:

    &lt;dependency&gt;
        &lt;groupId&gt;com.johnsnowlabs.nlp&lt;/groupId&gt;
        &lt;artifactId&gt;spark-nlp-spark23_2.11&lt;/artifactId&gt;
        &lt;version&gt;2.6.2&lt;/version&gt;
    &lt;/dependency&gt;

**spark-nlp-gpu:**

    &lt;dependency&gt;
        &lt;groupId&gt;com.johnsnowlabs.nlp&lt;/groupId&gt;
        &lt;artifactId&gt;spark-nlp-gpu-spark23_2.11&lt;/artifactId&gt;
        &lt;version&gt;2.6.2&lt;/version&gt;
    &lt;/dependency&gt;

**FAT JARs**

* CPU on Apache Spark 2.4.x: [https://s3.amazonaws.com/auxdata.johnsnowlabs.com/public/spark-nlp-assembly-2.6.2.jar](https://s3.amazonaws.com/auxdata.johnsnowlabs.com/public/spark-nlp-assembly-2.6.2.jar)
* GPU on Apache Spark 2.4.x: [https://s3.amazonaws.com/auxdata.johnsnowlabs.com/public/spark-nlp-gpu-assembly-2.6.2.jar](https://s3.amazonaws.com/auxdata.johnsnowlabs.com/public/spark-nlp-gpu-assembly-2.6.2.jar)
* CPU on Apache Spark 2.3.x: [https://s3.amazonaws.com/auxdata.johnsnowlabs.com/public/spark-nlp-spark23-assembly-2.6.2.jar](https://s3.amazonaws.com/auxdata.johnsnowlabs.com/public/spark-nlp-spark23-assembly-2.6.2.jar)
* GPU on Apache Spark 2.3.x: [https://s3.amazonaws.com/auxdata.johnsnowlabs.com/public/spark-nlp-spark23-gpu-assembly-2.6.2.jar](https://s3.amazonaws.com/auxdata.johnsnowlabs.com/public/spark-nlp-spark23-gpu-assembly-2.6.2.jar)",1.0
g7edrp0,j3uabw,"
I see you've posted a GitHub link to a Jupyter Notebook! GitHub doesn't 
render large Jupyter Notebooks, so just in case, here is an 
[nbviewer](https://nbviewer.jupyter.org/) link to the notebook:

https://nbviewer.jupyter.org/url/github.com/JohnSnowLabs/spark-nlp-workshop/blob/master/tutorials/Certification_Trainings/Public/9.SentenceDetectorDL.ipynb

Want to run the code yourself? Here is a [binder](https://mybinder.org/) 
link to start your own Jupyter server and try it out!

https://mybinder.org/v2/gh/JohnSnowLabs/spark-nlp-workshop/master?filepath=tutorials%2FCertification_Trainings%2FPublic%2F9.SentenceDetectorDL.ipynb



------

^(I am a bot.) 
[^(Feedback)](https://www.reddit.com/message/compose/?to=jd_paton) ^(|) 
[^(GitHub)](https://github.com/JohnPaton/nbviewerbot) ^(|) 
[^(Author)](https://johnpaton.net/)",1.0
g7dr4k7,j3mwyk,"This class seems sus ngl. Which country is this in? Who makes a $400-$1000 HW a mandatory requirement. 

1.10-1.15 are quite similar. Both have eager execution enabled. If you are in a beginner machine learning class then I think the only thing they want to make sure is to have eager execution enabled. 

If you can give more details on why 1.10 maybe you can recompile TF source so that it works with CUDA 10.1.",3.0
g7fzlxf,j3mwyk,Difference negligible for most models you create,1.0
g7b3vie,j3b5es,"jesus can we please stop posting these things, they are making me so much less enthusiastic about ML",2.0
g7acljc,j37yt6,"Maybe I’m wrong bc I’m new to this but the input shape vector of (5,1) is 5 rows 1 column, but the array x is (1,5) shape. You have to transpose one of the vectors.",1.0
g7wrhq5,j37yt6,"Your input array has a ```dtype=int64```. That's not a valid input type for LSTM or for most layer types. You need to convert it to a float type. Additionally, provide a loss function on ```compile```.


```python
model = tf.keras.Sequential()
model.add(layers.LSTM(1, input_shape=(5,1)))
model.add(layers.Dense(1))

x = tf.convert_to_tensor(np.array([1,2,3,4,5], dtype='float32').reshape(1,5,1))
y = tf.convert_to_tensor(np.array([6], dtype='float32'))

model.compile('rmsprop', 'mae')
model.fit(x,y)
```",1.0
g79oz2z,j34rt7,"for DRL we have tf-agents which is based on tf2. pytorch has no special RL extensions but is good enough as it is. tf1 is an example of graph-based approach that gives some insight into how to run stuff on GPU but this only has some value if you will work with similar proprietary frameworks for GPU and want to check similar designs on tf1 first. otherwise, it is not convenient and difficult to debug, so probably worth knowing in general but not actually learning/using.",2.0
g79xgnj,j34rt7,I would learn tf2 and only learn tf1 if you have to because it's like premature optimization at this point to learn it if you haven't already.,1.0
g79ksd2,j3268v,You're probably the first person here I've seen running on a 3090. Does performing regular math or FTTs with TF work fine?,11.0
g79rbjn,j3268v,"Yeah it seems to work with basic stuff. A matmul for example: [https://imgur.com/a/tkveCCh](https://imgur.com/a/tkveCCh) (add, divide also works)",3.0
g7anraw,j3268v,[deleted],2.0
g7cscn4,j3268v,"I've tested 1.14, 2.1.0 and 2.4.0-dev20201001 (nightly) and they all seem to work with basic operations.",1.0
g7a6vlv,j3268v,Try some of your old notebooks to see the results.,3.0
g7aegsa,j3268v,"I am facing the same problem with my new RTX 3090, a Palit GamingPro on Windows 10.  
I've tried very simply CNNs on CIFAR10 and MNIST with various optimizers but I constantly get NaNs and garbage output.  


I've so far tried with and without Mixed Precision. CUDA 11.1 with cuDNN 8.04, CUDA 10.1 with cuDNN 7.65. And installing tensorflow-gpu on completely fresh environment, testing 2.1, 2.3.4 and 2.4dev (nightly).

Games work completely fine and all stresstesting goes through without a hitch. I'm kinda at a loss for what do to now, so any help would be appreciated.",3.0
g7b7pjz,j3268v,"Finally got it to work!  
Don't know if you're also using Anaconda, but this is how I solved my problem:  


1. Create fresh conda environment
2. install the essential packages you need that are not Tensorflow related
3. Use pip install on tf-nightly-gpu
4. Install CUDA 11.1 with cuDNN 7.65 (8.04 didn' not work) seperately (not through conda), because the cudatoolkit is too low it seems for RTX 3090 that conda forces you to use.

Now I can actually run through my tests. Hope this helps you out!",6.0
g7cr6jh,j3268v,"Thanks for the help, glad you got it to work.

I haven't had much luck with this method unfortunately. I tried a new conda environment with tf-nightly-gpu using cuda 11.1 with cuDNN 7.65, but it was running in CPU mode because it couldn't find the cuDNN DLLs. When I renamed them it gave me this error: [https://imgur.com/hkLRGas](https://imgur.com/hkLRGas) (Loaded runtime CuDNN library: 7.6.5 but source was compiled with 8.0.2. CuDNN library needs to have matching major version...).

I also tried 11.1 and cuDNN 8.0 and got this [https://imgur.com/fMP37dO](https://imgur.com/fMP37dO) (Non-OK-status: GPULaunchKernel() Internal: unspecified launch error).

I might try building tensorflow from source later to see if I can get it to compile with the latest cuda/cuDNN and see if that helps.",1.0
g7e1okr,j3268v,"Hmm, now that I think about it, I actually have both 8.04 and 7.65 files in my cuda 11.1 folder. I had first put 8.04 in there but then overwrote some files when I dropped in the 7.65.

Currently running on the 456.55 drivers too.",2.0
g7i1odd,j3268v,"Thank you so much for sharing everything here, I never would have figured it out on my own!

&amp;#x200B;

This worked for me:

1. Create new conda environment for python 3.8
2. Install tf-nightly-gpu using pip (not conda)
3. Install cuda 11.1
4. Drop files from cudnn 8 into the cuda folder
5. Then drop files from cudnn 7.6.5 into the cuda folder
6. Restart computer (something with path variables I guess)

&amp;#x200B;

I can only confirm that the Conv2D and Dense layers work, I haven't done a full test.

&amp;#x200B;

Edit:

Every now and then it seems to start to randomly give errors on not being able to use cudnn anymore. After a reboot it works fine again, but simply restarting python does not seem to do the trick. I see that there is a new nightly build, let's see if it helps",2.0
g7e6odo,j3268v,"Yeah it could still be loading the version 8 dll in your case.

I did finally get it working with cuda 11.0 (using the ptxas.exe from cuda 11.1) and cuDNN 8.0.2. (thanks for the tf-nightly tip)

It was randomly crashing once in a while with CUDA\_ERROR\_LAUNCH\_FAILED, but it seems to work fine if CUDA\_LAUNCH\_BLOCKING is set to 1. I don't know if it's a good workaround since it makes cuda kernel launches synchonous to the host (might make training less efficient), but it works for now.",1.0
g7g6x0c,j3268v,"Nice that you managed to get it up and running too. I haven't had that problem at least so no idea how to solve instead of workaround.

But the performance increase is really nice for the workstation, and if this is your first RTX card I recommend this: [https://www.tensorflow.org/guide/mixed\_precision](https://www.tensorflow.org/guide/mixed_precision)",1.0
g7k2vn6,j3268v,"I'm running on a 3080 FE and am getting some odd issues as well. Some code that I had running on a 1660 was working just fine a few days ago, but after installing the 3080 it gives me NaN values for loss pretty consistently. It still runs perfectly fine on the CPU so im at a loss for what could be happening here. Gonna try some of the software configuration stuff that the other posters here tried, posting this comment for the sake of google-ability.",1.0
g7t052w,j3268v,What version of TensorFlow are you using that is compatible with cuda 11? I thought all tensorflow builds used 10.1,1.0
g83jm64,j3268v,"I used tf-nightly-gpu (installed via pip) which is compiled with cuda 11.0, I got it working with 11.1 and 11.0.

I needed to set the environment variable CUDA\_LAUNCH\_BLOCKING=1 to get it to work. Otherwise I got cuda launch errors.",1.0
g89o3ws,j3268v,Just tried this setup and im getting a CUDNN_STATUS_ALLOC_FAILED error. Gonna try some different versions of CUDNN.,1.0
g8bo6gz,j3268v,"Are you sure you set the CUDA\_LAUNCH\_BLOCKING env variable? I was getting similar errors without it (cuda launch failed, Check failed: status == CUDNN\_STATUS\_SUCCESS 7 vs. 0, etc). Seems to work fine with it set.

I was also getting BLAS errors at one point, which might have been fixed by making sure only one cuda version is installed (just move the v10.0, v10.2, etc folders somewhere else). It could have been a different error that fixed but I don't remember exactly.

Also make sure you don't have cudatoolkit/cudnn installed via conda (as they're not the latest version)",1.0
g8ciduf,j3268v,I tried rolling back my driver to 456.55 and completely uninstalled all CUDA stuff and tried your method with 11.0 and the method u/ThePauliPrinciple posted but nether work. Currently getting issues about CUBLAS_STATUS_ALLOC_FAILED and CUDNN_STATUS_ALLOC_FAILED. I'm not trying to train a large network and am using batch size of 1 so im not running out of memory I think. I made a post on the NVIDIA forums so hopefully I get word about official support of the 3000 series cards.,1.0
g8a6bt7,j3268v,What driver version are you using? I'm having trouble with the 456.71 - getting all sorts of errors about allocation failures for CUDNN and CUBLAS with your exact setup,1.0
g8bobuk,j3268v,"I'm using 456.55 at the moment (with cuda 11.1 and cuDNN 8.0.4)

Edit: I'm also using python 3.8 in anaconda, not sure if that's important",1.0
g792yxr,j2pbrc,"It's hard to know. Literally anything could be happening in that `load_model` because of the `custom_objects`. Do you load the model for every request?

But for context, an ""IndexedSlices"" is a sort of sparse tensor that you almost never see in the wild. Usually they only exist in the gradients of `tf.gather` which is a sort of indexing operation.",1.0
g7a2j3q,j2pbrc,Thanks for your reply. The model is loaded once on application initialization.,1.0
g75q8rj,j2j3xz,"Tried running as administrator?

When I get errors I try to segregate the code to narrow down the search for the root cause.

I did some googling and found similair issues reported, this might be the case:[https://python-forum.io/Thread-python-PermissionError-Errno-13-Permission-denied](https://python-forum.io/Thread-python-PermissionError-Errno-13-Permission-denied)

""That looks like an operating system issue. You appear to be using that  as a log file, and you don't have write access to that location. You can  either make sure you have write access to that folder, or use another  folder.""",1.0
g7bv17r,j2i582,"One of the document says If you have already attempted the exam, you have to uninstall Exam plugin and install again in pycharm.",1.0
g7dc9yw,j2i582,I did uninstall and reinstall when i registered for the exam the second time.,1.0
g78msy9,j2gn4k,"How are you using the terms ""constants"" and ""variables"" here? What is the difference in your question?",1.0
g78o8xr,j2gn4k,a constant would a tf.constant object and the variable a tf.Variable type object,1.0
g79yoyo,j2gn4k,I don't believe so. But you can create a mask to mask out specific values prior to calculating your loss.,2.0
g72t5xf,j21ocl,"You haven't said much about what the data is, what it represents, and what you're trying to get from it. Deep neural networks are going to work best on data that is highly nonlinear. The more nonlinear the data, theoretically the deeper the neural network will likely need to be. But that assumes your desired output is something that requires that nonlinearity.

&amp;#x200B;

What is the data? And what're you hoping to get out of that data?",1.0
g72tkie,j21ocl,"NAN (""Not a Number"") means that your network is blowing up during training. Something wasn't set correctly for your network, optimization, and dataset. This could be as simple as your learning rate is set too high on your optimizer.",2.0
g7385sy,j21ocl,"The data is a COVID-19 dataset which contains symptoms (columns) for each patient (row) and I’m trying to classify the severity of COVID 19 based on the symptoms each patient has, as well as their age. I have encoded all of the features to 0s and 1s as well as my output. Yet still training is getting harmed.",1.0
g73a3hl,j21ocl,Share your tf code for training?,1.0
g73jcmf,j21ocl,Can I pm you?,1.0
g74puez,j21ocl,"Are you normalizing your inputs? outputs? have you tried the options here?: 

https://www.tensorflow.org/tutorials/load_data/csv",1.0
g72u3so,j1zhh9,"Your code to train your neural network is all here. You should only be loading the model and running your prediction if that's all you want to do. Make a new script and only copy those portions of this over, then run that script.",1.0
g730h6g,j1zhh9,"Thanks for replying. Do you mean I should create a new file, and then try to load the model and run the prediction?",1.0
g730zv3,j1zhh9,"Yea. In the code above you're training your network prior to doing any prediction. If you don't want to train your network again, just delete all that code.",1.0
g75m3vp,j1zhh9,"It worked, but I get these errors when I run the prediction.

The code:

import numpy as np

from tensorflow import keras

from tensorflow.keras.preprocessing import image

\# predicting images

path = os.path.join('c:/', 'Users', 'USER', 'Downloads')

img = image.load\_img(path, target\_size=(300, 300))

x = image.img\_to\_array(img)

x = np.expand\_dims(x, axis=0)

images = np.vstack(\[x\])

classes = loaded\_model.predict(images, batch\_size=10)

print(classes\[0\])

if classes\[0\]&gt;0.5:

print(""It is a fox"")

else:

print(""It is a cat"")

&amp;#x200B;

and here are the errors:

Traceback (most recent call last):

File ""c:/Users/USER/Desktop/obj-classification/obj-class.py"", line 19, in &lt;module&gt;

img = image.load\_img(path, target\_size=(300, 300))

File ""C:\\Users\\USER\\Anaconda2\\envs\\py3-TF2.0\\lib\\site-packages\\keras\_preprocessing\\image\\[utils.py](https://utils.py)"", line 110, in load\_img

img = pil\_image.open(path)

File ""C:\\Users\\USER\\Anaconda2\\envs\\py3-TF2.0\\lib\\site-packages\\PIL\\[Image.py](https://Image.py)"", line 2878, in open

fp = [builtins.open](https://builtins.open)(filename, ""rb"")

PermissionError: \[Errno 13\] Permission denied: 'c:/Users\\\\USER\\\\Downloads'

&amp;#x200B;

Could you tell me what's  wrong with code, if you don't mind?

Sorry for bothering you.

Thank you very much",1.0
g75tnc3,j1zhh9,"Theres a problem with your path variable. Looks like it's pointing to a directory right now, not a file.",1.0
g72vkgd,j1sjpz,"Check out the available models: https://tfhub.dev/s?module-type=text-embedding,text-classification,text-generation,text-language-model,text-question-answering,text-retrieval-question-answering

There are only a few there for TF.js.",1.0
g75kfle,j1sjpz,"Thanks! mobilebert seems to be only suitable and available for tf.js It's also much smaller (96MB) than a real bert. So sticking to js doesnt make sense?

Do you think if I setup my own tf-based system that I will achieve better results than with spaCy or CoreNLP?",1.0
g7100gm,j1rnaa,"this NN in particular has 4 layers, and yeah the one with 50 neurons is the input layer (notice the input_shape explicitly mentioned)",2.0
g711h6e,j1rnaa,"Thanks for your quick reply. Alright, so the input\_shape basically tells me which is the input layer in my NN?",1.0
g711wpp,j1rnaa,"input_shape basically defines the shape of the data you're gonna feed into the network. Hence, it's compulsory to define input_shape for the input layer. For the later layers, Keras will take care of the math.",1.0
g713vyf,j1rnaa,"As many NN, the first layer is the input layer which has input_shape. The second two layers are the hidden layers. The last layer will show output the result of the NN. That's all😊",1.0
g715cy7,j1rnaa,"So just for clarification, how many nodes would my input layer have, 50 or 6?",1.0
g71do1l,j1rnaa,50,1.0
g715qmx,j1rfmr,Is this some kind of virus scam?,2.0
g70t1gp,j1pkgv,"the step (that 1/1 on your case) depends on the num of data/batch size.

did you specifically add batch size param to your model? try to use some small number like 16, 32, 64 so you wont run out of memory and the step can be a bit higher than that",1.0
g6zgj8c,j1id4b,"I run Linux on a number of my machines that I use for ML and for other purposes. I also run Linux on my laptop as my day-to-day system. I have a desktop that runs Windows 10 for other specific needs that Linux can't satisfy. I've been using Linux as my daily driver on my laptop for about 5 years. 

I have a few thoughts in response to your question:

1. Linux doesn't try to auto-update itself the way that Windows 10 does. You **can** set it up so it does so, but by default it doesn't. This means that when I install software on one of my machines, that software will still be working in weeks or months. There's no risk of an auto-update running and breaking things when I'm not looking.
2. By default, you can easily run a Linux distro without a desktop environment (DE). This means that you don't have to install all of that additional software and it won't be running by default, thus freeing up some memory and CPU. 
3. SSH to Linux machines is a breeze to setup. So setting up additional machines or virtual instances (like through AWS) is quick, and then I can just log onto these machines remotely from my laptop whenever I want: to check in on on-going processes or update software, set up new jobs, maintenance, etc.
4. Installing and setting up development software on Linux is a breeze thanks to a healthy array of package managers. On Ubuntu or Debian-based systems, **apt** has most of what one will need to set a machine up. That coupled with **conda**, **pip**, and perhaps some additional software, it's fast to install new libraries and programs, and dependencies are handled automatically.

And finally, all of this means that working in this model fits into the way that I work. Obviously it might not fit into your workflow or process. But this approach lets me have my more powerful hardware setup in a static location. None of them require monitors or keyboards/mice. I can login to all of them remotely from my laptop. That also means I'm pretty comfortable carrying around a low-power, less expensive laptop, because I'm not relying on it to do very much heavy computing at all. It's essentially for email, writing, and as a terminal connection to the compute machines.",19.0
g6zjwsc,j1id4b,"Never had much problem with windows since I run most of my applications in virtual environments, but the thing you said about package managers really hit it home. It really is a pain to install packages for windows native.

Thanks for the input, will keep it in mind when switching from my little sandbox to a more professional dev environment",5.0
g70e30z,j1id4b,"There is your answer. Virtual environments and ML are not friends. Virtual environments cannot take advantage of GPU. And windows ML Visa TF dependencies take too long to manage and make. Not that it's always a 100% breeze in Linux , but the difference is trying to build a house with a spoon, vs a contractor. (Linux being the contractor)

Personally Iv still had  pains with Linux, when I first started ML I was using a 650mx you with a 2nd i7, I wasn't able to run shit in ml without spending hours getting the right packages, as of a few weeks ago, I not have a 2080 max q with latest i7, and I still have issues running shit lol, but now it's cuz I have to downgrade. 

Now I tried doing this in windows and just was not able to take advantage of the GPU in a timeframe that made sense, since each project required different versions, AND VIRTUAL DOES NOT USE GPU THAT PIECE OF SHIT I LOST 3 DAYS TRYING TO MAKE THAT HAPPEN AND IT WASNT WORTH IT.

I'm drinks btw.",8.0
g71jj2q,j1id4b,I love this comment. Don't worry buddy. I'm drinks too.,2.0
g71pxsm,j1id4b,"Not to make you wander down that rabbit hole again, but WSL version 2 let's you use your gpu in virtual environments.",1.0
g72axms,j1id4b,"Virtual machines can make use of GPUs. It is a process called virtual pass through. Linus Tech tips, a YouTube channel, does this every so often to build a single, over powered computer that has multiple virtual machines for people to play video games on. To use virtual pass through I believe you need to have 1 gpu for your real machine and 1 for your virtual machine. In the past they could not share. I think there has been an advancement that allows the two to share a single GPU but don't quote me on that.",1.0
g6zgy3t,j1id4b,"There's a lot of technical answers to this question (which others can address), but I'll give you a practical answer as to why *you* should use Linux.  Basically, since so many people use Linux for TensorFlow, it's easier for you to also use it.

It kind of starts at the top and trickles down.  Most remote servers use Linux (for a lot of reasons), so if you want to develop an application that is going to run on a remote server, you might as well develop it in the same environment.  Of course, this means that a lot of the development for TensorFlow as well as online resources and such are also going to be written with Linux in mind.  This means that a lot of the resources you want to be using are going to be expecting you to be using Linux.  If you don't use Linux, you're going to have a harder time finding such resources.

Now, there's of course plenty of other reasons why'd you'd want to use Linux for this stuff, and a lot of those reasons aren't specific to TensorFlow (my line of reasoning works with development in general).  


&gt;just wondering if there are any particularities or features of tf that I'd only get on linux, compared to windows

I'm sure there are many at this point.  TensorFlow on Windows should work just about the same as it does on Linux.  Of course, as I mentioned, a lot of the tooling or repos you may want to incorporate in your TF project may only be compatible with Linux, so the answer to your question is kind of fuzzy in that respect.

Hopefully someone can chime in with any technical limitations of TF on Windows, if any exist.",7.0
g6zjoxc,j1id4b,"I was posed to ask this question exactly because of the lack of resources! Had a problem with my installation and nobody was talking about windows pathing issues.

My project is still on it's experimental phase. We gotta prove the main concepts are feasible before moving on to the large scale app development, but when we do make the switch, I will be sure to keep your suggestions in mind!",1.0
g6zqsfc,j1id4b,"Not sure what the current situation is, but building and distributing custom TF kernels was pretty much impossible on Windows. For instance, https://github.com/lmnt-com/haste builds just fine on Linux and PyTorch+Windows but TF+Windows isn't going to happen.",3.0
g71jtm0,j1id4b,Coding on Linux is creamier.,3.0
g704nm7,j1id4b,"linux is, at least in my opinion, a better choice than windows. while compatibility is sometimes, but rarely, an issue, linux is almost objectively better.

- most windows applications can be run on linux with wine, and all with a virtual machine
- linux distros typically have better performance than windows
- ms office is being replaced by google's online solutions 
- linux is open source. that's the big one. that means it's more secure, open, and free
- something like 97% of servers run linux, it's a good skill to learn

the only reason i would ever use windows is for gaming, which is also usually possible with wine on linux.",2.0
g70suj0,j1id4b,"I own a mac mini, a dell desktop running ubuntu, and a razer gaming laptop running windows 10. I've tried to set up a similar dev environment on all three. Every computer has had something stupid go wrong with a different package at one point in time. No environment is going to be perfect. Find what you like the most and run with it. I'd argue that linux (distro agnostic) is the most convenient, but if you like windows stick with it. I personally found windows was easiest to set up gpu utilization for deep learning.",2.0
g71e00w,j1id4b,Because that's where everything is tested and verified. And paying for an extra license for your VMs just makes absolutely no sense whatsoever. The value-add ML tools for Docker are available exclusively for Linux.,2.0
g6zs5b7,j1id4b,"Not trying to steal the question, but Linux (unix) doesn't support the new CUDA drivers do they? So if I have a 1080 I'm not using the cores if I just Unix?",1.0
g7095vz,j1id4b,Linux supports Cuda 10.2 currently. Which fully enables hardware on all Nvidia RTX 20 series Gpus. It works. And works wonderfully once it's set up.,2.0
g71edwh,j1id4b,"To make long arguments short, yes, move to Linux. 😎 You will never regret it as long you do not expect to play AAA games on a linux box.",1.0
g6yxusb,j1fmox,"[Ubuntu](https://www.tensorflow.org/install/gpu), mostly because that's what most of the TF resources assume you'll be using.",0.0
g6yxvl4,j1fmox,"If by ""distro"" you mean Linux distro, I believe most of TF is developed with Ubuntu in mind.",0.0
g6zkfji,j1fmox,"Ubuntu, used internally by Google!",0.0
g6yqhzj,j1eqir,"What does the network actually have to solve for (i.e., what is the challenge or problem that you are employing a neural network in regards to)? What are the constraints of the environment? It's impossible to suggest any first steps without an idea of the environment, what parameters the car has to operate within, what is the variance within the environment? What's the goal here? Does the car just have to drive on a track and not fall of?",2.0
g6yqzws,j1eqir,"This is a simple track and all the car needs to do is take these inputs in and then make a decision based on these whether to go forwards, brake, left, right or not press anything. So this is a categorisation problem and that’s why I initially thought of using a deep neural network.",1.0
g6yzl5i,j1eqir,"The network architecture is less important than the actual algorithm you'd need to use.  For example, to train a simple neural network to perform this task as a categorization problem, you'd need *a lot* of pre-generated data that would basically be the ""answer"" to the queries you're feeding the network.  At that point, you might as well just use your data as a look-up table rather than train a neural network (since your model would essentially just be memorizing that table).

If this isn't what you want to do and you want your model to actually learn to navigate the environment on it's own, then you'd probably want to look into reinforcement learning (where your simple architecture may be sufficient).  In fact, the environment you described is so close to that of [CarRacing-v0](https://gym.openai.com/envs/CarRacing-v0/) that you might as well use that instead.",2.0
g72v646,j1aejp,"It appears that you need to split the data in your generator prior to handing it off to ```fit```. 

Once it's split, you can pass your validation data to ```fit``` using the ```validation_data=``` argument.",1.0
g72w4d5,j1aejp,Whack. Oh well not the end of the world,1.0
g72y2tt,j1aejp,How're you constructing your generator?,1.0
g73b74q,j1aejp,"It just goes through my images, loads batch_size into an array. Then goes through my masks and converts batch_size into a one hot array. Then yields those as a tuple (X,Y)

It works but I’m using google colaborqtory and drive and it’s a pain in the ass to move around a lot of files to create my validation folders for a validation generator.",1.0
g6y1tcy,j19qx8,"Pretty good, I’ll use it as my guide when I decide to deploy a model",2.0
g6ymm22,j19qx8,Thanks a lot❤️,1.0
g6yq8on,j19qx8,"Do you have a personal blog or do you only publish on medium? 

Kudos for your post :)",2.0
g6yqvn2,j19qx8,"Thanks a lot.
I don't have a personal blog. This is the 2nd blog I've ever written. Hoping to write more blogs on some lesser known concepts like Federated learning, Fairness in AI, JAX, Julia, etc as a part of my #100DaysOfMLCode. Your support will really be helpful.",1.0
g6xqfcq,j18f1v,It takes a while. I was added a month or so later. You'll be added soon don't worry about it.,2.0
g6xqyr1,j18f1v,"I passed mine on the 20th, and I’m also waiting to appear on the network",1.0
g6v7y80,j0ubhc,"first, one of the reason overfitting might happen is when you train your model for too long or using too many epoch..

and second, by retraining model do you mean just running the same cell or did you restart the environment (rerunning all the cell from top)? if you only rerun the cell where [model.fit](https://model.fit)() is called (and not where the model got initialized) then it's definitely the case of overfitting by too many epoch.

since, when the training stopped, as long the machine is still running, the model is still saved on the memory and the condition is still the same (the parameters, weight, biases, etc) as the time where you stopped the training. so when you call the fit again, then it starts to train from where you left it off.

TL:DR basically if the machine is still running and the model doesnt get overwritten, the epoch adds up",1.0
g6v9txb,j0ubhc,"Shit, okay well I ended up running it from the top because I needed to import the image files. But when I stopped training yesterday I essentially just stopped the keyboard and there was an error, as in i stopped the cell from continuing. And today I re-trained it starting from the top. Hence I can’t run it unless the model has been initialized. However I’m going to try a few different more architectures. I was training it for a 100 epochs so maybe that’s an issue.",1.0
g6va9dw,j0ubhc,"well if you're not dealing with complex dataset/architecture, 100 epochs might be more than enough, hence the overfit tho",1.0
g6vah9o,j0ubhc,"My training set has 2297 images
Validation has 573
Testing has 394

Maybe it has something to do with my split?",1.0
g6vakr4,j0ubhc,It’s just weird because it was training fine yesterday and today it’s just a drastic difference after rerunning all the cells,1.0
g6ussgr,j0s938,Ampere **should** work if you're using the docker images from ngc.nvidia.com.,7.0
g6ustr9,j0s938,"**I found links in your comment that were not hyperlinked:**

* [ngc.nvidia.com](https://ngc.nvidia.com)

*I did the honors for you.*

***

^[delete](https://www.reddit.com/message/compose?to=%2Fu%2FLinkifyBot&amp;subject=delete%20g6ussgr&amp;message=Click%20the%20send%20button%20to%20delete%20the%20false%20positive.) ^| ^[information](https://np.reddit.com/u/LinkifyBot/comments/gkkf7p) ^| ^&lt;3",3.0
g6utljq,j0s938,Thanks. I'm not sure what the means but I'll have a look.,1.0
g6varah,j0s938,"this may be due to cuDNN not supporting RTX 3000 yet as it seems, which you need to run tensorflow on gpu, but i don't now",5.0
g6wpd2k,j0s938,"It should be updated in due time. TF is built on several software abstractions. I don't know if CUDA has been updated to support the 3000 series (or how much it needs to be updated) but given significant hardware changes, I would expect that to take some time.

After that, the various software layers on top of that will need to be updated up until TF.  It will take some time.  Assuming that the 3000 series offers similar improvements for DL as it does for software graphics rendering, I expect people are hard at work putting the pieces together. If it doesn't offer similar improvements, it may be better to just stick with proven hardware.",3.0
g6utl9w,j0s938,It should work.,2.0
g6uu92l,j0s938,"On the DeepFaceLab GitHub, people are reporting that DFL is having errors with the RTX 3000 cards and they've narrowed it down to TensorFlow needing updating I don't know much about any of this so wanted to get some additional feedback.",2.0
g6v0ao9,j0s938,"Just wait for some time, until some people actually test it.",2.0
g6w67l1,j0s938,Never buy something at launch unless you can afford to be the beta tester.,2.0
g6xkjdk,j0s938,damn bro ....great ans in one sentence,1.0
g8a8bob,j0s938,Just got my 3080 a week ago and I've been having a lot of trouble getting anything to run properly on Windows 10. Code that worked perfectly fine with a 1660 started giving me weird NaNs and stuff like that. Upgrading CUDA and cuDNN + using tf-nightly didn't fix the issues,2.0
g8bi1dr,j0s938,Thanks for letting us know.,1.0
g6vhn1q,j0s938,Ffs you would think this is the second thing they check at nvidia before release. Nope.,3.0
g6vghii,j0qtlw,One my friend said he cleared the exam in June and I still can't see his profile listed,5.0
g6w3r5u,j0qtlw,"Damn, that is fucked up",2.0
g6xp3r4,j0qtlw,Same problem here. I passed the exam on september 12 but still can't find my name in the directory.,2.0
g6v8haz,j0qtlw,"Probably around the same time when they release a JVM package which actually targets the compute capability which they've documented on their website.

That is, whenever doing so would make a Googler somehow look more intelligent than their colleagues.",2.0
g6v8krx,j0qtlw,Sarcasm?,1.0
g6v8roy,j0qtlw,Experience as a consumer of Google's software.,4.0
g6rukyg,j0jn31,Sorry the title was meant to be Keras not eras,1.0
g6sa5zg,j0jn31,https://medium.com/@rexdivakar/tensorflow-deep-learning-setup-using-gpu-1e98eb7462a5?source=friends_link&amp;sk=77b14b4149043c5f2c464aa0b0f36c5f,1.0
g6smewd,j0jn31,"Uninstall everything. Then if you are using windows, follow [this](https://bleedai.com/installing-tensorflow-2-0-gpu-in-windows-setting-up-your-nvidia-gpu-for-opencv-dnn/) tutorial. If you are using Linux, follow [this](https://medium.com/hackernoon/deep-learning-software-setup-cuda-10-ubuntu-18-04-15548cefa30) tutorial.",1.0
g6oc65c,j03epy,It's a value judgement but 80/20 is the canonical case between training and test/validation sets even 90/10 on huge datasets,7.0
g6xgbqp,j03epy,Thanks,1.0
g6oe8q9,j03epy,"I usually use the ratio of 70:15:15 or 80:10:10 for my dataset, where it represents Training: Validation: Test set.",6.0
g6xgbzj,j03epy,Thanks,1.0
g6o3fc9,j03epy,"Typically I split train test abt 80/20, and from the 80 training data, I do similar 80/20 split for train val split. If data is limited, something like 60/40 should be fine at both stages as well.",5.0
g6xgbge,j03epy,Thank you for replying. Can I ask a question about  a TensorFlow project I'm working on if that's okay?,1.0
g6pqovr,j03epy,"I do 80:10:10.

For you that would mean:

1.   0.8 * 1200 = 960 for training
2. 0.1 * 1200 = 120 for validation
3. 0.1 * 1200 = 120 for testing",2.0
g6xgay1,j03epy,Thank you for replying. Can I ask a question about  a TensorFlow project I'm working on if that's okay?,1.0
g6odb2l,j03djb,"80/20 must be a good ratio. 
Scipy's train_test_split function can be used for the same.
Also tf.keras.preprocessing.image.ImageData.Generator  function can be used in tensorflow.",1.0
g6pkxxm,j03djb,"For a proper model you'll need a train, validation and test split. Ideally, 60/20/20 split would be made, but if your dataset is small 80/10/10 is not out of the question.",1.0
g6nlh1r,j01iwa,"[https://www.tensorflow.org/tutorials/keras/save\_and\_load#checkpoint\_callback\_options](https://www.tensorflow.org/tutorials/keras/save_and_load#checkpoint_callback_options)

take a look here. it's similar to loading other type of formats",1.0
g6oemmy,j01iwa,"I think it's as simple as:

    import tensorflow as tf
    tfmodel = tf.keras.models.load_model('path/to/directory')

The key is that you are loading a directory, not a file.",1.0
g6qjbph,j01iwa,"If there's a saved-model there with the checkpoints.

Normally you build the model, then restore a checkpoint into it.",1.0
g6ory0p,izln3c,[deleted],1.0
g6owgjb,izln3c,really? Perhaps I should re-flash Kali Linux on my phone,1.0
g6irtlz,izdw8j,"Are you using TF 2 or TF1?

In TF1 you should provide the generator to `fit_generator` directly. There should be no need to convert it to a tensor. If you want to experiment and get a feel for how it works, you should be able to pull images, labels from the generator using `next(img_gen_train)`.

In TF2 fit_generator is deprecated as the standard fit method will natively support generators.",2.0
g6ivssy,izdw8j,When I do this it just says another error,1.0
g6ixw5a,izdw8j,What is the error message?,1.0
g6jnc8m,izdw8j,“Failed to find data adapter than can handle input”,1.0
g6m7hnx,izdw8j,Have you already used the flow or some flow_x method?  If so do you get the same error using next?,1.0
g6nw7de,izdw8j,What is the `type(image_gen_train)`. Can you check?,1.0
g6o9u5j,izdw8j,"Figured it out, I was being dumb and was passing the image data generator rather than the dataset after augmenting the images",1.0
g6h1wf7,iz5ovz,"You will install it in a VM the same that you would on Ubuntu that was not running in a VM. The tensorflow documentation at [tensorflow.org](https://tensorflow.org) describes exactly how to do this: 

[https://www.tensorflow.org/install](https://www.tensorflow.org/install)",3.0
g6hjdqr,iz5ovz,"Thank you. I've followed the instructions step by step, however I get an error when I try to verify the install. Does it possibly have something to do with the `0:00:01Killed` after the progress indicator?

Edit: the VM was running out of memory. I upped the memory allocation and it appears to be installing now...we'll see.

&amp;#x200B;

`(venv) me@ubuntoVM:~$ pip install --upgrade tensorflow`

`Collecting tensorflow`

`Downloading tensorflow-2.3.1-cp38-cp38-manylinux2010_x86_64.whl (320.5 MB)`

`|████████████████████████████████| 320.5 MB 6.7 MB/s eta 0:00:01Killed`

`(venv) me@ubuntoVM:~$ python -c ""import tensorflow as tf;print(tf.reduce_sum(tf.random.normal([1000, 1000])))""`

`Traceback (most recent call last):`

`File ""&lt;string&gt;"", line 1, in &lt;module&gt;`

`ModuleNotFoundError: No module named 'tensorflow'`",1.0
g6hqhwi,iz5ovz,"gonna go ahead and say ""yep"" to the ```Killed``` question.

try ```pip list``` to print out installed libraries. I'm assuming tensorflow will not show up there.

what are the spec's on your VM?",2.0
g6ifot7,iz5ovz,Are u expecting a GPU pass through ?,2.0
g6iphl9,iz5ovz,"I had not thought about that. Should I pass it thru? I've passed a usb through for another project, I assume it would be similar (and would be better for running TF)?",1.0
g6iwe33,iz5ovz,If ur planning to use tensor flow I would recommend not to use virtual machine since u will be wasting a lot of resources on it than ur model. If u want Linux for working either dual boot or install wsl2 else I use miniconda and windows for easier use.,1.0
g6jvc85,iz5ovz,"I guess I could just install it on the windows 10 machine itself, right? It's on all the time running the VM (to run a Home Assistant server)",2.0
g6obipj,iz5ovz,If u have a dedicated server run it as a container else if ur on own machine better use anaconda,1.0
g6gzkpo,iz5ovz,"pip install tensorflow?

Please check out Tensorflow.org where all of this is described in great detail",1.0
g6e98y8,iyrmg7,"if you really want to understand what tensorflow is under the hood, then you need to understand some mathematics behind it and also a good proportion of software engineering, try to understand the syntax when doing projects or when you are faced with unfamiliar model, I'm no master of tensorflow myself, but with both (maths and SE) skills in your hand, then you can master it in no time.",9.0
g6e9na1,iyrmg7,Thanks for your immediate comment. It is the syntax that confuses me usually. Sometimes I find no mention of reason for why a line is written or the arguments used and such. It would be of great help if you tell the medium you used to learn TensorFlow. I am strong at DL theories (and the math that come with it). It is the lines of codes that throws me off,2.0
g6eajvz,iyrmg7,"I'm an IT student myself so I used to have a lot of software engineering projects, so the SE thinking translates easily. My suggestion is to just try to keep doing projects, and deepen your knowledge with the language (python in this case), and learn to read the official documentations, it's pretty good at explaining the syntaxes",3.0
g6eb2h1,iyrmg7,Thanks. Hopefully I'll get good at it,2.0
g6f3n75,iyrmg7,"If you've got a strong math background, I would try to program as much as you can, focusing on building generic applications not related to ML to get your development skills up.",2.0
g6f4xdp,iyrmg7,"Thanks for the advice. Will do it. After all, it's my coding skills I need to hone. I am a Mechanical engineering student. So, all I know in coding is to use functions and data structures. It's the OOPs that gives me a hard time. Hopefully, a lot of coding will make me better.",1.0
g6f5bti,iyrmg7,"I've been a professional developer for over a decade. I can help you if you would like. I'm very sure that your math are stronger than mine. I'm happy to answer questions and do code reviews for you, especially if you can answer math questions I have. 

Feel free to send me a DM. I'm still home close to 24/7 for the foreseeable future due to the pandemic.",2.0
g6f5i8m,iyrmg7,Wow. Words can't explain how generous that is from you. Thanks a lot. I am sure I'll learn a LOT from your experience.,2.0
g6f3hwd,iyrmg7,"This is the right answer. And you don't have to become a talented mathematician by any means to get it. The programming aspect is much more important for me at least. For the math, I quickly went through a statistics course and a linear algebra course on Khan Academy, then set TF to eager mode, turned on the Python debugger, and took a couple hours to step through it piece by piece. It becomes a whole lot less mysterious after doing this. You see where the numbers come from, you see what matrix operations are being done, and it all kind of seems obvious at that point. 

Also, coding gradient descent by hand after having an understanding of the math was a crucial step for me:

https://towardsdatascience.com/gradient-descent-in-python-a0d07285742f

And don't get me wrong, I'm not a mathematician. I more or less skimmed the math courses. You're working with computers, you don't need to be able to solve these things by hand, which I probably couldn't. Just having an understanding of the why involved is enough to get started. I got down into the guts of a dense layer, knew enough to know why they were taking a dot product, knew enough to know why relu was doing what it was doing, and I was good.",1.0
g6edm7x,iyrmg7,[https://github.com/ahmadmustafaanis/Getting-Started-with-Tensorflow-2](https://github.com/ahmadmustafaanis/Getting-Started-with-Tensorflow-2),3.0
g6edyie,iyrmg7,[https://github.com/ahmadmustafaanis/Machine-Learning-Path](https://github.com/ahmadmustafaanis/Machine-Learning-Path),4.0
g6d9e61,iylh1m,"Nothing wrong with this technique; it's called gradient accumulation if you're interested in reading about others who use that technique.

There are 2 potential downsides. First is that you'll need to keep the gradients in memory during forward passes as well which might further reduce the maximum batch size you can use per iteration. Second is that the computation isn't _exactly_ the same as what you'd get if you had a larger batch size in the first place due to floating point semantics (`x = a; x += 0.1` is not necessarily the same as `x = 0.1; x += a`).",4.0
g6db0ap,iylh1m,"Thanks, that makes sense. Would it be better if I reduced the smaller batch size and changed the weights to float64?",1.0
g6e9uen,iylh1m,"In practice it's unlikely you'll run into floating point precision issues when doing gradient accumulation. Unless you have a very very good reason, I'd stick with float32 over float64 and, if possible, I'd go to float16 and increase the batch size even further.

Outside of scientific computing, I don't see a need to use float64 in ML-land.",1.0
g6czurs,iyfhq8,= 1.0,1.0
g6cadav,iy9sol,"TF2 because that's the way. TF1 is over so no point in beating the dead horse. Refactored my entire codebase and I'm on 2.2 now. It's working, it's clean and easy to debug",6.0
g6crf2q,iy9sol,[deleted],-1.0
g6db3lh,iy9sol,"Because I simply don’t want to? More technically, I have about 9 models running in production very smoothly on GPU/CPU instances with tf-serving. Now why on earth I would switch to PyTorch just for lullz?",4.0
g6dbg1b,iy9sol,[deleted],-1.0
g6dcnzp,iy9sol,Hahaha.. So? I don’t think Google will switch to PyTorch and that’s enough for me. 🍻,3.0
g6cr4ga,iy9sol,"There are 2 major reasons to stick with TF 1.x over 2.x for us.

1) each new version of TF brings new bugs and regressions in core functionality; upgrading is like walking through a minefield of features where something that used to work is now unusably broken
2) performance; eager execution is slow

So, our legacy code is on TF 1.14 and new code is on PyTorch. Couldn't be happier now that we've switched.",1.0
g6dbfce,iy9sol,"No sir, this is factually wrong. Your code is buggy because you didn’t transform it properly. I would suggest going through documentation with ample time first. 
1. Each new version reduce bugs and adds LOT new functionalities.
2. Performance depends on how you refactor your existing codebase. If I’m paid enough, I would be happy to make it run as or more smoothly compared to graph based tf1.x",0.0
g6b7q22,iy7mpo,"Oh boy, you need to package this up so it's real easy to use. I could imagine that this could become a thing on yt",2.0
g6bn72h,iy6drm,"Cool! How'd you do it?

Now just generate a bunch of guillotines eh?",5.0
g6bqvow,iy6drm,"I've done this with StyleGAN2.  
For this I've researched an image for each of them, let a python code align it to perfectly center the face.  
After that I let StyleGAN2 project each image, which basically means optimize the input vector in order to get close to a desired target image.  
Then I could interpolate between the different input vectors I found &amp; generate images inbetween, which resulted in this video.

If you're interested in trying this yourself you should clone this github:  

[https://github.com/justinpinkney/stylegan2](https://github.com/justinpinkney/stylegan2) . align\_images.py does the centering for you, project\_images.py will find the best input vectors it can find.",2.0
g6bph8h,iy6drm,"Very smooth transitions, looks great",2.0
g6bq8x7,iy6drm,thanks :-),1.0
g6bpos8,iy6drm,[deleted],2.0
g6bq87a,iy6drm,how so?,4.0
g6cr7ik,iy6drm,[deleted],1.0
g6em0hf,iy6drm,"could you maybe direct me to the clickbait you're talking about? If I check my channel I subjectively find 2 cases, this and the other video you already ranted about in the post comments are none of them.  


don't mistake this as me being unable to take criticism but maybe you could formulate the logical conclusions that lead to your opinion if you want anything to change ( what I assume you do because you invested the time to comment, respond, check my profile to search for another post and also commented there)",0.0
g6gpup2,iy6drm,lmk if there's a response to come,0.0
g69tgr7,iy0312,Wdym performs better? GANs are very sensitive to tiny hyperparameter changes which could be the reason why the two frameworks give different results.,4.0
g69tm4m,iy0312,"But I was looking at some repos to get an idea and they said, if using in production then use the putorch implementation",1.0
g6bga4e,iy0312,"So there are some random parameters that change across the 2 frameworks 
This could be stuff like weight initialisation.
So there is a way where you extract the random seed of an environment and then you can use that seed to make reproducible results.
You might want to look into the seed used by pytorch it'll give you a nice idea of what's happening",3.0
g6bgdgq,iy0312,Use the seed in tensorflow?,1.0
g6bhbo4,iy0312,"So I'm not sure about this but it's worth a shot.

Randomness in tensorflow and pytorch come from numpy I guess. I'm not very sure.

So if you seed numpy you may end up getting what you want.

Hope it works❤️",1.0
g6bhnzw,iy0312,"I feel like somebody would have done it by now, will try though!",2.0
g6ainrn,iy0312,https://youtu.be/XHyASP49ses,0.0
g6bhfqy,iy0312,"I feel like there was a lot of bias in that video, hate towards python too.",1.0
g6ap16x,iy0312,"No, Tensorsflow performs better with same hyperparameters and GPUs etc.",0.0
g6b6jv9,iy0312,But say specifically for things like CycleGAN it preforms better,1.0
g6894y9,ixpdcf,"Ur question looks ambiguous, but if ur looking to load a model then tensor flow provides ,

from tensorflow.keras.models import load_model

Model=load_model('ur model name')

To check ur model summary

Model.summary()",1.0
g68cuqx,ixpdcf,[deleted],1.0
g69muza,ixpdcf,The code which u shared abouve will extract the model and run but for ur needs I should check ur code and ur requirement before I can suggest it to u,1.0
g68mv8v,ixifkq,"Same issue tho, I still have no idea on how to solve it right now. There are several issues on tensorflow github but no one helps for me. You may check it out tho.",2.0
g6eoclh,ixifkq,Are you also facing similar issue,1.0
g6fi3sw,ixifkq,"I solved yesterday, literally struggle for 2 weeks.",2.0
g6xxale,ixifkq,"Thanks a lot `patricktu1258` I followed the approach mentioned in the link and it worked, I have also used `tensorflow-gpu==2.0.0` and `keras==2.2.4`",1.0
g6xxoao,ixifkq,[https://giphy.com/gifs/thanks-thank-you-kazoo-kid-l3q2wJsC23ikJg9xe](https://giphy.com/gifs/thanks-thank-you-kazoo-kid-l3q2wJsC23ikJg9xe),1.0
g6fjou9,ixifkq,"My suggestion is: check tf.executing_eagerly and model.run_eagerly. If both true, try this. https://keras.io/getting_started/faq/#how-can-i-obtain-the-output-of-an-intermediate-layer-feature-extraction",2.0
g6735ke,ixifkq,I think [this](https://stackoverflow.com/questions/34097281/how-can-i-convert-a-tensor-into-a-numpy-array-in-tensorflow) may help you,1.0
g67ccql,ixifkq,I have gone through this post but nothing worked,1.0
g67ctp2,ixifkq,What have you tried?,1.0
g6aa08c,ixifkq,yes all of it,1.0
g675jzm,ixifkq,"Try to get the session from keras:

from keras import backend as K 
sess = K.get_session()

Then try option 2 with this session:

result.eval(session=sess)

This might do the trick, but its a long time since i worked with tf 1.",1.0
g671ldm,ixifkq,Not a 100% sure if this works but did you try np.array(result) ?,0.0
g67ca45,ixifkq,"&gt;np.array(result)

I tried but it throws this error `NotImplementedError: Cannot convert a symbolic Tensor (avg_pool/Mean:0) to a numpy array.`",1.0
g6776uw,ixgm51,Very cool. So far I'm using pushover to do that,1.0
g67feeq,ixgm51,Hey thanks. First time I heard of it. Will consider integrating to pushover for notifications.,1.0
g67gacd,ixgm51,"I basically use it for everything: to get me informed when the model is training, to get scores, to get information about possible errors...",1.0
g67goox,ixgm51,It didn’t seem free. That would be a concern for us,1.0
g67gru7,ixgm51,"True, they're not free.",1.0
g662xrg,ixccfh,"Start with MNIST classification, goto Cats and Dogs, then see how you can improve these 2 models in TensorFlow, then go for Housing Prices Prediction, then Sentiment Analysis.",8.0
g6667i6,ixccfh,"Thank you! Also, do you know if my 2020 MacBook Pro can run the trainings for these datasets? I’ve read online that I’ll need a windows/Linux machine with a dedicated GPU, is this true? I know I can also use cloud computing, but I wanted to know if I can get away with using my Mac.",1.0
g66b6z2,ixccfh,Use Google Collab so you can train with GPUs  in reasonable times. Your Mac can only train on the CPU which is much less efficient so you’ll only be able to train small models and it’ll take a long time,1.0
g66eygi,ixccfh,[deleted],3.0
g66g00x,ixccfh,Doesn’t matter for learning the basics...,2.0
g66v22t,ixccfh,"All of these models will run on your machine. Yes having a GPU has a great impact on training time, but I don't think these models will take much time to train. But when you are going for bigger datasets, yes, it might be useful to have a MAC.

And honestly, in 2020, it doesn't matter if you use MAC or Windows or Ubuntu. Just having an NVIDIA card(AMD does not work) is sufficient. I have seen a lot of professors doing big tasks on MAC. 

Google Colab, is a good free option for GPU, Deep note is a good option for free cpu etc.",1.0
g66j7v9,ixccfh,"Google Andrew NG, open his Stanford basic course, finish it first, open his deep learning courses on coursera, finish them. Then start doing TF exercises",3.0
g66r1y5,ixccfh,"Thanks for the advice. I found a tutorial from tensorflow using karas to build a model for clothing. It’s making some sense. After I finish this I’ll probably check out some of those vids to further solidify my understanding, and then hopefully apply it to my own projects.",0.0
g67rjya,ixccfh,"an excellent endeavor.

the most basic beginner project i can think of is your homework.

you now have something to discuss with your educators.",2.0
g68yx3o,ixccfh,"I’m currently taking assembly language, discrete math, physics, and bio. And my assembly language and discrete math professors are incapable of teaching their subjects, let alone any machine learning. I wish I could ask them",1.0
g6gg1zm,ixccfh,"then i suggest you go back and ask for your money back.

then go find someone who can teach you the elementary assembly language, discrete math.

it is called the golden rule.

he who has the money.

makes the rules",1.0
g662pp1,ixccfh,"SAME
I have been going through deep learning with python bcs the pdf is online for free. Ppl normally recommend hands on machine learning with scikit learn and tensorflow. I couldnt not find a free pdf for it tho.",1.0
g6dm5cc,ixccfh,"You can get it here 

https://www.pdfdrive.com/handson-machine-learning-with-scikitlearn-and-tensorflow-2e-e189685098.html",1.0
g634e7v,iwxmyz,yes,4.0
g638l4e,iwxmyz,yessss,2.0
g64h8lo,iwxmyz,Better performance than Google colab !,2.0
g638so6,iwxmyz,Why not?,1.0
g63jh7k,iwxmyz,It should work,1.0
g63kl3c,iwxmyz,Buddy if ur GPU has cuda cores then that's all is needed for deeplearning stuffs. Clock speed and ram size varies the performance of the card,1.0
g64jf8l,iwxmyz,yes * 1660,1.0
g65o23d,iwxmyz,Yes roughly the speed of the 1070,1.0
g62munf,iwscxi,RemindMe! 2 days,1.0
g66j9o7,iwscxi,"There is a 21 hour delay fetching comments.

I will be messaging you in 2 days on [**2020-09-23 05:56:06 UTC**](http://www.wolframalpha.com/input/?i=2020-09-23%2005:56:06%20UTC%20To%20Local%20Time) to remind you of [**this link**](https://np.reddit.com/r/tensorflow/comments/iwscxi/how_to_best_use_tfgathergather_nd_to_collect/g62munf/?context=3)

[**CLICK THIS LINK**](https://np.reddit.com/message/compose/?to=RemindMeBot&amp;subject=Reminder&amp;message=%5Bhttps%3A%2F%2Fwww.reddit.com%2Fr%2Ftensorflow%2Fcomments%2Fiwscxi%2Fhow_to_best_use_tfgathergather_nd_to_collect%2Fg62munf%2F%5D%0A%0ARemindMe%21%202020-09-23%2005%3A56%3A06%20UTC) to send a PM to also be reminded and to reduce spam.

^(Parent commenter can ) [^(delete this message to hide from others.)](https://np.reddit.com/message/compose/?to=RemindMeBot&amp;subject=Delete%20Comment&amp;message=Delete%21%20iwscxi)

*****

|[^(Info)](https://np.reddit.com/r/RemindMeBot/comments/e1bko7/remindmebot_info_v21/)|[^(Custom)](https://np.reddit.com/message/compose/?to=RemindMeBot&amp;subject=Reminder&amp;message=%5BLink%20or%20message%20inside%20square%20brackets%5D%0A%0ARemindMe%21%20Time%20period%20here)|[^(Your Reminders)](https://np.reddit.com/message/compose/?to=RemindMeBot&amp;subject=List%20Of%20Reminders&amp;message=MyReminders%21)|[^(Feedback)](https://np.reddit.com/message/compose/?to=Watchful1&amp;subject=RemindMeBot%20Feedback)|
|-|-|-|-|",1.0
g63cxai,iwscxi,"Finally got it! For anyone else wondering, in this case you’d use gather() with the batch_dims equal to the axis, in my case, 2",1.0
g64hl4m,iwr39o,I wanna know that too !,1.0
g65i8ib,iwr39o,"I think i found it. The list starts on `line 4336` in the `tensorflow/models/blob/master/research/object_detection/core/preprocessor.py` file of the github repo.

Doesnt look like there are any affine transformations which is a bit of a let down.",2.0
g65jgko,iwr39o,Yo thanks mate. !,1.0
g61kf7p,iweqv0,May be try this model.layers[index that u want].output,2.0
g62uwec,iweqv0,Do I need to run `model.predict(data)` before running `model.layers[index].output`,1.0
g62wtkd,iweqv0,Yep,2.0
g632k99,iweqv0,"Thanks for the help, one small thing why output of `model.predict(data)` is `&lt;class 'numpy.ndarray'&gt;` and output of `model.layers[index].output` is `&lt;class 'tensorflow.python.framework.ops.Tensor'&gt;` how can we convert this tensor to numpy array",1.0
g5zqei7,iwekoy,Pretty spooky how the phasing stimulates your emotions.,1.0
g5zx5zd,iwekoy,positive or negative stimulation?,1.0
g5zyiuh,iwekoy,"I have feelings about each president, but, in retrospect, could not have predicted the feelings provoked while viewing the image as it slowly transformed.",1.0
g5yubeb,iw9wjy,"I think in Keras, you have to convert it to a tensor before passing. Try converting it to a tensorflow tensor, using tf.constant or tf.covert\_to\_tensor(tf.Variable), and then pass that object.",2.0
g5z2hbw,iw9wjy,thats throws the error  `ValueError: Failed to convert a NumPy array to a Tensor (Unsupported object type numpy.ndarray)`  So i looked for possible solutions and one was to convert it into float format so I first converted each nested array to float but still the error persists and if i try to convert the entire array to float using   `input = input.astype(np.float32)` i get  `ValueError: setting an array element with a sequence.`,1.0
g5z3n5a,iw9wjy,In case you haven't checked this: [https://stackoverflow.com/questions/63219795/valueerror-failed-to-convert-a-numpy-array-to-a-tensor-unsupported-object-type?noredirect=1&amp;lq=1](https://stackoverflow.com/questions/63219795/valueerror-failed-to-convert-a-numpy-array-to-a-tensor-unsupported-object-type?noredirect=1&amp;lq=1),1.0
g5za9vg,iw9wjy,I just check this. The only difference is that he/she is using images as input so the arrays are of fixed length but in my case i going to try to pad but it just dosent seem to be possible because some features are just too long.,1.0
g5zapv1,iw9wjy,Use a [RaggedTensor](https://www.tensorflow.org/guide/ragged_tensor),1.0
g5zln89,iw9wjy,"That would be my initial thought, too.",1.0
g5ztfs8,iw9wjy,"Edit: Thanks!, ive gotten it to work now",1.0
g6b2039,iw9wjy,Are there any specific models that I should try? I am currently trying a single LSTM  and double LSTM model and getting a 75-80% score considering I have only 550 samples.,1.0
g5vfnwv,ivxzpy,"Are you trying to achieve multilabel classification? If so, instead of lists containing the classes, you should use a sparse matrix for the outputs. Ex: Instead of \[1,3\] use \[0,1,0,1,0\]. Another solution might be to change the loss to 'categorical\_crossentropy', 'sparse\_categorical\_crossentopy' expects a sparse matrix (like I just showed).",2.0
g5vfw8o,ivxzpy,"Also, don't use lists for your data as a rule of thumb. TF places much nicer with np arrays.",1.0
g5y3qy1,ivxzpy,"Ohhh okay that makes sense, I'll try the sparse matrix out, thank you! Btw changing the loss to categorical_crossentropy didn't work either and i am of course convert the lists to numpy arrays, they are lists just because of how I generate my training data.",1.0
g60i52v,ivxzpy,"Ok, good to know. I wasn't sure if the loss change would work. I was skeptical of passing lists as labels since they are different dims. Typically you can use scalars for single-label (multiclass) classification problems and keras will handle it.",1.0
g60iawk,ivxzpy,"ALSO: Do not use tf.nn.softmax activation for the output. That means all outputs probabilities sum to 1. That is good for single label classification, but it seems you are trying to get multilabel. I think sigmoid would be better.",1.0
g60im4z,ivxzpy,"Thanks for your help, I will try that out as well!",1.0
g5y90cg,ivxzpy,"Make sure your input data is shaped like a proper multi-dimensional array. 

[https://stackoverflow.com/questions/4674473/valueerror-setting-an-array-element-with-a-sequence](https://stackoverflow.com/questions/4674473/valueerror-setting-an-array-element-with-a-sequence)

&amp;#x200B;

It may also help to build up your model layer by layer to investigate where the error occurs.",1.0
g5tzo5o,ivve4y,"this is some interesting dataset, one that pop up to my head immediately is to predict discount effectiveness depending on the sales date, price, type of product, etc.",2.0
g5txsi4,ivve4y,"I dont know what you are selling, but combine date number of sales with weather data you could maybe predict for upcoming weeks with forecast. Maybe the shop could put the product you forecast high demands at the entrance? A little like you see shovel at the entrance of walmart after first snow ?",3.0
g5ukhhr,ivve4y,You can do your own homework instead of asking Reddit to do it for you.,4.0
g5uq473,ivve4y,Agree. You'd need to provide WAY more information about what you're trying to do than this output.,1.0
g5uil16,ivve4y,Net revenue per category by X period. Or net revenue per product by X period. Then identify strategy for that period,1.0
g5u0qz2,ivve4y,"All the clasic once you have time, user, types looks like a standard dataset 
Cut and paste google  have fun",0.0
g5tgx86,ivln9o,"I might be wrong but this is not really a DL problem. There is a basic amount of non linearity that is supposed to be there in the problem your trying to solve with DL. The dataset looks like a typical Random Forest problem. I would say your network will just overfit easily or gradients will vanish. 
Please ensure that the problem you are trying to solve has a certain amount of non linear parameters to be learnt before applying DL on it.",2.0
g5tkt7x,ivln9o,"You know, I thought so, I even asked last time if I could use a structured numerical dataset like this and people were telling me why not? I knew there would be some issues with that.",2.0
g5ttilr,ivln9o,"Yeah exactly see we need to proceed to DL only after the statistical algorithms in ML aren't able to produce good results. Yes I agree DL has been able to solve really crazy problems but that exactly is the catch here DL performs well only when there are a lot of things to learn. 
PS you can do stuff like linear regressions, logistic regression etc even with tensorflow so if your not a big fan of sklearn then no issues you can stick with tensorflow itself even though I would strongly recommend sklearn. 
Good luck❤️",1.0
g5tu3cg,ivln9o,"Thanks, yeah I actually was doing a lot of sklearn before and wanted to hop into tensorflow, but thought I could start our basic and do a tensorflow project with neural networks on a dataset like this. The thing is I may have to either try what the other commenter said or just go ahead and complete the project with sklearn. But now I know that tensorflow is usually used for Dataets which have lots of relationships between variables and thus performs better on those. Thanks",2.0
g5s78px,ivln9o,The data set is all binary 0s and 1s except for the severity column which is the feature im prediction and has 0-4 as its predictors. Ages are as follows but in ranges. Each range ie. 26-50 maps to a label. Please point out issues with model or dataset as to why this may be happening,1.0
g5tdtq6,ivln9o,"First, you don't have ""no"" loss, you have ""nan"" loss, which means your blowing up your network, so there's no surprise it's not learning anything.

Lower your learning rate a lot. Shrink your network, you have a lot of layers with a lot of features each for data that looks relatively straight ahead.",3.0
g5tkvol,ivln9o,Can I even apply deep learning to this?,1.0
g5tndef,ivln9o,"You may not need to. And like the other commenter points out, this problem may be just as well solved through other approaches. Don't go deep. Stay shallow if you want to try to do this with tensorflow. One layer so it's only learning a linear function.",2.0
g5tp55r,ivln9o,"One layer for input, one layer for soft max output?",1.0
g5tq5vg,ivln9o,"```python
model = tf.keras.Sequential([
    tf.keras.layers.Dense(4, activation='softmax', input_shape=[len(train_dataset.keys())])
])
```

Which for that case, you don't even need the Sequential anymore.",1.0
g5tqp9e,ivln9o,Thanks I’ll try thus,1.0
g5svn6z,ivklwl,sweet. love seeing 8k content on my 720p display which is downgraded to 420p due to youtube app.,3.0
g5szsig,ivklwl,i like your humor,3.0
g60lo1c,ivklwl,thanks lets be friends,1.0
g5re0xw,ivez7l,"Usually deep learning frameworks only support Nvidia, because of their Cuda api. But recently there were some efforts by tensorflow to support opencl..",1.0
g5sn1lx,ivez7l,"I know, but I also know that ROCm is an open source alternative in order to use Tensorflow with AMD cards. I just did find anything explaining how to install it with navi cards.",1.0
g5qc6jv,ivanii,"You ask about the method to upload trained models, but really you need to figure out where to upload models.  GDrive is not a good solution (except for very casual/one-off cases).  It's just not machine friendly enough.

Normally, you'd upload models to a cloud provider's storage solution, like AWS' S3.  If you just need to upload a one-off or experimental model, you can use the CLI (something like `aws s3 cp local_model.zip s3://.../remote_file.zip`).  Ideally, though, the uploading of the model would be part of an automated process, where you can use something like boto3 in Python to do it.

Of course, S3 isn't free, so you'd have to deal with costs.  Assuming you weren't going crazy with uploads, it's affordable enough that you may be able to use the free-tier without paying anything.  Other cloud services have similar promotions, I believe.  Something like git-lfs would make sense if your model is coupled with your code (i.e., some example that you want to make easy to setup), but by using a cloud provider, you can utilize the models in a very flexible way.  Whether that's just sending a link to someone or hosting it somewhere or fetching models from it for a larger pipeline or whatever, it's basically the standard way of doing it.",1.0
g5qoab9,ivanii,"Thanks for such a detailed answer. Yeah, looks like a cloud service is probably my best bet. I'll try and explore the various free-tiers. Thanks again! :D",2.0
g5rgvbl,ivanii,what do you mean by gdrive is not machine friendly?,1.0
g5pivgn,iv2wrr,how is this related to tensorflow,0.0
g5q8fat,iv2wrr,"Tensorflow doesn’t stand apart from the data you are training on or transfer learning with


If you are doing anything serious with tensorflow you are going to have to deal with data preparation and annotation, etc. 

The more you know about all the tools you can find and learn for data preparation, the smoother your tensorflow journey and the results quality will become.",2.0
g5rbdqb,iv2wrr,thats machine learning specific not tensorflow specific. that's like posting a bunch of pictures of dirt you like in r/apples,-2.0
g5nlrkw,iuvxyx,"Have you tried installing tensorflow-gpu using conda? I can see you are using python.

https://anaconda.org/anaconda/tensorflow-gpu

I'm pretty sure that fixed my install earlier this year.

If you haven't used conda before, you will need to install it. Have a read about conda, anaconda, miniconda, and using conda virtual environments.

Great work getting into machine learning at 14!",3.0
g5nxc4g,iuvxyx,"Apologies for so many replies, but it actually works - THANK YOU! I think the issue was with the CUDA and CUDNN version, as Tensorflow support doesn't seem to be great. Also, I used to despise Anaconda for no reason in the past, but you've made me an instant fan, because of how it takes care of all of the installs. I don't say this often on the internet, but I really appreciate the help!",2.0
g5ry9lp,iuvxyx,"Glad you fixed it, and learnt not to dislike stuff for no reason.",1.0
g5o7wdz,iuvxyx,"I've made an edit with an update with how I fixed the issue, and got everything to work (without Anaconda).",2.0
g5nm7xc,iuvxyx,Doesn't Tensorflow 2.3 support GPU...I don't think I should have to install tensorflow-gpu separately. Please correct me if I'm wrong.,1.0
g5ry458,iuvxyx,"I know you already fixed it, just commenting here for posterity - I believe the conda install for tensorflow-gpu will also include several dependencies that aren't included in pip install.",1.0
g5nmc7y,iuvxyx,"Also, is there a reason that conda would work instead of pip?",1.0
g5rx96n,iuvxyx,"Have a read of pip vs anaconda: https://stackoverflow.com/q/20994716/10615407

Long story short, pip installs python packages. Conda installs python and other dependencies.

Conda is great!",1.0
g5nwafm,iuvxyx,Unfortunately the conda version still doesn't recognize the GPU.,1.0
g5nlcwo,iuvxyx,"U have not installed the matching cuda and driver version, please follow the below url and upgrade the appropriate drivers for it to get working.



“TensorFlow Deep learning Setup using GPU” by rexdivakar https://link.medium.com/TFceZAZgR9",1.0
g5nm4hw,iuvxyx,"I checked the chart in the article, and I do have the proper driver for CUDA 11.",1.0
g5nmcp2,iuvxyx,"Run this and let me know ur output

which nvcc",1.0
g5nmla3,iuvxyx,/usr/local/cuda-11.0/bin/nvcc,1.0
g5nn01t,iuvxyx,"    sudo dpkg -i cuda-repo-ubuntu1804_10.0.130-1_amd64.deb sudo apt-key adv --fetch-keys https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64/7fa2af80.pub sudo apt-get update sudo apt-get install cuda-10-0

 

    conda install cudatoolkit=10.0.130",1.0
g5nn4td,iuvxyx,"So that would install cuda 10, right? Sorry to be finicky, but does that mean that CUDA 11 doesn't work with tensorflow?",1.0
g5no6f2,iuvxyx,"well it should but sometimes i get the same error so i rolled back to CUDA 10 and never got an issue later, if u want may be u can give it a try !",1.0
g5nof5o,iuvxyx,Oh ok thanks! Is there any need to somehow uninstall the current version (11)?,1.0
g5nqg2b,iuvxyx,No its not needed u install the cuda 10 and it will add up,1.0
g5nrf9v,iuvxyx,"Ok thanks, I will try it! Can you please post another comment, with all of the lines separated. I'm not being able to properly run:  `sudo dpkg -i cuda-repo-ubuntu1804_10.0.130-1_amd64.deb sudo apt-key adv --fetch-keys` [`https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64/7fa2af80.pub`](https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64/7fa2af80.pub) `sudo apt-get update sudo apt-get install cuda-10-0`",1.0
g5nszbn,iupf66,RemindMe! 2 Days,2.0
g5r8bm3,iupf66,"There is a 21 hour delay fetching comments.

I will be messaging you in 2 days on [**2020-09-20 02:07:53 UTC**](http://www.wolframalpha.com/input/?i=2020-09-20%2002:07:53%20UTC%20To%20Local%20Time) to remind you of [**this link**](https://np.reddit.com/r/tensorflow/comments/iupf66/for_gan_training_is_it_important_that_the/g5nszbn/?context=3)

[**CLICK THIS LINK**](https://np.reddit.com/message/compose/?to=RemindMeBot&amp;subject=Reminder&amp;message=%5Bhttps%3A%2F%2Fwww.reddit.com%2Fr%2Ftensorflow%2Fcomments%2Fiupf66%2Ffor_gan_training_is_it_important_that_the%2Fg5nszbn%2F%5D%0A%0ARemindMe%21%202020-09-20%2002%3A07%3A53%20UTC) to send a PM to also be reminded and to reduce spam.

^(Parent commenter can ) [^(delete this message to hide from others.)](https://np.reddit.com/message/compose/?to=RemindMeBot&amp;subject=Delete%20Comment&amp;message=Delete%21%20iupf66)

*****

|[^(Info)](https://np.reddit.com/r/RemindMeBot/comments/e1bko7/remindmebot_info_v21/)|[^(Custom)](https://np.reddit.com/message/compose/?to=RemindMeBot&amp;subject=Reminder&amp;message=%5BLink%20or%20message%20inside%20square%20brackets%5D%0A%0ARemindMe%21%20Time%20period%20here)|[^(Your Reminders)](https://np.reddit.com/message/compose/?to=RemindMeBot&amp;subject=List%20Of%20Reminders&amp;message=MyReminders%21)|[^(Feedback)](https://np.reddit.com/message/compose/?to=Watchful1&amp;subject=RemindMeBot%20Feedback)|
|-|-|-|-|",1.0
g5o9byp,iulacf,I've seen a couple of your vids after seeing your first vid on mel spectorgrams recently.  Thanks : ),1.0
g5ogk48,iulacf,Thank you for watching!,2.0
g5jdmu7,iu9fc7,"Maybe it is a virtual env error, or some messed up version error, just uninstall all the TensorFlow versions, and simple type 

    $ pip3 install tensorflow

This will automatically install the latest TensorFlow with all the GPU drivers. No need to mention GPU seperately.",2.0
g5jzrpo,iu9fc7,"I made sure to uninstall tensorflow completely with

    pip uninstall tensorflow
    pip3 uninstall tensorflow
    python -m pip uninstall tensorflow
    python -m pip3 uninstall tensorflow

it seemed it was completely removed as 

    pip show tensorflow
    pip3 show tensorflow

showed no tensorflow

however, when I then do `pip install tensorflow` or `pip3 install tensorflow` and then

    pip show tensorflow
    pip3 show tensorflow

It shows tensorflow as version 2.3

but when I enter `python` , which is version 3.5, and then import tensorflow, it says `importerror no module named tensorflow`, yet if I do `python3` which is version 3.8, then I'm able to import tensorflow

I want to use version 3.5 for python and tensorflow. How can I do this?",1.0
g5jqeea,iu9fc7,"Try: `python3 -m pip install tensorflow`
This has been the most consistent for me.",1.0
g5jzrc4,iu9fc7,"I made sure to uninstall tensorflow completely with

    pip uninstall tensorflow
    pip3 uninstall tensorflow
    python -m pip uninstall tensorflow
    python -m pip3 uninstall tensorflow

it seemed it was completely removed as 

    pip show tensorflow
    pip3 show tensorflow

showed no tensorflow

however, when I then do `pip install tensorflow` and then

    pip show tensorflow
    pip3 show tensorflow

It shows tensorflow as version 2.3

but when I enter `python` , which is version 3.5, and then import tensorflow, it says `importerror no module named tensorflow`, yet if I do `python3` which is version 3.8, then I'm able to import tensorflow

I want to use version 3.5 for python and tensorflow. How can I do this?",1.0
g5k1558,iu9fc7,"Probably best to use virtualenv for a specific Python version, something like:

```
virtualenv --python=/usr/bin/python3.5 ./venv
source ./venv/bin/activate

pip install -U pip
pip install -U tensorflow  # GPU package included on supported cards
```",1.0
g5k1sh6,iu9fc7,"do I enter `virtualenv --python=/usr/bin/python3.5 ./venv source ./venv/bin/activate` all as one line? When I try that it says `there must be only one argument: DEST_DIR`

I can use Python 3.8 if its easier. I just wanted to use python 3.5 since I set `alias python=""/usr/bin/python3.5""` in `~/.bashrc`",1.0
g5ks2u9,iu9fc7,"Create a new environment with conda and python 3.7.0 (don't try newer versions!).

Activate this new environment and install tensorflow-gpu (not tensorfow) with pip within it.

It should install Tensorflow 2.3.0.

From Nvidia side you should have proper GPU driver, CUDA 10.1, proper cuDNN for CUDA 10.1 installed. Follow the official manual from Nvidia. Don't install drivers with CUDA 9, 10.0, 10.2, 11.0 or those standalone CUDA versions.

Using messed up environments with older Tensorflow versions, newer python versions and relying on tensorflow package to install tensorflow-gpu package are reasons why many people have trouble with installing Tensorflow, not something from Nvidia side.

&amp;#x200B;

`conda create --name py37 python==3.7.0`

`conda activate py37`

`pip install tensorflow-gpu`",1.0
g5llxvv,iu9fc7,why do I have to use Python 3.7 and CUDA 10.1? Why can't I use Python 3.5 or 3.8 and CUDA 10.0 or CUDA 11.0?,1.0
g5lo9kq,iu9fc7,"As for Python, I lost 2 weeks of my life trying to install all of this before I found that some newer version like 3.7.7 was the culprit. I think 3.5 would work, but I'm done with experimenting myself and use 3.7.0 as a safe haven.

As for CUDA - TF 2.0 works with CUDA 10.0, TF 2.1+ work with CUDA 10.1 and 10.2 and 11.0 are not supported yet as far as I remember. You have to use exact versions for all of it to work properly. So TF 2.3.0 + CUDA 10.1 is the latest setup. Try it with Python 3.5 if you need.",1.0
g5lp3vg,iu9fc7,"I tried doing `sudo apt install cuda-10-1` and it says `unmet dependencies: cuda 10-1 depends: cuda-runtime-10-1 but it is not going to be installed depends: cuda-demo-suite-10-1 but it is not going to be installed`

should I remove all previous versions of CUDA such as 10.0? If so, how?",1.0
g5lqnoj,iu9fc7,"I'm not an everyday Linux user but I managed to install all of this on Ubuntu 18.04 following some blog post. Maybe this one - [post](https://medium.com/@cwbernards/tensorflow-2-3-on-ubuntu-20-04-lts-with-cuda-11-0-and-cudnn-8-0-fb136a829e7f)

Stick with the versions I mentioned, don't experiment with the newest like he does for now. I bet his setup isn't working properly.",1.0
g5ltgt7,iu9fc7,"I followed the steps in that post. Now when I do `nvcc -v` it says `nvcc is not currently installed` even though I followed all the steps for CUDA 10.1 in https://developer.nvidia.com/cuda-10.1-download-archive-update2. 

I already have `/usr/local/cuda-10.1/bin` in $PATH and `/usr/local/cuda-10.1/lib64:/usr/local/cuda-10.1/extras/CUPTI/lib64` in `LD_LIBRARY_PATH`",1.0
g5k1bta,iu5x6h,"This is a difficult question to answer as you haven't provided any real information about what you're after. 

What do you mean by ""without internet connection""? Do you mean the Pi cannot ever be connected to the internet? You can put a model on the Pi's SD card using a computer and then load the files in the Pi's OS. 

What is it that you want to do? If you plan on making a web-scrapper you will need internet for that to work. If you just want to sort you're various cat and dog pics on a local hard drive, then you don't.

And what do you mean by ""teachable machine model""? Aren't all neural nets trainable? Are you looking for a pre-made program that has the training algorithms already made and the neural net model created so all you have to do is feed it data and let it train?",2.0
g5ke6kk,iu5x6h,"maybe what he means by teachable machine is a ML model created with this site 

[https://teachablemachine.withgoogle.com/](https://teachablemachine.withgoogle.com/)",1.0
g5kedt9,iu5x6h,"I don't really have much experience with machine learning on rasp pi, but the teacheable machine site mentions that you can export the model as tensorflow.js, and then use it as it is or convert it to tensorflow lite (which is an on device tensorflow model). try to look on how to convert it and how to put the tensorflow lite model to your device.",1.0
g5j01ow,ituuek,It’s weird that you framed this as a tensorflow tutorial. This is the object detection tutorial from the actual YOLO site with three lines added at the end to save the crop with matplotlib lmao,2.0
g5gm1vp,itsfkx,\*laughs in 1.15...\*,3.0
g5h51od,itsfkx,You honestly don't need GPU support to do the exam so don't worry about (I completed it Aug 31st).,3.0
g5n75pr,itsfkx,"You will have to use 2.0 (and not any other version) for the exam. In particular you'll need to avoid using 2.3, because models trained and saved with 2.3 have a compatibility issue with the backend that's used for grading the exam.",3.0
g8jh116,itsfkx,"Thank you for sharing the information!
I believe such important detail needs to be on the exam instructions. I know switching to a cloud alternative (e.g. Google Colab) on the fly takes not much time, but such stressful surprise is not necessary at all right at the beginning of an exam.",1.0
g5jtc29,itsfkx,I have the same question and am too planning to take the exam. I plan to upgrade to TF2.3 if the test plugin force installs TF2.0 in the beginning. I just can't get TF2.0 to work on my computer.,2.0
g5h1q63,itsfkx,"are you sure the exam plugin installs tf2? I assumed you already needed tf installed as well as pycharm obviously etc. before installing the plugin.
also question to somebody who has already taken exam... can I download plugin get everything sorted and take exam on a later date?
ps. I already have paid for exam and have not yet taken.",1.0
g5m448e,itsfkx,Yes it again installs the tf2,1.0
g5m5g0z,itsfkx,"This will be a problem.

For those with CC &lt; 3.5 (i.e. CC 3.0) cards or requiring instruction restrictions (for older systems) or have specific Python versions\* will fail on a standard TF install (that require custom built wheels).

Additionally various GPU optimizations (and even GPU enablement itself) are dependent on the TF wheel, I assume they get around this by asking which version you'd like to install.

This is not good on so many levels if they enforce a particular install.

Many thanks for that input!

PS. I have built many times from scratch custom wheels that are required for specific hardware architectures.

\*Although 3.7 is mandated I believe, so that sorts out that issue!",1.0
g5m5yuq,itsfkx,Also they demand I believe Python 3.7... 3.6 will fail due to issues allegedly.,1.0
g8khi03,itsfkx,"If you had to use Google Colab during the exam, please share your experience. I have a **question** about it [*here*](https://www.reddit.com/r/tensorflow/comments/j9kxhf/can_i_pass_the_tensorflow_developer_exam_with/). Your feedback will be very much appreciated",1.0
g5fy2b7,itlfzx,"Bias is set to false before a batchnorm layer since batchnorm adds a bias on its own, so it would be redundant to add a bias to the conv too. Bias is removed because it adds extra parameters which can quickly scale up with large models.",3.0
g5g2usm,itlfzx,"One note though, if the leakyrelu, or any other activation, was before the batchnorm, then bias would have to be activate.",2.0
g5hdzsq,itlfzx,"Thanks, guys, for your responses! What if there is no batchnorm in any layer, yet we set the BIAS = FALSE, how will that affect the network and what will that mean for its performance?",1.0
g5g3tq5,itlfzx,"Dlib recently added this functionality, you can read more about its rationale [here](https://www.reddit.com/r/dlib/comments/ilmyd2/automatically_remove_bias_from_layers_that_are/).",2.0
g5f494n,itiske,"~800s per epoch... that's painful man. Get a GPU if you don't have one already. 

Either reduce learning rate according to a predefined schedule, or reduce learning rate after your validation loss has plateaued for a few epochs.",8.0
g5f5yf2,itiske,"Thanks, I'll look into that. I'm training on a P4000 - wouldn't mind a couple of used 1080Ti/2080Ti's though...",1.0
g5fgto0,itiske,3070’s are looking pretty good,3.0
g5ga79j,itiske,"Use Google Colab and a tpu, it's free and fast if you can afford the storage of the data on gcs buckets",2.0
g5ergl8,itiske,"If it uses some kind of gradient descent, the step size can be large. Try reducing it.",6.0
g5erq2i,itiske,"Thanks, I'll give it a shot!",1.0
g5gaffq,itiske,"Probably your learning rate is too big, try using triangular learning rate reduction and try to find the optimal learning rate for your model.

Here is an awesome tutorial, use the triangular 2 learning rate scheduler from tensorflow though, and not the one provided in the tutorial.

https://www.pyimagesearch.com/2019/07/29/cyclical-learning-rates-with-keras-and-deep-learning/

On the same website you can find information about optimal learning rate finding, but you can Google learning rate finder for keras and you will find plenty of projects",2.0
g5hyqw2,itiske,Thanks!,1.0
g5fbroc,itiske,Is that analogous to decreasing the learning rate?,1.0
g5fh4bv,itiske,Yes,1.0
g5erh8v,itiske,"Improvements of neural networks during the learning process are not guaranteed to be monotonic. In addition, improvements of the network on training data are not guaranteed to yield improvements on non-training data.  This can be due to dissimilarity between the distributions of the training and non-training data. That is, the training data may not be entirely representative of the non-training data.

Judging by your time-per-epoch metric, I am guessing you are attempting to train a very large neural network. It has been proven that larger networks are inherently more difficult to train, which leads to ""instability"" during the learning process.",5.0
g5esb6w,itiske,Thanks for the insight. I am training a large model on a segmentation task using satellite imagery. I'll ensure that all data is well represented in the training set.,3.0
g5f7tjy,itiske,Lower your learning rate or use a scheduler to lower it automatically when the model hits a plateau,3.0
g5fbvv5,itiske,Only thing I can think of is make sure you are listening to techno while GANing,1.0
g5fzx2r,itiske,Try to use learn rate decay. i think so it should help you.,1.0
g5g0mky,itiske,How big is your test set?,1.0
g5eeeka,itgv7c,How long did processing one frame take?,1.0
g5db0kx,itboqc,Try to tune up for a group study that's the easiest and fastest way of learning,1.0
g5gaw8l,itboqc,Thanks!,1.0
g5esfd9,itboqc,i use youtube,1.0
g5gawha,itboqc,Thanks!,1.0
g5da44h,it7i8l,"*  [Fine-tune a pre-trained detector in eager mode on custom data](https://github.com/tensorflow/models/blob/master/research/object_detection/colab_tutorials/eager_few_shot_od_training_tf2_colab.ipynb) 
* [https://github.com/tensorflow/models/blob/master/research/object\_detection/g3doc/tf2.md](https://github.com/tensorflow/models/blob/master/research/object_detection/g3doc/tf2.md)
* [https://tensorflow-object-detection-api-tutorial.readthedocs.io/en/latest/training.html](https://tensorflow-object-detection-api-tutorial.readthedocs.io/en/latest/training.html)",4.0
g5da5bt,it7i8l,"
I see you've posted a GitHub link to a Jupyter Notebook! GitHub doesn't 
render large Jupyter Notebooks, so just in case, here is an 
[nbviewer](https://nbviewer.jupyter.org/) link to the notebook:

https://nbviewer.jupyter.org/url/github.com/tensorflow/models/blob/master/research/object_detection/colab_tutorials/eager_few_shot_od_training_tf2_colab.ipynb

Want to run the code yourself? Here is a [binder](https://mybinder.org/) 
link to start your own Jupyter server and try it out!

https://mybinder.org/v2/gh/tensorflow/models/master?filepath=research%2Fobject_detection%2Fcolab_tutorials%2Feager_few_shot_od_training_tf2_colab.ipynb



------

^(I am a bot.) 
[^(Feedback)](https://www.reddit.com/message/compose/?to=jd_paton) ^(|) 
[^(GitHub)](https://github.com/JohnPaton/nbviewerbot) ^(|) 
[^(Author)](https://johnpaton.net/)",2.0
g5ghggw,it7i8l,Thanks ! Quite helpful !,1.0
g5elaas,it7i8l,"Could you please explain why would someone use TF2 object detection when we have Yolo V5 which is damn faster?

Is it because of the fact that TF can provide better accuracy?

Also, one thing I'm aware about using YOLO over TF is that in YOLO the inference time would be constant irrespective of the number of objects in the image while in the case of TF inference time may vary depending on the number of objects in the image.

I'm still learning, please feel free to correct me if stated something wrong!",2.0
g5ghanx,it7i8l,"Insightfull ! Will check on the yolo implementation ! 

Thanks !",1.0
g5cniil,it7i8l,"I have been doing [this one](https://youtu.be/tPYj3fFJGjk) I’m 4 and a half hours in. 

Find it extremely helpful",1.0
g5cp4mu,it7i8l,I have watched it a while ago. I don't remember him using object detection api. Correct me if I am wrong.,1.0
g5cpkvw,it7i8l,You may be right I misread the original post. Sorry 😞,2.0
g5ccljv,it61cl,"Use Categorical Cross entropy instead of Sparse Categorical Cross entropy, as you're not performing binary classification. You'll also want to feed your masks in as one hot vectors (as you mention) and normalise your satellite images. If you need any more help, let me know",0.0
g5cf1n5,it61cl,"Believe it or not I actually just gave myself a migraine stressing over this. (It’s for my thesis) So I’m lying down. But I definitely want to talk to you later when my eyes are back to normal. 
In the meantime. Is there a way to do one shot conversion on a generator?",1.0
g5c4lbt,it3ivh,"Following code worked:

    def parse_str(str_tensor):
        raw_string = str_tensor.numpy().decode(""utf-8"") 
    
        # play with raw string
        raw_string = 'AAA'+raw_string     
        return raw_string
    

Call parse function:


    def tf_pre_processing(row):
      return tf.py_function(parse_str, [row['context']], [tf.string])
    
    
    train = t.map(tf_pre_processing).batch(1).take(1)
    
    list(train)",1.0
g5b6zmo,isv70s,I’m only here to learn but had to comment to commend you for RoastBot. Hilarious.,2.0
g5bazit,isv70s,"Haha, thank you RoastBot is exactly what I named it actually.",2.0
g5c6mtq,isv70s,Well I saw it in the picture.,2.0
g5ciezf,isv70s,ah that makes sense,2.0
g5b8zr9,isv70s,[deleted],1.0
g5b9cal,isv70s,I didn’t think of that but fair enough. Hopefully OP puts proper controls around it if it is meant for non-personal use.,1.0
g5bb4kb,isv70s,"Yeah nah it's just a personal project, if my friends want to try it out I let them but I don't plug anyone in if they don't want it.

Currently it's only accurate maybe half the time anyways so the effect isn't that strong even if the roast does kind of apply to the person",2.0
g5c2sjt,isjnc4,If you have any interest in audio DSP then I highly recommend Valerio’s channel. Full of gems.,1.0
g5io5v6,isjnc4,Thank you!,2.0
g54v7ar,iry241,"&gt;  how do you decide which distribution strategy to chose?

I see this decision as driven by hardware. Start with the simplest thing, and only to go something more complex if the simple one doesn't scale to your hardware.

Multiple GPU -&gt; MirroredStrategy
Too many GPUs to fit in one machine -&gt; multi-worker-mirrored strategy.
CentralStorageStrategy/ParameterServerStrategy =&gt; maybe if the model parameters are too big to mirror to each device?",2.0
g52l752,iru30u,"This will work - you needed to set the dependencies to be the same as the sample code you found:

[https://imgur.com/a/txjSEH1](https://imgur.com/a/txjSEH1)

Obviously these are way out of date - you should try and find some more up to date examples.

[https://codesandbox.io/s/tensorflowjs-real-time-object-detection-forked-yrhdh?file=/src/index.js](https://codesandbox.io/s/tensorflowjs-real-time-object-detection-forked-yrhdh?file=/src/index.js)",2.0
g50bqdm,irmxqh,"You might want to look at https://rastervision.io/, although they've moved to PyTorch from Tensorflow, the documentation works through some of the workflows.",3.0
g51s8sk,irmxqh,"Read this: https://www.jeremyjordan.me/semantic-segmentation/amp/

And https://nanonets-com.cdn.ampproject.org/c/s/nanonets.com/blog/semantic-image-segmentation-2020/amp/",2.0
g526f19,irmxqh,"great resources, would also recommend [Awesome-Semantic-Segmentation](https://github.com/mrgloom/awesome-semantic-segmentation) for actual code",2.0
g583jpi,irmxqh,This has been very helpful,2.0
g52x1a1,irmxqh,"Take a look at this video and it's corresponding blog.

He has explained the whole process of image segmentation in a very simple way. 

https://youtu.be/M3EZS__Z_XE",1.0
g59qmq4,irmxqh,"Agh, He does binary classification. I'm struggling with how to setup the multiclass classification.",1.0
g4xp02v,irb1wj,"Yes.

You can return lists of layers and add each one (so it's one big sequential).

You can also put one sequential in another:

```
def my_conv_stack():
  return Sequential([
    Conv2D,
    BatchNormlization,
  ])

model = Sequential([
  my_conv_stack(),
  my_conv_stack(),
])
```

Or you can use the keras functional api to pack a bunch of layers together into models, and put those models in the sequential:

```
def my_conv_stack():
  input = tf.keras.Input(...)
  x = input

  conv=tf.keras.Conv2D(...)
  x = conv(x)

  norm=tf.keras.layers.BatchNormlization(...)
  x = norm(x)
  
  return keras.Model(inputs=[input], outputs=[x])
```

Or if you don't like the ""models in models"" you can go full ""keras-functional"":

```
def my_conv_stack(x):
  conv=tf.keras.Conv2D(...)
  x = conv(x)

  norm=tf.keras.layers.BatchNormlization(...)
  x = norm(x)
  
  return x

input = keras.Input(...)
x = input
x = my_conv_stack(x)
x = my_conv_stack(x)
x = my_conv_stack(x)
model =  keras.Model(inputs=[input], outputs=[x])
```

They're all the same, and just result in slightly different code organization, and object layout.

The main point is that you can do whatever you want and it's composable.

&gt;  x=norm(conv)

but you can't pass a **layer** as input to a **layer**. You can only pass a **tensor**.",5.0
g57u9r0,irb1wj,Thanks very much for taking the time to write this up,1.0
g4x8cdu,irb1wj,"Sorry I’m not certain, but i believe if you want to create these more custom layers, you want to create a class that extends the Layer type, and you probably need to use the functional API of keras for the layers you are using inside of it.",3.0
g4xcdcf,irb1wj,"Humnn not sure, but what happens if you do model.summary() ?",1.0
g4x6kv1,ir801n,https://www.tensorflow.org/tutorials/images/classification,3.0
g4xnd7v,ir801n,"I wish it was that easy
I saw the tutorial, tried it on Colab and got lost",0.0
g4xnv4v,ir801n,"Sorry to say that, but I doubt you will find help here for a class assignment that is basically a tutorial without specific questions.",3.0
g4xohu6,ir801n,"Agreed, this is a basic problem that only requires doing some research and carefully going through a tutorial.",2.0
g4y0x4k,ir801n,"[https://colab.research.google.com/drive/1MbvNbsunXyhEjqdlQDhrZGWKYXpwM3Q2?usp=sharing](https://colab.research.google.com/drive/1MbvNbsunXyhEjqdlQDhrZGWKYXpwM3Q2?usp=sharing)

Here is one of my submission for online course. Maybe you can use it as reference.",1.0
g4y8pek,ir801n,"Will try later, thanks",2.0
g51cazp,ir801n,"that was what I was looking for, thanks again",1.0
g51m3mr,ir801n,Ur welcome,1.0
g4w8opm,ir4rqs,"The algorithm is open, but the implementations by Nvidia is under a non commercial license.",10.0
g4wpr01,ir4rqs,From my understanding algorithms and mathematical equations can not be patented.,6.0
g4wz6ii,ir4rqs,"They officially shouldn't be, but that won't stop someone from trying and suing every copmpany they can find that's e.g. [filming a yoga class](https://www.eff.org/deeplinks/2014/10/octobers-very-bad-no-good-totally-stupid-patent-month-filming-yoga-class#:~:text=The%20yoga%20patent%20came%20out,listed%20himself%20as%20the%20inventor.)",2.0
g4xx86d,ir4rqs,Google has a patent on Dropout layer,1.0
g4yaxfe,ir4rqs,"Yeah, fortunately as far as I know to protect the principle from patent trolls and keep it free for all. Correct me if I am wrong.",1.0
g4yji5d,ir4rqs,You are right.,1.0
g4ymvs1,ir4rqs,Thank you,1.0
g4xltag,ir4rqs,"I may very well be wrong

My understanding is the nvidia implementation is not open for commercial use, but the algorithm can be.

Here's an implementation in tf2 licensed under MIT (so available for commercial use) [https://github.com/manicman1999/StyleGAN2-Tensorflow-2.0](https://github.com/manicman1999/StyleGAN2-Tensorflow-2.0). 

Not a lawyer, so would be curious if someone confirms with someone that is.",2.0
g4vg8bo,iqzfy4,"Use a cnn with padding=""same""",2.0
g4vl7ks,iqzfy4,"it is very hard to answer your question without any context.
actually, if you look at a seq2seq model it is basically 2 models connected together an encoder + a decoder.

So if you break this down and you focus on the first model (encoder) you have multiple choices you can go with an LSTM/GRU based model and you can use masking to have variable input length. You can go with a Transformer based model (such as BERT) which is faster and better. You can go with some kind of CNN but I have some doubt about the result compared to the two other techniques.

For the second part of the model (decoder) you can fix the output size for it whether it is LSTM/GRU or Transformer.

can you give more details about what you want to achieve and the context we might be able to help you better 😉",1.0
g4w8ve2,iqzfy4,"Thank you for your response! Essentially, I want to apply some transformation f to a set of input points, and get the transformed points out, but I don't know how many points I want to pass in ahead of time. So if I pass in (x1, x2, x3), I want the network to produce (f(x1), f(x2), f(x3)), etc. I'm not sure if I'm stating the problem well, my apologies.",1.0
g4w9ouc,iqzfy4,That looks like you need to batch your dataset. You can use tf.dataset to create batches. There are some great tutorials available on TensorFlow website that you can follow.,1.0
g4v2nm3,iqxz0o,Check the wheels [here](https://github.com/fo40225/tensorflow-windows-wheel),1.0
g4v76av,iqxz0o,Oh. I didn't mention. I'm running Debian based Linux. Don't think a windows binary will work,1.0
g4wab3h,iqxz0o,Do you mean this https://www.tensorflow.org/install/lang_c ?,1.0
g4vspmg,iqxvxr,"Cuda shares object references are always weird.

My advice would be to let conda manage your environment because you’re dealing with more than just wheels (and are kind of out of scope with virtualenv).

If you want to avoid conda, try changing CUDA_PATH in your environment variables.",1.0
g4vtuaf,iqxvxr,Can you guide me how to set CUDA_PATH in my environment?,1.0
g4vwfqf,iqxvxr,"Assuming you're on Windows 10, you can type ""Environment Variables"" in the start menu search and it should come up with ""Edit the System Environment Variables.""

From there, You need to press ""environment variables"" in the bottom right, then choose CUDA_PATH in the ""system variables"" section and press edit to change it to your chosen path.",1.0
g4vwt95,iqxvxr,"Oh OK. That was the first thing I did. The CUDA_PATH is set to Cuda 11, but Python still looks for Cuda 10.1.",1.0
g4vyakb,iqxvxr,"Are you using prebuild wheel/pip packages?  Those were compiled against Cuda 10.1 and will only work for that specific version.  If you want to use 11, you could try [building from source](https://www.tensorflow.org/install/source).",1.0
g4vyscz,iqxvxr,Nice! Very good point. I think this is my problem. Thanks for your help.,1.0
g4tdjhr,iqky1s,"Essentially, tensorflow is a python library made by google that allows you to create, train, export, and deploy machine learning models. This has a large focus on deep learning and neural networks, although it also has basic estimators. 

More recently, a library called keras was introduced, which uses tensorflow as a backend, to perform lower level operations. Keras makes it more concise to create and train models, making it very useful for all tensorflow developers.",3.0
g4t066h,iqky1s,"Tensorflow is a framework for machine learning. Tensorflow 2 specifically uses Keras as backend. The course you mentioned is by Jose Portilla who is one of the best instructors in the field.

Personally, I bought (some torrented) multiple courses of him and A-Z.

Tensorflow 2 will start from probably Basic ANN",1.0
g4t3d2l,iqky1s,So Tensorflow is not a tool but rather the environment?,1.0
g4t3j9e,iqky1s,"Its a library, not environment",8.0
g4t3sha,iqky1s,"OK, I expected I will log into Tensorflow tool or site. 😀",0.0
g50x502,iqiaap,"Ok, I just made my code in the way it just considers my detection with maximum score, then I just try and match it with a ground truth. If there is a match (with the respective IoU of my choosing and score threshold as well), then it's a 1, if there is not a match, its' a 0. Applying the mean on that, it will give my idea of Average Recall for max detections = 1.

Observing the results, it gives a much much better result when comparing to the COCO AR maxdets=1 metric. They consider all ground truths on this metric.",1.0
g4pa6dd,iq4js3,"Try this: [Stanford Blog](https://stanford.edu/~shervine/blog/keras-how-to-generate-data-on-the-fly)

It helped me!",8.0
g4pcaqs,iq4js3,"Thanks, although I've already stumbled across that post.

Seems as though I overlooked how much memory it took to train on batches of 64 - by dropping to 2 I'm operating at \~3GB. I \*think\* my problem's resolved.

Thanks for taking the time to help",2.0
g4pd5d3,iq4js3,"Cool! Maybe try a batch size of 8, or 16, or 32? You don't want to not utilise your RAM fully ;)",3.0
g4qivkt,iq4js3,I recommend streaming from directory instead of loading into RAM,1.0
g4r1hej,iq4js3,"Yes, this is what we are also doing because even some time 256-512 Go of RAM is not enough anymore...

Take a look at the tfrecord file in Tensorflow.",2.0
g4rfq32,iq4js3,"This approach only loads a batch into memory, not the entire dataset",1.0
g4rgdse,iq4js3,"Yes that is correct, which is how the original problem will be solved (running out of memory)",0.0
g4kxkxo,ipjnhk,"1. `tf.convert_to_tensor(model.trainable_variables)` fails likely because it's a jagged array (ie: the weights and biases are not the same shape within each layer and likely vary by layer as well). I didn't read the paper, but if `w` can be reorganized as a vector, you could try iterating over all variables and concatenating them into a single 1D list and then convert that to a tensor.
2. Yes, every call will see the new variables.",2.0
g4p4lbl,ipjnhk,"Thank you! I think i've implemented it properly in the code below - I figured an equivalent problem was to take the mean of each layer of w, rather than matrix multiplying arrays of size millionsXmillions. Anyway, for some reason I thought iterating in a custom loss function wasn't possible. Thanks for the idea!


    def net1loss(y_true,y_pred):
        net_output = y_pred[:,:,:,0:1]
        input_image = y_pred[:,:,:,1:2]

        weights = net1.trainable_weights
        length = len(weights)
        layersMu = tf.zeros([length],dtype=tf.dtypes.float64)
        for i in range(length):
            arr = weights[i]
            layersMu[i] = tf.math.reduce_mean(arr)
        learnedReg = lambdaP * tf.matmul( layersMu - mu , tf.matmul(sigmaInv, layersMu - mu) )

        return K.sum( K.square(net_output-input_image) ) + learnedReg",1.0
g4j4b6u,ipbse4,"Sorry but it's a bit hard to figure out where the error is, but if you can find the line, usually np.expand\_dims(or it's tensorflow equivalent) ought to do the trick. Algorithms usually expect (L, L, 1) shaped files, where L is 1024 for you, I guess.",2.0
g4jf8s2,ipbse4,It's an error with the data shape you are inputting into the model. Since you're doing NLP model it's probably the sequence length that you have not considered.,1.0
g4il5i5,iow8ik,"THese models have similar architectures, but totally different shapes.

The Torch model goes 512 -&gt; 256 -&gt; 128 -&gt; 3 channels, and the TF model goes 256-&gt; 128-&gt; 64-&gt;32-&gt;16-&gt;8-&gt;3 channels.

The torch model uses Relu, the tensorflow model uses LeakyRelu.

It looks like you're not comparing apples to apples. Why not eliminate some of these differences to simplify the comparison?",11.0
g4q2p3j,iow8ik,"I rebuilt the TF model (for 512x512) to this

    def make_generator_model():
        model = tf.keras.Sequential()
        model.add(layers.Dense(64*64*512, use_bias=False, input_shape=(100,)))
        model.add(layers.BatchNormalization())
        model.add(layers.LeakyReLU())
    
        model.add(layers.Reshape((64, 64, 512)))
    
        model.add(layers.Conv2DTranspose(256, (3, 3), strides=(2, 2), padding='same', use_bias=False))
        model.add(layers.BatchNormalization())
        model.add(layers.LeakyReLU())
    
        model.add(layers.Conv2DTranspose(128, (4, 4), strides=(2, 2), padding='same', use_bias=False))
        model.add(layers.BatchNormalization())
        model.add(layers.LeakyReLU())
        
        model.add(layers.Conv2DTranspose(3, (4, 4), strides=(2, 2), padding='same', use_bias=False, activation='tanh'))
        print(model.output_shape)
        return model

I decided not to change it to ReLU because of what I've read, but might do so if it doesn't improve. I'm already seeing better results, though it's only on epoch 10 so I can't quite tell!

Thanks again",2.0
g4judz9,iow8ik,"This is great advice, thank you! I'll give it a shot. I was under the impression that gradually changing the channels would help the model but I think I was wrong",1.0
g4glq1n,iow8ik,"had the same problem with a MLP:  
eventhough the initializer had a similar name and should have done the same, they had not

you could try using the torch initializer for your tf network",6.0
g4gp8em,iow8ik,"thanks for your comment!

whats the high level explanation of using a torch initializer for tf?",1.0
g4h643c,iow8ik,"just a small node:

if you need tf only for deployment, then you can still train it in torch extract the weights and store them in a tf-network ;)",8.0
g4h5qqo,iow8ik,"for the dense layer I used the following initializer:

    class CustomKernelInitializer(tf.keras.initializers.Initializer):
        def __call__(self,  shape, dtype=None):
            t = torch.Tensor(shape[0], shape[1])
            v = torch.nn.your_torch_initializer(t, other_parameter).detach().numpy()
            return tf.keras.initializers.constant(value=v)(shape=shape, dtype=dtype)

and the same for the bias initializer

obviously you have to choose your initializer in torch for 'your\_torch\_initializer' and adjust further parameters for 'other\_parameter' ;)",5.0
g4j0llx,iow8ik,"Different initializers are constructed for different activation functions and different scenarios. Often researchers also just find one specific initialization to work well for a certain problem, without any explanation. 

So it's not like the one in torch is better than tf. It's just different.",2.0
g4j1ebz,iow8ik,"oh yes, it wasn't my intention to say, that one initializer is worse in general; one just turned out to result in a better performance and it could have been the other way around. And the first thing I tried was to use the better performing initializer in the other framework and achieved similar performance. So I just wanted to highlight this possibility. But it seems that u/suki907 had a deeper look in the code and found dissimilarities which might be the reason for the performance differences",3.0
g4in8k3,iow3gd,"Oh, tf.einsum doesn't broadcast?... but what do you need the ones for anyway?

If you squeeze/reshape them out you could say this as: `tf.einsum('bc,acde-&gt;abde', A, B)`",1.0
g4w7n19,iow3gd,"Thank you, it solves the problem :)",1.0
g5c5b98,ioveog,Hi just wondering if the approach you outlined is what you ended up doing. Did it work out? Thanks.,1.0
g5c5gkp,ioveog,Haven't tried it yet cause I was to lazy to code it up 😃. But when as soon as I tried it out I will let you know 👍.,2.0
g5c6lbr,ioveog,Ok cool. Good luck!,1.0
g4ft3j2,iosbe5,"There's not going to be a one-liner trick to do this.

To calculate the gradients you need access to the intermediate results of the forward pass. 

You will need to do some ""recomputation"" or ""rematerilization"" tricks to make it work. 

Basically:

1. Write a loop over the dataset batches.
2. Accumulate the list of outputs you need to calculate the loss.
3. Calculate the global loss.
4. Loop over dataset batches in the same order.
5. Calculate the gradients for each batch using [GradientTape.gradients](https://www.tensorflow.org/api_docs/python/tf/GradientTape)'s ""output_gradients"" argument.
6. Accumulate those gradients in the loop
7. Apply the gradients.",3.0
g4fws92,iosbe5,"A good example would be the one given by tensorflow in their website.
Go to this section where they explain Pix2Pix there you'll get an idea of what is mentioned above 
Basically these 7 steps in code 🌻",2.0
g4g4f36,iosbe5,"Thanks. what i am confused about is if i only have epoch loss, how/why do i calculate the gradient per batch of data? As far as the optimizer is concerned it doesn't care that i computed outputs in batches it just wants a loss for each sample no? I'm only doing a train step once per epoch",1.0
g4g2nq1,iosbe5,"what i am confused about is if i only have epoch loss, how/why do i calculate the gradient per batch of data? As far as the optimizer is concerned it doesn't care that i computed outputs in batches it just wants a loss for each sample.",1.0
g4i1e8z,iosbe5,The problem is that it needs intermediate results to calculate the gradients.  from the forward pass to calculate the gradients.,3.0
g4fxvsn,ionajb,"This is a good question. I am also searching for some sources which can help me to implement a base paper and reproduce the results. 

If we can do it for one paper and get the desired results, that helps us to enhance the model or use it in a different context.",4.0
g4fybvu,ionajb,"Exactly ☺️
Do update the thread if you have found something 
Thanks in advance ❤️",3.0
g4g7lil,ionajb,"It is worth looking to Jax and Objax ([https://github.com/google/objax](https://github.com/google/objax)), which are designed specifically to be lighter weight and easier to implement research projects into. The abstractions and high level APIs in tensorflow, pytorch, and etc are useful when you want to efficiently describe a fairly well known architecture or training procedure and do it at scale, but the tradeoff is that it can be very hard to implement extremely custom behavior (e.g. from a research paper).",3.0
g4garx4,ionajb,Awesome!! Will look into it 🌻,1.0
g4ex5zu,ionajb,It's not worth doing.  Papers should have code - if they don't then it's unlikely they even contain enough details to reproduce their results.,4.0
g4ffkiz,ionajb,Happy Cake day but poor advice. You should know how to reproduce results so that you can carry on the research in the future or modify layers to your own use,8.0
g4fwqom,ionajb,That's a good reason why papers should have code.  But go for it if you want to.,-1.0
g4f3uxx,ionajb,Great point but then let's say there is an implementation in pytorch and I wanna reproduce the results in Tensorflow2 so getting my hands dirty with some techniques to read papers would be good right?,2.0
g4fb5xe,ionajb,nice point there :D,2.0
g4fwmn7,ionajb,Implementing research papers and translating code from pytorch to TF2 are two different things.,-1.0
g4cbyei,io50vp,What are you doing with Tensorflow on Raspberry Pi? Are you training a new model or using a pre-trained one? Do you need Tensorflow for the second option?,1.0
g4cl6wm,io50vp,"These are the notes that I have learnt from my project and for that Im training a new model. Hmm whether or not you will need to use Tensorflow for any project would greatly depend on what you require for your specific project, you will only need Tensorflow if the pre-trained model used is created using Tensorflow.",1.0
g4dhknh,io50vp,Cool guide.,1.0
g4eopf2,io50vp,Thanks man!! :D,1.0
g4b6f6o,io16oc,"Academic/Research papers will often mention custom training and loss functions which you can learn from (although research is almost done exclusively in pytorch not tf). Looking through GitHub TF implementations of papers also helps you build an understanding. 

More importantly, you mentioned that you don’t have a strong math base. It will be hard to progress in learning ML if you do not have a strong math base w/ calculus and linear alg. I’d recommend you go on khan academy and complete their calc and linalg course if you really want to understand these custom loss functions. Otherwise, just stick with the built-in functions since they’re already good enough for 99.9% of use cases except for some niche research projects.",4.0
g49znho,inug0e,"My biggest suggestions: learn how to describe your data and the problem you want to solve. You probably find the reason why your network is not training. What are the 15 inputs and the 4 outputs?  
Also use snipping tool instead of mobile phone [win] [shift] [s].
Make plots of your data, look for correlation. 
Starting with neural networks and tensorflow can be a pain, but things will get easier the more you learn",12.0
g4aminf,inug0e,"There is nothing but guesswork to be done here based on this single screenshot. Agree with u/le_theudas...we need a LOT more context about the data, the problem, the hardware, etc. to troubleshoot this...",6.0
g4awn0n,inug0e,"The same metric for test and train suggests that there is more for the model to learn.

Things to suggest:

1. Smaller learning rate.
1. More nodes, not more layers (a  lot more nodes).

You need to make sure that at least the train metric is good once that is achieved you can worry about optimizing for best train metric.",2.0
g49xfxw,inug0e,Did you standardize or normalize your data?,3.0
g4arosx,inug0e,Yes I did,-1.0
g4app5g,inug0e,Try a single layer of dense of 128 or 256. The model is probably too deep and too narrow for small dataset.,1.0
g5gmumg,inug0e,Or at least my dataset which was pre processed,1.0
g49vgok,inug0e,"This is a very small model, try creating a bigger model to see what happens.",1.0
g49vu00,inug0e,i dont think his model is small.his model is not training at all. its just predicting random outputs. what does your dataset look like?,5.0
g49zdzv,inug0e,You're right the loss should have decrease at least a little bit.,3.0
g4ba4cv,inug0e,"Yes, most of the times the problem is with the data and not with the model. So check whether the input data that is being fed to the model is correct or not. Sometimes data processing unknowingly corrupts the data. Better to visualise it.",2.0
g4banxm,inug0e,i dont know if its even a dataset problem. the model isnt learning at all like its weights are frozen. 1/4 accuracy for  4 categories means its just predicting randomly.,2.0
g4barv1,inug0e,This 'might' happen if the data is gibberish.,3.0
g4bb1bg,inug0e,gibberish data does give gibberish output,2.0
g4arpni,inug0e,I’ll send a picture of the dataset,1.0
g4b1asu,inug0e,"Have you tried changing activation functions?  
[https://mlfromscratch.com/activation-functions-explained/](https://mlfromscratch.com/activation-functions-explained/)",1.0
g4d889y,inug0e,Yes I went from sgd to categorical crossentorpy to sparse categorical crossentropy,1.0
g5c5nha,inug0e,"Those are loss functions, not activation functions.  

Did you ever end up improving your model? If so, what did you do?",1.0
g5gmoc4,inug0e,I’m planning on linking my colab notebook today,2.0
g5gn9lh,inug0e,"I tried redoing a column in my data which consisted of encoded values from 0-10, everything else in my dataset was from 0-4 so I don’t know if that one column was throwing it off?",2.0
g49le63,inrwdb,"cool.

when do you plan to put it on github",1.0
g4aw7a6,inrwdb,I would reccommend GRUs because LSTMs do not maintain the text's structure as well as GRUs,1.0
g4b5dbd,inrwdb,Thank you il try them!,1.0
g47takd,inh4ho,"Tensorflow does have some issues with python 3.8 (at least the versions available with conda). This normally works with 3.7, so when you create the environment, use: conda create -n [name-of-env] python==3.7",5.0
g47m68z,inh4ho,"Try running the command:
conda update anaconda

And you then rerun the tensorflow GPU installation command.",1.0
g47sx3s,inh4ho,https://github.com/rexdivakar/Deep-Learning-Setup,1.0
g48gbpi,inh4ho,"conda create  -n envname python=3.7

conda activate envname

conda install tensorflow-gpu",1.0
g497p7c,inh4ho,Ditch conda. Dl your py and use virtual environments.,1.0
g49d40x,inh4ho,Tensorflow 1.x does not run on python 3.8. you need to use tensorflow 2.x for that.,1.0
g47aruv,indpdk,Following. Recently started learning ML. Set up SageMaker and learning the aws ui and features. Can walk you through if if interested,1.0
g48d1s0,indpdk,I’ll pm you. Thanks,1.0
g47oeoz,indpdk,why can't you use tensorflow locally on the raspberry pi,1.0
g486aps,indpdk,I could but I would like to learn how to use aws more,2.0
g45c8sc,in0w5y,"If it's just for a personal and non-commercial project, [it looks like you could use Flickr's API to mass-download images based on their tags](https://medium.com/@adrianmrit/creating-simple-image-datasets-with-flickr-api-2f19c164d82f) for free, via a python script.



For projects going commercial, you'd have to respect image licensing (can probably filter to get the freely usable images via the API) and also make arrangements with Flickr to get a paid API key for this purpose.",1.0
g4666m9,in0w5y,"Yes, it is personal experimenting to learn. I was going through Udacity's TensorFlow class and was thinking how cool would it be to try doing this on other images so that I can learn it better. At that moment, it dawned on me that I would need to aggregate the images and label it. would be simple if google returned exactly what you googled, but that is not always the case. I will check out this flcikr API, learning AI on the weekend is fun but not manually pulling pictures lol.",2.0
g466l0p,in0w5y,Wow this is some good quality data right there. You just made my day,2.0
g46uwbd,in0w5y,"One thing that I will mention is that for personal projects especially, learning to use Beautiful Soup (a python package for processing webpages/we scraping) has been incredibly useful for automating getting various resources.",1.0
g43jjje,imwn8j,"Looks like TF isn't working with CUDA11 yet, just install the latest CUDA which it works with",1.0
g43rumo,imwn8j,Check official [requirements](https://www.tensorflow.org/install/gpu) and install dependencies accordingly. Hope this helps !,1.0
g46s7m8,imwn8j,"OK, tf nightly 2.4 works with cuda v11.",1.0
g43hpl7,imoi8d,"1. The fighter winning or loosing the fight would be what you want to predict right? That's the target variable then. When you split the data that would be your y variable. You'd have to one hot encode them.

2. Could you share a sample of the CSV? Not too sure you mean by format them. But as you're using a NN you need to normalise the numerical variables and one hot encode the categorical variables. 

3. You can use train_test_split() from sklearn.",1.0
g42dcih,imn425,"Maybe this is what you want:

https://youtu.be/uhzGTijaw8A?t=2231

Either that or subclass `Model` and overload it to do what you want.",1.0
g4ko8eo,imn425,"I tried what is said in the video, but I'm confused.... addloss receive a scalar, but losses return batch-ed (1d-tensors) values, right?! 

About subclassing Model, I'd have to overload the fit method if I'm not wrong... and that's something that I'd like to avoid, since I'd have to deal with callbacks, concurrent calls to data generators and all the other things that Keras/Tensorflow abstracts for me.   


I was thinking about the ugliest way to do that... use skip connections, concatenate with the NN output, them I'd be able to do what I want. I think it is possible, because the model doesn't have contractible or expansible layers, so all layers' output are ""dimentionally coherent"".  But that bothers me because now my model will keep spiting intermediate layers after training.",1.0
g4sfopz,imn425,"For subclassing look at the “train_step”.

Anywhere you deal with losses keras will take the average the loss if you don’t return a scalar.",1.0
g69mxnc,imn425,"In the end, I decided to use a skip connection (tf.concat) with this layer to the last layer, and train using a custom function with dealt with the extra channels. After training, I just delete this last layer and I have what I wanted. =D",1.0
g405l8u,imfvuv,Seems 17 minutes too long,1.0
g3xfb8d,im5ev8,This  doesn't sound right. Verbosity just changes what gets printed.,8.0
g3xg58i,im5ev8,"It's entirely possible it has something to do with tf-nightly-gpu, windows, or cuda 11.

Either way it was such an unintuative and effective fix i wanted to put it online for anyone else having similar issues",2.0
g3xqobr,im5ev8,"It can really depend on the workload. Printing output can be a surprisingly expensive task - if your batch size is quite low, you have lots of data, and verbosity is high, then it wouldn't surprise me if it added significant times to training, though hours to seconds per epoch definitely sounds extreme.",3.0
g3vcgjx,ilxeoz,You need to post some code or something.,2.0
g3vfk64,ilxeoz,"Sorry, I updated it.",1.0
g3xgtz6,ilxeoz,"Your code looks reasonable. Nested tapes work. 

I would start with a simpler setup and incrementally build up to this, until it breaks. 

Have you checked all these commn reasons for getting broken gradients?

https://www.tensorflow.org/guide/autodiff#getting_a_gradient_of_none",1.0
g3vxufp,ilvfep,"Honestly you should probably ask soccer enthusiasts first. 

That aside, what sorts of results are you hoping to predict? If you want to predict changes in possession, you might want a data point every second (or whatever) that is a ""frame"" of the entire situation. As in, who has the ball, who is in what part of the field, what time is left on the clock, etc. If you just want to predict wins and losses, you don't need so much data. You could start with just wins and losses based on certain factors (which players are injured, home vs away, etc). You can just do this in a spreadsheet.",1.0
g3w2xjg,ilvfep,Dont have a great way of doing this but do you have a data source for soccer games which you can share? Sounds like an interesting project for the future,1.0
g3wb0qn,ilvfep,"Back in the days we have develop online sport betting game (virtual money). We have used data feed from https://www.lsports.eu, but there is also https://www.sportradar.com. First you will need to decide in what specific sport and league you are interested, then what type of outcome you want to predict (pre-match, live). This decision can significantly reduce your cost for this data feed, because it can be very expensive. 

To get better idea what kind of outcome your AI could predict search for some online betting sites...",1.0
g3wfu6x,ilvfep,"Soccer is going to be a tough one I guess.
There are only a few goals so the amount of randomness is high.  
I believe it could be good to work with bayesian modeling, so you could get probability intervals. 
A different approach without too much machine learning could be to use something like glicko/elo. It also might be a nice baseline. E.g. you could scrape all games for all players and simulate the glicko scores from the very past. It might be a nice idea to take every 15 minutes as one game. So each actual game counts as 6. If a goal it's made it counts as a won game for the scoring team. For example a 2 to 0 counts as 2 wins and 4 draws.  
To calculate the end result you can sample from that distribution",1.0
g3tnr8f,ilpu89,"## [https://github.com/JohnSnowLabs/spark-nlp](https://github.com/JohnSnowLabs/spark-nlp)

## Overview

We are very excited to finally release Spark NLP 2.6.0! This has been one of the biggest releases we have ever made and we are so proud to share it with our community!

This release comes with a brand new MultiClassifierDL for multi-label text classification, BertSentenceEmbeddings with 42 models, unsupervised keyword extractions annotator, and adding 28 new pretrained Transformers such as Small BERT, CovidBERT, ELECTRA, and the state-of-the-art language-agnostic BERT Sentence Embedding model(LaBSE).

The 2.6.0 release has over 110 new pretrained models, pipelines, and Transformers with extending full support for Danish, Finnish, and Swedish languages.

## Major features and improvements

* **NEW:** A new MultiClassifierDL annotator for multi-label text classification built by using Bidirectional GRU and CNN inside TensorFlow that supports up to 100 classes
* **NEW:** A new BertSentenceEmbeddings annotator with 42 available pre-trained models for sentence embeddings used in SentimentDL, ClassifierDL, and MultiClassifierDL annotators
* **NEW:** A new YakeModel annotator for an unsupervised, corpus-independent, domain, and language-independent and single-document keyword extraction algorithm
* **NEW:** Integrate 24 new Small BERT models where the smallest model is 24x times smaller and 28x times faster compare to BERT base models
* **NEW:** Add 3 new ELECTRA small, base, and large models
* **NEW:** Add 4 new Finnish BERT models for BertEmbeddings and BertSentenceEmbeddings
* Improve BertEmbeddings memory consumption by 30%
* Improve BertEmbeddings performance by more than 70% with a new built-in dynamic shape inputs
* Remove the poolingLayer parameter in BertEmbeddings in favor of sequence\_output that is provided by TF Hub models for new BERT models
* Add validation loss, validation accuracy, validation F1, and validation True Positive Rate during the training in MultiClassifierDL
* Add parameter to enable/disable list detection in SentenceDetector
* Unify the loggings in ClassifierDL and SentimentDL during training

## Bugfixes

* Fix Tokenization bug with Bigrams in the exception list
* Fix the versioning error in second SBT projects causing models not being found via pretrained function
* Fix logging to file in NerDLApproach, ClassifierDL, SentimentDL, and MultiClassifierDL on HDFS
* Fix ignored modified tokens in BertEmbeddings, now it will consider modified tokens instead of originals

## Models and Pipelines

This release comes with over 100+ new pretrained models and pipelines available for Windows, Linux, and macOS users.

The complete list of all 330+ models &amp; pipelines in 46+ languages is [available here](https://github.com/JohnSnowLabs/spark-nlp-models/).",1.0
g3tt42v,ilptk5,"Yeah, usually something like: 

 `for _ in range(100):`

`opt.minimize(loss, var_list=var_list)`

where opt is an instance of SGD.",2.0
g3xxbfr,ilptk5,Thank you,2.0
g3rctqy,ildm1t,"It does, I also built some wheels with 3.8 before so [https://github.com/davidenunes/tensorflow-wheels](https://github.com/davidenunes/tensorflow-wheels) it should be OK. For 3.9 I suspect they have to fix some things that have been deprecated for a while now, but we'll see xD",7.0
g3reiq9,ildm1t,"Thanks! 
I’ll use it with 3.8.5 then.",3.0
g3s0mcg,ildm1t,I just wanted to say that your wheels have saved me multiple times. :),2.0
g3sdfyf,ildm1t,"good to hear,   
I started sharing them when I found how building one can be a pain, especially with less resources. So I'm glad &lt;3",1.0
g75t5ok,ildm1t,"How did you installed it?  pip install --upgrade tensorflow  its not working for me.

ERROR: Could not find a version that satisfies the requirement tensorflow (from versions: none)

ERROR: No matching distribution found for tensorflow

&amp;#x200B;

Edit. Yes im a noob with python. I was using 32 bit version. Already solved.",1.0
g3tgbkv,ildm1t,i've had 3.8.4 working with tf 2.2.0 for a month or so.,2.0
g3pokfu,il0yru,So the issue is that the image_dataset_from_directory() creates a 4D tensor when my LSTM layer requires a 5D tensor. I'm still trying to fix it.,2.0
g3yqcha,il0yru,Your model expects sequences of 5 pictures as inputs. You need to adjust your data generator. This should help https://medium.com/smileinnovation/training-neural-network-with-image-sequence-an-example-with-video-as-input-c3407f7a0b0f,1.0
g3otr4d,il0yru,You need to add None for the unknown batch size at the start of INSHAPE.,1.0
g3otye3,il0yru,"So I have to change INSHAPE to (None, 5,224,224,3)?",1.0
g3ou12z,il0yru,"Yes, this should probably help 🙂",1.0
g3ou2bx,il0yru,Ok I'll try it and update you soon if it works.,1.0
g3ovdyx,il0yru,"INSHAPE = (None, 224, 224, 3)

Got the same error :

 ValueError: Input 0 of layer sequential\_9 is incompatible with the layer: expected ndim=5, found ndim=4. Full shape received: \[None, 224, 224, 3\]",1.0
g3qinc1,il0yru, [https://uta.box.com/s/e7nsmloj8xmblosvfg98q42fgqnjy6dv](https://www.google.com/url?q=https%3A%2F%2Futa.box.com%2Fs%2Fe7nsmloj8xmblosvfg98q42fgqnjy6dv&amp;sa=D&amp;sntz=1&amp;usg=AFQjCNGZdOEWnjYJYOX9e95AjyfG1ufDsA)  the dataset is unable for downloading !,1.0
g3qites,il0yru,Not too sure it was up a month ago when I started this project.,1.0
g3mk4l1,ikq115,"Maybe use Lstm with two features, one is the values of the time series, the other one is 0 before this special point in the time series and 1 after this point.",2.0
g3mh5o0,ikq115,Interesting question that concerns me also currently,1.0
g3krn95,ikiuc7,"You can use the `.weights` attribute. For instance, `layer = tf.keras.layers.Dense(512)`, then, `layer.weights` to get the weights.",1.0
g3krpb9,ikiuc7,Use this when you're looping through your layers.,1.0
g3krvk5,ikiuc7,"For the moment I’m using TF 2.0 and it doesn’t work , but I m willing to switch it to Keras . I ll give it a try thank you sir",1.0
g3ks3w8,ikiuc7,"You can use `tf.keras` in TF 2.0, it's the default high-level API of TF starting that version.",3.0
g3kukig,ikiuc7,"Please do take note that when accessing weights in TF, you have to use the model on an input first. Otherwise, you'll retrieve an empty list.

You can also use the `.weights` on the model itself, i.e.

    &gt;&gt;&gt; model = tf.keras.Sequential([
                    tf.keras.layers.Dense(100, ""relu""),
                    tf.keras.layers.Dense(10)
                ])
    &gt;&gt;&gt; model(tf.random.normal([2, 100])  # just to get some weights
    &gt;&gt;&gt; model.weights

Cheers!",2.0
g3kuosx,ikiuc7,thank you so much ! :),1.0
g3kusop,ikiuc7,Were you able to extract the weights?,1.0
g3kvbub,ikiuc7,The output gave me exactly the output of  tf.training_variables() in TF . Still doesn’t print weights values,1.0
g3kvjx7,ikiuc7,"If you're using `model.weights`, that will give you a list of the weights. You can access them individually, e.g. `model.weights[0]` will give you the weights of the first layers.",1.0
g3kvr78,ikiuc7,"Also, if by `tf.training_variables`, you mean `model.trainable_variables`, its output is also the list of weights of your model.",1.0
g3ovl90,ikiuc7,"Just a small hint
Instead of print you can go with tf.print when trying to print a tensor ❤️",1.0
g3kvi5f,ikiuc7,"I found something else :
model.get_weights() and it works !",1.0
g3kw29o,ikiuc7,They're almost the same. The difference is  that `model.get_weights` gives you the numpy arrays instead of `tf.Variable`.,1.0
g3kw7zc,ikiuc7,"`model.weights` and `model.trainable_variables` give you the tf.Variable or ""eager tensors""",1.0
g3kw6w8,ikiuc7,"Yes !That’s what I was looking , thank you again for your patience :)",1.0
g3k9v07,ikdsrw,"The silver lining is that when people search for your name, they don't think that you're so desperate that you have to pay $100 to get your name listed on a web page.",3.0
g3jv5nv,ijyi3d,"Nice, it was quite insightful !",1.0
g3glowi,iju7co,"So you're offering excellent salaries and millions of dollars in shares.... And yet you are using a yahoo email address?

Are you also a Nigerian prince with cash flow problems in your spare time? :)",5.0
g3h6rzp,iju7co,"Lol, I've had it since 1999.  My co-founder just bailed on me, we're still an early start-up.",1.0
g3g5asb,iju7co,Is there a website or something where I can learn more about the company?,2.0
g3h7q8x,iju7co,"[NapticAI.com](https://NapticAI.com) is our website, Naptic, Inc. is the company. This is me [https://www.linkedin.com/in/jeff-schulze-a0821a42/](https://www.linkedin.com/in/jeff-schulze-a0821a42/).  We're still an early start-up, the valuation was based on similar companies and some large contracts we have procured.",1.0
g3ha7n5,iju7co,"I really think you should change your approach to recruiting. If you actually are willing to pay what you said, either hire a headhunter or post it yourself on LinkedIn jobs etc. Search for AI (Data Scientist/Machine Learning Engineer is what you are looking for) guys working for big corps in your vicinity and message them on LinkedIn. Your company depends on this particular individual you are going to hire and the approach you are taking towards hiring seems sub-optimal. Just my two cents. I can help you figure out the keywords to use or the people to target if you want. Message me if needed. Good luck

Edit: Your use case isn't that hard. You don't need the best of the best people to do this. If you are interested in contracting it out, do let me know.

r/DataScienceJobs is your best bet on Reddit",1.0
g3hd9hd,iju7co,Thank you for the feedback.  I have recently taken some of those steps.  My co-founder bailed on me and started his own company associating a sense of urgency to complete some contracts.,1.0
g3h0niy,iju7co,"you never get a second chance to make a first impression.

so.

an 18m valuation and your email address is on yahoo.com",2.0
g3h72b7,iju7co,"Lol, Its my personal email address I've had for years.  We're still in early stages, we've just received some large contracts and my co-founder bailed.",1.0
g3h6i5y,iju7co,So your company received an 18M valuation but you need someone to do the heavy lifting and actually provide the value?,1.0
g3h8gu9,iju7co,"I worked for a surveillance company for years building and maintaining hardware and software for IP cameras, during that time I developed a prototype AI, a pitch deck, and sold the product to clients.  I have a full stack architect that works on the UI.  I've trademarked and registered the C-corp, produced branding and marketing materials.  I just need some assistance fulfilling some contracts. Thanks.",2.0
g3h94iq,iju7co,"Why do you give yourself an 18m valuation? To me, it seems like you have nothing but an idea, which is worthless unless realised. If you have good reason for that valuation, it would be in your best interest to state it.",1.0
g3hb71c,iju7co,"That evaluation was given to me by Capital Factory in Austin, TX.  4.5m for 25% of Naptic, conditionally (the largest valuation we received).  Capital Factory also funds Athena Security, in the same market and extended to them a greater valuation. We are indeed an early start-up, however I have procured some large contracts that need fulfilling in order to complete my end of the terms sheet.   My co-developer bailed on me and started his own company, Pryvent.  I am in need of someone to fill his shoes going forward. As stated previously, I have developed a proof of concept and a fully functional prototype. Thanks.",1.0
g3g1uqb,ijqahx,"&gt; some say we should not do it

Do you have a source for this?",1.0
g3g1z3h,ijqahx,"Found it roaming around stackoverflow. Don't have the link, sorry.",1.0
g3g4tr9,ijgcoe,"Personally I don't know much about acing GSoC but one thing I got to know from my seniors was that open source contributions matter a lot. Try to get in a few good pull requests to the tensorflow repository.
This would definitely boost your XP points.",1.0
g3cr5cn,ijc7wr,I got that too but everything still worked. Let me know if u figure it out tho. Should actually use the GPS support.,1.0
g3ctnzi,ijc7wr,I also installed Cuda and still got it.,1.0
g3ctbc1,ijc7wr,i had succes with karas and plaidml backend,1.0
g3cxzav,ijc7wr,Rocm,1.0
g3f6jjm,ijc7wr,Pick a Linux distro and install ROCm.,1.0
g3ciavf,ijblh0,"i had a lot of trouble too - a LOT of outdated guides around

just follow instructions from tensorflow itself and use an env:

[https://www.tensorflow.org/install](https://www.tensorflow.org/install)

&amp;#x200B;

edit: 

to use GPU  I have following installed in my env:

with pip:

\- tensorflow 2.3.0

with conda:

\-cudatoolkit 10.1.243

\-cudnn  7.6.5

&amp;#x200B;

host system hat nvidia driver 450.xx",16.0
g3cx9dn,ijblh0,This is the way,6.0
g3cgjp4,ijblh0,I had anaconda distribution and just did pip install tensorflow 2.. seemed to work ok??,7.0
g3cr2zo,ijblh0,I think he is talking about the TensorFlow GPU module,7.0
g3cswkx,ijblh0,Ok fair enough. I am an uber noob with all this anyway,1.0
g3drnoa,ijblh0,"I just use Google Colab and it works great, or SageMaker if I'm on AWS. But yeah Nvidia drivers on Linux are trash. Guess using Docker might make it easier, and then you have an ephemeral container to use.",3.0
g3fy1r5,ijblh0,"&gt; But yeah Nvidia drivers on Linux are trash.


That's just not true ...",1.0
g3ggi2z,ijblh0,Which part?,1.0
g3cxae2,ijblh0,"The only time I have ever had an issue install TensorFlow was with the GPU version on my laptop in Linux. If found a simple process that allows it to be installed easily and I made a post about on reddit.

Unfortunately I'm just in the process of moving but I don't comment much so if you're interested you should be able to find it in my comments fairly easily.",2.0
g3dey6z,ijblh0,"Tensorflow is a breeze. Getting .tflite models to work is a PITA!

Only ever installed the CPU version but Anaconda is the way to go.",2.0
g3dfmrh,ijblh0,"As a footnote you need to install the correct packages for each version of Tensorflow you use. 

For instance Object Detection requires mostly Tensorflow 1.x to work correctly so you must match the packages you install with this. I know this is changing but matching packages with every version was probably my biggest pain.",2.0
g3ewmic,ijblh0,"If anyone is looking for help with this in the future:

https://anaconda.org/anaconda/tensorflow-gpu",2.0
g3ey5t7,ijblh0,If only there was a native package manager that programs could use to specify their dependencies so everything gets installed with one single command without dirtying the rest of the system,2.0
g3ff6te,ijblh0,That's the main reason why I use the TF+CUDNN docker image.,2.0
g3ctso5,ijblh0,Same here. Wish it just worked well in nodeJs,1.0
g3ez6xo,ijblh0,"Because Python dependency packaging is for some reason much less robust than similar systems, and Tensorflow is big and clunky.",1.0
g3fy3zf,ijblh0,"Never had a problem with Tensorflow.

With bumpy on the other hand ....


But I was always due to not upgraded setuptools or missing headers. Which I consider to be my fault.",1.0
g3g0p14,ijblh0,"Even the guides in their own website are outdated. I wanted to insatll 2.3.0 gpu module, it took me a good time to realize that python 3.8 does not read the path! In website it just says add this stuff to path",1.0
g3bpueq,ij7b8j,"I am the developer. It is pretty rough at the moment, any suggestions are welcome.",5.0
g3bru6d,ij7b8j,"adding link here as comment

https://github.com/lsgrep/mldocs",6.0
g3brzx9,ij7b8j,thanks.,2.0
g3i1x7d,ij7b8j,Hi! You can publish your workflow on my new platform if you want: [https://www.alfredworkflows.store/](https://www.alfredworkflows.store/),1.0
g3jdmxq,ij7b8j,"Hi, I did, [https://www.alfredworkflows.store/workflows/mldocs](https://www.alfredworkflows.store/workflows/mldocs). Thanks. Great platform.",1.0
g39kqoi,iix5cp,how are you doing it now?,2.0
g39m9ot,iix5cp,"Right now i just save them as a list which sort of looks like this:

var\_list = \[&lt;tf.Tensor: shape=(1, 1), dtype=complex128,  numpy=array(\[\[1.+0.j\]\])&gt; , &lt;tf.Variable 'Variable:0' shape=(1, 1)  dtype=complex128, numpy=array(\[\[-1.69192745+1.673864j\]\])&gt; ,  &lt;tf.Variable 'Variable:0' shape=(1, 2) dtype=complex128,  numpy=array(\[\[-2.35951903+3.9386028j , -2.24349482+1.71687213j\]\])&gt;,.....\]. 

This is a solution from a previous problem, which gets fed to the loss function, and then to the SGD optimizer.

And if I want to save them into a file, I use pickle.

It seems to be working when run the optimizer function sequentially, but with pool.map it somehow doesn't. It doesn't calculate the loss",1.0
g39mfvf,iix5cp,"you might need a mutex lock, if it is a shared list",2.0
g3bdt4e,iix5cp,"Could you elaborate on it, please? I've never used that before in Pool, or Processes. 

And why is that necessary?",1.0
g3beo37,iix5cp,"https://stackoverflow.com/questions/46101678/atomic-updates-to-variables-in-tensorflow

because different parts of the graph in different thread s might try to update a variable",2.0
g3bj8uk,iix5cp,thanks,1.0
g38hyhn,iih9z6,This could be really cool as a demo for teaching the principals behind machine learning!,2.0
g36danj,iibrcd,That’s trippy af but pretty cool,3.0
g3dsx9k,iibrcd,thanks,2.0
g37fkob,iibrcd,Thanks I hate it,1.0
g3dsykf,iibrcd,with great pleasure :),1.0
g32huq9,ihpyvy,There have been several posts answering these questions in detail over the last two months in the sub.,8.0
g32r0jy,ihpyvy,"A couple of people here have it. 

I wrote my experiences here:  [https://towardsdatascience.com/my-experience-with-the-tensorflow-developer-certification-exam-c75d2d1759de](https://towardsdatascience.com/my-experience-with-the-tensorflow-developer-certification-exam-c75d2d1759de) 

1) The exam is not question-based, rather you're given a problem and a data set and need to score satisfactory on the problem in order to pass. The Syllabus gives some hints on what you can expect. 

2) It was for me, but I had some issues with training on Cuda on windows. I spent more time training than I would have normally. 

3) I work with TF so I already had a lot of experience with it. I'd say I could do it again in about 8-10 days, of which 4-5 are the Coursera course. In the end I did study long enough to be able to dream the syntax and pass with a good degree of certainty. However I didn't get time off work for this so I had to spread it out over a couple of months.

4) I work for a consultancy company that has clients all over Europe. Client puts out a request and we try to see if we can staff a team or a couple of people for a project.  So far I've gotten a couple of more interesting gigs coming up because of it. No raise or anything that's measurable.",3.0
g335h5h,ihpyvy,whats a sample question,1.0
g34bz7l,ihpyvy,whys this downvoted,1.0
g31yqp6,ihpyvy,im preparing myself to take it. So i cannot answer your question but if you're up for it you can stay in touch with me. Like help each other out with this journey. Idk the tensoflow community is not very responsive so when i end up in a problem its a drag. So two brain is batter than one,2.0
g33jnnu,ihpyvy,bro try Daniel bourke's video source it might help you!!!,2.0
g33x920,ihpyvy,[link](https://www.reddit.com/r/tensorflow/comments/hqd0qd/megathread_tensorflow_certification_exam/?utm_source=share&amp;utm_medium=ios_app&amp;utm_name=iossmf),1.0
g33zisc,ihpyvy,"Daniel has this really nice video and it has everything. I would suggest you try it. But apparently they cannot talk much about the exam itself but he shares how he prepared and cracked the test.

[https://www.youtube.com/watch?v=ya5NwvKafDk](https://www.youtube.com/watch?v=ya5NwvKafDk)",1.0
g31zb7r,ihngx5,"I'm started learning TF like 1 month ago, so i'm not a expertise, but i would recommend you to start with: Aurélien Géron - Hands-On Machine Learning with Scikit-Learn, Keras, and TensorFlow_ Concepts, Tools, and Techniques to Build Intelligent Systems-O’Reilly Media (2019). This book explain very begginer concepts so it's very helpfull.

And also, be aware of wich TF version are you learning becouse there are significant differences between codding with TF 1.x and TF 2.x.",3.0
g317y12,ihngx5,"I configured tensorflow recently in Anaconda and got it up and running. I watched below 2 sessions which gave me a good idea. 


TF workshop 1
https://www.youtube.com/watch?v=F_uuqfgdZZw 
TF workshop 2
https://www.youtube.com/watch?v=eohgFfioP-8&amp;t=167s",2.0
g32eawt,ihngx5,try  [https://www.freecodecamp.org/learn](https://www.freecodecamp.org/learn),1.0
g3pxgz0,ihlqp8,"Autoencoder is symmetrical, so you can get same input as output if your latent space is not even. I mean if you get odd feature map size after every pool layer, it is going to suppress size of 1 at least which causes not to get both input and output of same size.",1.0
g30njcl,ihjsyb,"cool.

learning tensorflow is a good first step.

check your favorite web search engine.

find a teaching method that favors you.

you will then be on your way to learning tensorflow",5.0
g315sne,ihjsyb,Can Someone Also Specify Any Courses Or Books To Learn Tensorflow,1.0
g31a1e1,ihjsyb,"TF workshop 1
https://www.youtube.com/watch?v=F_uuqfgdZZw 
TF workshop 2
https://www.youtube.com/watch?v=eohgFfioP-8&amp;t=167s 

I watched the above workshop and started executing his jupyter notebooks in GitHub",1.0
g2zkihu,ihdg7o,"Might help to share a (simplified, if necessary) notebook.  Given a reasonable model structure, I would probably start looking at the labels first.  Do you labels match the output structure? Have they been one hot encoded? etc.",2.0
g3pj5ms,ihdg7o,"So some of my labels are 0s and 1s, my output is 0-3, and there’s one feature where its countries and I’ve labeled from 0-10. I think this could be my problem when I feed them in to my network.",1.0
g2zzo3j,ihdg7o,"0.25 feels like the accuracy when basically it is just guessing.

Nan comes from missing data usually",1.0
g302ngm,ihdg7o,make sure your dataset doesn't have missing/nan values in the first place,1.0
g3046ux,ihdg7o,Also check if there are no nan values produced in the preprocessing of your features. For example by division throuh 0 or log of 0.,1.0
g30984t,ihdg7o,Try decrease your learning rate,1.0
g2yvi41,ih7b0q,"Adam optimizer has a state (it keeps track of 1st/2nd moments). When you restart the training (recompile the model, etc.) it start with a fresh/new Adam optimizer.",5.0
g2zrmse,ih7b0q,"I know, in fact in Pytorch one has to checkpoint also the optimizer. My understanding was that on the other hand when I checkpoint a model in keras Adam 's state is automatically saved. Isn't it true? When I call model.load_weights(..) am I not also loading the weights of the Adam optimizer?

And if the state of Adam gets discarded, is there a way to checkpoint Adam too? Should I use load_model instead of load_weights?",1.0
g2yd0z5,ih7b0q,When you call fit again the epoch gets reset to 0 again. If the learnig rate scheduler uses the epoch it also begins from start. You can set the inital epoch in the fit method. This way you could start at the point where training stopped and the learning rate should also be right then.,3.0
g2yfxga,ih7b0q,"Yes, I forgot to mention that I set the initial epoch to the one of the last checkpoint",1.0
g2yhoh7,ih7b0q,Could it be that the cycles maybe still get shifted?,1.0
g2wtzbr,igxey2,"Is this on mobile?  Why do you want to use TFLite?  


If you convert your TFLite model to ONNX format (or back to .pb), you could use something like [ML.NET](https://ML.NET) to run inference on it: [https://github.com/dotnet/machinelearning-samples](https://github.com/dotnet/machinelearning-samples)",2.0
g2wpptd,igx22q,"The Ubuntu 20.04 Python 3 version is 3.8.

If you look at the Tensorflow 1.13.1 wheels available at PyPi (https://pypi.org/project/tensorflow/1.13.1/) you can see that they don't have that version available for Python 3.8.

If you want to install Tensorflow 1.13.1 on Ubuntu 20.04, you need to first install Python 3.7 + pip, and use that to then install Tensorflow 1.13.1.

I recommend https://github.com/pyenv/pyenv",3.0
g32qu96,igx22q,Thanks very much - resolved my problem!,1.0
g34ehyw,igx22q,Great.,1.0
g2vqs31,igktx5,"Are you asking how to implement a RNN? Or you want to understand how to use a RNN? 

Tensorflow is a tool, and understanding how to use it is different to understanding the theory behind NN.",1.0
g2vy81g,igktx5,"I am asking which aproach should I take. I read that you can use RNN for Time-series predictions? (Stock market etc), would it be appropriate for my case?",2.0
g2wfqca,igktx5,"So as far as I know you can use tensorflow.js which might be very convinient since you already know JavaScript and yes you can go for an RNN based solution as ETA depends on the previous path as well.
Two popular RNNs are LSTM and GRU and tensorflow.keras.layers have direct callable modules for the same.
The docs are pretty well made so you might wanna check that out.

Bonus** Tensorflow.js allows in-browser computation so hosting it if you want to will be pretty easy as well.",1.0
g2wioz7,igktx5,"Ok thanks, just a little confused about the beginning of your comment, i can’t use tensorflow.js? What should I use?",2.0
g2wm003,igktx5,Aaah sorry typo ...I meant you can use it 😅,1.0
g2tnvbe,igcsun,"I'm biased, I know, because I teach them, but the Coursera specializations ""TensorFlow: In Practice"" and ""TensorFlow: Data and Deployment"" are pretty good. For more advanced stuff I'm working on another specialization coming out before the end of the year.  


For a taste of what they're like (particularly at the beginning) check out my 'Machine Learning Foundations' short course that I published on YouTube.",5.0
g2tp6sz,igcsun,Do you want to disclose what advance specialization we might expect :P,1.0
g2tr8a8,igcsun,"Sure -- it'll go into the functional APIs as well as stuff like extending keras, building your own layer types, loss functions, optimizers etc.  


Then it'll pivot to some more advanced Computer Vision than in the CNNs course, and if I have time, dip into some more generational AI with GANs etc.",4.0
g2tskpe,igcsun,"Wow, sounds exciting. Looking forward to it.",1.0
g2u3xwp,igcsun,"Hands on machine with scikitlearn keras and tensorflow by Aurelien Geron is an amazing book which covers deeplearing, tensorflow and keras in great detail. Be sure to get the second editon tough since the first edition only covers tf 1.0.",2.0
g2u7bj2,igcsun,"I am just like you, new to Deep Learning. I also went through some ML courses (IBM Cognitive classes). I am now doing the ""TensorFlow: In Practice"" coursera specialization (tought by @Laurence_Moroney)...
I can't compare with other courses out there but I know one thing, it got me into the practical stuff right the way!
I had to google few things every now and then, but I am glad I came across this specialization. Recommended :)",1.0
g2suxsh,igbw6e,"This is likely not the best method but I'll toss it out there simply as an option.

You can use Lambda layers to create layers that do what you want. In this case, you can use them to split up the input into chunks. Specifically,

sub_section = Lambda( lambda x: x[:,start:stop] )(giant_tensor)

You can then use a dense layer on each sub_section,

dense_result = Dense(num_dense_nodes_1)(sub_section)

Repeat this for each sub_section of the giant_tensor. Then you'll need to concatenate all your dense_results together,

dense_results = [dense_result_0, dense_result_1, dense_result_2, ...]
concatenated_results = Concatenate(axis=1)(dense_results)

Then you can finish off with some dense layers to analyze everything together,

result = Dense(num_dense_nodes_2)(concatenated_results)
outputs = Dense(num_outputs)(result)

Define your model and compile,

model = Model(inputs=giant_tensor, outputs=outputs)
model.compile(loss=loss_fn, optimizer=optimizer_fn)

You can use this method to create custom NN with any shape or using any layer types that you need. Upon completion you can run model.summary() to get a summary statement of you model. You can use for-loops to create all the initial lists and just tell it the size and amount of overlap for the sub_section tensors. You will need to reduce the size of the your array by making num_dense_nodes_1 smaller than the gap stop-start (the length of sub_section) or else when you concatenate your results you will end up with the same issue. (I don't know why you want to conserve the shape through the network but that might be a bit of a challenge given your input size.)",2.0
g2tnofu,igboh2,"The TensorFlow community site is a good place to start :)  


[https://www.tensorflow.org/community](https://www.tensorflow.org/community)",7.0
g2so2e7,igboh2,Also interested in this answer lol,19.0
g2syeol,igboh2,"There's no single community where people hang out. TF has a lot more (60k) posts on SO than PyTorch (18k). So that's there. 

People also post stuff here so feel free to post questions here.",6.0
g2t1ooa,igboh2,"Listen harder the framework is the questions are more, so it doesn't mean people who use TF are more than PYT users.",-3.0
g2ta4aj,igboh2,Maybe try a little better to explain what you're looking for instead of asking others to listen harder? ;),9.0
g2teg4w,igboh2,"&gt;Listen harder the framework is the questions are more, so it doesn't mean people who use TF are more than PYT users.

To be fair, it seems like this was supposed to read

&gt;Listen, the harder the framework, the more questions there are. So, it doesn't mean people who use TF are more than PYT users.",8.0
g2th6uf,igboh2,"Ah, fair enough.",4.0
g2txeb1,igboh2,"&gt;rk, the more questions there are. So, it doesn't mean people who use TF are more than PYT users.

yeah sorry for commas :D",2.0
g2sujch,igboh2,"What's the PyTorch site?

Also, reddit is a bad place to get meaningful help.  Sometimes you'll get lucky, but reddit is better for sharing articles and having ""discussions.""  Stack Overflow is a much better resource, but you're never going to be guaranteed to get answers to your questions there, either.

As far as TensorFlow having a bigger community than PyTorch, I've heard the opposite.  Regardless, a community doesn't necessarily mean a bunch of people ready and willing to answer questions regarding the library.  It usually means more developers are working on or with the library (which, obviously, can result in more answers for questions, but it doesn't necessarily imply that).

I'll add that I haven't come across the issue your describing, personally.  I've either been able to find the answers I need or figure it out myself without much trouble.  But between the drastically different versions and the pace at which the field evolves, you're bound to have a hard time getting directed answers for library-specific questions.  If you need such answers and PyTorch provides the environment to facilitate that, then you should consider switching, cause TensorFlow isn't gonna get anymore user-friendly anytime soon.",7.0
g2t1zbj,igboh2,"yeah but i am forced to use TF, we use it for production so i have no choise. personally i use Pytorch,",0.0
g2vx8ml,igboh2,There is one on google groups,1.0
g2wagwq,igboh2,You can find way more questions with Tensorflow tags on Stack Overflow.,1.0
g2xdadk,igboh2,"are you kidding me? you should know stats if you are in Deep learning. First, of course Pytorch has it's own website that is where we post answers(btw i guarantee you will get answer in less than a 6 hours), and if framework is hard the more questions appear, it is natural, is it doesn't imply theat Tensorflow has many users compared to pytorch.",1.0
g2so0xi,igbcwi,"Did you get all the “cuda” library files put in the right spot to activate gpus?
Edit:to",2.0
g2sxy84,igbcwi,"Yes, the GPU are definitely activated. This is what it says when I intialize the device strategy:

    INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:0', '/job:localhost/replica:0/task:0/device:GPU:1')

Also they jump from \~0% load to the aforementioned 10-20% when the model is fitted which wouldn't happen if they weren't utilized",1.0
g2uiizw,igbcwi,You may be using a different environment than what to gpus may be configured to,1.0
g3g9zvn,igbcwi,No it's the correct one. They're def active,1.0
g2u58ym,igbcwi,"Not an ideal solution, but could you pass the GPUs through to a VM (iommu dependant) and use them in Linux, where these things are usually easier?",2.0
g2ryi03,ig6tiv,"cringe is passable, right?",3.0
g2s4nus,ig6tiv,"Might be easier if you use image segmentation to extract shoulder and head points to calculate the angle between them.

You can also try to adapt the pose estimation API from TensorFlow, using [this](https://youtu.be/nUjGLjOmF7o) as a help.",1.0
g2s50ya,ig6tiv,"Thanks, I am looking into it",1.0
g2rcjvl,ig3593,"My understanding here is very shallow, but I thought MLKit was for hosting models via API that were properly load balanced and versioned. Essentially it's for deploying models that you still expect to run in proper containers, rather than in TFLite where you are actively transforming the model to make it run natively in the browser.

I may be completely wrong about this as I've never used either. I've only seen a couple talks/YouTube vids on these tools.",2.0
g2tm6od,ig3593,"ML Kit is not a replacement for TensorFlow Lite, and in fact uses TensorFlow Lite under-the-hood. It's a terrific way to get started with using pre-built models with a friendly programming API.  


When you want to get a little deeper and build your own models, you can use TensorFlow to train them (or transfer learn from existing models in TensorFlow Hub) and then convert them to TensorFlow Lite format.   


At that point you can either use the tflite model directly in your app, or via ML Kit, whichever way suits you better :)  


So it's not that they should be compared -- it's more that they can be used to complement each other :)",2.0
g2tmyeh,ig3593,"Thanks for the insight. Interestingly, I'm doing your course on TensorFlow Deployment (deeplearning.ai).

Been an amazing experience till now!
Thanks for that too :')",1.0
g2tnzv4,ig3593,Thanks! :) Glad you're enjoying.,1.0
g2q5m4p,ifpv1u,"Tbh I am not impressed. I think you took the opposite approach of what a tutorial should be. It's like you took the simple Tensorflow documentation examples, and plugged them into your own classes, which makes it more complicated to jump into and customize (especially with the Matplotlib part), without compensating by offering more explanations. 

I think a tutorial should be either minimal, like the Tensorflow documentation, or very well explained.",4.0
g2xkifk,ifok7d,"Interleave is just a way of iterating through your dataset while applying a map function, but it can work on many datasets or data files concurrently. See https://www.tensorflow.org/api_docs/python/tf/data/Dataset.

Shuffle does what it implies :)",2.0
g2n1llq,ifddc7," [https://automatetheboringstuff.com/chapter18/#:\~:text=Clicking%20the%20Mouse&amp;text=click()%20method.,than%20the%20mouse's%20current%20position.](https://automatetheboringstuff.com/chapter18/#:~:text=Clicking%20the%20Mouse&amp;text=click()%20method.,than%20the%20mouse's%20current%20position.)",1.0
g2n2lfw,ifddc7,Thank you :) do you know if this sort of method can be used with Tensorflow so I could only click on identified objects though?,1.0
g2n3k7u,ifddc7,"Yes, you can. I browsed through the post but if your example is using opencv and TF you can use the center coordinates of the predicted bounding box to determine where you need to click. You might need to add an offset to account for the screen being larger than what tensorflow is seeing, but it should be possible. I'd say its probably easier to do in Python than in Java.",1.0
g2n4tya,ifddc7,"Awesome :D  thanks, I appreciate it",1.0
g2m40ai,if90gu," Two. Just add a Dense Layer with one node and linear activation function as the final layer. The usual loss function for such a regression problem would be the mean squared error.

 Three. Yes, just set batch size to 1.",5.0
g2m4xwd,if90gu,Thanks !,1.0
g2n4ja8,if90gu,"1. `import tensorflow.keras as tf` in Tensorflow 2.3 to access Keras models. (You only need to install tensorflow, either the cpu or the gpu version, no need to install Keras with pip).",1.0
g2ms4zb,if90gu,You could rescale a sigmoid output to strictly get outputs between a range,0.0
g2kvl1x,if202m,"it will work, but the 6GB VRAM might mean a large model just won't fit into memory as opposed to the 24GB of the Tesla K80 used by colab.",10.0
g2kxazm,if202m,"Thanks for this. I'm working with Android .tflite so I could maybe separate my models according to category and get my users to download what models they need (plus it could be a way to monetise anything I create)

Thanks for both answers. I haven't a bigger budget atm. I had a feeling it was suitable but I didn't want to spend and then discover it wouldn't work.",3.0
g2kzddv,if202m,I managed to train a 400MB transformer on an 8GB GTX1080 by using a small batch size so I think you should be fine if the models are small enough to be runnable on mobile.,2.0
g2ktbid,if202m,Every GeForce card by Nvidia support Cuda.,7.0
g2kxbmz,if202m,Thank you.,3.0
g2ljnbu,if202m,I'd advise you to go for a 2060 (6gb)/2060 super(8gb). And ig there are tensor cores in the 2060 and not in 1660ti. You can practically double the memory by using mixed precision.,5.0
g2lsbwz,if202m,"That's thrown a spanner in the works!

I know nothing about graphics cards but price is an issue. I've been told I won't get a better card for the price.",2.0
g2lsolp,if202m,"I think a 2060 super will cost about $100 more than the 1660ti (don't quote me on that tho), but will offer significant speedups while training.",1.0
g2lthu4,if202m,"Spotted the graphics card on a deals website so not so sure whether that will be true.

I know for £60/ $100 more you get a 100% improvement but I have a budget. You definitely have thrown a spanner in the works though as I was purchasing tomorrow.

Thanks for the feedback though, I really appreciate this.",1.0
g2mkskl,if202m,"Get a nvidia gpu with tensor cores (2000 series) preferable with as much vram as possible or wait for the new generation that is comeing very soon( prices of current gen  2000 series RTX Turing will drop a lot)

1660 is a great and best value GPU currently on the market but for gaming.If money is big issue go for second hand 1070 or 1080 with 8gb",4.0
g2pd836,if202m,"Thanks but I've noticed 1070's and 1080's are almost double the price, even used are coming up at £100 above my budget. I'll maybe hold off and see if something comes up on a second hand site like Gumtree.",1.0
g2s8ayu,if202m,prices will not drop. 3000 series will start at a higher price.,1.0
g2ldgl8,if202m,Make sure the GPU isn't overheated and you use good PSU,3.0
g2lfr7h,if202m,"Thanks, I think the PSU I bought was overkill so should be fine although I need more cooling in my build. Thanks though didn't consider this. I've never been a gamer so never had the need for a GPU (that's why I went for the 3200g chip as the graphics are on board it.) I know nothing about them :)",2.0
g2km2xs,if17h0,"You can have only one system-wide CUDA version afaik. As a result, if thats for TF2, it wont work with TF1. I would suggest using conda to install tensorflow, since it installs cudann and Cuda toolkit in the environment itself. Thus, you can have different versions of Cuda in different envs for diff TFs.",2.0
g2kmj7b,if17h0,"Yeah that's what I normally do, use conda to install everything including cudatoolkit and cdnn. 

But it started giving error saying it couldn't find the lib files for running in GPU. Which is kinda of weird. I also had as well the CUDA and CDNN installed manually , so I don't know if that created some issues.",1.0
g2l8exo,if17h0,"Yeah, might be worth to try without the system-wide Cuda, since it has already been added to PATH.",2.0
g2klxe2,if0vrv,The output of that fully-connected layer is one unit.,2.0
g2km0qw,if0vrv,"A dense layer means that all the nodes of the previous layer will be fully connected (the weights) to itself. So your Dense(1) layer only has one node, with 9 weights attached to it. If you were to have a Dense(2), you would have 2 nodes with 9\*2 weights connected to them.",2.0
g2knno2,if0vrv,"Thanks. A related question -- if I do have Dense(1) I essentially lose all information of the input layer, right? Hence why it is better to have more than one node?",1.0
g2knzmm,if0vrv,"Well, I would not say lose, but rather ""condense"". That's the objective of neural networks, the more deeper the networks are (more layers) the more abstract the information of the input gets along the way.

In relation to have 1 or 2 nodes, it really depends on your objective. But in a very general perspective, yes you can consider that you retain more information of the input with 2 nodes.",3.0
g2ku4fw,if0vrv,"But if I just have a very deep network with all of the hidden layers having only one node each, then that wouldn't be any better of just having one layer with one node, right?",1.0
g49z16v,if0vrv,"Yes, imagine f(x) = 2x + 3, g(x) = 8x + 1... Then: f(g(...(x))) = ax + b, you can't get a more comlex form. This is also why we use random init. for the weights. If all weights were to start at the same value, we would encounter the exact same problem.",1.0
g2km3kr,iex39j,"Have you tried setting a random seed? Also, write and run the model using two different Python scripts or notebooks?",2.0
g2kmw32,iex39j,"I've used both fit() and custom generators (a lot of times) to train my models. I have never experienced **significantly** differences. But my guess would be it all has to do with the randomness of the data being fed to the model. Especially if your dataset isn't big.

When your dataset is big (MNIST, Imagenet big) the randomness is less important. Since there is so much data, the model will converge the expected performance value.",1.0
g3hqeha,iex39j,"https://github.com/tensorflow/tensorflow/issues/37581#issuecomment-683922948

The `dataset.zip` is running two independent shuffles.",1.0
g2k83fy,iew324,woooo,1.0
g2kjeqy,iew324,It is not implemented in TensorFlow...,1.0
g2io0m1,iepmoe,I think maybe masking is what you are looking for?,4.0
g2ipzdo,iepmoe,So basically train it to predict the output function and pull out the outlier in the sentence?,2.0
g2ilrze,iepjp4,You could use the tensorflow Dataset API for this. Or you write your own data generator function https://stanford.edu/~shervine/blog/keras-how-to-generate-data-on-the-fly,10.0
g2j1v85,iepjp4,"Ah, that looks ideal! Thanks for the help!",1.0
g2jhmtr,iepjp4,Use the cloud ? Try google cloud - bigquery for dB and and gogle colab for modeling. Cost will be negligible,2.0
g2jopz9,iepjp4,Sframes,2.0
g2eg6ba,ieallh,"https://www.jetbrains.com/help/pycharm/installing-uninstalling-and-upgrading-packages.html

Make sure Keras is installed.",1.0
g2e2lm9,ie763v,"&gt; time series forecasting with feature columns or using time series forecasting just with categorical data?

Regardless of the implementation you need to convert the categorical to a 1-hot or a vector. Once you've done that you can concatenate them into your feature vector, and use any other timeseries tutorial.  (Unless you want to make an explicit Markov chan model)

`feature_columns` are really unfriendly, and are even less friendly about sequences.

I would have a look at using these two functions to do the conversion from ""a sequence of class IDs"" to a ""sequence of vectors"":

https://www.tensorflow.org/api_docs/python/tf/keras/layers/Embedding
https://www.tensorflow.org/api_docs/python/tf/one_hot

Also these [experimental!] layers that handle all the feature_column functionality in a much more direct way:

https://www.tensorflow.org/api_docs/python/tf/keras/layers/experimental/preprocessing/IntegerLookup
https://www.tensorflow.org/api_docs/python/tf/keras/layers/experimental/preprocessing/StringLookup
https://www.tensorflow.org/api_docs/python/tf/keras/layers/experimental/preprocessing/Hashing?version=nightly
https://www.tensorflow.org/api_docs/python/tf/keras/layers/experimental/preprocessing/CategoryEncoding
https://www.tensorflow.org/api_docs/python/tf/keras/layers/experimental/preprocessing/CategoryCrossing?version=nightly

But I don't know how/if they handle the extra dimension added by the sequence.",1.0
g2d37zc,ie49a7,"Why not? Tensorflow does not care about the source of the dataset.

You can download data from whichever type of source file you want, CSV, xlsx, image files with a custom data loader. Your custom data loader then converts these to numpy arrays which you can then push through a tensorflow neural network. iirc, this is routinely done with the MNIST dataset for digit recognition.",4.0
g2da4cl,ie49a7,"Yeah thought so, realized that’s the biggest benefit  of tensorflow",1.0
g2dcv9g,ie49a7, [https://www.tensorflow.org/tutorials/keras/regression](https://www.tensorflow.org/tutorials/keras/regression)  gives an example of reading a csv file with pandas for use as a Tensorflow dataset.,3.0
g2dmcfn,ie49a7,THANKS!,1.0
g2dfc7e,ie49a7,In CS nearly everything is sooner or later a number. So yes!,1.0
g2bm62a,idvfny,"Just ran into something similar yesterday! Check that you are using CUDA 10.1. In our case we had 10.2 installed, so the cudart dll file didn't match up with what tensorflow was looking for.",1.0
g2bpcl8,idvfny,"Thanks for your answer, sadly I have 10.1 installed :/",3.0
g2bpy7r,idvfny,I got this error when I didn't have the --gpus all flag set. I'm afk but think that's the correct command,1.0
g2cd8qc,idvfny,Where should i type this?,1.0
g2cyb4n,idvfny,"are you running it in a docker? I have a Ubuntu/NVidia setup and use the following in terminal:

    docker run --gpus all -it -p 8888:8888 tensorflow/tensorflow:latest-gpu-jupyter jupyter notebook --notebook-dir=/tf --ip 0.0.0.0 --no-browser --allow-root --NotebookApp.allow_origin='https://colab.research.google.com'",1.0
g2bwx9m,idvfny,"Did you make sure to completely uninstall any instances of cuda before reinstalling using their guide? Are you windows or Linux? Are your drivers fully up to date?

(I JUST got this working on my Ubuntu setup a couple days  ago after many hours of struggle)",1.0
g2ccy73,idvfny,"I m using windows, and yes I did all of these. Congratulations on getting rid of this torture !",2.0
g2cjduo,idvfny,"If you are using Conda, you might just use conda install tensorflow-gpu.TF-Gpu needs Cuda to run on GPUs, and the most common source of issue is that people have a wrong version of Cuda installed that is incompatible with the TF version that he/she installed. This is common for people who use the system-wide installation of Cuda and then install TF using pip (I also did this when I first jumped into ML).

You can use conda to install TF-GPU. The advantage is conda itself provides the appropriate CudaNN and CudaToolKit along with TF. So you don't need to install Cuda separately.

Another advantage of using conda is that, you can have separate TF/PyTorch/Cuda versions in different environments and they'll work perfectly.

Refer to this (My Doubt when I first discovered this stuff):-

[https://stackoverflow.com/questions/59529804/nvidia-cudatoolkit-vs-conda-cudatoolkit/59940352#59940352](https://stackoverflow.com/questions/59529804/nvidia-cudatoolkit-vs-conda-cudatoolkit/59940352#59940352)",2.0
g2ck6bb,idvfny,"Sadly I try to use it without conda, tried to use conda but it seemed mode complicated than what I will code on tf :/

I may turn to conda when I am out of ideas, this sure will be valuable then. Thanks !",2.0
g2d33fb,idvfny,"This is fine if you're doing your own setup, but I first tried setting up my environment with conda, and it worked great...until I tried downloading the most recent TF2 Object Detection API. You have to use pip to install their tools and their buildwheel overwrites tons of your local libraries. You'll end up with TF2-GPU installed through Anaconda with one version, and regular TF2 installed through pip with a different version. Anaconda freaks out and if you try to retrain any models from the object detection API, TF-GPU just won't work. I made a post about it [here](https://stackoverflow.com/questions/63493682/is-there-a-way-to-use-the-new-object-detection-api-for-tf2-with-anaconda-on-ubun) on StackOverflow, and nobody has any ideas.

In short, Anaconda can make your life a lot simpler...until you're forced to use pip to install conflicting libraries. Then it becomes a nightmare",2.0
g2d7pv8,idvfny,"Yeah, I have experienced this issue somewhat on a smaller scale though, while trying to get trt\_pose work. I failed to get it working, mainly for other reasons, but my takeaway was that to avoid using pip and conda together to install closely-related stuff.",3.0
g2e3mvg,idvfny,Definitely,1.0
g2c0m0o,idvfny,"Follow ma steps it should help u out, [Deep learning setup](https://github.com/rexdivakar/Deep-Learning-Setup)",1.0
g2cdwsx,idvfny,"Thank you for replying, will try this out!",2.0
g2cdlui,idvfny,I experienced the same problem. I have a solution if you can afford to not use the gpu. Uninstall the gpu version of tensorflow and install the normal version. An error will show up but the program will work.,1.0
g2beuff,idslny,TF2.0 uses Keras as default High Level API. I am not sure but i think they dropped support for their own high level API because of Keras. You better Use Keras as high level API,2.0
g2bi9e2,idslny,"https://www.tensorflow.org/api_docs/python/tf/keras/layers/MaxPool2D

MaxPool2D is a Keras function",1.0
g2dfwfm,idslny,"I think that is what aiproshar is saying. MaxPool2D is a Keras function, tf.nn.maxpool(2d) is tf's own function. They take the same arguments and are doing the same thing, except that tf.nn.maxpool can take more than 2 dimensions.",1.0
g2dnlqc,idslny,"Ah, thank you. I misunderstood since I don't know the functions too well.",1.0
g2956qr,idh1oz,"Disclaimer: I didn't read anything and I am just guessing.


Google Colab will cover you.",3.0
g2a7j52,idh1oz,"It wont because for the certification you have to use pycharm. I tried googling to see if the graphics card in the computer I posted was up to spec, but I do not see anything that list the number of gpus.",1.0
g8koztb,idh1oz,how did you go around using GPU with TF2.0.0??,1.0
g29zd9w,idh1oz,"Only google colab will cover you. For extra precaution, and for peace of mind, you could buy Google Colab Pro for a month which costs only $9.99. What is more important is making sure your PyCharm environment, tensorflow package, and everything is installed and loaded well enough.",1.0
g8koykc,idh1oz,did you really need GPU to finish the exam? I can't get TF2.0.0 (the exam's version) to use my GPU (compute capability = 5) no matter what...not locally nor using Google Colab! (if I set TF there to be 2.0.0 I can't get GPU)...any suggestion please?,1.0
g287quo,idbq6o,"I've never even heard of a [Tensorbook](https://lambdalabs.com/deep-learning/laptops/tensorbook), but it looks like an incredible waste of money.

I'm curious, why have such an overpowered laptop for deep learning?  Wouldn't you rather invest that money in a proper server which you could access from a cheaper laptop?

As far as your experience with their customer support: that's a shame considering how popular Lambda seems to be.  But I also find it odd that one would need customer support for this.  What exactly do you need customer support for?",2.0
g28btng,idbq6o,"i live out of country so the specifics in terms of ordering and shipping to my country require additional inputs from their side.

server based ML adds up quick in terms of costings and there is diminished returns after barely a few months. plus living and working on the move mea s im not always in areas with stable net connection.",1.0
g28g853,idbq6o,"&gt;i live out of country so the specifics in terms of ordering and shipping to my country require additional inputs from their side.

Damn, then that really sucks.  You basically paid premium for that kind of support.  I'd definitely be upset enough to raise the issue, however possible.  


&gt;server based ML adds up quick in terms of costings and there is diminished returns after barely a few months. plus living and working on the move mea s im not always in areas with stable net connection.

I'm not suggesting using cloud resource (although it is a fair option), but rather to buy/build an on-premise server.  I mean, Lambda specializes in that, but I wouldn't even bother considering how much cheaper it would be to build one yourself.",1.0
g28dwka,idbq6o,what kind of a system would you reccomend,1.0
g28h2ca,idbq6o,"Instead of a $3k laptop, you could have spent $2.5k on a server and $500 on a decent ThinkPad (or whatever floats your boat; I even experimented with using a $200 chromebook which worked reasonably well).

I built a server which initially cost \~$1.2k for deep learning, and I built it so that it was easily extensible.  Since buying it (about two years ago), I've probably invested another $1k in it, and it's been nothing but upgrades, no replacements (another GPU, more RAM, another SSD).

I have the server hardlined into my router at home.  I can access it from anywhere as a result, but I can also access it locally if I'm on the same network.  Of course, I can also access it from any machine, so I don't need a dedicated laptop or anything.  I've even used my phone to monitor training and make small adjustments to scripts and stuff.",1.0
g27lkg8,id94gn,"I created a mega thread for the certification, it is one of the pinned posts in this subreddit, you are welcome to check it out",4.0
g29kn5f,id94gn,Thanks.,1.0
g27icgc,id94gn,how much does it cost,1.0
g29kw78,id94gn,100 $,1.0
g27jafy,id94gn,yes,1.0
g27p84n,id94gn,Me too,1.0
g27qi9n,id94gn,"I am preparing right now, gonna be hard work but I’m willing to put in the time, there is no rush too take it when your ready. I suggest getting the hands on machine learning Keras,Tensorflow, Scikit Learn book by Aurelian Geron take notes and make sure to practice. Also if you go on tensorflow a website and go to the learn section, they have outlined a bunch of resources for you to use to learn tensorflow. There’s a free UDacity course as well as some other ones. And also if u want to, look at the math concepts if u want a truly deep understanding. But none of this matters unless u practice with your own projects which I have to start doing",1.0
g28h3vs,id94gn,Me please xd,1.0
g29avba,id94gn,"Yeah, preparing!",1.0
g28nq2j,id7a0r,"It looks like you are overwriting x on every line.

Try adding stuff sequentially

&gt; model = keras.Sequential( [
&gt; 
&gt;  keras.Input(shape=x_train[0].shape), 
&gt; 
&gt;  layers.Conv1D(32, kernel_size=(3, 3), activation=""relu""),
&gt; 
&gt;  layers.Dense(num_classes, activation=""softmax""), 
&gt; 
&gt; ] )",1.0
g267qbu,icmh64,"The future requires Data Rights.  
(and meta-data rights, and meta-meta-)",1.0
g23fdes,iclxnv,"There's a lot of misinformation in these comments. First of all you don't absolutely need a new laptop, you can run tensorflow on a gpu in Google colab if you wanted from your current laptop.

With that said, yours is definitely becoming a bit dated. Still, the other guy definitely oversold you. 8gb ram and an i5 is plenty, any really heavy lifting you might need do could be done remotely with something like Azure or AWS.",20.0
g23g18o,iclxnv,"A somewhat unrelated doubt. If I later go on to give the tensorflow developer exam by Google, would I need a GPU? Google officially doesn't suggest any requirements and says it trusts the developer's choice/maturity.",3.0
g23hirr,iclxnv,"[Setting up your environment to take TF Developer Certificate Exam](https://www.tensorflow.org/site-assets/downloads/marketing/cert/Setting_Up_TF_Developer_Certificate_Exam.pdf)

Yes, according to this that exam runs in PyCharm and will require a GPU. PyCharm is also kind of memory intensive as a heads up, but still you should be fine with an i5 and 8gb ram as long it has a GPU.

&amp;#x200B;

That being said there is quite a decent [sized skills checklist](https://www.tensorflow.org/site-assets/downloads/marketing/cert/TF_Certificate_Candidate_Handbook.pdf) recommended before taking that and if you really don't want to upgrade immediately you don't have to and you can take the 2 courses you posted from your current laptop.",4.0
g23hom9,iclxnv,Great. Thanks a lot!,1.0
g23ui8w,iclxnv,"I saw Lenovo was having a huge sale on laptops on eBay yesterday, give it a look",2.0
g23z3zk,iclxnv,Thanks. You shall have your video card.,2.0
g23e4cp,iclxnv,"Do these courses mention any hardware requirements? I noticed Google Colab mentioned, so probably at lease some course material will be run in cloud. Usually ML courses work with simple models and small data sets. Also TF can be run without GPU acceleration. I have taken some on-line ML courses and never had any need for significant computing resources.",2.0
g23ft8g,iclxnv,No it doesn't mention any hardware requirements. Is Google colab a good alternative?,1.0
g23ju09,iclxnv,Yeah it's great although there are other alternatives with better GPU like kaggle but I think colab when paired with drive is good starting point for Freshers like us,1.0
g27ur9x,iclxnv,"iv done bith those courses training on my asus g75vx with a i7 from 2013. at the end of the day your learning stuff, bot actually training for deployment or work, so dont worry about gpu specs. colab if you want too.",1.0
g23bp7t,iclxnv,"dude there are ton of laptops out there as per your question but what about price?

ok as you asked about it think you go with a laptop which have these configs

\--&gt; I5 (MIN) AND I7 (RECOMMENDED)

\--&gt; 16GB RAM

\--&gt; 512SSD AND 1TBSSD (RECOMMENDED)

\--&gt; GO WITH NVIDIA'S GPU 20 SERIES WHICH ARE 2060(STARTING), 2070,2080 etc",-4.0
g23c1ky,iclxnv,My question was about if I would absolutely need a GPU.,1.0
g23c82z,iclxnv,"bro you asked""would i need a new laptop"" so i suggested it ...and for this question my answer is YES you should",-7.0
g23cave,iclxnv,"Okay, thanks for the suggestions!",1.0
g23bzdh,iclxnv,"A laptop with Nvidia external GPU , preferable pascal architecture(1000 series like 1050 1060 1070 etc.. ) or the best option is turing architecture ( 2000 series like 2060 2070 etc.. but those are expensive.If thats still too expensive you can rent out computing power from amazon aws",-2.0
g22gpj0,icdywx,Try changing the maximum of your bounded tensor spec to to 2 for the action spec leaving the shape and all the same as it is originally.,1.0
g22kpd7,icdywx,"Correct me if I'm wrong but I don't think that will help. Changing the maximum value will allow the action to have a larger value, 1 --&gt; 2. I need 2 actual actions though as I want the AI to drive a car, throttle and steering. I think bumping up the maximum could work if I were simply choosing 1 of a group of options.

I will looking into this more in the morning when I can think. If I'm misunderstanding you please let me know.

I found a tutorial by ""Machine Learning with Phil"" where he specifically builds a network which allows him to have multiple, continuous actions. His implementation doesn't use tensorflow for training, he builds his own process to some degree. This is a bit more into the weeds than I was hoping for the first, test version.",1.0
g22wj9w,icdywx,I believe you are just specifying the num actions and tf agents take care of all the dirty work like one hot encoding behind the scenes. Such that you are just worried about receiving an int corresponding to your prediction. I'll have to confirm and let you know if thai is the case.,1.0
g239lkx,icdywx,"It's probably because you're using BoundedArraySpec rather than BoundedTensorSpec.

I remember having a similar issue",1.0
g23wvz1,icdywx,I just tried tried a BoundedTensorSpec and found that it doesn't fix the error.,1.0
g7au14c,icdywx,"Hi there,

Did you make any progress on this? I'm currently looking at a similar issue (didn't realise initially that the action spec was so going to be so limited in shape!)",1.0
g7azmuf,icdywx,"IIRC, the issue was using the DQN network. This network will not allow you to use a continuous action space, it requires discrete. As a result I had to go with a different type of network.",1.0
g22t7t1,iccfg1,"But why do you need tensorflow? If yours strategy works fine with ML, it doesn't mean that DNN, for example, will work better.",2.0
g23gyqk,iccfg1,"Not saying it will, but I hope it will. I’m willing to put in the investment to try, if not just to learn.",1.0
g27v9wn,iccfg1,DDDDDEEEE EEEMMMMMMMDDD YOOUUUU,1.0
g1ze3vo,ic10dq,"That's a little vague, I've written alot of code in C++ and transferred it to python. So tell us why you need it in C++ and I might be able to help.",1.0
g1ztalj,ic10dq,"I am interested in this as well. We need to perform inference on the pc gpus i.e. cannot use the cloud.
We have very strict performance requirements as this is an online 200 meter/minute production line. All of the code is currently implemented in c++.

Tensorflow lite has a great c++ api. With tensorflow, ever since moving to 2.x (i build from source on windows + nvidea cuda), the SavedModelBundle[Lite] has been running x4 slower than the python prediction...
Would greatly appreciate any insights on this...",1.0
g212fry,ic10dq,"Well, let us assume that I have a model that  I built using Tensorflow Python. That model is used for classification or any another task. If I want to use that model with its weights in C++, how can I do that???",1.0
g27ucaa,ic10dq,"Just check an example how in cpp a model is loaded, and if similar .weights files are used",1.0
g1z7z3o,ic0jmr,"I am sorry if this is wrong since i use pytorch mainly where the tensors follow numpy syntax. There i would do it like this:
TensorName[TensorName==10]=0

I.e. You pass a boolean index tensor and replace all instances where TensorName ==10",1.0
g20b72g,ic0jmr,"You can use tf.math.mod(input_array, 10) since mod supports broadcasting.",1.0
g20byci,ic0jmr,Although using map_fn as you did works for me as well..,1.0
g216fr9,ibwqvt,"Sounds cool! NEAT is a fantastic algorithm. If you haven't already, you should also try to implement HyperNEAT.

Anyways, what is the advantage of using TF for NEAT as it doesn't do any backprop?",2.0
g1yplkg,ibwqvt,I would like to experiment with it. Good job!,2.0
g1zhizj,ibwqvt,Thank you for your feedback! I’ll post an update when the project is ready to be published.,1.0
g1zcwbn,ibwqvt,"Hey, can you pleaee share resources you're using for genetic algorithm. I'm gonna need for implementing my major project",1.0
g1zhe1b,ibwqvt,"What do you mean by “resources you are using for genetic algorithm” and what is your “major project” for? University?

Maybe the [NEAT paper](http://nn.cs.utexas.edu/downloads/papers/stanley.ec02.pdf) would be of some value for you.",1.0
g1zhj9c,ibwqvt,"I mean tensorflow tutorials, docs. By major project I mean my senior year project",1.0
g1zih8s,ibwqvt,"TensorFlow doesn’t have any tutorials (as far as I know) for genetic algorithms, if they had I wouldn’t have needed to create my project...",1.0
g20p3nk,ibwqvt,Sounds great! You have a repo?,1.0
g1ya21x,ibujpy,"CUDA is exclusive to NVIDIA gpus. Unfortunately NVIDIA has effectively monopolized the deep learning gpu market. In recent years AMD has made some progress in getting tensorflow working on their products but it's still subpar compared to NVIDIA. 

Would suggest either buying a NVIDIA gpu or using Google Colab if you want to try out gpu-accelerated tensorflow.",6.0
g1ya7iu,ibujpy,"It's complaining missing CUDA, which is supported only on NVIDIA GPUs. You probably need to install a TensorFlow version running ROCm instead. But AFAIK it's a pretty involved process, and ROCm only runs on Linux.",2.0
g1yal8g,ibujpy,"You can do some searching on OpenCL and fight for hours and you might eventually make something work. But I wouldn't waste my time.

Are you just learning right now? You probably won't run into much where you need GPU acceleration.

You can always run TensorflowJS in the browser :)",2.0
g1ydv8j,ibujpy,"You can use the new DirectML backend from Microsoft.
[I made a video about it](https://youtu.be/KUaj6VQqTgM)",2.0
g1yhfa3,ibujpy,Try kaggle with free quotas on GPU and TPU. Solve all your hardware problems or you can sign up for free cloud credits on major cloud vendors. All you need is a browser and stable internet connection.,2.0
g21gnrr,ibujpy,"i got RX 5700 working on linux with plaidml.

also see here:

[https://forum.faceswap.dev/viewtopic.php?t=562](https://forum.faceswap.dev/viewtopic.php?t=562)",1.0
g286rwt,ibujpy,"If you are running Linux on your machine, you can use AMD's custom version of TensorFlow.

The easiest way to do so is by installing Docker on your machine and running it inside a container. You can find the image here: [https://hub.docker.com/r/rocm/tensorflow](https://hub.docker.com/r/rocm/tensorflow)

Getting a shell in your current working directory inside the container is very easy and can be done in a single command (slightly modified version of the command that can be found in the DockerHub description or the README of the repository):`docker run --rm -it -v $(pwd):/dockerx --network=host --device=/dev/kfd --device=/dev/dri --ipc=host --shm-size 16G --group-add video --cap-add=SYS_PTRACE --security-opt seccomp=unconfined rocm/tensorflow`

Your content is then available inside the /dockerx directory.

If you prefer not to use docker, you'd have to install ROCm on your machine. Then you can use `tensorflow-rocm` from PyPI.

The code for tensorflow-rocm is available on GitHub: [https://github.com/ROCmSoftwarePlatform/tensorflow-upstream](https://github.com/ROCmSoftwarePlatform/tensorflow-upstream).

&amp;#x200B;

I've used this to train some neural networks on a Radeon Vega VII and it works great in the meantime.",1.0
g1x0swd,ibk9vw,"There's nothing wrong with what you've written. 

You can do the same thing reverse for the inverse.

If you prefer keras layers, this sort of thing is packaged into:

https://www.tensorflow.org/api_docs/python/tf/keras/layers/experimental/preprocessing/IntegerLookup

https://www.tensorflow.org/api_docs/python/tf/keras/layers/experimental/preprocessing/StringLookup

Note their ""invert"" option.",2.0
g1wo0w1,ibk9vw,If the labels have ordering use the encoder which does sequentially label one column from 0 to n. If the values aren't related to each other I.e you cant compare value1 &gt; value2 + 3 then you gotta do one-hot encoding or subdivided the column into fewer categories and onehot those.,1.0
g1w48jf,ibf13a,"Those are ""symbolic"" or ""graph"" tensors. These are what tensorflow passes to your code during the `tf.function` compilation step.


https://www.tensorflow.org/guide/intro_to_graphs",1.0
g1yemce,ibf13a,So do you know how to print values of that tensor? how to slice them? K.eval() is not working.also sess.run() is not working too.,1.0
g21xudx,ibf13a,Tf.print will print the value when the calculation runs.,1.0
g22t245,ibf13a,"and do you know how to get those values? i just want to take first 2 values of that vector which has 3 components , third component is redundant",1.0
g23fxxy,ibf13a,Does x[:2] work?,1.0
g23lhfq,ibf13a,no. i already rewrite code in complete different manner.thank you for trying,1.0
g1xmvjr,ibczyu,"Nice! I gotta check that playlist, I haven't had the chance to get into audio with ML yet, thanks and keep up the good work!",1.0
g1zak4i,ibczyu,Thank you!,1.0
g1qpk8m,iartfa,"In Keras you can pass the argument trainable=False to not train an especific layer, so you can choose which layer to not train by creating a model and passing the keyword trainable=False to that layer.

Examples:

model = keras.Sequential()

model.add(keras.Input(shape=(1024,))

model.add(keras.layers.Dense(300, activation=""relu"", trainable=False))     model.add(keras.layers.Dense(100, activation=""relu"", trainable=False))",2.0
g1qqjv8,iartfa,So this specific example doesn't train the neural network at all!,1.0
g1qtj16,iartfa,"So, I just showed how to freeze certain layers, of course you need to have some trainable layer, although it would be funny to set all layers as not trainable.",2.0
g1qtokv,iartfa,I understand,1.0
g1qqxnx,iartfa,It works! Strange that the other way doesn't work.,1.0
g1rs346,iartfa,You must be using TF1.whatever as TF2 has keras built into it,1.0
g1pid2i,iamdmc,"Do you have the correct CUDA and cuDNN versions installed?

Also tensorflow 2.2.0(the latest tensorflow) supports gpu without tensorflow-gpu installed.",4.0
g1pjmjg,iamdmc,My Gpu cuda version is 2. Can it really work?,2.0
g1pku8e,iamdmc,"Version 2 is really old. Tensorflow(2.2.0) specifies that you need cuda 10.1, cuDNN 7.6, and your drivers must be version 418.x or higher. Don’t forget to update your drivers before installing cuda.

https://www.tensorflow.org/install/gpu",2.0
g1plmki,iamdmc,So i cant use this GPU for tensorflow?,1.0
g1pjgpd,iamdmc,"The official guide in helpful

Search tensorflow GPU install",2.0
g1ngynt,ia5aq6,Some episodes of the [Inside TensorFlow](https://www.youtube.com/playlist?list=PLQY2H8rRoyvzIuB8rZXs7pfyjiSUs8Vza) series on YouTube cover TF internals.,2.0
g1scqju,ia5aq6,yeah these are good - although of varying quality,1.0
g1hknp6,i9tkdp,"If you disable automatic differentiation, i don't see any reason why it couldn't be used for all kinds of computations.",3.0
g1hhc34,i9tkdp,I’m not entirely sure what you mean but something that can be really helpful is Lambda layers. You can essentially put any computation on the data that you’d like. I would look into the keras Lambda layer,2.0
g1ihrmv,i9tkdp,"I think so. @tf.function decorator is a good way to this.
I am not exactly sure what you mean but in tensorflow 2.0 you can directly use @tf.fubction for building graphs",2.0
g1hhbud,i9so1r,"I'm guessing you save the model along with its weights as an .h5 file. Then you take a look at its file size. I did it and my vgg16\_model.h5 file is 553.5 MB, pretty close to VGG-16 Ref.",2.0
g1dsyts,i99p7g,"Have a look into tensorboard, it’s just adding a callback, then a command in the terminal returns a URL to view interactive results in the browser. You can see learning rate as well as all your metrics and much more.",2.0
g1ekssf,i99p7g,Is there a way to view tensorboars in a Jupiter notebook?,2.0
g1f5g0n,i99p7g,"Should be able to launch and use it in the colab environment, not sure if it works in a standard environment. Though there are a few lower level mechanisms as well:

1. Write a callback function. That callback function will have access to the loss information and allow you to do arbitary actions with it.

2. Get the history object that is returned from the fit function.  This will contain the entire loss history which can be easily plotted with matplotlib.

Edit: Wasn't thinking. lol  Just start the tensorboard server and in the training notebook have the tensorboard callback stream its logs to the location that tensorboard is expecting logs to be. Should be fine as long as jupyter can write to this location.",1.0
g1vmo6i,i99p7g,Unfortunately for my use case tensborboard seems very complicated to implement. I have a reinforcement learning use case and one has to change the output of the tensorboard to get a sensible reading.,1.0
g1hoi9k,i99p7g,"Are you fitting it to data using model.train? If so, the Model.train method returns a keras history object that contains a log of the loss function over successive steps.",2.0
g1ledg2,i99p7g,No I am using it for a reinforcement learning algorithm. modile.compile is the last command for the layer.,1.0
g1nu7y4,i99p7g,"Well I have no reinforcement learning experience, best of luck though",1.0
g1ig6rh,i99p7g,"set [model.fit](https://model.fit) equal to a variable:

hist = [model.fit](https://model.fit)(...)

hist.history contains data of the loss that you can plot",1.0
g1le808,i99p7g,What would I put into fit()?,1.0
g1mkkmd,i99p7g,"Well that line is what trains the model so generally you would use X\_train and Y\_train, whatever that may be for you",1.0
g1mkqt1,i99p7g,I would recommend starting with basic NN like predicting the equation of a line or a simple CNN to get the basics of tensorflow down.,1.0
g1vpdiz,i99p7g,"Hey thanks for the help. I ended up getting the loss from hist.history! I have a question for you if you don't mind. Here are a few episodes:

    Episode1
    {'loss': [3.8067822456359863]}
    {'loss': [2.6884610652923584]}
    {'loss': [2.408583879470825]}
    {'loss': [2.009864091873169]}
    {'loss': [2.718052387237549]}
    {'loss': [3.46987247467041]}
    {'loss': [3.057431936264038]}
    {'loss': [2.0055043697357178]}
    {'loss': [1.0517576932907104]}
    {'loss': [1.9371025562286377]}
    {'loss': [1.4520397186279297]}
    Episode2
    {'loss': [0.9365871548652649]}
    {'loss': [2.0109543800354004]}
    {'loss': [0.9774717688560486]}
    {'loss': [1.2693524360656738]}
    {'loss': [2.2984461784362793]}
    {'loss': [1.3964312076568604]}
    {'loss': [7.567145347595215]}
    Episode3
    {'loss': [3.377556324005127]}
    {'loss': [1.9067448377609253]}
    Episode4
    {'loss': [2.9948017597198486]}
    {'loss': [1.1620774269104004]}
    {'loss': [1.0258220434188843]}
    {'loss': [8.953570365905762]}
    Episode5
    {'loss': [1.0103785991668701]}
    {'loss': [3.130033016204834]}
    {'loss': [2.861300468444824]}
    {'loss': [1.0058826208114624]}

What are these values exactly? I'm having a hard time interpreting them.",1.0
g1vq0xt,i99p7g,"So from my interpretation each “episode” the game or whatever ur doing from RL is running 8 times, each with its own loss. 

The loss should be constantly decreasing, as that means that the model is actually learning. However in what you provided the loss seems to fluctuate which is indicative of overfitting or the model just not really learning correctly. 

I don’t have much experience with RL so I would look into overfitting for RL or example pipelines

Edit: 8",1.0
g1vtcl5,i99p7g,"Thanks for the insight. RL has to first figure out what and where is before it can try to make an optimal choice. Also at the beginning the algorithm is making random choices so maybe that could be the reason or does the loss only have to do with the NN? Here are some of the last episodes run in the game where the agent has found an optimal path:

    Episode 194
    {'loss': [1.42763090133667]}
    {'loss': [0.008339452557265759]}
    {'loss': [0.004218542017042637]}
    {'loss': [0.00744678033515811]}
    Episode 195
    {'loss': [0.007931355386972427]}
    {'loss': [0.005060480907559395]}
    {'loss': [0.0026697954162955284]}
    {'loss': [0.0010476167080923915]}
    Episode 196
    {'loss': [0.00099584658164531]}
    {'loss': [0.000627979519777]}
    {'loss': [0.0005589322536252439]}
    {'loss': [0.000355718657374382]}
    Episode 197
    {'loss': [0.00020644901087507606]}
    {'loss': [9.806344314711168e-05]}
    {'loss': [0.00023352655989583582]}
    {'loss': [3.612062573665753e-05]}

So we see a definite decrease over time so would that conclude that the algorithm is in fact doing what is wished and that's it?",1.0
g1vto05,i99p7g,"seems like it is learning. If you are using open AI gym or something like that there should be an easy way for you to visualize the game to actually see what’s going on

Or even better just try testing the model post-training to see how it would do",1.0
g1vuq8g,i99p7g,Yea I know already that it's learning but I am trying to compare two different algorithms to see which has the better loss function i.e. which is always making the better /most efficient choice.,1.0
g1da7ss,i971p5,"This post by Colah is great:
https://colah.github.io/posts/2015-08-Understanding-LSTMs/",1.0
g1n5cyo,i971p5,Actually very nice. Thanks,1.0
g1d5cdb,i96r90,"I asked this similar question on social media about 3 years ago.  And like you, I also got crickets...

I hope that you take this a sign that tensorflow is generally a super messy framework with few standards for testing / building DL projects.  I've switched over to pytorch and haven't looked back.  Looking over old TF code still gives me shivers.",1.0
g1exqzr,i96r90,"There are many ways to structure your machine learning projects using Tensorflow.

Here's one: https://github.com/cs230-stanford/cs230-code-examples

Since Tensorflow 2.x is closer to PyTorch, I would follow the repo's PyTorch structure.  If it's Keras, there's another way to parse out the directory structure that makes good sense.",1.0
g1d6b4d,i942ot,"In the terminal, can you execute

&gt; conda activate

and then do

&gt; which python

It will show you the path of the conda python executable. You can specify this path in the pycharm.",2.0
g1etzpk,i942ot,"Your reply is actually pretty funny because pycharm had already automatically filled in the existing environment option with the anaconda python executable path that I get from running ""which python"", and I just assumed it was wrong because I thought that the interpreter would need to be in the same folder as the virtual environment where I installed TensorFlow. I guess some things you learn the hard way. I appreciate the help.",1.0
g1cebdb,i90opa,Who here doesn't know what complex numbers are? Jesus.,3.0
g26ct80,i8zaxr,I just received this survey and went very heavy on powerful GPUs.  Hope that happens (more V100s etc),2.0
g2c5u5w,i8zaxr,"Try using the TPU, it will give you a 5x speedup at least! It took a while for me to rewrite the whole pipeline, but it was worth it. I am able to train a model on a tpu in 8 hours while on a single GPU it would take days",1.0
g1b8she,i8v9nb,Is this similar to green screen effect !?,1.0
g18oyv2,i8j5wa,"If you're on windows if you open up resource monitor you can see the ""cuda"" tab which i believe is how much GPU utilization you're getting.",2.0
g18pbz1,i8j5wa,I am using Linux,1.0
g18phsl,i8j5wa,Ahh sorry missed that...,1.0
g18q4cd,i8j5wa,You didn't miss it. I added it after your question,1.0
g18tgcc,i8j5wa,on linux using nvidia you do `nvidia-smi` which tells you the current GPU utilisation. Not sure how to get the exact figure for the model itself but that's what I use.,2.0
g18v4nk,i8j5wa,"I use that as well but I was looking for something more precise. For example, currently I am using Jupyter notebook and everyone I use this command, it shows by default 325 MB. This is before I define and even load the model.",1.0
g1atua8,i8j5wa,Tf does allocate all available GPU ram for a model if you do not explicitly tell it not to do it. No matter how small the Model is.,1.0
g181ghn,i8f29p,"I would look into the Tensorflow Object API, you have access to a lot of trained networks on the COCO dataset for object detection. Then I would just count the number of bounding boxes that were classified as 'person'. 

There are quite a few tutorials on YouTube for this kind of stuff",3.0
g183ulp,i8f29p,Great! Thank you very much for the info! I'll look into this!,2.0
g199zla,i8f29p,"I just did a quick run of yolov3+deepsort on your video .. as you can see it can't detect the packed crowd in the background very well because of the low resolution (a human would also have difficulty). Detectron2 might work better than Yolo for this task, but it was easier for me to try this for you .. take a look and download it if you like .. I will delete it in 24h [https://www.dropbox.com/s/qa77o3xxpwd658n/berlin-count.mp4?dl=0](https://www.dropbox.com/s/qa77o3xxpwd658n/berlin-count.mp4?dl=0)",1.0
g19aca7,i8f29p,"Also, the way Yolo works .. it will only predicts a fixed number of objects per image. Can't remember the exact number on the top of my head, but is much less than the crowd size for sure.",1.0
g19clv1,i8f29p,"Wow! Amazing! Seriously. Thank you very much for your effort! It really looks great.

It's really fascinating how this works and how it also can recognise bicycles and trucks. I am not sure about the numbers though - they seem to jump a little bit. Do you think, that the numbers of people in foreground are correct? 

Yeah, sadly the video is only 720p but even for this low quality, the results are already mind blowing. Thank you very much! I will have a look at yolov3 and deepsort. I downloaded the video. Thx",1.0
g19jgf5,i8f29p,"The counting is totally not accurate :-)

It tries to detect individual people and assigns a number to keep track , but it is far from perfect and gets lost easily.",1.0
g18ni5x,i8f29p,Take a look at object detection NNs such as:  Yolo/Detectron2/Tensorflow Object Tracking API and DeepSort (simple online realtime tracking - a neural network strategy to track people in video so you don't count them twice in a video).,1.0
g18xx0r,i8f29p,Thank you!,1.0
g1791my,i8b1s9,"Hard to say without seeing your code, as you could easily be misusing TF and not know it.",5.0
g17abjv,i8b1s9,"[https://github.com/cpita/TicTacToe](https://github.com/cpita/TicTacToe)

It's pretty messy right now... The relevant files are *train.py* and *policies.py,* the only bit that changes with the implementation of tf is the creation of the model (on the init of the NeuralNetPolicy), the predict() on sample() (where I previously had my own version of predict by performing a forward prop) and the train\_on\_batch() on update\_gradients() (previoulsy I used my own implementation by calling sgd\_step())",1.0
g17p59v,i8b1s9,"I think the main thing here is that you're dealing with very small models, in eager mode. So you're mostly measuring TensorFlow's python+op overhead.

Look how they do it in this tutorial:

https://www.tensorflow.org/tutorials/reinforcement_learning/actor_critic

They pack the data-collection into a `tf.function` (it's basically compiler). I tried running that tutorial without the `tf.function` and it was 10x slower.",2.0
g17ypfo,i8b1s9,"Okay so I took out all of the training part and now the only thing that the model does is predict.

When using the TF `model.predict()` it was about 1000 times slower than my matrix multiplication in numpy. I then read that it is not recommended to use `model.predict()` on just one training example, and that I should rather use `model.__call__()`. I did it this way and got about a 10x speedup. Still 100 times slower than numpy.

I have now realized that tensorflow is running on 'eager' mode, and that's why it's so slow. I don't know how I can leverage `tf.function` since I only wanna run one line, `model.__call__()` on non-eager mode. How do I do this?? Seems like a pretty simple task, which can be replicated in a few lines of code.",1.0
g17hdfw,i8b1s9,Are you using a GPU?,2.0
g17ighj,i8b1s9,"I'm not; I am training it on my MacBookPro's CPU. I could of course rent a GPU on aws or azure but I'm not exactly sure of how I could leverage it, as the learning process has to go episode by episode sequentially.",1.0
g17okep,i8b1s9,It's okay. For small models like this GPU won't make a difference.,1.0
g17s2xa,i8b1s9,"I’m really just curious, it doesn’t seem that far fetched to believe numpy is just straight up outperforming tensorflow on this particular task.",1.0
g17xuh5,i8b1s9,But 100 times slower seems way too much,1.0
g1ey09e,i8b1s9,"^ this.  Even Jeremy Howard only claims Tensorflow is 10x slower than PyTorch, which is absolutely not the case. But he's gotta shill for fast.ai library somehow...",1.0
g1ey189,i8b1s9,"**I found links in your comment that were not hyperlinked:**

* [fast.ai](https://fast.ai)

*I did the honors for you.*

***

^[delete](https://www.reddit.com/message/compose?to=%2Fu%2FLinkifyBot&amp;subject=delete%20g1ey09e&amp;message=Click%20the%20send%20button%20to%20delete%20the%20false%20positive.) ^| ^[information](https://np.reddit.com/u/LinkifyBot/comments/gkkf7p) ^| ^&lt;3",1.0
g1exwgl,i8b1s9,"!?!?!?!? If your code is working with numpy, why not just directly translate into jax/trax numpy or 

```import tensorflow.experimental.numpy as np```

and call it a day?",1.0
g174jvq,i87cun,The results look very impressive! But it is made in PyTorch...,1.0
g14pubb,i7xg00,"Have you tried using a different feature vector extraction network? There are a number availible on tensorflow hub and you can sort them by TF version.

I am FAR from an expert, but I changed out the feature vector extraction network in an example last night and it was just changing one line of code to point to the right URL.",1.0
g14qfpy,i7xg00,Can you put the link for them please? I can’t seem to find them,1.0
g14qom2,i7xg00,https://tfhub.dev/,1.0
g14rdr7,i7xg00,Ohh I thought tensorflow hub was its repository on GitHub. I clearly have alot to learn. Thank you!!,1.0
g14r3t5,i7xg00,"Are you running this in Colab? Try restarting the runtime and add ""%tensorflow\_version 1.x"" in the first code cell. Then

import tensorflow  
print(tensorflow.\_\_version\_\_)

If your running it in Jupyter Notebook then create a new Environment with all dependencies (I think Tensorflow version 1.14.2 was the last stable version) so when creating your environment type  

conda install -c conda-forge tensorflow=1.14 (assuming you used Anaconda to install)

Welcome to the nightmare world of Object Detection. I'm still trying to understand enough to get things working on .tflite properly.",1.0
g14rtft,i7xg00,I am running the model on my command line. I tried creating a virtual environment for tensorflow version 1.13 but then it didn’t work because alot of files are missing and have been added t versions above 2.2 . I tried changing the model I am using and I am still facing the same error. Do you suggest working on Jupyter  Notebook instead?,1.0
g14t0dd,i7xg00,"I've mostly been using Colabs but I have both versions installed on my PC in different environments. Installing was easy (I'm an Android coder and not used to CMD pip ect.) and as simple as  ""conda install -c conda-forge tensorflow=1.14 ""

It can be a real PITA getting so far and then running into issues. I've hit many brick walls.",1.0
g14irgf,i7v2vz,"It's to allow pre-existing code written in numpy to run in tensorflow.  As in, you change `import numpy as np` to `import tensorflow.experimental.numpy as np` and your code continues to run, except now each of your numpy arrays is actually a thinly-disguised Tensorflow tensor.

If you're writing new code, I can't imagine there's any performance benefit to using this over native Tensorflow.",10.0
g15cbhq,i7v2vz,The most important thing: can i set slices and how slow is that?,2.0
g15z315,i7v2vz,"Yes, slicing (\_\_getitem\_\_) is supported but \_\_setitem\_\_ is currently not.",1.0
g14z68g,i7v2vz,"Wait what, importing numpy from TensorFlow makes your array partly a tensor? Where can I read more on this magnificent fact?",1.0
g150fjb,i7v2vz,https://www.tensorflow.org/guide/tf_numpy,1.0
g15c5us,i7p6oz,"[Terms and Conditions](https://app.trueability.com/candidate/terms_of_services/3OW4NxBpEB7)

1. c.: 

&gt; I agree not to share or compromise any Program content, questions, or answers related to my Certification attempt(s).

1. f.:

&gt;I will report anyone who steals, shares, colludes or otherwise compromises Certification Program content.

This is a professional certification and everyone should be professional about it. I would strongly discourage anyone from violating the certification terms or engaging in actions that devalue your own certification.",1.0
g16nae5,i7p6oz,"Thanks for pointing this out, appreciate your help",1.0
g1379bm,i7m16q,Can you describe your problem more ?,1.0
g13a25l,i7m16q,I have a crime set with longitude/latitude and time and I wanted to use tensorflow/an RNN to predict potential 'hotspots' for crime. Was looking for a way to implement this with tensor,1.0
g13aj02,i7m16q,"First of all, you should probably use clustering for location wise crime hotspots.

Secondly, have the two predictor attributes as the output of the RNN architecture.",1.0
g13b01d,i7m16q,"Ah okay, is there any material that you suggest I go through. Am still a bit new to using this",1.0
g13jrjw,i7m16q,"Google: predicting latitude and longitude neural networks

This leads to many related works",1.0
g13rmat,i7h80p,"I am somewhat confused. I've been under the impression most of numpy's functionality is replicated natively in tf. I mean summation, multiplication, aggregation, concatenation etc... What does tf.experimental.numpy add to the existing implementation of tf?",3.0
g14j8a7,i7h80p,"I think the idea is that it's a drop-in replacement for numpy, so that numpy code doesn't have to be rewritten in the Tensorflow api.  You literally change `import numpy as np` to `import tf.experimental.numpy as np` and your code continues to run, except now each numpy array is actually just a  wrapper round a Tensorflow tensor.",2.0
g1ey8ae,i7h80p,"Because Jax/Trax both have the NumPy API and Tensorflow is trying to bring both into its wings.

You can use Trax to implement a custom Keras (tf.keras) layer as of 2.2...",2.0
g13vsr0,i7h80p,What about median?,1.0
g14t2gm,i7h80p,You could use [https://www.tensorflow.org/probability/api\_docs/python/tfp/stats/percentile](https://www.tensorflow.org/probability/api_docs/python/tfp/stats/percentile). Note that not all NumPy APIs are currently supported but free interoperation with TensorFlow packages should help.,2.0
g12k765,i71ixs,"optimizer = tf.keras.optimizers.Adam(0.5)

@tf.function
def run():
  optimizer.minimize(loss, var_list=[y_N])",1.0
g0x6i81,i6ozcu,"I think these are 2 questions :

1. How to load a dataset into TF:

\- Load your data, extract features and targets.

\- Add shape of features to model definition (first layer)  

\- Pass train\_features &amp; train\_target to train\_model

\- Predict on Test/Live.

See here :

 [https://medium.com/@k3no/practical-keras-59c9d18ef6cf](https://medium.com/@k3no/practical-keras-59c9d18ef6cf) 

2.  How to use sklearn test\_split :

 [https://scikit-learn.org/stable/modules/generated/sklearn.model\_selection.train\_test\_split.html](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html) 

Basically feed it all your data and a split %, plug resulting df's into the above pipeline.

    #For example:
    
    
    # Percent of dataset to split into test set
    TEST_SIZE = 0.06
    
    # Splits the training_data into a training and test set
    train, test = train_test_split(training_data, test_size=TEST_SIZE, shuffle=True, random_state=42)
    train_X, train_Y, test_X, test_Y = train[feature_names], train[TARGET_NAME], test[feature_names], test[TARGET_NAME]",2.0
g0x8yx1,i6ozcu,"First, thank you so much for your response! 

In regards to your 1st point, do train\_features and train\_target have specific parameters you need to set, or is it built in to the API?",1.0
g0xv9v6,i6ozcu,"They are both data frames/tensors you pass to your model along with other parameters from the model you built, so something like this:

    train_model(regressor_model, train_Features, train_Target, epochs, batch_size)

so in your case the train\_target is the dataframe or array with Red/Blue and train\_Features is the dataframe with  the relevant columns/rows from your dataset.",1.0
g0y0ofg,i6ozcu,Thank you! This connected the dots for me. I'm gonna give it try tonight!,1.0
g0wtbm5,i6nd9x,"You need an expand dims there.

So like

img=img.expandDims(0);",1.0
g0x50l0,i6nd9x,"&gt;img=img.expandDims(0);

Thanks! Now I get the error:

    expected conv2d_input to have shape [null,224,224,3] but got array with shape [1,244,244,3]

So now I got 4 dimensions which is good, but how do I get null instead of 1?",1.0
g0wz8x4,i6nd9x," This should work in tensorflowjs:

    image = tf.expandDims(image, 0);",1.0
g0x519r,i6nd9x,"Thanks! Now I get the error:

    expected conv2d_input to have shape [null,224,224,3] but got array with shape [1,244,244,3]

So now I got 4 dimensions which is good, but how do I get null instead of 1?",1.0
g0y8any,i6m8pp,"It looks like you're writing TensorFlow1  code in TensorFlow2.

Have you read any of the tutorials on tensorflow.org? 

Maybe start here: https://www.tensorflow.org/tutorials/customization/custom_training_walkthrough#define_the_loss_and_gradient_function",1.0
g12iwdj,i6m8pp,"Can you try to put the cost computation inside the loss function ?

loss = lambda:  -tf.reduce\_mean(input\_tensor=tf.reduce\_sum(input\_tensor=tf.math.log(y\_N), axis=0))",1.0
g0vaahf,i6b750,"I'm not 100% I understand what you want the output to look like, but perhaps [tf.concat](https://www.tensorflow.org/api_docs/python/tf/concat) is what you're looking for. If this isn't quite what you're looking for, it may help to know what you expect the result to look like. 

    &gt;&gt;&gt; a
    &lt;tf.Tensor: id=0, shape=(3, 2), dtype=int32, numpy=
    array([[ 1,  2],
        [ 5,  6],
        [ 9, 10]])&gt;

    &gt;&gt;&gt; b
    &lt;tf.Tensor: id=1, shape=(3, 2), dtype=int32, numpy=
    array([[ 3,  4],
        [ 7,  8],
        [11, 12]])&gt;

    &gt;&gt;&gt; tf.concat([a, b], axis=1)
    &lt;tf.Tensor: id=14, shape=(3, 4), dtype=int32, numpy=
    array([[ 1,  2,  3,  4],
        [ 5,  6,  7,  8],
        [ 9, 10, 11, 12]])&gt;


Formatting tip: Indent code in the editor to get proper code formatting.",1.0
g0ve3d1,i6b750,"thanks for the tip.

&amp;#x200B;

well. the dataset comes with a 'features' and 'label' dictionary. The 'features' dictionary is made of 13 tensors each is a column of data. Such as, one is 'age' and it has the age of the titanic survivors, another is 'fare', and so on.

How do I get those 13 tensors so that they can be inputted into the model?

It's not as simple as data\['features'\] and data\['label'\] for x and y. it spits back an error message that the input is 13 tensors when it's looking for one.

the data in this data set is in the shape of (1309,)

so

a =

\[

\[1\]

\[2\]

\[3\]

\]

b =

\[

\[a\]

\[b\]

\[c\]

\]

&amp;#x200B;

and I would like it to be so it looks like 1 and a are features from one entry, 2 and b for another and so on. tf.concat didn't work. I implore you, please try the dataset yourself. i'm lost :(",1.0
g0vh9gv,i6b750,"Hey, while I was googling for the dataset docs, your question on SO popped, so I threw in a demo there with an attached notebook.  For reference, here is the notebook where I do what I'm assuming you want here: https://colab.research.google.com/drive/1dHNe9rYaJSgqbj_QtQ1aJL_7WgKnLKsU?usp=sharing

Edit: I had actually broken one thing while doing some editing. Should be fixed and working now.",1.0
g0xc9n4,i6b750,"Thank you!

this is what i was looking for. one thing though, the last column is supposed to be the output ('survived' is the dictionary key)

How would I make it so it's 

    # Input data and associated label
    def transform_data(item, label):
    
      # Extract values
      age = item['age']
      fare = item['fare']
      survived = label
      #survived = tf.one_hot(survived,2)
    
      # Create output tensor
      output = tf.stack(age, fare,survived, axis=0)
      return output, label

doing the above (or even coupling the three 2 feature categories as list or tuple) gives me an axis error.",1.0
g0xejla,i6b750,"I was able to get it to work with age and fare as the features and survived as the label like this:

    def transform_data(item, label):
    
      # Extract values
      age = item['age']
      fare = item['fare']
      survived = label
      #survived = tf.one_hot(survived,2)
    
      # Create output tensor
      output = tf.stack([age, fare,tf.cast(survived, dtype=tf.float32)], axis=0)
      return output, label

but what about the other features? how can I make this work?

    # Input data and associated label
    def transform_data(item, label):
    
      # Extract values
      age = item['age']
      fare = item['fare']
      boat = item['boat']
      body = item['body']
      cabin = item['cabin']
      survived = label
      #survived = tf.one_hot(survived,2)
    
      # Create output tensor
      output = tf.stack([age, fare,boat,body,cabin,tf.cast(survived, dtype=tf.float32)], axis=0)
      return output, label

when I try mapping that I get this error:

 TypeError: Tensors in list passed to 'values' of 'Pack' Op have types \[float32, float32, string, int32, string, float32\] that don't all match.",1.0
g0xeudc,i6b750,"I've added some additional code snippets to the bottom of the notebook shared earlier.  Survived is actually already captured as the label value and passed to the network to train (That's what it's training to make predictions upon in the demo).

The added samples after training demonstrate how the label is tracked in the dataset alongside the input values, and then shows creating a custom input value, passing that to the model, and the output of the model.

Regarding other columns, you'll have to be careful about how you enter data.  You need to encode the string values in some way.  Passing the raw strings will not be possible. You'll need to explore the data to determine the best method to accomplish this.",1.0
g0xgxga,i6b750,"thank you! yup used tf.strings.to\_number() and it worked. thank you thank thank you!

actually didn't work for the model, but I can use tokenization, I'm sure.

I'll be sure to give you the ups and answer on SO",1.0
g0tabjq,i640fe,"At the risk of making assumptions about how you want to webdev, take a look at TF Serving (in Docker) to create a REST API that you can integrate into your server as you like: https://www.tensorflow.org/tfx/serving/docker",6.0
g1a8y8r,i640fe,You can also try this service which runs on top of TF Serving. I use it to quickly deploy and test my models  https://www.bubblepop.io/,1.0
g0tdckx,i640fe,"1. No, it should not run significantly slower.  Some tests showed saved_models loaded into TensorflowJS having a [slightly faster inference speed than the Python environment](https://1.bp.blogspot.com/-00haeTw4boo/XhzSH0X47bI/AAAAAAAACkE/N-UuL41c6_0-fjDBQVYBTdSs9vzfb_hjgCLcBGAsYHQ/s1600/gpu%2Bmodel.png) ([source of chart](https://blog.tensorflow.org/2020/01/run-tensorflow-savedmodel-in-nodejs-directly-without-conversion.html)).

2. This will work okay and I've used it in the past.  It's made very simple thanks to the Tensorflow serving Docker container.

3. Have done this as well. It was biting off a little more than I had expected, as I needed to learn about using Flask with a wsgi compliant web server, but wasn't an enormous challenge.

One thing that might ease your decision:  Much of the code that does heavy lifting and needs to be highly optimized is not native Python code - rather the Python API is an interface to C++ bindings. As such TensorflowJS other mature APIs aren't likely to present major performance differences.

However, not all of the other APIs are considered to be stable.  Python is stable however, and has a rich history and library of tools for data science, so that's what most people use.  Personally, I have vastly more experience in Java and JavaScript than I do in Python, but 100% prefer a Python environment for managing data preparation, augmentation.",2.0
g0w2pqw,i640fe,"Option 3. I would use Django Backend, since most of things like asynch operations are pretty straightforward in Djnago. Also, you have liberty of using other Python based packages just incase.",1.0
g0q7m2x,i5grtd,"Are you spelling the package correctly in your imports? 

import tensorflow",1.0
g0q20s0,i5d23v,"I have basically the same setup for an app, but for simplicity I just used a Flask backend. Basic workflow I've used:

1. Client side, let the user select an image from their machine. Load image bytes (locally) into a canvas, which I will then later draw bounding boxes over.

2. When the user hits the button to trigger inference, convert image to a base 64 string. Call some API endpoint to trigger inference on the data.

3.  Server should already be running and have the model ready to go. Do any necesary preprocessing, then run inference on it. First one is usually slow.

4. Not worked with Yolo, but with the TF object detection API it would report a large number of bounding boxes with confidence ratings. I provided a value which seemed to be a good dividing line between detection and noise.  You will likely have to experiment with this.

5.  Server returns filtered bounding boxes - may include class information if this is multiclass detection.

6. Draw bounding boxes in the canvas over the image.  

After this I cropped each bounding box and passed them to the next inference layer, but if you're only concerned with the count of objects you could probably stop at step 5.",2.0
g0s4608,i5d23v,Awesome makes sense. I'll check out TF Object detection API. Thank you for your help!,1.0
g0p4n8m,i5d23v,Yolo v4,1.0
g0ph8wa,i5d23v,"thanks, I'll look into it!",1.0
g0rh2i6,i592vd,"The top layer is mostly known for being the classification layer and is normally just fully connected layers and the rest of the model is the feature extractor where all the convolutional layers are present.

The feature extractor, gets you the relevant features of the image, then these features are passed to the top layer where they are classified (dog or cat).

When we are fine tuning, we use a pre trained model. It can be the entire model or only a few layers.


When ""Keras"" is saying that is necessary to use the top layers of the pre trained model, this is ONLY if you are using the model with the exact same purpose as it was defined. What this means is, if the Keras model was trained to classify only cats and dogs, and you also want to classify cats and dogs, then you should use the top layer, as it was trained for those classes.

If you want to train/fine tune the model for other purposes and classes, then you should remove the pre trained top layer (the classification layer) and normally, add the exact same layer (without pre trained weights) with the classes you want.

This is a much quicker process. Because the pre trained models are trained on millions of images and the convolutional part of the model, is the most difficult part to train, learning features is very challenging. So you want to take advantage of those learnt weights on the convolution layers, and train a new classification layer for your purpose. The training will converge much faster against training all from scratch.

The preprocessing is a combination of normalisation and standardisation. The normalisation is almost a must. The last one, not so much when fine tuning. 

Normalisation puts the pixel values between 0 and 1, it helps the weights to have a low value and converge faster. The standardisation uses the mean and standard deviation values of the dataset in which they used to trained the model, to make the training data zero centered.

If you do not have the same training dataset, I believe it's not helpful.

If you are not getting good results with it, do not use it, it's not mandatory. But normalisation you should (X/255).",2.0
g0rjq9o,i592vd,Thanks for the reply! It helped a lot!,2.0
g0n4qk6,i55qmp,"Check if tensorflow has found your gpu with:

```
tf.test.is_gpu_available()
```

```
tf.config.list_physical_devices('GPU')
```

You don't need the strategy scopes to train on a single device.",2.0
g0ovwe4,i55qmp,GPU is available,1.0
g0pec5w,i55qmp,"Hmmm that’s weird, usually it says that GPU available if you set up everything correctly including CUDA and CUDNN. Try doing it without the strategy scopes and see if it works?",1.0
g0n9op6,i55qmp,"Do you have CUDA and CUDNN installed on your pc and in your PATH? And if so, are you sure you’re using the right version? Different tensorflow versions require different driver versions.

Also, you don’t need all that code just to utilize a single GPU. For tensorflow 2, it automatically uses your gpu if it’s available on your system and you have the correct cuda+cudnn installed.",1.0
g0ow1lr,i55qmp,my be my  CUDA and cudnn version mismatch. I am currently in the  process of re-installing those.,1.0
g0mu8nh,i53rhx,The error is exactly what it says. That object does not have a “.sess” attribute.,0.0
g0mcsur,i4v1h2,https://youtu.be/tPYj3fFJGjk,3.0
g0lz81w,i4r7lt,"nice tutorial! i'm following you on youtube and github and your tutorials is helping me a lot!

i'm trying to make a food detector, and your videos is helping me so mutch!

thank you!",1.0
g0kwft3,i4r4js,"It's cool that you are having fun! Keep going! And don't forget the basics, they are very important!",3.0
g0v6je6,i4r4js,Thank you! I won't!,1.0
g0jhvjs,i4o3cz,"The first method saves the state of the optimizer, the structure of the model and the weights. The second method only saves the weight.

The difference is the save-function. The first one use probably model.save(). 

The second one uses model.save_weights().",3.0
g0jsja2,i4o3cz,"Does anyone know how to speed up the process of saving and loading the model?

I my current setup i work with tf.session to speed up the process and only save the model without the optimizer. Maybe somebody comes by and can give me a hint.",1.0
g0rd14t,i4o3cz,Saving and loading the model really should not take up much time. I believe the ModelCheckpoint should have some tooling to only save if validation loss is better? If not you can always right your own callback logic using `tf.keras.callbacks.Callback`.,2.0
g0s0tbv,i4o3cz,"Thank you. I did write my own callback for tensorboard to figure out what is wrong. Because i am hardware limited, i train my model on the gpu and the load it into a another programm that runs on the cpu. These kind of operation is not very well supported by tensorflow. Also my current tensorflow version is 1.13, because i have to use pyinstaller to export my programm to the server. Newer version of tensorflow will not work with pyinstaller sadly. 

if i had two gpu available, it wouldnt be such a bottleneck for my application. I appreciate your help.",1.0
g0jhx92,i4o3cz,"See docs on ModelCheckpoint:


    tf.keras.callbacks.ModelCheckpoint(
        filepath,
        monitor=""val_loss"",
        verbose=0,
        save_best_only=False,
        save_weights_only=False,
        mode=""auto"",
        save_freq=""epoch"",
        options=None,
        **kwargs
    )


And the accompanying note further down: 
&gt; Whether only weights are saved, or the whole model is saved.

Presumably, your configuration for ModelCheckpoint is saving both the model and the weights, whereas your second methodology only saves the weights. To confirm, you could try using the following to initialize your ModelCheckpoint and determine if they come out more similar:

`checkpoint = ModelCheckpoint('model{epoch:08d}.h5', save_weights_only=True, save_freq=1)`",2.0
g0jc3vo,i4mx5v,"Oh. What a bummer. Two days of searching for a solution until I ask Reddit. Then after 40 minutes I find the solution. It was as I expected something with the conversion of the dataset. Instated of doing it by myself with Numpy I just used some functions from Tensorflow and everything went well.  
`def change_shape(x):`  
 `# Change the shape to (48, 48, 3)`  
 `x = np.reshape(x, (len(x), 28, 28, 1))`  
 `# Current shape (len, 28, 28, 1)`  
 `x = tf.image.grayscale_to_rgb(tf.convert_to_tensor(x))`  
 `# Current shape (len, 28, 28, 3)`  
 `x = np.array(tf.image.resize(x, [48, 48]))`  
 `# Current shape (48, 48, 3)`  
`# Normalise the data and change data type`  
 `x = x / 255.`  
 `x = x.astype('float32')`  
 `# Preprocess input`  
 `return x`

This does the trick.",2.0
g0ivmjg,i4iz35,"The answer will probably differ based on what abstraction, if any, you're using to load and manage the data. Are you using a tensorflow [Dataset](https://www.tensorflow.org/api_docs/python/tf/data/Dataset) or loading directly using [ImageDataGenerator](https://www.tensorflow.org/api_docs/python/tf/keras/preprocessing/image/ImageDataGenerator).flow_from_directory or some other mechanism?",1.0
g0j9zb0,i4iz35,Happy Cake Day!,2.0
g0ix0tc,i4iz35,"It's not a Tensorflow dataset, it's my own. So probably be using ImageDataGenerator. But it's my first time doing this on my own dataset so I'm not sure.",1.0
g0ixhed,i4iz35,"For clarity, you can use the Dataset abstraction with your own data, this is what I use for managing images. It's actually quite nice, as it gives some great tools for parallel loading, caching, etc. 

For ImageDataGenerator, if you're using flow_from_directory, note that it requires a very specific directory structure to work. For this one I simply setup different directories, one for train data, one for validation data, and one for test data. It was fairly painless, but not the most flexible solution.

For labeling, it will depend on the nature of the labels.  Is this a classification problem?  Binary/multiclass?",1.0
g0iy2g3,i4iz35,It's a multiclass classification problem. I just have so many folders it's a bit confusing how to handle it. But they are all ordered properly.,1.0
g0iytth,i4iz35,"Then, with flow_from_directory, the directory structure should be something like this: `parent &gt; label &gt; samples`.

    &gt; train
        &gt; A
            &gt; img_00000.jpg
            &gt; img_00001.jpg
            &gt; ...
        &gt; B
            &gt; img_01000.jpg
            &gt; img_01001.jpg
            &gt; ...
        &gt; C
            &gt; img_01000.jpg
            &gt; img_01001.jpg
            &gt; ...
    &gt; test
        &gt; A
            &gt; img_00000.jpg
            &gt; img_00001.jpg
            &gt; ...
        &gt; ...
    &gt; validate
        &gt; ...

In this example A, B, and C would be specific classes.  Make sure each parent folder (train, test, validate) have all the same folders, even if some end up being empty. 

Once its organized, you should be able to configure an ImageDataGenerator, then use flow_from_directory and pass the directory location and it should be able to load in images and apply appropriate classes.

Note: This is just one way to use the ImageDataGenerator, and there are numerous other ways of loading, preparing/augmenting and providing data with TensorFlow/Keras. If this doesn't work for you, then I would explore some of the other options, or just look at the documentation for `fit` as it describes how data and labels can be provided to it.",2.0
g0izo3u,i4iz35,Thank you I will try it out. Appreciate you helping me.,1.0
g0iztw4,i4iz35,"No worries, feel free to reach out if you get stuck on something. Don't be afraid to play around with other data loading pipelines - honestly, it might seem like a small detail, but the data loading/processing is pretty significant so getting comfortable with it can really improve your capabilities.",2.0
g0izw8e,i4iz35,I will definitely do that. Yes I realised its way more complex than it seems but I'll learn.,1.0
g0fp61r,i44552,"## Overview

We are excited to release Spark NLP 2.5.5 with 28 new pretrained models for Lemma and POS in 14 languages, bug fixes, new notebooks, and more!

As always, we would like to thank our community for their feedback, questions, and feature requests.

## New Features

* Add getClasses() function to NerDLModel
* Add getClasses() function to ClassifierDLModel
* Add  getClasses() function to SentimentDLModel

Example:

    ner_model = NerDLModel.pretrained('onto_100')
    print(ner_model.getClasses())
    #['O', 'B-CARDINAL', 'B-EVENT', 'I-EVENT', 'B-WORK_OF_ART', 'I-WORK_OF_ART', 'B-ORG', 'B-DATE', 'I-DATE', 'I-ORG', 'B-GPE', 'B-PERSON', 'B-PRODUCT', 'B-NORP', 'B-ORDINAL', 'I-PERSON', 'B-MONEY', 'I-MONEY', 'I-GPE', 'B-LOC', 'I-LOC', 'I-CARDINAL', 'B-FAC', 'I-FAC', 'B-LAW', 'I-LAW', 'B-TIME', 'I-TIME', 'B-PERCENT', 'I-PERCENT', 'I-NORP', 'I-PRODUCT', 'B-QUANTITY', 'I-QUANTITY', 'B-LANGUAGE', 'I-ORDINAL', 'I-LANGUAGE', 'X']

## Enhancements

* Improve max sequence length calculation in BertEmbeddings and XlnetEmbeddings

## Bugfixes

* Fix a bug in RegexTokenizer in Python
* Fix StopWordsCleaner exception in Python when pretrained() is used
* Fix max sequence length issue in AlbertEmbeddings and SentencePiece generation
* Fix HDFS support for setGaphFolder param in NerDLApproach

## Models

* We have added 28 new pretrained models for Lemma and POS in 14 languages:

|Model|Name|Build|Lang|
|:-|:-|:-|:-|
|LemmatizerModel (Lemmatizer)|`lemma`|2.5.5|`br`|
|LemmatizerModel (Lemmatizer)|`lemma`|2.5.5|`ca`|
|LemmatizerModel (Lemmatizer)|`lemma`|2.5.5|`da`|
|LemmatizerModel (Lemmatizer)|`lemma`|2.5.5|`ga`|
|LemmatizerModel (Lemmatizer)|`lemma`|2.5.5|`hi`|
|LemmatizerModel (Lemmatizer)|`lemma`|2.5.5|`hy`|
|LemmatizerModel (Lemmatizer)|`lemma`|2.5.5|`eu`|
|LemmatizerModel (Lemmatizer)|`lemma`|2.5.5|`mr`|
|LemmatizerModel (Lemmatizer)|`lemma`|2.5.5|`yo`|
|LemmatizerModel (Lemmatizer)|`lemma`|2.5.5|`la`|
|LemmatizerModel (Lemmatizer)|`lemma`|2.5.5|`lv`|
|LemmatizerModel (Lemmatizer)|`lemma`|2.5.5|`sl`|
|LemmatizerModel (Lemmatizer)|`lemma`|2.5.5|`gl`|
|LemmatizerModel (Lemmatizer)|`lemma`|2.5.5|`id`|
|PerceptronModel (POS UD)|`pos_ud_keb`|2.5.5|`br`|
|PerceptronModel (POS UD)|`pos_ud_ancora`|2.5.5|`ca`|
|PerceptronModel (POS UD)|`pos_ud_ddt`|2.5.5|`da`|
|PerceptronModel (POS UD)|`pos_ud_idt`|2.5.5|`ga`|
|PerceptronModel (POS UD)|`pos_ud_hdtb`|2.5.5|`hi`|
|PerceptronModel (POS UD)|`pos_ud_armtdp`|2.5.5|`hy`|
|PerceptronModel (POS UD)|`pos_ud_bdt`|2.5.5|`eu`|
|PerceptronModel (POS UD)|`pos_ud_ufal`|2.5.5|`mr`|
|PerceptronModel (POS UD)|`pos_ud_ytb`|2.5.5|`yo`|
|PerceptronModel (POS UD)|`pos_ud_llct`|2.5.5|`la`|
|PerceptronModel (POS UD)|`pos_ud_lvtb`|2.5.5|`lv`|
|PerceptronModel (POS UD)|`pos_ud_ssj`|2.5.5|`sl`|
|PerceptronModel (POS UD)|`pos_ud_treegal`|2.5.5|`gl`|
|PerceptronModel (POS UD)|`pos_ud_gsd`|2.5.5|`id`|

Languages: Armenian, Basque, Breton, Catalan, Danish, Galician, Hindi, Indonesian, Irish, Latin, Latvian, Marathi, Slovenian, Yoruba

## Documentation and Notebooks

* New notebook for pretrained [StopWordsCleaner](https://github.com/JohnSnowLabs/spark-nlp-workshop/blob/master/jupyter/annotation/english/stop-words/StopWordsCleaner.ipynb)
* New notebook to [Detect entities in German language](https://github.com/JohnSnowLabs/spark-nlp-workshop/blob/master/tutorials/streamlit_notebooks/NER_DE.ipynb)
* New notebook to [Detect entities in English language](https://github.com/JohnSnowLabs/spark-nlp-workshop/blob/master/tutorials/streamlit_notebooks/NER_EN.ipynb)
* New notebook to [Detect entities in Spanish language](https://github.com/JohnSnowLabs/spark-nlp-workshop/blob/master/tutorials/streamlit_notebooks/NER_ES.ipynb)
* New notebook to [Detect entities in French language](https://github.com/JohnSnowLabs/spark-nlp-workshop/blob/master/tutorials/streamlit_notebooks/NER_FR.ipynb)
* New notebook to [Detect entities in Italian language](https://github.com/JohnSnowLabs/spark-nlp-workshop/blob/master/tutorials/streamlit_notebooks/NER_IT.ipynb)
* New notebook to [Detect entities in Norwegian language](https://github.com/JohnSnowLabs/spark-nlp-workshop/blob/master/tutorials/streamlit_notebooks/NER_NO.ipynb)
* New notebook to [Detect entities in Polish language](https://github.com/JohnSnowLabs/spark-nlp-workshop/blob/master/tutorials/streamlit_notebooks/NER_PL.ipynb)
* New notebook to [Detect entities in Portugese language](https://github.com/JohnSnowLabs/spark-nlp-workshop/blob/master/tutorials/streamlit_notebooks/NER_PT.ipynb)
* New notebook to [Detect entities in Russian language](https://github.com/JohnSnowLabs/spark-nlp-workshop/blob/master/tutorials/streamlit_notebooks/NER_RU.ipynb)
* Update documentation for release of Spark NLP 2.5.x
* Update the entire [spark-nlp-models](https://github.com/JohnSnowLabs/spark-nlp-models) repository with new pre-trained models and pipelines
* Update the entire [spark-nlp-workshop](https://github.com/JohnSnowLabs/spark-nlp-workshop) notebooks for Spark NLP 2.5.x",1.0
g0fp6v8,i44552,"
I see you've posted GitHub links to Jupyter Notebooks! GitHub doesn't 
render large Jupyter Notebooks, so just in case here are 
[nbviewer](https://nbviewer.jupyter.org/) links to the notebooks:

https://nbviewer.jupyter.org/url/github.com/JohnSnowLabs/spark-nlp-workshop/blob/master/jupyter/annotation/english/stop-words/StopWordsCleaner.ipynb

https://nbviewer.jupyter.org/url/github.com/JohnSnowLabs/spark-nlp-workshop/blob/master/tutorials/streamlit_notebooks/NER_DE.ipynb

https://nbviewer.jupyter.org/url/github.com/JohnSnowLabs/spark-nlp-workshop/blob/master/tutorials/streamlit_notebooks/NER_EN.ipynb

https://nbviewer.jupyter.org/url/github.com/JohnSnowLabs/spark-nlp-workshop/blob/master/tutorials/streamlit_notebooks/NER_ES.ipynb

https://nbviewer.jupyter.org/url/github.com/JohnSnowLabs/spark-nlp-workshop/blob/master/tutorials/streamlit_notebooks/NER_FR.ipynb

https://nbviewer.jupyter.org/url/github.com/JohnSnowLabs/spark-nlp-workshop/blob/master/tutorials/streamlit_notebooks/NER_IT.ipynb

https://nbviewer.jupyter.org/url/github.com/JohnSnowLabs/spark-nlp-workshop/blob/master/tutorials/streamlit_notebooks/NER_NO.ipynb

https://nbviewer.jupyter.org/url/github.com/JohnSnowLabs/spark-nlp-workshop/blob/master/tutorials/streamlit_notebooks/NER_PL.ipynb

https://nbviewer.jupyter.org/url/github.com/JohnSnowLabs/spark-nlp-workshop/blob/master/tutorials/streamlit_notebooks/NER_PT.ipynb

https://nbviewer.jupyter.org/url/github.com/JohnSnowLabs/spark-nlp-workshop/blob/master/tutorials/streamlit_notebooks/NER_RU.ipynb

Want to run the code yourself? Here are [binder](https://mybinder.org/) 
links to start your own Jupyter server!

https://mybinder.org/v2/gh/JohnSnowLabs/spark-nlp-workshop/master?filepath=jupyter%2Fannotation%2Fenglish%2Fstop-words%2FStopWordsCleaner.ipynb

https://mybinder.org/v2/gh/JohnSnowLabs/spark-nlp-workshop/master?filepath=tutorials%2Fstreamlit_notebooks%2FNER_DE.ipynb

https://mybinder.org/v2/gh/JohnSnowLabs/spark-nlp-workshop/master?filepath=tutorials%2Fstreamlit_notebooks%2FNER_EN.ipynb

https://mybinder.org/v2/gh/JohnSnowLabs/spark-nlp-workshop/master?filepath=tutorials%2Fstreamlit_notebooks%2FNER_ES.ipynb

https://mybinder.org/v2/gh/JohnSnowLabs/spark-nlp-workshop/master?filepath=tutorials%2Fstreamlit_notebooks%2FNER_FR.ipynb

https://mybinder.org/v2/gh/JohnSnowLabs/spark-nlp-workshop/master?filepath=tutorials%2Fstreamlit_notebooks%2FNER_IT.ipynb

https://mybinder.org/v2/gh/JohnSnowLabs/spark-nlp-workshop/master?filepath=tutorials%2Fstreamlit_notebooks%2FNER_NO.ipynb

https://mybinder.org/v2/gh/JohnSnowLabs/spark-nlp-workshop/master?filepath=tutorials%2Fstreamlit_notebooks%2FNER_PL.ipynb

https://mybinder.org/v2/gh/JohnSnowLabs/spark-nlp-workshop/master?filepath=tutorials%2Fstreamlit_notebooks%2FNER_PT.ipynb

https://mybinder.org/v2/gh/JohnSnowLabs/spark-nlp-workshop/master?filepath=tutorials%2Fstreamlit_notebooks%2FNER_RU.ipynb



------

^(I am a bot.) 
[^(Feedback)](https://www.reddit.com/message/compose/?to=jd_paton) ^(|) 
[^(GitHub)](https://github.com/JohnPaton/nbviewerbot) ^(|) 
[^(Author)](https://johnpaton.net/)",1.0
g0fen4w,i42955,"For anyone trying to make a custom object detection model, be sure to use 300-400 images and train it till the error is is really low latleast below 0.1 which took almost 4 hours for me on google Colab.",5.0
g0fkn4k,i42955,"Great article and fantastic timing, I was actually just searching for a proper explanation on how these segmentation networks technically predict the information.

I'm a bit confused about the following: you say

&gt;If the centre of the ground truth box falls into a cell, that cell is responsible for detecting the existence of that object.

so does that mean that the model is trained only for that one box to predict a dog, and the adjacent boxes not to? Or are all boxes that contain a dog trained to predict the dog?

And what is the actual architecture of the model? It is able to predict B bounding boxes for each box, does it use a decoder architecture for this?

&amp;#x200B;

Edit: your ""intersection over union"" figure seems to not be viewable by others. I imagine it's your google drive and you haven't set it to public.",4.0
g0g7cs8,i42955,"Each cell in this grid can predict a fixed number of boundary boxes. For example if in a cell there are two objects and somehow we have only one bounding box for a single cell , than only one object can be detected.I think in YOLO , each cell can predict 5 bounding boxes.
Now as you might have seen that we get output with respect to each cell in the grid, the x, y are offsets of corresponding cells. So you may understand when full object is in a single cell, how the bounding box is formed.
But now if an object is in many cells, in that case we select the most thick bounding box which indirectly means that many bounding boxes are enclosing this object and there the output is with respect to that cell where the center of ground truth box lies. 
There is a single nwtwork which segments the image and  predicts bounding boxes and it is fully made up of convolutional layers",2.0
g0jdk3y,i42955,[deleted],1.0
g0jhbug,i42955,why not see the original YOLO paper and now recently they have published yoloV4.,1.0
g0jjuhn,i42955,[deleted],1.0
g0jm9qy,i42955,https://arxiv.org/abs/1804.02767,1.0
g0fn7xj,i42955,this is not related to tensorflow use r/learnmachinelearning,2.0
g0g48yf,i42955,there is a keras implementing too linked in it which you can modify to tf.keras.,1.0
g0fn7oj,i418o4,You don't have to zip it. Put it up in the server or with a cdn that supports gzip compression and enable it. Sever will automatically compress it before sending to browser. And browser will automatically decompress it your receipt.,1.0
g0fhbxo,i3zq1y,That's because your input is of mixed `dtype`,1.0
g0h6cb2,i3zq1y,"the type both shows ""tf.float64)""

are you saying that have different shapes for my input and output cant work?

or should i normalize my values to a tf.float32",1.0
g0cpk1y,i3lz1m,"You run 'Python', not 'Tensor'

Then you could, for example, type:

import tensorflow as tfprint(tf.\_\_version\_\_)

And if that code runs, you know tf is working on your mac  


EDIT: Also, this would be a better link:  [https://www.tensorflow.org/install](https://www.tensorflow.org/install)",1.0
g0cv31q,i3lz1m,"TensorFlow is not a command you can run on terminal, it’s (most widely known as) a library that can be used in a programming language called python, I get from your post that you are probably not familiar with it, if that is the case, then you first wanna learn how to program with python before jumping into TensorFlow, it’s not hard at all, just watch some tutorials on the Internet.

If you are familiar with it, then just watch some tutorials online on how to get started, if you wanna learn TensorFlow better I HIGHLY SUGGEST the [TensorFlow in practice specialization ](https://www.coursera.org/specializations/tensorflow-in-practice) course by Laurence Moroney, a google developer advocate.",1.0
g0g97gf,i3lz1m,Thanks for the kudos :),1.0
g0gwlgq,i3lz1m,"No problem, you are a great teacher!",1.0
g0borq1,i3j03j,[row row fight the powah](https://youtu.be/0V7aUT13qtM),1.0
g0by7ey,i3j03j,"Wow, your channel is a goldmine. I'm really astonished you only have 5k subs",1.0
g0c6wgc,i3j03j,Thank you very much!,2.0
g0axipt,i3dg4f,"Provide more info about the script, what versions are you using? What are your code doing? Also format the code it’s unreadable..",2.0
g1f5lhs,i3dg4f,"im getting the same error,

Did you solve it??

and if so can share what you did",2.0
g1f64m7,i3dg4f,"I change tha batch size 8 to 1, cz I have less ram and try to run it again",1.0
g1f7q8e,i3dg4f,Soo changing the batch size solved it?,1.0
g1f8627,i3dg4f,Yes,1.0
g0ad3vx,i3aafi,"    import pandas as pd
    
    training_data = pd.read_csv(""path_in_your_computer/dataset.csv"").set_index(""yourindex"")
    
    There's other options, check the pandas read_csv docs...  

Full example:

 [https://medium.com/@k3no/practical-keras-59c9d18ef6cf](https://medium.com/@k3no/practical-keras-59c9d18ef6cf)",1.0
g0d5vh0,i3aafi,"Thanks for the help, for the “yourindex” part, does it matter what we put? I saw that on the example they used “id”",1.0
g0dbiep,i3aafi,"If you don't give it an index it will simply number ( index ) your rows in order or appearance, the index is useful if you are doing operations and need to keep the order by some specific column like id in the example case.",1.0
g099fjd,i357w9,Are they NV-linked?,1.0
g09akgo,i357w9,They are not.,1.0
g0a1jg3,i357w9,"If you only have 1 machine then multi worker will slow down training considerably. NV link would be the only way to speed up training with mirrored strategy, since reduce_all will take less time per gradient update than non nvlink",2.0
g0ch5b4,i357w9,"Ok, thanks for the answer.",1.0
g08zk04,i33arn,"not a model error

use %cpaste if pasting code",2.0
g09rust,i33arn,It says that %cpaste isn’t a command for me,1.0
g09rzye,i33arn,use ipython,1.0
g0a5vbf,i33arn,Ok thanks! I got it,1.0
g07rtdg,i2ytc9,It took 2 weeks to arrive,5.0
g07ur59,i2ytc9,Can u please share ur experience throughout and how was the exam pattern ??,5.0
g07vjn4,i2ytc9,"Please check out [this](https://www.reddit.com/r/tensorflow/comments/hqd0qd/megathread_tensorflow_certification_exam/?utm_source=share&amp;utm_medium=ios_app&amp;utm_name=iossmf) thread I made about the exam, if you have more question feel free to ask there, so that other may benefit from the answers.",4.0
g07vsag,i2ytc9,Thanks mate 😊,1.0
g07vuga,i2ytc9,No problem!,1.0
g08c2hh,i2ytc9,Did you do it for career reasons or just out of interest?,2.0
g08d7lg,i2ytc9,I was asked to do it by my boss,4.0
g08exzg,i2ytc9,"Interesting! Now that you have it, any thoughts on what next?   


Curious if you (or your boss) would be interested in a more advanced certificate, and if that would be considered to have value?",2.0
g08jgas,i2ytc9,"I genuinely searched today for a more advanced certificate from the TensorFlow team, so yeah I would be interested, I mainly just want to learn more advanced stuff about TensorFlow and ML.",3.0
g0bzlel,i2ytc9,"I'm working on the Advanced TensorFlow Specialization right now, and hope to have it launched before the end of the year. May have a certificate exam that goes along with it too in a similar way to the one that you've done. Looking into the logistics of that.",2.0
g0g43e3,i2ytc9,"That really great to hear, I am looking forward to it! :)",1.0
g0g49ou,i2ytc9,[deleted],1.0
g0g58ls,i2ytc9,RemindMe! eoy “Check if the advanced TensorFlow specialization has been released”,1.0
g0g5jdd,i2ytc9,"I will be messaging you in 4 months on [**2020-12-31 09:00:00 UTC**](http://www.wolframalpha.com/input/?i=2020-12-31%2009:00:00%20UTC%20To%20Local%20Time) to remind you of [**this link**](https://np.reddit.com/r/tensorflow/comments/i2ytc9/finally_received_my_certificate_tensorflow/g0g58ls/?context=3)

[**1 OTHERS CLICKED THIS LINK**](https://np.reddit.com/message/compose/?to=RemindMeBot&amp;subject=Reminder&amp;message=%5Bhttps%3A%2F%2Fwww.reddit.com%2Fr%2Ftensorflow%2Fcomments%2Fi2ytc9%2Ffinally_received_my_certificate_tensorflow%2Fg0g58ls%2F%5D%0A%0ARemindMe%21%202020-12-31%2009%3A00%3A00%20UTC) to send a PM to also be reminded and to reduce spam.

^(Parent commenter can ) [^(delete this message to hide from others.)](https://np.reddit.com/message/compose/?to=RemindMeBot&amp;subject=Delete%20Comment&amp;message=Delete%21%20i2ytc9)

*****

|[^(Info)](https://np.reddit.com/r/RemindMeBot/comments/e1bko7/remindmebot_info_v21/)|[^(Custom)](https://np.reddit.com/message/compose/?to=RemindMeBot&amp;subject=Reminder&amp;message=%5BLink%20or%20message%20inside%20square%20brackets%5D%0A%0ARemindMe%21%20Time%20period%20here)|[^(Your Reminders)](https://np.reddit.com/message/compose/?to=RemindMeBot&amp;subject=List%20Of%20Reminders&amp;message=MyReminders%21)|[^(Feedback)](https://np.reddit.com/message/compose/?to=Watchful1&amp;subject=RemindMeBot%20Feedback)|
|-|-|-|-|",1.0
g7rx3yt,i2ytc9,Great really looking forward to the advanced version as well!,1.0
g09x8qb,i2ytc9,Not gonna lie looks amazing !,2.0
g2yhyk4,i2ytc9,"Quick question pls, will you get asked, in the exam, to plot results or images??
I know how to plot simple results like accuracy/losses, but some visualization scripts used in the Coursera specialization looked sophesticated to me!",1.0
g30jh98,i2ytc9,"No, you don’t have to worry, plotting is completely irrelevant to the exam, the only thing you should worry about is the accuracy of your models",2.0
g310j8m,i2ytc9,It's great I don't have to focus much on the plotting part (for now!). Thanks,1.0
g4gx734,i2ytc9,"I am really tired of fixing bugs of my local machine's TF setup (e.g. my GPU can't handle Bidirectional(LSTM) layers)
I am thinking of buying Google Colab Pro just for one month to use, hopefully, in the exam.
Will that be possible or do I have to do everything on my PyCharm?? What are better alternatives you could advice for? (other than the expensive option of buying new hardware )",1.0
g4gz58c,i2ytc9,"I think [this](https://www.reddit.com/r/tensorflow/comments/hqd0qd/megathread_tensorflow_certification_exam/?utm_source=share&amp;utm_medium=ios_app&amp;utm_name=iossmf) mega thread I created a while back might be of some help to you

Edit: also FYI, you don’t need to pay for google colab to use it, you can do that for free.",1.0
g4ivd0n,i2ytc9,"I looked at it, again, thanks.",2.0
g8kp9p8,i2ytc9,"did you need GPU to finish the exam? I can't get TF2.0.0 (the exam's version) to use my GPU (compute capability = 5) no matter what...not locally nor using Google Colab!

if I set TF in Colab to be TF2.0.0 I still can't get GPU...any suggestions, please? (TF2.2+ works fine on my local machine with GPU)",1.0
g07hhre,i2w7db,Tensorflow in Practice specialization on Coursera is a great introduction series.,1.0
g08f2je,i2w7db,(blush) Thank you! :),5.0
g08jum5,i2w7db,"No really, thank you! You’re an engaging teacher, and I want that neural network coffee mug!",1.0
g08tyix,i2w7db,"Just asking, how much experience do you need already in deep learning for the course? I have done some WEKA before but I am not too experienced with deep learning.",1.0
g0a3qdu,i2w7db,"You don’t really need any experience in deep learning, but Python is required.",1.0
g0bzgyd,i2w7db,"Thank you so much! And Haha! Sorry, not sharing the mug! :)",1.0
g0ayfj6,i2w7db,"Thanks for the feedback /u/naivoder_

Happy learning !!!",1.0
g04wc9p,i2icui,"I started working on NSFW Filter as a cool side-project and once I thought I had an MVP, I open-sourced it and shared it on GitHub.

Then a few interested people came along and made it better and we finally released it. 

I decided to share it on Product Hunt, echoJS and stuff like that to get more contributors to improve the project. (At this point me and another guy were the only ones active on the project)

After sharing I saw a spike in the number of visitors and after a few days I just checked the product hunt page to find NSFW Filter as featured!

This is my first project that is going this ""big"" maybe that is why I am so excited!

Check it out: [https://www.producthunt.com/posts/nsfw-filter](https://www.producthunt.com/posts/nsfw-filter)

GitHub: [https://github.com/navendu-pottekkat/nsfw-filter](https://github.com/navendu-pottekkat/nsfw-filter)",10.0
g04zmcl,i2icui,Thats beautiful! Keep it up :3,2.0
g0510cd,i2icui,Thank you! This subreddit has been really helpful!,2.0
g06ucgr,i2icui,would be cool on r/developerShowcase,2.0
g046dvq,i27xij,"You should go to tensorflow documentation to see 
callbacks",2.0
g06ktjz,i27xij,Check out all the Keras functionality for decay [link for [optimizers](https://keras.io/api/optimizers/)],1.0
g06lqfa,i27xij,This talks about decay which I am using already as a linear piece wise decay. I am interested in coupling both learning rate warmup followed my learning rate decay for VGG styled models.,1.0
g06lvyh,i27xij,"Look at the learning rate schedular via callbacks, you can manually program the learning rate incrementation method (and setup a warm-up plus a decay) by creating a schedule function that determines LR via epoch https://www.tensorflow.org/api_docs/python/tf/keras/callbacks/LearningRateScheduler",2.0
g06m9w0,i27xij,"Last question, do you know how to use such a learning rate scheduler with tf.GradientTape() instead of fit() ?",1.0
g06mmj4,i27xij,If you're looking to do something like that I'd suggest a different approach: create a tf.keras.optimizers.schedules.LearningRateSchedule instance and pass it as learning_rate argument to your model's optimizer. This allows you to define a custom learning rate scheduler and won't interfere with the usage of Gradient tape instead of fit. Hope this helps!,1.0
g06msol,i27xij,Thanks !,2.0
g2s8xr1,i27xij,Where can I find a tutorial for using tf.keras.optimizers.schedules.LearningRateSchedule? I went to the [TF LearningRateSchedule](https://www.tensorflow.org/api_docs/python/tf/keras/optimizers/schedules/LearningRateSchedule) and found it to be quite blank.,1.0
g06iya4,i27fld,"AWS elastic beanstalk is a layer on top of EC2, and EC2 has a good support for wide range of ML frameworks. I never tried on bean stalk earlier, but I think we can deploy a docker with tensorflow serving or a tensorflow flask/django application docker on bean stack",1.0
g0282bm,i26w92,"I am thinking if tensorflow will not be a good candidate to solve this problem? 

If you're doing it for an application, i will recommend doing pixel by pixel comparison. Get the different pixel, you should have the element cut out.",11.0
g028onp,i26w92,"It gives a very bad result, is what I tried first, things that should be red aren't and things that shouldn't are. For example if you see the black shadow edge in the hand those pixels did not changed color, the background was already black.",1.0
g02acmc,i26w92,Have you looked into opencv.js?,2.0
g02al3p,i26w92,"&gt;opencv.js

ohh I haven't, that looks interesting, thanks!",3.0
g02aro5,i26w92,Why don't u try segmentation models and there are loads of model which are pre trained on humans,5.0
g02h3dp,i26w92,"Thanks!

I google it and seems almost ideal.

I'm having trouble finding how to actually use it, I just find papers and stuff, could you recommend a link?",1.0
g02i73x,i26w92,https://youtu.be/xXzNsOHsrmo try this or search some videos on youtube related to mask rcnn with keras implementation since ur working with tensorflow.,1.0
g02697v,i26w92,"I'm using tensorflow.js

I divided the pictures in smaller parts, training data is the background pic + person pic = resulta pic.

my neural net is something like this

  model = tf.sequential();

  model.add(tf.layers.dense({units: 2406, inputShape: \[2406\]}));

  model.add(tf.layers.dense({units: 2406}));

  model.add(tf.layers.dense({units: 2406}));

  model.add(tf.layers.dense({units: 2406}));

  model.add(tf.layers.dense({units: 2406}));

  model.add(tf.layers.dense({units: 25}));

  model.add(tf.layers.dense({units: 25}));

  model.add(tf.layers.dense({units: 25}));

  model.add(tf.layers.dense({units: 25}));

  model.add(tf.layers.dense({units: 25}));

  model.compile({loss: 'meanSquaredError', optimizer: 'sgd'});

&amp;#x200B;

I don't know a lot of machine learning I'm just playing around. How could I improve this?

I'm trying to measure how fat I am (measure my area in the pic) to see if doing diet is effective :P",2.0
g02ygck,i26w92,You may want to look into convolutional networks. They will almost certainly improve your performance.,3.0
g0405kl,i26w92,"tf.layers.dense() without an activation function is a simple linear regression. When you stack multiple dense() layers, they add up linearly and become equivalent to tf.layers.dense({units: ~~1~~ 25, inputShape: [2406]}); 

One thing that might solve your problem is https://blog.tensorflow.org/2019/11/updated-bodypix-2.html

If your background doesn't change (I mean it can move a bit but the objects remain the same otherwise) you could use much simpler algorithms that would first align the background image with the test image, and then determine your shape based on subtraction.

P.S. Your area depends on how close you stand to the camera. It's not a very reliable method!",3.0
g04clei,i26w92,"Thank you!

So you are saying adding layers as I'm doing has no effect? how can I change that?

bodypix doesn't seem to be accurate enough: [https://i.imgur.com/aaKwSf3.png](https://i.imgur.com/aaKwSf3.png)

Subtracting the images and applying a threshold is what I attempted first but it works worse than my current neural net attempt: [https://imgur.com/a/Zh6eSQd](https://imgur.com/a/Zh6eSQd)

I have marks in the floor so that I stand in the same place always, same with the camera. When I get the red area by hand there is a good correlation between weight that day and the number of red pixels: [https://i.imgur.com/lho6aLV.png](https://i.imgur.com/lho6aLV.png)",2.0
g04t438,i26w92,"&gt; So you are saying adding layers as I'm doing has no effect? how can I change that?

Try specifying an activation function (e.g. sigmoid). https://js.tensorflow.org/api/0.6.1/#layers.dense It may not improve things (training is tricky) but it will utilize the layers better. Also, it would help to reduce the number of hidden layers to 1 or 2 with a non-linear activation.

&gt; bodypix doesn't seem to be accurate enough

Try it with full body images, e.g. the test ones from https://blog.tensorflow.org/2019/11/updated-bodypix-2.html

&gt; Subtracting the images and applying a threshold is what I attempted first but it works worse than my current neural net attempt:

If having a green screen is an option, it would completely solve your problem.",2.0
g06nbyk,i26w92,"seems to be improving! [https://i.imgur.com/FSdcBwP.png](https://i.imgur.com/FSdcBwP.png?1)

I did this:

`model = tf.sequential(); model.add(tf.layers.dense({units: 2408, inputShape: \[2408\]})); model.add(tf.layers.dense({units: 2408, activation: 'sigmoid'})); model.add(tf.layers.dense({units: 2408, activation: 'elu'})); model.add(tf.layers.dense({units: 2408, activation: 'linear'})); model.add(tf.layers.dense({units: 2408, activation: 'relu'})); model.add(tf.layers.dense({units: 2408, activation: 'tanh'})); model.add(tf.layers.dense({units: 25})); model.add(tf.layers.dense({units: 25})); model.add(tf.layers.dense({units: 25})); model.add(tf.layers.dense({units: 25})); model.add(tf.layers.dense({units: 25}));`

I might play around with bodypix

lol at some point I did put one but it was too inconvenient, I want something totally automatic [https://i.imgur.com/kiPu3aL.png](https://i.imgur.com/kiPu3aL.png?1)",1.0
g02f72n,i26w92,Exactly this question! :I want to remove people from a picture. What’s the best approach?,2.0
g02yq1m,i26w92,Look up image segmentation and neural in-painting with GANs or something like this,2.0
g0575l0,i26w92,"You can archive that using Opencv, just google background subtraction.

&amp;#x200B;

 [https://docs.opencv.org/3.4.8/d8/d38/tutorial\_bgsegm\_bg\_subtraction.html](https://docs.opencv.org/3.4.8/d8/d38/tutorial_bgsegm_bg_subtraction.html)",1.0
g05kt0b,i26w92,Maybe this video/paper can help: [video](https://youtu.be/ICr6xi9wA94),1.0
g06l7v4,i215tw,"Congrats, you ran into the interpretability problem. Big problem for NN/ML designers in understanding how the network actually works. As far as seeing the contributions of each layer or node in a neural network, there are some existing architectures for understanding this (Google is your bff). As far as your second question


&gt;Shouldn't there be a matrix somewhere that is 4 x 3 = 12 weights showing the contribution of each of the 4 features to each of the 3 neurons in the first dense layer? 

If by contributions you mean weightage of each node in the network (analogous to the connectivity of the neuron) then yes. Those are the weights and IIRC you can extract them from a layer by a single call. (Define the layer as an object and then make the call in accordance to the Keras API), It will be like layer.weights or layer.w",2.0
g06oldg,i215tw,"I just found out how to do this .  There is a .get_weights() which returns a numpy array and a .weights that returns a tensor . Thank you, this is such an important component that I feel like is massively overlooked.  Explainable AI I feel like is the only way we can really start to understand the backend of the complex processes we are modeling.  I work in bioinformatics so yea it’s important to get your classification accuracy high but what do the features inside mean biologically? That is why I’ve steered away from neural networks but this new architecture is so elegant I can’t not learn it!",2.0
g06oub8,i215tw,"Yeah fosho. It's really cool and the application to biotech is awesome. Interpretability is a big thing, as you do more research, you will find out more about it. There is an entire segment of AI dedicated to developing systems that turn the black box into something comprehensible to normal people. Keep learning, you're on the right path! Good luck on your future projects",1.0
g06p63d,i215tw,Thank you!,2.0
g06pcsh,i215tw,"Btw, not sure if you’re active on stackoverflow but if you have any insight on this it would be super helpful https://stackoverflow.com/q/63175471/678572",2.0
g06q9av,i215tw,"I think you have an incorrect idea of the purpose of the dense layer. It is important to differentiate between a neuron and node. IIRC, in the human brain, there are specific neurons that code for certain things (like a neuron that fires when you see a doughnut, I know I'm over simplifying it but bear with me). In neural networks, the property is mimicked via a layer. But this is where the similarities end. In neural networks, you do not map individual neurons to features from the input, but you train a sequence of layers upon a dataset in order to infer new predictions from new inputs. Each layer is made up of a sequence of nodes, and each node connects to each input, and the network (over the course of training) adjusts each node's weight to produce an overall output that conforms to the target result. Wiring an INDIVIDUAL NODE to a feature is not something that can be done and defeats the entire purpose of training a neural network (and that fine grained manipulation would break any training that the system had performed). If you want to improve the accuracy of your system or improve Recall/Precision, you should experiment with more layers, different types of layers, different optimizers, callbacks, etc. But the type of adjustments you are trying to make ""connecting a certain neuron to a certain feature"" is not what NNs are for and breaks their working mechanisms (the weights are adjusted over training automatically, you can't just change the weights yourself).

Hope this cleared up at least a little!

Edit: fuck me, I misspoke. I should have been more clear. When I say you can't adjust the weights yourself, I didn't mean you can't implement architectural changes via callbacks, optimizers, etc. that change the weightage of nodes automatically over the course of training (optimizing them to be the best possible), I meant you can't change the weightage by typing in your ideal number for a node weight.",1.0
g06s1e3,i215tw,"Thanks for looking into that problem with such detail.  Yea, I definitely understand it’s not accurate (yet) and that you can’t (not should you) directly hardcode an input feature to a specific neuron.  What I was trying to do was have the NN decide which neuron it goes to maybe by having some type of soft max function where it starts to minimize the output values to the adjacent neurons in the layer.  I think this can be possible because dropout layers can randomly cut some connections.  This could be like dropout in some ways.  It would be really useful and interpretable if a NN could train a model where feature A and B went to neuron 1, feature C went to neuron 2, and feature D went to neuron 3 could somehow minimize the loss better than any other combination or something.  Essentially, how can the features be combined in a mutually exclusive way to minimize the loss?",2.0
g06sg25,i215tw,"Dropout is entirely random with a predefined probability setting so it wouldn't be as specific as you were looking for but it is most certainly a great tool for training complex nets while preventing overfitting. In response to your last question: 

&gt;how can the features be combined in a mutually exclusive way to minimize the loss?

I think this could be done via feature combination or data augmentation of a sort. For example: instead of passing In petal length and width to a certain layer, pass in a ratio of both (calculated in preprocessing) to a single layer or sequence and use those outputs as additional inputs for the network. The possibilities are endless and far too many to state here but I would look into all of the following: feature engineering, optimizations, callbacks, probability dependent dropouts. You could even stack networks or hell, make some random forests and start pruning those bad boys. Like I said the possibilities are endless but those stuff I listed above are great starts. For the project you are tackling above in the iris dataset, getting an accuracy of 85%+ is super reasonable and a great start. You could always keep perfecting but as a biotech guy I'm sure you have plenty of combinatorial genetics ML-powered projects you want to try lol. Again, I wish you luck!",1.0
g016tld,i215tw,"&gt; Without this type of understanding, this algorithm is pretty much a black box.

Someone should have explained that in the first place

Its one of the most commonly known downsides of a NN . If you are looking for well defined interpretability than you are choosing the wrong model",1.0
g018e3r,i1zxk4,Looks like you ran out of memory i.e. your model is too big.,6.0
g020bbr,i1zxk4,So now what to do please suggest me something :'),1.0
g04u4eh,i1zxk4,Use fewer samples / use a smaller type or https://downloadmoreram.com/index.html,2.0
g00vunt,i1zxk4,"Can you please create github gist with error message from terminal and source  code. 
Thank you 🙏",6.0
g09f5ra,i1zxk4,"Your tensor shape is 52 million, so you're out of memory.",2.0
g0arckj,i1zxk4,"So how to fix it I do step according to this tutorial please help :,-) https://tensorflow-object-detection-api-tutorial.readthedocs.io/en/latest/install.html",1.0
g0asym6,i1zxk4,Use less memory.,2.0
fzy7mtj,i1fpxh,"i see your model only has 1 single layer, is that right?",1.0
g03vnbd,i1fpxh, C çvyybbuuyyft you ggggffffff to the t to to the,1.0
fzypgcf,i1fpxh,Yes you are correct,0.0
fzz36o9,i1fpxh,i guess that's the problem. what's the purpose of neural net if you only have a single layer?,1.0
fzz3f9n,i1fpxh,"You're right. Here's my current code:

    model = tf.keras.Sequential([
        tf.keras.layers.Dense(1, activation='softmax',
                              input_shape=[1, ]),
        tf.keras.layers.Dense(8),
        tf.keras.layers.Dense(4)

    ])


This gives me

Epoch 1/10
330211/330211 [==============================] - 282s 854us/step - loss: 0.5625 - mae: 1.3455 - mse: 2.0037 - accuracy: 0.2508
Epoch 2/10
330211/330211 [==============================] - 269s 815us/step - loss: 0.5625 - mae: 1.3460 - mse: 2.0044 - accuracy: 0.2511
Epoch 3/10
330211/330211 [==============================] - 280s 848us/step - loss: 0.5625 - mae: 1.3460 - mse: 2.0045 - accuracy: 0.2514

I stopped it

Can you please give me a suggestion of how I should layer it?",1.0
g09fluf,i1fpxh,What's your data? What are you trying to do? Your network is almost certainly way too small.,1.0
g0b9tpg,i1fpxh,"I have about 7 million times:

float64, [0,1], [0,1], [0,1], [0,1]

I'm trying to find a pattern within a biological system to predict protein folding...",1.0
fzy9k3q,i1fpxh,You need to have at least 4 (output) neurons for your desired y and have softmax as your activation function. Also make sure you specify input shape.,1.0
fzypk80,i1fpxh,"I've had a very tough time trying to specify the input shape, it's always the wrong one. Output neurons should be like this?

&amp;#x200B;

neuron for 0

neuron for 1

neuron for 2

neuron for 3

&amp;#x200B;

?",0.0
fzypyti,i1fpxh,"Change the 1 in the 2nd line to a 4. Also make sure you convert y into an array so if y I’d originally 0, it’s now [1,0,0,0]. If y is 1, it’s now [0,1,0,0], etc. Input shape is another parameter like the activation function. I’ve got to warn you though, you will get bad results with your current architecture.",1.0
fzyzmmn,i1fpxh,"Thank you for your suggestions. Ok I changed it to softmax and reshaped my output to a,b,c,d the way you described (each being either 0 or 1 at a time, eg:

&amp;#x200B;

`value,a,b,c,d`

`460121378802106371,0,0,1,0`

`828640918192970058,1,0,0,0`

`894462404293372279,0,0,0,1`

`224143438513116277,0,1,0,0`

&amp;#x200B;

Is this better now?

I am unsure of what I should use as a shape...

&amp;#x200B;

Here's my code now

&amp;#x200B;

        model = tf.keras.Sequential([
            tf.keras.layers.Dense(4, activation='softmax',
                                  input_shape=[1, 1]),
            tf.keras.layers.Dense(4)
        ])
    
        optimizer = tf.keras.optimizers.RMSprop(0.001)
    
        model.compile(loss='mse',
                      optimizer=optimizer,
                      metrics=['mae', 'mse'])",1.0
fzzmxly,i1fpxh,Ok now normalize x so all values are between 0 and 1.  You don’t need the loss again in metrics. loss should be categorical crossentropy,1.0
g08bf50,i1fpxh,"Took me a while until I realized I can just use "".divide""... still no change:

    def build_model():
        model = tf.keras.Sequential([
            tf.keras.layers.Dense(1, activation='softmax',
                                  input_shape=[1, ]),
            tf.keras.layers.Dense(4),
            tf.keras.layers.Dense(4)
    
        ])
    
        optimizer = tf.keras.optimizers.RMSprop(0.001)
    
        model.compile(loss=tf.keras.losses.BinaryCrossentropy(from_logits=False),  # 'mse',
                      optimizer=optimizer,  #
                      metrics=['mae', 'mse', 'accuracy'])
        return model

&amp;#x200B;

    _________________________________________________________________
    Epoch 1/10
    330211/330211 [==============================] - 228s 690us/step - loss: 3.0286 - mae: 0.5481 - mse: 0.4888 - accuracy: 0.2516
    Epoch 2/10
    330211/330211 [==============================] - 227s 686us/step - loss: 2.9751 - mae: 0.4880 - mse: 0.4118 - accuracy: 0.2516
    Epoch 3/10
    330211/330211 [==============================] - 227s 686us/step - loss: 1.5148 - mae: 0.5338 - mse: 0.4634 - accuracy: 0.2495
    Epoch 4/10
    330211/330211 [==============================] - 229s 695us/step - loss: 1.3949 - mae: 0.7801 - mse: 1.2013 - accuracy: 0.2495
    Epoch 5/10
    330211/330211 [==============================] - 237s 719us/step - loss: 1.3950 - mae: 0.9156 - mse: 1.8016 - accuracy: 0.2495
    Epoch 6/10
    330211/330211 [==============================] - 243s 736us/step - loss: 1.3950 - mae: 0.9588 - mse: 2.0273 - accuracy: 0.2495
    Epoch 7/10
    330211/330211 [==============================] - 249s 754us/step - loss: 1.3950 - mae: 0.9635 - mse: 2.0524 - accuracy: 0.2494
    Epoch 8/10
    330211/330211 [==============================] - 252s 764us/step - loss: 1.3950 - mae: 0.9666 - mse: 2.0712 - accuracy: 0.2494
    Epoch 9/10
    330211/330211 [==============================] - 253s 767us/step - loss: 1.3950 - mae: 0.9843 - mse: 2.1699 - accuracy: 0.2495
    Epoch 10/10
    330211/330211 [==============================] - 248s 752us/step - loss: 1.3950 - mae: 0.9800 - mse: 2.1458 - accuracy: 0.2492
    bash-3.2$",1.0
g10x3gn,i1fpxh,"Now I have very good results, almost 55%, thank you. I use 10 layers with 1024, 512, ..., 16, 8, 4, 2, 1 each softmax except for 1 which is sigmoid.

&amp;#x200B;

Can you please tell me how to save the results and be able to evaluate my model, please? I would like to enter a value and get a result now, thank you in advance.",1.0
fzyj53m,i1etni,"You are only saving to the list, the trainable weights. You can see that you also have Non trainable weights in the summary.

When you check the length, you are also just checking the length of trainable layers.

My guess is that you have in total, 100 layers, 68 trainable and 32 non trainable.

So when you load the weights, you need to account the non trainable weights as well, that's why it's giving you the error, because `model.set_weights()` sets the weights to the entire model.

You want to do something like this (not tested).

    for idx, layer in enumerate(model.trainable_layers):
        layer.set_weights(vgg_19_np_wts[idx])",2.0
fzyted7,i1etni,"Good point, do you know how to iterate through all layers of a model? Whether it be trainable or non-trainable?",1.0
fzyua03,i1etni,"It would be as simple as

    for layer in model.layers:
        layer.set_weights(vgg_19_np_wts)",1.0
fzyzrwl,i1etni,"I don't think this would work because:

    type(winning_ticket_model.trainable_weights), len(winning_ticket_model.trainable_weights)
    # (list, 68)

Versus:

    type(winning_ticket_model.layers), len(winning_ticket_model.layers)
    # (list, 53)

Therefore, ""model.layers"" is not counting the 15 layers which ""model.trainable_weights"" does.",1.0
fzz0jby,i1etni,"The code that works is:

model.weights

len(winning\_ticket\_model.weights)

\# 100",1.0
fzwh4a2,i1c86o,"You'll probably want to create your own implementation to support a 3D topography. I imagine you should be able to copy the scipy implementation for COO or something similar, and just add a fourth array for the 3rd dimension of your sparse array. Obviously you'll have to come up with operator methods on your own, but it shouldn't be too much work.",1.0
fzzeq4r,i1c86o,"I tried some things (code below), but now I happened to get some known bugs from the input layer. I'll see if I can go around [this issue](https://github.com/tensorflow/tensorflow/issues/25980), but it seems that unfortunately I would need to use dense array

`from tensorflow.keras.layers import Dense, Flatten`

`from tensorflow.keras import Input, Model, callbacks, models`

`from tensorflow.keras import backend as K`

`from tensorflow.keras.optimizers import Adam`

`import tensorflow as tf`

`import sparse`

&amp;#x200B;

`def convert_sparse(sparse_matrix):`

`indices = list(zip(*sparse_matrix.coords))`

`values = sparse_matrix.data`

`dense_shape = sparse_matrix.shape`

`return {'indices':indices,'values':values, 'dense_shape':dense_shape}`

&amp;#x200B;

`main_input = Input(shape=(5,5,5,), sparse=True, name='main_input')`

`flattened = Flatten()(main_input)`

`output = Dense(1, activation='softmax', name='output_actor')(flattened)`

&amp;#x200B;

`model = Model(inputs=[main_input], outputs=output, name='model_critic')`

`model.compile(optimizer=Adam(lr=0.01), loss='mean_squared_error')`

&amp;#x200B;

`coords = [[0, 1, 2, 3, 4], [0, 1, 2, 3, 4], [0, 1, 2, 3, 4]]`

`data = [1.0, 2.0, 3.0, 4.0, 5.0]`

`x = sparse.COO(coords, data, shape=(5,5,5))`

`batch = sparse.stack([x, x, x], axis=0)`

`tensor = tf.SparseTensor(**convert_sparse(batch))`

`model.predict(tensor)`",1.0
fzyq1wg,i188kz,Wow it's like they're listening to my complaints to my coworkers. Is the data pipeline bottleneck actually better?,2.0
g044h2w,i188kz,"*TF 2.3: Complaints to coworkers addressed*

*TF 2.4: Complaints about coworkers addressed*",3.0
fzs6ons,i0reqm,"import tensorflow_hub as hub

useModel = hub.load(path_to_savedmodel_folder)",1.0
fzsiju7,i0reqm,"If anyone happens to see this I solved it by downloading the tar.gz file, extract it into your project directory so that the saved_model.pb is accessible. Use save_load or load_saved_model, can’t really remember, but not just the normal load. From there you can create the model but some more steps are still required to infer from it",1.0
fztwpsn,i0nrni,This has potential as an ad blocker.,1.0
fzu02rq,i0nrni,How do we go about that?,1.0
fzvvjft,i0nrni,Use the same image processing hooks but train a different model based on known ads. Filter lists from ublock origin would be a good source for scraping ad images.,1.0
fzvx0ho,i0nrni,That is a good idea. It is worth trying out. Maybe that could be our next project!,1.0
fzr1n5d,i0l29r,thanks I will need it!,2.0
fzsra4o,i0l29r,Glad I can be of help :),1.0
fznawmq,i04xby,Could it mean “unknown”? Could it be an artifact from copy/paste or some such operation showing up? Maybe an image of what you’re referring to would help but I can’t think of anything in particular.,1.0
fzluwcx,hzv6x7,"This link might help you 
https://www.tensorflow.org/tutorials/keras/save_and_load",3.0
fzll8ki,hzv6x7,If you are using keras you can save entire model along with weights or only weights if you want. Then next time when you are working you can just load the saved model rather than training from starting.,2.0
g09g8b2,hznhyw,Isn't that to be expected? Especially if you're fetching from disk and not from RAM,1.0
g0a3rmy,hznhyw,I image the prefetching would mitigate this though,1.0
fzhu7aw,hzb0b4,"Ok I answered my own question. Here is the solution:

https://storage.googleapis.com/tensorflow/libtensorflow/libtensorflow-cpu-linux-x86_64-2.3.0.tar.gz

Replace the version number at the end with the one you are looking for.

I don't want to be an ass, Tensorflow is a nice and complex piece of software... but seriously I am tired of jumping through so many hoops for stuff as basic like this.
Information is spread between too many places and not accurate. Tensorflow website point to outdated libtensorflow v1.15.0 and github page point to Google Cloud Storage for nightly build (which mean it can break without warning...)
Seriously it's nothing short of gruesome.

Some bugs stay in place for way too much time (looking at you go bindings...)",3.0
fzifcc0,hzb0b4,"Well to be honest 1.15 is not outdated, since first version is still supported. But yes, I can't migrate to tf2 because there is no official prebuilt binaries of C API. I have spent some time trying to build it myself, but there are so many underwater rocks combined with long compilation time that I gave up and used prebuilt C API.",1.0
fzgn2ko,hz3vl0,"Pandas is the go to library for everything csv related. + it works for other data formats like excel, json, XML, etc",3.0
fzgrafy,hz3vl0,"Thanks for the advice, I tried to do import pandas as pd and it says that there’s no module names ‘pandas’. I know I have pandas installed because when I do pip install pandas and conda install pandas it says pandas is installed. Am I using the wrong version or something.",1.0
fzgzk9c,hz3vl0,"Chances are that you are using the wrong version of Python/wrong Python environment (well, not using one in which you installed Pandas).

What OS are you using? What are you using to run your python program (from the command line, or another program?).

Without knowing more about those things, I'd suggest running 'pip -V' and look at the directory it is in. And within python, you might run something like 'help(""py"")' and take a look at where it says the File is (take a look at the directory).",3.0
fzh2zd1,hz3vl0,I’m using the anaconda prompt to run this program. [Here’s](https://i.imgur.com/Xdr6QPv.jpg) a photo for reference.,1.0
fzh59or,hz3vl0,You have to install pandas after you activate tf_2. You're installing it to your (base) environment but then switching to a new one.,2.0
fzh7acw,hz3vl0,Ah I see thank you.,1.0
fzh7wgi,hz3vl0,"Sure thing, you should also learn about using conda install. It'll help if you ever switch out of Windows.",1.0
fzhi88w,hz3vl0,it's pretty straightforward: https://www.tensorflow.org/tutorials/load_data/csv,1.0
fzjduae,hz3vl0,I’m just confused because when they enter the file they seem to have some kind of link but my file is on my computer.,1.0
fzkmu7n,hz3vl0,"they download the files, then use:make_csv_dataset

     # https://www.tensorflow.org/tutorials/load_data/csv
     import functools
     import numpy as np
     import tensorflow as tf
     path='worldwide_happiness_report.csv'
     dataset = tf.data.experimental.make_csv_dataset(path,batch_size=8)
     print(dataset)",2.0
fzp2uqx,hz3vl0,I see thank you,1.0
fzhcgn9,hywcvr,"Dude, your videos are absolutely incredible! I'm planning on doing a side project that requires working with audio signals but I didn't have the slightest clue on how to get started, then I discovered the gold mine that your channel. I can't thank you enough, dude! Looking forward to your next video. :)",1.0
fzhjt29,hywcvr,Thanks a lot :) I'm glad the videos help you.,2.0
fzenfwp,hyrr8r,There's a tutorial here - [https://towardsdatascience.com/artificial-neural-networks-optimization-using-genetic-algorithm-with-python-1fe8ed17733e](https://towardsdatascience.com/artificial-neural-networks-optimization-using-genetic-algorithm-with-python-1fe8ed17733e),2.0
fzg6ebx,hyrr8r,I wouldn't go in to areas like this unless you have a good reason not to use standard backpropagation.,1.0
fzer7ex,hyr34l,"Need to be more specific when you say LSTM takes in list of inputs, does it take one sequence followed by the other or you want to create two lstms that take these two inputs separately and then concatenate the outputs",2.0
fzetqxr,hyr34l,"There is a single LSTM layer, and a single training sample would be a list of sequences (e.g.: 10). This layer is just to get embeddings for said sequences and after that layer they are compared using cosine similarity.",1.0
fzlg5ec,hyr34l,"So these 10 sequences can be treated as the features, you directly pass th to the embedding layer in keras specifying the embedding dimension",1.0
fzh9fl0,hyr34l,"&gt; I don't know if the gradients will backpropagate

They won't if you use numpy in there.

(but have you seen tf.experimental.numpy)

&gt; I don't know which axis to concatenate.

Are these two sets of features for the same timesteps? concat the features. Are they two timeseries of the same features? concrat the times. neither? Don't concat, that doesn't make sense.",1.0
fzj6qc9,hyr34l,"thank you for the heads up about numpy, but still would the gradients flow back, I was also thinking instead of that loop (which turned out to be wrong anyways) I would, before passing anything to the model, concatenate horizontally the training samples (which essentially make up one training sample) then pass that to the model and in my call function I would just slice what I concatenated (would be sliced into N equal parts) and pass each one to the LSTM, but still my primary concern remains.",1.0
fzlamxl,hyr34l,"&gt; would the gradients flow back

If you stick to tensorflow ops, yes.

But it's easy to test if your gradients are working.

Have you read this doc, specifically the ""getting a gradient of None"" section:
 https://www.tensorflow.org/guide/autodiff#getting_a_gradient_of_none

It lists the common failure cases.",1.0
fze8q3j,hyp2x4,The driver version is fine. 418 and 450 are backward compatible with CUDA toolkit 8 and 9. The problem is CUDA toolkit and cuDNN. IIRC TensorFlow 1.x requires CUDA toolkit 9 and cuDNN 7. However I'm not sure how to resolve this in Colab... It's easier if you're on a regular Ubuntu machine.,1.0
fzeu4dn,hyp2x4,"Hello sir, If you know the Solution for regular Ubuntu, it works fine for colab too.",1.0
fzeyfwh,hyp2x4,My solution is to just use NVIDIA docker. You only need the driver and NVIDIA docker to run any version of TensorFlow.,3.0
fzdvoew,hyo4ww,What’s the train_x and train_y?,1.0
fzdvqtx,hyo4ww,"A lot of csv data. Train_x is 9 columns and many rows, train_y is 1 column, many rows.",1.0
fzdw1ov,hyo4ww,added a bit more info to the post; parse_csv,1.0
fze3nyv,hyo4ww,I would guess your placeholder_y and train_y has different shape and/or dtype.,1.0
fzfbje4,hyo4ww,Why do you think its train_y?,1.0
fzfwrzn,hyo4ww,"I haven't really used tf version below 2.x. So, maybe I am wrong.

So, you have given dtype =  tf.int64 and shape = \[\] to your placeholder\_y. I understand you have train\_y as one column so that's like a 1-d tensor. But is the shape of train\_y really like this: \[None\]? It can also be \[None, \] or so. Also the dtype of train\_y may not be int64. (Perhaps I am confused!!!)

Therefore, I would recommend to check the type and shape of train\_y and initiate the placeholder\_y accordingly.",1.0
fzcg4lq,hyf0t1,"python 3.5.6.

python 3.8.1 is the current version

on mac",1.0
fzd6mho,hyf0t1,"I don't understand the issue. You said it yourself, TF2 does not support the concept of a ""session"". You don't use the session method at all in TF2.

I would recommend you look at the TF2 tutorials on the TF website. They will show you how to build models in TF2 without the use of ""session"".",1.0
fzqo6yx,hyf0t1,"Thank you, I was taking an online lesson but I ended up returning it. Now I am working with another lesson that uses TF2",1.0
fzdgp6s,hyf0t1,If you really wanna use tensorflow 1.x do a conda install tensorflow==1.15.0,1.0
fzqo7la,hyf0t1,Thank you,1.0
g09gfqs,hyf0t1,Don't use or bother learning TF1. There's no point.,1.0
g1iyird,hyf0t1,yeah i returned the course. I am learning TF2 now. Thanks!,2.0
fzc0vvr,hycvhi,"There isn't a built in way with Youtube's API. 

However, there _is_ [""Youtube 8M"", which has ""350,000 hours of video"" and segmentation data.](https://research.google.com/youtube8m/index.html)

Since you want specific videos from specific channels, [this StackOverflow link](https://stackoverflow.com/questions/8081676/how-to-download-a-youtube-video-using-the-youtubes-api) recommended the Python packages [`pafy`](https://pythonhosted.org/Pafy/) and [`youtube-dl`](https://ytdl-org.github.io/youtube-dl/index.html)

It might make the most sense to:

1. Use YouTube's official API to get a list of the video IDs that you want.
2. Use one of those two packages (pafy or youtube-dl) to download those videos.",5.0
fzc5n2z,hycvhi,"Sweet looking into it now, thank you!",3.0
fzc0kia,hycvhi,youtube-dl,1.0
fzegu2w,hycvhi,Try to use free video downloader for youtube [https://notmp3.com/free-video-downloader-for-youtube/](https://notmp3.com/free-video-downloader-for-youtube/) It might help.,1.0
g5nqdst,hycvhi,You can use [Jihosoft 4K Video Downloader](https://www.jihosoft.com/free-video-downloader.html) to download YouTube videos. It supports batch download and can save all videos in 1080P and 4K UHD quality.,1.0
fzdcxv8,hy9h5d,"https://pypi.org/project/tensorflow/
Go to Release History, pick a version, click Download files. 

You might also want to check compatible CUDA and cuDNN versions somewhere else.",1.0
fzbbgmc,hy80o8,"I suspect that one is diplaying the number of batch and the other the number of samples. 17441 / 546 = 32

So nothing wrong here, just different way to print the advencement of the training.",3.0
fzbc01u,hy80o8,Maybe it's version issue cuz i tried same thing month ago and it ran perfectly but now I reinstalled everything and got this results.  Also I used GPU version same results.,1.0
fzc2z0h,hy80o8,"I wouldn't excalty call it an issue, maybe the older version which you used showed the number of training objects, but now it just shows the number of batches that the model needs to run on. Your training objects are still the same.",1.0
fzapuw2,hy6hx8,"Source code: [https://github.com/uvipen/Super-mario-bros-PPO-pytorch](https://github.com/uvipen/Super-mario-bros-PPO-pytorch)

Full demo: [https://youtu.be/MpWnWWeuRVc](https://youtu.be/MpWnWWeuRVc)",1.0
fzavvf3,hy6hx8,"For being so awesome, it sure does suck at the flagpoles.

Nice work. That brings back a lot of memories.",1.0
fzaetjy,hy4drx,"The interesting TensorFlow(js) is around the 7 minute mark.

I build the original for this as an iPhone app about 10 years ago and realised recently that I should be able to do it in the browser using things like TensorFlow.js

The GitHub repo is here - [https://github.com/atomic14/ar-browser-sudoku](https://github.com/atomic14/ar-browser-sudoku)

You can also try it out here - https://sudoku.cmgresearch.com

The actual model ended up being pretty simple - a single convolution layer followed by a dense hidden layer and then the output layer.

I guess printed digits are not really that hard to recognise. Was a pretty good project to learn on as I could train it on my CPU.",2.0
fzan2s8,hy4drx,"Very nicely explained. If you do it one level lower, you will have to invent the universe.",1.0
fzatnd6,hy4drx,"Thanks! It's a bit of a tricky one - some of the image processing is pretty simple - greyscale and thresholding, then you need to jump up a level to TensorFlow and solving full coverage problems...",1.0
fzcdfl2,hy4drx,Thanks for the great explanation and elegant solution. I would have attempted in a totally inefficient way and probably would have tried to force brute the sudoku.  It worked great on my Iphone X and Samsung S9 inside the Reddit app webview. Congrats!,1.0
fzce7gk,hy4drx,"That's awesome - it always worries with mobile stuff - so many different phones out there. Pretty much guaranteed not to work on some.

I'm tempted to try training up the neural network on the full images of the cells so that the digit extraction phase is not required.

Not sure what impact that will have on performance. At the moment we only need to run the neural net over boxes with digits in which tends to be in the low 20s for most puzzles. Will also make generating good training data more difficult.",1.0
fzchgb0,hy4drx,"I was reading up on the WASM backend that you used and that I haven't tried yet. It is supposed to be compatible with 90% of devices and run faster than the WebGL backend for small models like the one you created. I learned quite a lot of techniques from your tutorial, thanks again for sharing!",1.0
fzdo3xh,hy4drx,"Thanks! I need to do a write up comparing the backends. 

I was seeing some very erratic performance from the webgl backend. I think fir a small model the overhead of getting data into it is too much. I need to do some more thorough investigation of each option.",1.0
fzaegri,hy37jh,"I'm following this guide which seems the best I've come across.

[https://www.youtube.com/watch?v=mmj3nxGT2YQ&amp;t=24s](https://www.youtube.com/watch?v=mmj3nxGT2YQ&amp;t=24s)

You'll need to watch his previous videos and the one on how to label your images. 

Edit. Not sure if that answers your question if you don't want the Object detection api.",2.0
fzake4b,hy37jh,Unless you have thousands of annotated images I think you're going to need to rely on fine-tuning a pretrained model.,2.0
fzajylw,hy37jh,Also check out [roboflow.ai](https://roboflow.ai) that gives an easy way for end to end model creation. I couldn't create a .tflite file from my models and why I stopped using the site but it makes things a lot easier if it's just a .pb file you want to create.,1.0
fzb6rf9,hy37jh,"Why are you opposed to using a premade model like YOLO. In my opinion, its best to try a premade model with your own dataset and try your own model with a popular dataset before trying both together. I assume you just want to try this for the learning aspect?",1.0
fz9ptan,hxzf5d,What type of algorithm are using? Are all your dataset images same?? How much the average lost did you reach before using this model?,1.0
fz9qehv,hxzf5d,"I'm not sure what I'm talking about here just kind of guessing from the code but I think the algorithm is stochastic gradient descent. I'm using 19 different images to train the model, but the different images contain the same exact button. At most I've achieved something around 0.001 loss.",0.0
fz9rixy,hxzf5d,"The stochastic gradient descent, is a type of optimizer, however,  this is was not my question.

My question is which algorithm are using for detection. For instance, Yolo , R-CNN or Faster R-CNN?",1.0
fz9s8tj,hxzf5d,"Sorry, like I said I have no idea what algorithm the code is using, im following this tutorial https://github.com/tensorflow/models/blob/master/research/object_detection/colab_tutorials/eager_few_shot_od_training_tf2_colab.ipynb

Maybe ""rela"", if thats a thing. I think I've seen that somewhere in there.",1.0
fz9s9j9,hxzf5d,"
I see you've posted a GitHub link to a Jupyter Notebook! GitHub doesn't 
render large Jupyter Notebooks, so just in case, here is an 
[nbviewer](https://nbviewer.jupyter.org/) link to the notebook:

https://nbviewer.jupyter.org/url/github.com/tensorflow/models/blob/master/research/object_detection/colab_tutorials/eager_few_shot_od_training_tf2_colab.ipynb

Want to run the code yourself? Here is a [binder](https://mybinder.org/) 
link to start your own Jupyter server and try it out!

https://mybinder.org/v2/gh/tensorflow/models/master?filepath=research%2Fobject_detection%2Fcolab_tutorials%2Feager_few_shot_od_training_tf2_colab.ipynb



------

^(I am a bot.) 
[^(Feedback)](https://www.reddit.com/message/compose/?to=jd_paton) ^(|) 
[^(GitHub)](https://github.com/JohnPaton/nbviewerbot) ^(|) 
[^(Author)](https://johnpaton.net/)",1.0
fz9tud4,hxzf5d,Try to manipulate the model parameters from the config file. Save the original values just in case you needed it later....,1.0
fz9ua29,hxzf5d,"But overall is this something doable? Am I just doing something wrong or this is a difficult task to ask the model to predict? Also another question, the tutorial is using a model that has a 640×640 preset resolution for the images required. Is there anyway I can change that or do I have to train a new model?",1.0
fza5nz1,hxzf5d,"Some models have threshold value, which is adjusted by the user. For example, let's say we have a threshold for the confidence. This threshold is adjusted to 0.5 (50%), so when the model predicts any prediction which has confidence value less than 0.5 (50%) , will be removed and it will keep the predictions which are above 50.... I assume that's your problem. What I suggest that you need to read about the model you have applied and what parameters would control this model's output...",1.0
fzbbgd2,hxzf5d,Hey thanks. I've found the algorithm name - its a single shot box detector. I'm going to take a look at the configuration file to see if i can tweak the threshold as you suggested but is there also a way to change the resolution of the model or do I have to change models to do that?,1.0
fzbvhi6,hxzf5d,"Some models have fixed resolution which is specified in the configuration. Changing the resolution might occur an error or it might change the accuracy of the model... 

My suggestion is to read about the algorithm that you will use and see if it is suitable for your need or not , before applying the code and training. If you did that you will save your time I can guarantee that from my humble experience 😆 good luck...",1.0
fz85sck,hxou7d,"I find that jupyter resets are usually due to resource exhaustion.   I see that you are calling this 100 times in a list comprehension, and you are converting the same pandas dataframe to\_numpy() each time, with no (apparent) dependency on ""samples"".    I would generate X\_test completely outside that loop one time, to see if it succeeds.   A single X\_test.shape and y\_preds.shape would probably shed some light on the problem.    

My wild guess is that you need to reduce your batch size",2.0
fz7dw1u,hxou7d,"Plus the kernel gets into a temporary folder, when I run os.getcwd() I get /tmp/random\_string",1.0
fz7kobm,hxou7d,There are lots of things that could go wrong in that line. Break it up and try them one at a time.,1.0
fzd6wyo,hxou7d,"Unless your data is extremely small, a batch size of over 2,000 likely requires more memory resources than your machine allows. In cases like these, the Jupyter server crashes and requires restarting. 

I would recommend greatly shrinking your batch size. What data are you working with? For reference, my 1080Ti can only really handle batch sizes of 128 of 256x256 images.",1.0
fzealmw,hxou7d,The data has around ~ 2Gb and I'm working with a GTX 1660TI,1.0
fz9i0pf,hxnzep,"You can batch five (1, 10) vectors together. Look Into the tensorflow datasets API, or check out a quick numpy tutorial.",1.0
fzaljvn,hxnzep,"I looked up information on datasets and realized I'm also already using a dataset to feed my data into tensorflow:

`dataset = tf.data.Dataset.from_tensor_slices((df_train.values, targets))`

But I'm not seeing a way to logically group multiple values. So let me give an example:

Instead of passing:

    col1 col2 col3 col4 col5 col6
    c    a    t    h    a    t

I want to tell tensorflow that each 3 elements is logically related to each other so that the AI can better understand the model:

    col1     col2
    [c,a,t]  [h,a,t]

Does that make sense?",1.0
fz6seik,hxk85r,"They have refreshed the ""TensorFlow Basics"" section of the guide.

https://www.tensorflow.org/guide/tensor",1.0
fz6lj32,hxk3t2,"
I see you've posted a GitHub link to a Jupyter Notebook! GitHub doesn't 
render large Jupyter Notebooks, so just in case, here is an 
[nbviewer](https://nbviewer.jupyter.org/) link to the notebook:

https://nbviewer.jupyter.org/url/github.com/arjun-majumdar/Lottery_Ticket_Hypothesis-TensorFlow_2/blob/master/VGG_19_CIFAR10.ipynb

Want to run the code yourself? Here is a [binder](https://mybinder.org/) 
link to start your own Jupyter server and try it out!

https://mybinder.org/v2/gh/arjun-majumdar/Lottery_Ticket_Hypothesis-TensorFlow_2/master?filepath=VGG_19_CIFAR10.ipynb



------

^(I am a bot.) 
[^(Feedback)](https://www.reddit.com/message/compose/?to=jd_paton) ^(|) 
[^(GitHub)](https://github.com/JohnPaton/nbviewerbot) ^(|) 
[^(Author)](https://johnpaton.net/)",1.0
fz8d5ks,hxk3t2,How’s your learning curve like?,1.0
fza50ke,hxk3t2,I haven't used model.fit() so didn't generate the visualisation for the learning curve,1.0
fzbsh8h,hxk3t2,Added the learning curves for accuracy and loss,1.0
fzbzykv,hxk3t2,So its a clear sign of overfitting,1.0
fz9itcy,hxk3t2,"Maybe I missed it in your code, but I don’t see you performing any data augmentation. There are a large number of things that could be “going wrong”, try tweaking your hyper parameters and experiment to see what works.",1.0
fza568f,hxk3t2,In cell number 22 of Jupyter notebook you will find the code for InageDataGenerator() where data augmentation is being defined.,1.0
fz6ihjs,hxjcrj,Actually I'm doing it side by side so not more than a month.,2.0
fz6lwot,hxjcrj,"The time which it will take you depends on how much time you are ready to devote at the current moment. Considering you are very determined at the moment, it would not take you more than 2 weeks if you work for it around 3 hrs / day.
The best way I would recommend way to understand tensorflow properly is to complete some guided projects first to give you a headstart rather than searching for all syntax from scratch. Once you get confident enough with the syntax, you can go ahead to complete 1-2 good projects by yourself or with a group.
Once you have a few good projects and a good hold of the syntax, you can mention tensorflow on your resume before applying to internships. Good luck :)",2.0
fz6n6ig,hxjcrj,"Oh that's great! I have a lot of time on my hands due to the current pandemic situation, so that shouldn't be a problem at all. Also what would be the best place to find the kind of guided projects you talk about? Does Kaggle fit into that category?

Thank you for the detailed reply!",1.0
fz6nc6a,hxjcrj,"Yes on kaggle you can participate in competitions and try yourself first. Once you have tried everything you could, go to the notebook of the top submission and check out all the data processing steps and model creation in depth. Other thing you can do is search for guided projects from rhyme on Coursera. I am not sure if these courses are free or not, you will have to check out",4.0
fz6nszb,hxjcrj,Thanks!,1.0
fz7wiam,hxjcrj,"I'm a pharma student with an idea for the app , please pm or reply to this if you wanna discuss . It involves simple machine learning but i don't have any expertise so looking to Collab.",1.0
fz6lfao,hxjcrj,Me too,0.0
fz6gtou,hxiwzi,"Hello, I hope this helps.

First, you can install CUDA 10.1 by `sudo apt install nvidia-cuda-toolkit`. After installing, run `nvcc -V`. Then you will get an output similar to the following,

    nvcc: NVIDIA (R) Cuda compiler driver
    Copyright (c) 2005-2019 NVIDIA Corporation
    Built on Sun_Jul_28_19:07:16_PDT_2019
    Cuda compilation tools, release 10.1, V10.1.243

This means that CUDA is successfully installed on your Ubuntu 20.04. The difference though is that CUDA is not installed in the usual path (i.e. `/usr/local/cuda`, `usr/local/cuda-10.1`), instead, it is installed in `/usr/lib` (i.e. `/usr/lib/cuda`). You can check this on your own by running `whereis cuda`.

Then, you can install cuDNN 7.6.5 by downloading it from this [link](https://developer.nvidia.com/rdp/form/cudnn-download-survey). Choose *Download cuDNN*, and you'll be asked to login or create an account. After logging in and accepting the terms of cuDNN software license agreement, a list of downloadable cuDNN software will be displayed. Click on *Download cuDNN v7.6.5 (November 5th, 2019)* *for CUDA 10.1*, then choose *cuDNN Library for Linux*. After downloading, extract the files by running `tar -xvzf cudnn-10.1-linux-x64-v7.6.5.32.tgz`.

Next, copy the extracted files

    sudo cp cuda/include/cudnn.h /usr/lib/cuda/include/ 
    sudo cp cuda/lib64/libcudnn* /usr/lib/cuda/lib64/ 

Set the file permissions,

    sudo chmod a+r /usr/lib/cuda/include/cudnn.h /usr/lib/cuda/lib64/libcudnn* 

Then export the following environment variables,

    echo 'export LD_LIBRARY_PATH=/usr/lib/cuda/lib64:$LD_LIBRARY_PATH' &gt;&gt; ~/.bashrc
    echo 'export LD_LIBRARY_PATH=/usr/lib/cuda/include:$LD_LIBRARY_PATH' &gt;&gt; ~/.bashrc

Run

    source ~/.bashrc

Finally, you can now install TensorFlow GPU,

    pip install tensorflow

The `tensorflow` package now includes GPU support.

Check that TensorFlow can detect your GPU,

    import tensorflow as tf
    tf.config.list_physical_devices(""GPU"")

You should get an output something like this,

    [PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]

Credits to [meetnick](https://askubuntu.com/users/263979/meetnick) and [singrium](https://askubuntu.com/users/822295/singrium) for answering [this related question](https://askubuntu.com/questions/1230645/when-is-cuda-gonna-be-released-for-ubuntu-20-04) in [AskUbuntu](https://askubuntu.com/). It helped me a lot when I encountered an issue installing TensorFlow 2.0 with GPU support in my Regolith Linux (based on Ubuntu 20.04).",3.0
fz6h83r,hxiwzi,"&gt;sudo apt install nvidia-cuda-toolkit

Some packages could not be installed. This may mean that you have requested an impossible situation or if you are using the unstable distribution that some required packages have not yet been created or been moved out of Incoming. The following information may help to resolve the situation:

The following packages have unmet dependencies: nvidia-cuda-toolkit : Depends: nvidia-cuda-dev (= 10.1.243-3) but it is not going to be installed Depends: nvidia-opencl-dev (= 10.1.243-3) but it is not going to be installed or opencl-dev but it is not installable Recommends: nvidia-cuda-doc (= 10.1.243-3) but it is not going to be installed Recommends: nvidia-visual-profiler (= 10.1.243-3) but it is not going to be installed Recommends: nsight-compute (= 10.1.243-3) Recommends: nsight-systems (= 10.1.243-3) E: Unable to correct problems, you have held broken packages.

\&gt; Already tried Aptitude install nvidia-cuda-toolkit but nothing

The following actions will resolve these dependencies:

&amp;#x200B;

Keep the following packages at their current version:             

1)      libcupti-doc \[Not Installed\]                                    

2)      nvidia-cuda-dev \[Not Installed\]                                 

3)      nvidia-cuda-doc \[Not Installed\]                                 

4)      nvidia-cuda-toolkit \[Not Installed\]                             

5)      nvidia-opencl-dev \[Not Installed\]                               

6)      nvidia-visual-profiler \[Not Installed\]                          

7)      openjdk-8-jre \[Not Installed\]                                   

8)      openjdk-8-jre-headless \[Not Installed\]                          

&amp;#x200B;

Leave the following dependencies unresolved:                      

9)      libcupti-dev recommends libcupti-doc                            

10)     nvidia-cuda-gdb recommends nvidia-cuda-doc (= 10.1.243-3)       

11)     nvidia-cuda-toolkit recommends nvidia-cuda-doc (= 10.1.243-3)   

12)     nvidia-visual-profiler recommends nvidia-cuda-doc (= 10.1.243-3)

Clicked yes, and I get the same error installing",1.0
fz6hqv5,hxiwzi,"In *Additional Drivers*, are you using the proprietary NVIDIA driver?

[https://ibb.co/7bxk4Wz](https://ibb.co/7bxk4Wz)",2.0
fz6kaxz,hxiwzi,"I believe so!

[https://imgur.com/a/Kl1Ip6y](https://imgur.com/a/Kl1Ip6y)",1.0
fz6kp0y,hxiwzi,Was this your configuration when you tried installing `nvidia-cuda-toolkit`?,2.0
fz6ldfc,hxiwzi,"Yes it was :/

[https://imgur.com/a/BFLD8L8](https://imgur.com/a/BFLD8L8)",1.0
fz6l0c0,hxiwzi,"In my experience, when you change the selected driver there, for some reason, the installation of `nvidia-cuda-toolkit` gets undone.",2.0
fz6l4ts,hxiwzi,Have you tried doing `sudo apt --fix-broken install`?,2.0
fz6lejh,hxiwzi,"&gt;sudo apt --fix-broken install

It pretty much says everything is fine

0 upgraded, 0 newly installed, 0 to remove and 1 not upgraded.

This is so weird....",1.0
fz6m7wh,hxiwzi,"At this point, this may seem silly to suggest, but have you tried running `sudo apt-get update` and then `sudo apt-get upgrade`?",2.0
fz6mmsz,hxiwzi,"Yes. I'm 2 days deep into this problem. Already tried purged Nvidia too and re-installing it using Ubuntu-drivers autoinstall and nothing.

Thank you so much for trying to help",1.0
fz6mr8p,hxiwzi,"How about `sudo apt --fix-broken install -o Dpkg::Options::=""--force-overwrite""` ?",2.0
fz6nfr7,hxiwzi,"haven't tried that one yet! Let me check.. (runned apt-get update &amp; upgrade before this just because, same error instaling nvidia-cuda-toolkit btw)

Here's the output of the command:

`sudo apt --fix-broken install -o Dpkg::Options::=""--` 

`Reading package lists...` 

`Done Building dependency tree`

`Reading state information...` 

`Done 0 upgraded, 0 newly installed, 0 to remove and 0 not upgraded.`",1.0
fz6p4dm,hxiwzi,"Since you did `sudo apt update` and `sudo apt upgrade`, what is the version of your `gcc`? Are you using 8 or 9 now?",2.0
fz6pvms,hxiwzi,"# gcc --version
gcc (Ubuntu 8.4.0-3ubuntu2) 8.4.0

I believe this is the correct one",1.0
_,hxiwzi,,
fz6eijd,hxib6p,Tensorflow Specialization on Coursera. It's free for now if you sign up using University Email ID,7.0
fz6n68z,hxib6p,"That medium Post should help you, there are lots of Ressources and Tips for the Certificate.

“Google Certified Tensorflow Developer — Learning Plan, Tips, FAQs &amp; my Journey” von Harshit Tyagi https://link.medium.com/6P2PmmPdp8",2.0
fz6fjd4,hxib6p,"Thanks dude, duly noted",1.0
fz6ii98,hxib6p,!remindme 2days,1.0
fz94cwi,hxib6p,"There is a 15 hour delay fetching comments.

I will be messaging you in 2 days on [**2020-07-27 08:48:27 UTC**](http://www.wolframalpha.com/input/?i=2020-07-27%2008:48:27%20UTC%20To%20Local%20Time) to remind you of [**this link**](https://np.reddit.com/r/tensorflow/comments/hxib6p/tensorflow_course/fz6ii98/?context=3)

[**CLICK THIS LINK**](https://np.reddit.com/message/compose/?to=RemindMeBot&amp;subject=Reminder&amp;message=%5Bhttps%3A%2F%2Fwww.reddit.com%2Fr%2Ftensorflow%2Fcomments%2Fhxib6p%2Ftensorflow_course%2Ffz6ii98%2F%5D%0A%0ARemindMe%21%202020-07-27%2008%3A48%3A27%20UTC) to send a PM to also be reminded and to reduce spam.

^(Parent commenter can ) [^(delete this message to hide from others.)](https://np.reddit.com/message/compose/?to=RemindMeBot&amp;subject=Delete%20Comment&amp;message=Delete%21%20hxib6p)

*****

|[^(Info)](https://np.reddit.com/r/RemindMeBot/comments/e1bko7/remindmebot_info_v21/)|[^(Custom)](https://np.reddit.com/message/compose/?to=RemindMeBot&amp;subject=Reminder&amp;message=%5BLink%20or%20message%20inside%20square%20brackets%5D%0A%0ARemindMe%21%20Time%20period%20here)|[^(Your Reminders)](https://np.reddit.com/message/compose/?to=RemindMeBot&amp;subject=List%20Of%20Reminders&amp;message=MyReminders%21)|[^(Feedback)](https://np.reddit.com/message/compose/?to=Watchful1&amp;subject=RemindMeBot%20Feedback)|
|-|-|-|-|",2.0
fz6krld,hxhbfk,"I would say yes to your last suggestion.

Posting to Reddit and waiting took probably longer than just doing it.",2.0
fz4hj8i,hx74qf,Well my suggestion WOD be to learn how to Google information before starting with Tensorflow.,1.0
fz4ixwb,hx74qf,Well i already did but it seems that when i try and install it in my virtual enviroment it only works in there and nowhere else. I can go into my ide(anaconda) and use it as it comes up with error,1.0
fz4nav9,hx74qf,"But that's how it is supposed to work.

If you have a new project create a new environment. If you want to use your environment in your ide you usually have to link the ide to the python executable.

In pyCharm you would open settings -&gt; set project interpreter and there you would enter /some/path/to/repo/.venv/bin/python",1.0
fz4pip9,hx74qf,So in order to use the tensorflow library in my normal ide i have to link it? How would you do that? I can use tensorflow in my cmd but not in anaconda,1.0
fz4rs45,hx74qf,Nvm i figured it out,1.0
fz6bduo,hx74qf,"I did it by creating new environment and in that I again downloaded all the libraries including Tensorflow and Keras through GPU, it worked for me",1.0
fz3xfne,hx5oqs,"
I see you've posted a GitHub link to a Jupyter Notebook! GitHub doesn't 
render large Jupyter Notebooks, so just in case, here is an 
[nbviewer](https://nbviewer.jupyter.org/) link to the notebook:

https://nbviewer.jupyter.org/url/github.com/arjun-majumdar/Lottery_Ticket_Hypothesis-TensorFlow_2/blob/master/Data_Augmentation_Conv6_CIFAR10_Example.ipynb

Want to run the code yourself? Here is a [binder](https://mybinder.org/) 
link to start your own Jupyter server and try it out!

https://mybinder.org/v2/gh/arjun-majumdar/Lottery_Ticket_Hypothesis-TensorFlow_2/master?filepath=Data_Augmentation_Conv6_CIFAR10_Example.ipynb



------

^(I am a bot.) 
[^(Feedback)](https://www.reddit.com/message/compose/?to=jd_paton) ^(|) 
[^(GitHub)](https://github.com/JohnPaton/nbviewerbot) ^(|) 
[^(Author)](https://johnpaton.net/)",3.0
fz47i52,hx5oqs,Maybe your augmentations are too destructive? Or maybe your normalisation is causing problems?,2.0
fz49s15,hx5oqs,Suggestions?,1.0
fz4ajzb,hx5oqs,Try reducing the distortions in your image augmenter. If you take the distortions to zero is the accuracy restored?,2.0
fz4mv78,hx5oqs,"When I reduce 'rotation\_range' from 90 to 20 while keeping width\_shift\_range = 0.1,     height\_shift\_range = 0.1 and horizontal\_flip = True, the validation accuracies are as follows:

Conv-6 CNN (Winning Ticket) model metrics using Data Augmentation: accuracy = 0.7617, precision = 0.7670 &amp; recall = 0.7617

Conv-6 CNN (Winning Ticket) model metrics WITHOUT Data Augmentation: accuracy = 0.7796, precision = 0.7862 &amp; recall = 0.7796",1.0
fz4p0yt,hx5oqs,Hey the problem is you need to train the model with Data Augmentations for more epochs in order for the model to converge as you can see the Train Accuracy is 63.73 for the model trained on data augmentation and the Test Accuracy is 66.43 i would say its pretty self explanatory where as the model trained on without data augmentation scored 90.25 Train Accuracy and corresponding Test Accuracy is 79.22 you see the difference right?,1.0
fz32shm,hx0cea,"Wait, this is a copypasted OpenCV facial recognition tutorial where the word face was replaced by mask.",2.0
fz36u7r,hx0cea,"Well if you have gone through the article, you ll know i have used opencv to detect faces and then the classiifer we trained in this takes the frames as input and classifies if the face is wearing a mask or not. So no this is not a copy paste but i have most certainly used Opencv",1.0
fz270ri,hwv13i,"Exactly what it’s saying, you don’t have enough memory to allocate the array. What’s your system stats? Are you running gpu? Do you enough vram, enough ram even. What are the total trainable parameters in your model. Without these can’t really say what could be the problem.",3.0
fz272wk,hwv13i,Yes nvidia tesla. I am not training any model. I am running a model on a video for object detection,1.0
fz274r0,hwv13i,"Total trainable parameters? And your Tesla vram amount? I would also remove any incremental memory growth in your script, as tf is not yet perfect in dynamic memory allocation on gpu vram.",2.0
fz2h8hv,hwv13i,"Try this. I had similar problems and the following method worked for me .I am not sure if this would work for you too but just try it, it won't break anything and if it helps cheers,

After `import tensorflow as tf`

`from tensorflow.compat.v1 import ConfigProto`

`from tensorflow.compat.v1 import InteractiveSession`

&amp;#x200B;

`config = ConfigProto()`

`config.gpu_options.per_process_gpu_memory_fraction = 0.75`

`config.gpu_options.allow_growth = True`

`session = InteractiveSession(config=config)`

The gpu\_memory\_fraction can be set to different values. THe ones that have worked for me are 0.6, 0.7, 0.75.",2.0
fz4qv0g,hwv13i,I hope OP responds if this helped them. Seems like one of those Stack Overflow answers that had a weird quark and you have the answer that helps thousands of people years later.,1.0
fz210dl,hwssgt,If you are good with keras.. you can do pretty much anything with TF. Even TF is encouraging to use keras,2.0
fz29bno,hwssgt,"While I'm biased (:) ), I would recommend that you stick with TF, because you can go deeper than Keras, with, for example custom layers, writing your own loss functions, training loops etc.  


Or, you could use some of the rest of the ecosystem -- such as getting into TensorFlow Lite (and associated technologies like ML Kit) for mobile ML development etc.",2.0
fz1q626,hwssgt,"It depends on your use case. All these frameworks are setup to solve problems depending on the functionality needed. 

Read this for details:
https://deepsense.ai/keras-or-pytorch/",1.0
fz1ytr6,hwssgt,can you make a program that can ask questions using a set of facts using only keras,1.0
fz2518l,hwssgt,"If you really want, you can only use variables, tensors, modules, and write your own custom stuff. There's even [tf.numpy](https://www.tensorflow.org/api_docs/python/tf/experimental/numpy) in nightly.",1.0
fz2tqf8,hwssgt,"Tensorflow and keras are the same thing now. You're almost always going to be using the keras API, even if you're doing some more exotic stuff.

As someone who was familiar with keras+TF about 3 years ago, I remember it used to feel like you were using two separate libraries. However, nowadays the distinction is only really about where you import from in the TF library. It all works together so seamlessly.",1.0
fz2h679,hwootp,"Didn’t trace through all your code, but that final error message suggests to me that you forgot a dimension for “batch.” TF convolutional layers always take two more dimensions than their name suggest: one for channel and one for batch size.",1.0
fz2to2r,hwootp,"Solved it. It seems that while he generating the slices the dimensions were screwed.

However, due to the tf.datagen() based flow() data augmentation, the accuracy which I get for the Conv-6 CNN is much lesser as compared to original dataset without augmentation.

Here, I train of augmented dataset but test the model accuracy and loss on validation dataset which is not augmented.

But still the accuracy is low as opposed to non data augmentation.

Any idea?",1.0
fz26v6e,hwonph,"1. Accuracy is going to be a value between 0 inclusive and 1 inclusive.  This is the percentage of times it correctly guesses the right category. You're reporting this value from a single step that has a batch size of 1, so that means you evaluate one input and check the output category to the labelled category, it will either be right or wrong, giving you an accuracy for that step of either 0.0 or 1.0. 

2. I would consider a larger batch size for training, this will likely give you more useful output data as well. Since I don't see the model definition, I don't know what's going on with your loss value, but I'm assuming it's not being calculated correctly.  Loss value is important and is often a better representation of the model's performance than raw accuracy. I guess the setup seems okay - I normally would use numpy for this kind of thing rather than pandas, so there might be more insight someone else can supply.",2.0
fz29n00,hwonph,"I was able to get it training a little better by changing the batch size and making it iterate over the data multiple times rather than just once (it was stopping once it had looked at all data a single time). I got to 55-57% accuracy this way but I was aiming for more like 70%.

Do you have any thoughts on my last question or how the person who wrote the article I linked would have fed their hero/champion model into another ML session to get more accurate winrates? I have this model for champions right now that I'm not leveraging at all because I'm not sure how to tell tensorflow to use it.",1.0
fz2adla,hwonph,"Based on the data you are using and the notes in the article, it seems like your accuracy of 55-57% is in line with their performance.  Note this section and the accompanying chart:

&gt;One reason why the team composition is so informative is that in the beginning of the game, there is barely any variance in the numerical features, so they are useless. As a game progresses, more information are accumulated in the numerical features so that the team composition is relatively no longer important. Therefore, close to the end of the game, the two predictions overlap since the variance in the numerical features is large enough to solely tell the outcome of the game.

[Chart](https://miro.medium.com/max/700/1*valErOMHFLaajsn-fnt_jA.png)

At no progress in the game (when the only information available is just the champion data, which seems to be exactly what your input is) the accuracy was in the low 0.5 range for one-hot encoded data and a about 0.58 for Hero2vec solution.  It appears that the percentages improved as the game progressed and more data became available.

Based on that results, one might conclude that either that the data is insufficient, or that perhaps team structure isn't a terribly powerful predictor of victory. I'm not familiar with the game, how teams are constructed, etc, so I can't really provide much insight on that.",2.0
fz43dzl,hwonph,"After more testing with my win rate model it's very clear it's overfitting the data in order to get 55-57% and it's useless for prediction. I believe this is because I'm using naive 1-hot encoding for the champions rather than a ""hero embeddings"" model. I'm not using the ""hero embeddings"" method from the article yet since the article doesn't explain how to.

So my remaining questions are:

1. How do I feed champion role information into tensorflow when creating my winrate model? (this is the process hinted at the end of the article ""Both using logistic regression, the overall accuracy is higher when the input is embedded with **hero embeddings** than when the input is simply one-hot encoded.""
2. And a new problem I noticed...How do I tell tensorflow that these aren't just 10 distinct numbers - that they are actually two bags of 5 numbers vs 5 numbers where order doesn't matter within a team and also ordering of the two teams themselves doesn't matter? For example, with my current model, if I swap the champions from the first team with those from the second team I can get wildly different results when the results should be the same. The same thing can happen just changing the order of champions within a team.",1.0
fz4czgy,hwonph,Do I need to combine each team into a single tensor with length 5 so that tensorflow knows they are logically grouped together?,1.0
fz61owr,hwonph,"If the unique combination is all that matters over order, it may be possible to create bindings to combinations to explicit values so that the network only gets a single input that represents a particular grouping.  However, I would probably just let the network learn the relationships.",1.0
fz6b4nw,hwonph,"I was able to get the emeddings for each champion so it's a list of floats for each champion like:

0.49207935-0.60436034-0.349179420.56692094-0.153209720.537356440.707275870.56730443-0.8129458-0.004154575

So to feed this into a winrate model you would  just pass?

0.49207935 -0.60436034 -0.34917942 ... \[total of 100 floats describing the 10 champions\] ... \[0/1 for win/loss\]

And you think the AI will figure out that each 10 is a champion and each 50 is a team? I'm pretty new to training models so genuinely not sure if this will work or not.",1.0
fz0xoix,hwobsu,how to use tf.GradTape with TF Quantization aware training? Any examples?,1.0
fz0p74a,hwn7kz,"Shouldn't be a reason why you can't. You would want to run different models in different threads on each, independently tho.... You'd run into serious challenges and core TF dev trying to pool resources.

Coral only runs inference on tflite models iirc.",1.0
fz0vwwp,hwn7kz,Yes it’s possible to combine and use all 3. You’d just have to have their respective models in their respective frameworks.,1.0
fz0jjgm,hwjwt3,When installing cuda it took me too long to figure out that you had to restart your machine after so that everything would configure correctly... that file you mentioned seems vaguely familiar to the problem I had.,1.0
fz0js78,hwjwt3,Nope I had CUDA from the past 7 months. After the new windows update I guess it started misbehaving I guess. Not sure if it was the windows update that caused this,1.0
fz0ouzr,hwjwt3,"I heard that the windows update has some bugs , that's why I haven't updated it",1.0
fz0wxrb,hwjwt3,"Haven't faced the issue but If you plan on reinstalling , Don't unsinstall anaconda. In the anavonda Navigator search for Tensorflow and remove all packages that contain this keyword. (This is important as it may create conflicts by staying)
Then install tensorflow gpu by using , 'conda install -c anaconda tensorflow-gpu' in the anaconda prompt in the right environment.
It will install the right version of everything and you won't need to woory about anything.
No restarts or shutdowns required.",1.0
fz11p0r,hwjwt3,This step is to be done after installing compatible versions of CUDA and CuDnn right?,1.0
fz12l0u,hwjwt3,"No. You don't have to worry about CUDA or CUDNN.
tensorflow gpu will install it automatically.
Just make sure you remove them before running the one line command.",2.0
fz12wo4,hwjwt3,Wow that sounds interesting! Isn't there any negative side to this step? Like if it is so simple then why do people usually go around doing such tiring steps for setting up CUDA?,1.0
fz14zwl,hwjwt3,"Not that I know of. I have been running TF gpu for about six months now and haven't run into problems involving CUDA or CUDNN. The most common problem I face is out of Memory problems( That is more related to my GPU capacity, which can be worked around easily). Anaconda has done a great job of simplifying these steps into a single step. As for why people go around doing the tiring steps, the possible expalinations I can think of are, i)everyone doesn't know about this
ii)anaconda is third party so tensorflow doesn't officially recommend this.The official recommendation is using pip.
But from my experience conda works just as good.

If however you still have resevations , you can go the pip way.
As this is a easy and convinient way I used, thought about informing.",2.0
fz13czs,hwjwt3,"Also one more doubt. According to this link, different version of tensorflow require different versions of CUDA and CuDNN. https://www.tensorflow.org/install/source_windows#tested_build_configurations How is a normal developer supposed to have multiple installations of CUDA for multiple projects",1.0
fz16dt1,hwjwt3,"Do you need to have multiple versions i.e. do you need both tf 1 and 2 ? For tensorflow 1 different version of Cuda and cudnn are required and for tensorflow 2 different.

Conda install does this automatically once you set the tensorflow version required.
I have tf 1 on linux and tf 2 on windows in my dual boot machine both running perfectly fine.

On linux there are some other problems, but that's mostly nvidia optimus driver problems. Windows installation works perfectly.",2.0
fz1yvpr,hwjwt3,"Amazing! So for installing a specific version of tensorflow-gpu for conda, we just add =1.13.0 in front of it right?",1.0
fz29j0s,hwjwt3,Yes,1.0
fz18jzb,hwjwt3,"And another thing, if you use conda package manager, it often  ensures that the dependencies are satisfied and  upgrades other packages accordingly. I mean it tries to make everything work correctly. I can't guarantee it will work everytime but I haven't had problems with this.",2.0
fz09p55,hwhbwr,"Holy crap these are awesome, really really great work! I was stubbornly trying to make my own onset detection a while ago without looking anything up (because I'm an idiot and like to hang my head against the wall) so this was really enjoyable to watch to see where I was on the right path and where I was messing up (I got it to work in the end, but it's a bit unorthodox). I was wondering, for amplitude envelopes don't you usually want to take the absolute value of each sample before you search for the max value in a frame? Or does the max function do that for you or something?",3.0
fz0sboa,hwhbwr,Yeah man the videos in this series are an awesome intro to some of the basic terminology of audio processing etc. Really great intuitive explanation of some typical preprocessing steps necessary for audio data. Cheers.,1.0
fyxa9c1,hw3we5,"Iirc the rtx series gpus are only better than the 1080 for half precision floating point(float16 instead of float32) calculations, which may not be applicable for all tasks since they are less precise than normal float32s and can be pretty unstable. The 1080s are a lot cheaper, and you can get a 1080ti (with 11gb vram) for the same price as a 2070 (8gb vram). However, even with half precision, the performance gain is minimal as it only becomes noticeable for builds with multiple gpus. Personally I’d get a 1080ti since it’s the best bang for your buck, but it’s all up to you. If you plan on gaming too the 20xx series might be a better suited for your needs lol.",4.0
fyyl10y,hw3we5,Thank you for your answer! I guess i will take 1080ti,1.0
fyx766x,hw3jq8,"That happens when there's a version conflict with your GPU driver, Cuda and or TF, usually the last two. If it's a new setup this is likely your problem


If it was working it also happens when GPU memory is corrupted and that can be fixed with a hard reboot",3.0
fyx8fkl,hw3jq8,Do you think purging CUDA and reinstalling the correct versions of CUDA and cuDNN would work?,1.0
fyxq53y,hw3jq8,"I have a couple versions of CUDA installed in /usr/local/ and I have a soft link /usr/local/cuda pointing to the version I want to use

It's easier to just change the soft link while you sort through everything rather than hunt down and remove each version. It's always a nightmare to get all 3 to play nice together

I'm on Ubunu - I'm using 
gpu driver (nvidia-smi 440.100) for a RTX 2060
cuda 10.0
tf 1.14.0


It usually takes a while for CUDA to catch up to TF, you might try an older version of TF",2.0
fyx5w76,hw3jq8,"Do you have any other programs open that may be using the GPU? Earlier today I forgot I had blender open while trying to load and make predictions with a model, and I got a similar error.",2.0
fyx6o7m,hw3jq8,Nope. It still happens when its the only program running.,2.0
fyybdnc,hw3jq8,Hey i encountered this error several time and just restarting my Jupyter notebook or kernel worked for me though I don't know why this thing happening 😕😅.,1.0
fyyc8dt,hw3jq8,Also forgot to mention i am using tensorflow 2.0,1.0
fyzehdj,hw3jq8,"I used to get the same error with my GTX card until I modified my GPU setup to allow for memory growth.  This is the setup script I've used:

    gpus = tf.config.experimental.list_physical_devices('GPU')
    if gpus:
      try:
        for gpu in gpus:
          tf.config.experimental.set_memory_growth(gpu, True)
        logical_gpus = tf.config.experimental.list_logical_devices('GPU')
        print(len(gpus), ""Physical GPUs,"", len(logical_gpus), ""Logical GPUs"")
      except RuntimeError as e:
        print(e)

That said, it would likely be difficult to debug without seeing the full trace.",1.0
fz2gvjk,hw3jq8,"I don't know if you have solved your problem but for anyone stumbling across this in future, try this after Tensorflow is imported. I am not sure of the technicalities but this just works for me.

`from tensorflow.compat.v1 import ConfigProto`

`from tensorflow.compat.v1 import InteractiveSession`

&amp;#x200B;

`config = ConfigProto()`

`config.gpu_options.per_process_gpu_memory_fraction = 0.75`

`config.gpu_options.allow_growth = True`

`session = InteractiveSession(config=config)`

the gpu\_memory\_fraction can be set to different values. The ones I have tried are 0.6, 0.7, 0.75",1.0
fyyt71h,hvuwd6,What compute capabilities does it support?,1.0
fyytbhr,hvuwd6,I don't understand ur question !!,1.0
fyywe3d,hvuwd6,"Different NVIDIA GPUs have different capabilities and versions of the interface to control them. I believe the most recent version is 7.5 and tf supports versions 3.0 and up. However every precompiled version I can find only supports 3.5 and up. 

I have a GTX770 I wanted to use to get my feet wet with tf but it uses CC 3.0 and I have had zero luck compiling from source.",1.0
fyz6ct8,hvuwd6,"Yeah, for GPU yes so u should install the necessary drivers as a base requirement and i cannot find drivers for every GPU has they have a tons of variations and built so its upto you who has to fix the driver issue may be i can suggest u some possible cuda and cudnn matchings !",1.0
fyzc236,hvuwd6,They already of the compatibility list on the tutorial site.,1.0
fyw6cqr,hvunr8,"Hey there my remarkable friend! I am going to bed now, but I can help ya later if no one does before.",1.0
fywdgj1,hvunr8,"What are the ods? Wow!

I'm having alot of issues making the tensorflow-gpu working. I'm going to try docker on windows right now. my last chance

&amp;#x200B;

 [https://www.reddit.com/r/tensorflow/comments/hvqtqk/really\_need\_help\_installing\_tensorflow\_gpu\_on/](https://www.reddit.com/r/tensorflow/comments/hvqtqk/really_need_help_installing_tensorflow_gpu_on/)",1.0
fyweryh,hvunr8,"are you familiar with tensorflow at all? It seems like the problem you have is on your code, not on the installation.

Share the code with me, I'll have a look later, meu camarada",1.0
fywflqv,hvunr8,"És tuga? Omg, caíste do céu? :0
Já te mando no private (ainda vou demorar um pouco!)",1.0
fywfzi9,hvunr8,"Tuga nada, sou o maior dos colonizados por voces haha. mande la!",1.0
fyvb122,hvqytu,"That’s great! I love the new experimental layers in keras and the replacement for the ImageDataGenerator, in general I think it’s great that they are starting to integrate the tf.data.Dataset API into more of their core tools",4.0
fyvg4mz,hvqytu,"Exactly. important update. Hope it works bug free, a lot of the 2.0 versions introduced annoying bugs =\\",3.0
fyvcltw,hvqytu,Sounds good...,1.0
fyvlq27,hvqtqk,"You're going to have some difficulty using TF+GPU on a Windows machine. I would highly recommend you look into Docker as a solution.

There is an official TensorFlow docker hub page. They have pre-built images for all combinations of TF versions, Jupiter notebook server, and GPU usage.

Edit: [https://hub.docker.com/r/tensorflow/tensorflow/tags?page=1&amp;name=gpu-py3-jupyter](https://hub.docker.com/r/tensorflow/tensorflow/tags?page=1&amp;name=gpu-py3-jupyter)

If you're not familiar already, learn about how to use docker. You can then pull one of the images from the url above, build it, then deploy it. It will run exactly like a Jupyter Notebook server but it will have a pass-through connection to your GPU and TensorFlow pre-setup.

&amp;#x200B;

For example, if you pull the ""2.0.1-gpu-py3-jupyter"" image... Once the image is pulled and built, you can launch the container (via CLI) as follows:

`docker run --gpus all -it --rm -v ~/path/on/home/machine:/tf -p 8888:8888 tensorflow/tensorflow:2.0.1-gpu-py3-jupyter`

Simply replace ""\~/path/on/home/machine"" with the desired folder that you want to work out of and the container will be mounted to your hard-drive and will be able to interact with the files on the host machine.

Best of luck.",2.0
fyw1bxf,hvqtqk,Thank you so much. I will try it when I'm on the computer,2.0
fywye76,hvqtqk,Do yourself a favor and dual boot Linux. I know there are many reasons to use windows. But there are also many reasons to run Linux. ML and Containers are two very important reasons to run Linux.,2.0
fywyubq,hvqtqk,"I know, and I'm familiar with Linux.
But the problem is, my good graphics card is on a Asus laptop where in windows (due to some Asus aps) I can limit my batery charge limit and therefore my batery stays healthy.
In Linux I'm not able to do that since Asus don't open source the batery drivers.

That's the solo reason I haven't switched to Linux",1.0
fyx35jc,hvqtqk,Is this still a thing in 2020?,1.0
fyx8pc0,hvqtqk,"Unfortunately
Thinkpad is the only company that has drivers for Linux",1.0
fyww5jy,hvqtqk,"I get the following error

docker run --gpus all -it --rm -v C:\Users\user\Desktop\tf_docker:/tf -p 8888:8888 tensorflow/tensorflow:2.0.1-gpu-py3-jupyter
C:\Program Files\Docker\Docker\resources\bin\docker.exe: Error response from daemon: could not select device driver """" with capabilities: [[gpu]].",1.0
fywy3js,hvqtqk,"Hmmm... tough for me to debug Window's errors when I only have Linux boxes at home.

Here's a thread for giving GPU acceleration to containers on a Windows machine:

[https://techcommunity.microsoft.com/t5/containers/bringing-gpu-acceleration-to-windows-containers/ba-p/393939](https://techcommunity.microsoft.com/t5/containers/bringing-gpu-acceleration-to-windows-containers/ba-p/393939)

They give some requirements for the host machine. They also explain a bit about what's going on in the post. Try running this:

`docker run --isolation process --device class/5B45201D-F2F2-4F3B-85BB-30FF1F953599 -v C:\Users\user\Desktop\tf_docker:/tf -p 8888:8888 tensorflow/tensorflow:2.0.1-gpu-py3-jupyter`

No guarantees that it will work or be stable but it's all I could find quickly!",1.0
fyx0ao6,hvqtqk,"Thank you so much for your reply!

It returns.. :/

""C:\\Program Files\\Docker\\Docker\\resources\\bin\\docker.exe: class/5B45201D-F2F2-4F3B-85BB-30FF1F953599 is not an absolute path.

See 'C:\\Program Files\\Docker\\Docker\\resources\\bin\\docker.exe run --help'.""",1.0
fyuxpqu,hvqtqk,"Use anaconda and use the following command
$conda install tensorflow-gpu

After gpu you can add ==1.x if you want a certain version",1.0
fyvb6i5,hvqtqk,"already tried, doesn't work",1.0
fyuyi9o,hvqtqk,"I had issues when I started so created the below repo, 

https://github.com/rexdivakar/Deep-Learning-Setup



Star if u like it !! And post me if u still need help",1.0
fyuyw55,hvqtqk,"Which versions of cudnn and cuda did you install?

Did you add them to path?",1.0
fyv83hb,hvqtqk,"Just do
`conda install tersorflow-gpu`
Conda automatically installs cudnn and other dependencies",1.0
fyvb6tx,hvqtqk,"already tried, doesn't work",1.0
fyuwl2w,hvqtqk,"Just install Cuda from Nvidia's website (10.1 preferable) and do this in  cmd:

pip install tensorflow-gpu",0.0
fyuzfoc,hvqtqk,"Did that, didn't work :/",1.0
fyv9ysu,hvqtqk,with [Cuda 10.1](http://developer.download.nvidia.com/compute/cuda/10.1/Prod/local_installers/cuda_10.1.243_426.00_win10.exe)?,1.0
fyvb7mt,hvqtqk,yes,1.0
fyutnj7,hvqiwx,"If you found this cool, please back our project at the global stage by dropping a like at [https://www.facebook.com/groups/buildwithaihack/permalink/3604158072945823/](https://www.facebook.com/groups/buildwithaihack/permalink/3604158072945823/)",1.0
fyui6ld,hvo6cq,"Vaguely speaking, it depends on so many factors that your question is not implying. 

Transfer learning by itself, 99.99999% sure it won't work.

Transfer Learning + Some Tweaking + Fine Tuning, maybe.",1.0
fyuo9v6,hvo6cq,yes,1.0
fysjfpc,hvbzi7,"I always thought that was due to the optimizers 2nd order estimates, which might need a while to get good.

I'd guess if you continue with a exact 2nd order optimization method you won't have that problem. Or if you do vanilla SGD with a sufficiently small learning rate.

However, it should still work fine if the Optimizer state is saved correctly.",1.0
fyscdyk,hvblf5,"Perhaps you need to update the nets module version. I assume it's installed via pip. Then first upgrade pip to the latest version, then install the latest version of nets and retry.",1.0
fysdcol,hvblf5,"Pip and nets are updated to the last version... Its a very weird error, cause I searched on the web and cannot found anything. All the python paths seems ok... Dont know why still giving error",1.0
fys277d,hva7rv,"You never actually say what went wrong?

That said, this line doesn't look correct.  I think you need tf.math.add instead of \`+\`

`g = tf.sigmoid(tf.matmul(X,W1)+b1)`

&amp;#x200B;

Edit: Actually looks like I'm wrong about +",1.0
fyrzgrn,hv9bll,"Maybe use photos and photometa data to identify black holes, planets or other objects from astronomy footage.",3.0
fysav4l,hv9bll,"Since you are interested in space , and sometimes images from space are blurred and has noise , why don't you use GAN (W-GAN Model ) for removing noise and debluring . Hope you like this :)",3.0
fysfzpg,hv9bll,"Galaxy Zoo was created (quite) a few years ago where humans have to classify Galaxies because machine learning wasn't good enough. You had to say what type a Galaxy was (barred, spiral etc.) and also say what way it was rotating.

[https://www.zooniverse.org/projects/zookeeper/galaxy-zoo/](https://www.zooniverse.org/projects/zookeeper/galaxy-zoo/)

What about trying modern ML models and techniques and see if you can classify your own predictions, maybe contact the guys at Galaxy Zoo and see if you can use their dataset and compare your results to theirs?

Or what about examining the Kepler Data and see if you can find an exoplanet?

There's loads of free datasets by NASA and plenty of data that has never been looked at. [https://data.nasa.gov/browse](https://data.nasa.gov/browse), I'm sure there's thousands of other free up to date stuff you could find.",3.0
fyrwjxg,hv9bll,"make a nn to predict and simulate the next pandemic. you can input the time of year, infection radius, days where you are infected but don't show symptoms yet, and chance of people dying, and use the covid19, sars 1 and mers outbreaks as data for it. then make a ui to display the progression of the infections like the way plague inc does.",2.0
fysavyq,hv9bll,"The trick is to find a problem in industry or academia which you see a potential solution to; a pattern which is hard to describe but visible to you.

Find a pile of data pertinent to the problem, then label it so that the pattern you see is visible to the NN — if you can see it in the data, so can the NN, but the network needs to be alerted of that pattern’s significance. It will then find underlying correlations which indicate the presence or absence of what you want it to see. The better your labeling, the better it will learn from the data provided.

You sound like you already have ideas in your head. Pick one and chase it!",2.0
fys1nol,hv9bll,New Bob Ross episodes of the Joy of Painting,1.0
fys1ql2,hv9bll,See if you can get him to paint space cabins,1.0
fyuqzj5,hv9bll,You can help me with mine... 😅 Im working with whole slide images. I guess something you would like.,1.0
fys3pjr,hv9bll,In which University are u doing ur degree ?,-2.0
fyqv5ge,hv1yz1,Sounds like you should just pass the original image and expect multiple roi with classes assigned to each. Look at YOLO architecture.,3.0
fyrfnbp,hv1yz1,Will look into it. I see that there are multiple versions. Are there any big changes with each version ?,1.0
fyqmpeu,hv0ann,You could try the AWS rekognition CompareFaces API,1.0
fyr9hco,hv0ann,"There is facenet on tensorflow, or else you can use open-face.. the advantage with facenet woth tensorflow is that you can use tensorflow.js",1.0
fyq4983,huweov,"I took it on Saturday and am waiting too. Initially I panicked when I didn’t get an email right away after I ended the exam, and I read from multiple sources that the feedback was almost instant. My sense now though is a lot more people are taking the certification, so it’ll take awhile before they get back to us.",2.0
fyto5w5,huweov,"Same, I took it on Sunday, so two days ago. I felt the same as you since multiple sources were saying they received the email instantly, but I still haven't heard anything either.",1.0
fypsx93,huweov,"I think it's supposed to be within 10 business days, at the most.",1.0
fyqaqsa,huweov,"any feedback on the exam? 
difficult?",1.0
fyqjk11,huweov,The exam itself is okay. I ran into some GPU issues but eventually resolved them. The specialization course on coursera was really helpful.,1.0
fyr3r69,huweov,"Good to hear as I am undertaking this now!

75% the way through almost (finishing off sequences).

I heard GPU access is very useful (running the code before submitting in PyCharm) and I have GPU access locally thankfully, for those that haven't I heard CoLab is a great alternative.",1.0
fytozkx,huweov,"I did the last three questions on Colab with GPU turned on in the runtime settings, and download the h5 file for each question, drag and drop into the Pycharm under the corresponding project folders, and I didn't receive any error or bug when I tested my models.  So I guess if you don't wanna run into any GPU issue or like me, running Pycharm on a Mac, Colab is def the way to go!",2.0
fysapqo,huweov,"Here is a tip: if you find during test the training was running on CPU, try install tensorflow-gpu package, it worked in my case.",1.0
fyvp5br,huweov,"I just received the certificate today, so it took about 3, 4 days to receive it. I haven’t seen my name on the network but I think it will update soon.",1.0
fyvtr5s,huweov,"Congrats to you! I got it this morning too. I think there should be a separate email for filling out info for the network some time later. Not sure tho, seems like they had made some modifications to the process.",1.0
fyw8bax,huweov,Oh really? I think it makes sense! Kudos to both of us!!,1.0
fzhhhdb,huweov,Did you ever get a separate email for getting your info on the developer network?,1.0
fys57pm,huut5a,"You could use Tensorflow for CV but it's overkill.  Instead just an a OCR library, a mounted camera and selective cropping.

You could use Tensorflow for processing the text output for dynamically selecting significant pieces of information from the OCR output or for filling in the missing details for numbers in the meter that haven't rolled over yet.  Personally, I would focus on that because it's a lot more deterministic.",1.0
fzc7fw2,huut5a,Hi. Sorry for the late response. My use case is about 30 of these images on a monthly basis and I would need the meter number (to compare against a pre-existing list) and the actual reading,1.0
fyop7x8,hur0vn,Spam every ml related sub why don't you.,3.0
fyoydpw,hur0vn,"You should probably ask a more specific question, this is just completely open ended. 

Are you looking for help with a specific piece of this architecture?",2.0
fynzxtf,hun41d,"The problem may be the batch size, which is your batch size?
There's no way a batch size of 32 won't work..

Also, are you using transfer learning? You could reduce the memory usage by training just the last layers",2.0
fyo0bkt,hun41d,At the moment it is 32 but I have tried it at 1 which if I remember correctly is the best for saving memory.,1.0
fyo0il0,hun41d,"Does it work with 32? How do you load the data? Do you have jpegs or is it a tfrecord? Also which is the biggest batch size you can use before encountering issues? Also, are you using keras? Can you share your code in a colab notebook?",3.0
fyo1raj,hun41d,"It doesn't work in any case where I change the batch size. I load the data using the keras flow_from_dataframe. The training data is augmented so I am thinking of testing it today without those augmentations and see how much that helps. Yes, I am using keras. I'll try to see if I can share it later but it's for my work so I have to see what I can do when I get there.",1.0
fyo134a,hun41d,I'm not sure if I am using transfer learning so I'll look into it. I do know some portion of layers are frozen from learning but I dont remember how much of them are frozen and when.,1.0
fyo1bf8,hun41d,Did you write the model or is it an example taken from somewhere? You could try with an inception net v3 from keras and try if it works for your case. Inception res net is hard to train..,2.0
fyo21k2,hun41d,My boss wrote the majority of the model from scratch. I'll definitely look into that. I have been looking into using EfficientNet but I think its only in the nightly build of keras.,1.0
fypeqi7,hun41d,When you are not training is the memory free? You can find out with “nvidia-smi” in your terminal.,2.0
fypf3wp,hun41d,"Yep, watch nvidia-smi shows only one of my gpus are running at ~3% however the problem is my system RAM fills not my VRAM.",1.0
fypfu5y,hun41d,Maybe ur dataset is too big to load. are you using a generator function that loads only small parts of your dataset for training?,2.0
fypg6t3,hun41d,"Maybe that's it, is there an easy way to implement this? Do I have to separate the generated dataset manually?",1.0
fyph1zv,hun41d,"[https://www.pyimagesearch.com/2018/12/24/how-to-use-keras-fit-and-fit\_generator-a-hands-on-tutorial/](https://www.pyimagesearch.com/2018/12/24/how-to-use-keras-fit-and-fit_generator-a-hands-on-tutorial/)   i think you should find some answers here.

basically you can just create a function with an endless loop which serves a chunk of your dataset without stopping. therefore you can use the python yield function or that stuff that is mentioned in the article.",2.0
fyphhec,hun41d,"Ok thanks, I'll see if it helps",2.0
fyphyqq,hun41d,Yeah this sounds like you might be trying to load the whole dataset at once. Are you using a DataGenerator? ImageDataGenerator might be what you need.,1.0
fypjumc,hun41d,So I looked at the link and unfortunately I don't think this is the problem. I am already going from the ImageDataGenerator to the flow_from_dataframe and inputting it to the model.fit function. When I ran the model.fit_generator function it tells me that its deprecated and that I should use model.fit instead.,1.0
fypihon,hun41d,You could test if this is the problem by running on a small set of images instead of the whole training set.,1.0
fypjzbh,hun41d,I have reduced the training set by a factor of around 8x and that did work though.,1.0
fyqe4yq,hun41d,"Don't know how you are feeding the data into your model, but problems with shuffle buffer? Had it before, in the fit function make shuffle = false.",2.0
fyqnv5s,hun41d,Thanks I'll try that. Would that have an impact on the quality of the model though?,1.0
fyqoaw5,hun41d,"In my experience, it will not, basically what it does is shuffling the training data for each epoch. Yes it is very much advisable to shuffle the data at each epoch but for the most cases, it's not worth the trouble since you are very much likely to achieve the desirable results by not doing it.
But there are many ways to do that. For once, I stopped using the shuffle property of the fit function and made a data generator for my self. 
You can give it a look by searching Keras Sequence Generator.

I've spent quit some time searching for reasons why the ""shuffle buffer"" issue was happening, since I had quite a beast configuration like yours, and basically the general idea is that the shuffling property of the Tensorflow/Keras library is not that well optimized. So when it starts bringing issues like these, disable it.

And, with Keras Sequence Generator, you don't store all of your data in memory, you can specify how many batches you store in memory, that's also one thing to look at, because 1.2 million images might just blow up you RAM.

But one problem at at time, good luck!",2.0
fyqoec9,hun41d,"Ok, thanks for the info",2.0
fynxf32,humsmk,"## Overview

We are excited to release Spark NLP 2.5.4 with the full support of Apache Spark 2.3.x, adding 43 new pre-trained models for stop words cleaning, supporting 26 new languages, a new RegexTokenizer annotator and more!

As always, we would like to thank our community for their feedback, questions, and feature requests.

## New Features

* Add support for Apache Spark 2.3.x including new Maven artifacts and full support of all pre-trained models/pipelines
* Add 43 new pre-trained models in 43 languages to StopWordsCleaner annotator
* Introduce a new RegexTokenizer to split text by regex pattern

## Enhancements

* Retrained 6 new BioBERT and ClinicalBERT models
* Add a new param `spark23` to `start()` function to start the session for Apache Spark 2.3.x

## Bugfixes

* Add missing library for SentencePiece used by AlbertEmbeddings and XlnetEmbeddings on Windows
* Fix ModuleNotFoundError in LanguageDetectorDL pipelines in Python

## Models

* We have added 43 new pre-trained models in 43 languages for StopWordsCleaner. Some selected models:

## Afrikaans - Models

|Model|Name|Build|Lang|Offline|
|:-|:-|:-|:-|:-|
|StopWordsCleaner|`stopwords_af`|2.5.4|`af`|[Download](https://s3.amazonaws.com/auxdata.johnsnowlabs.com/public/models/stopwords_af_af_2.5.4_2.4_1594742440083.zip)|

## Arabic - Models

|Model|Name|Build|Lang|Offline|
|:-|:-|:-|:-|:-|
|StopWordsCleaner|`stopwords_ar`|2.5.4|`ar`|[Download](https://s3.amazonaws.com/auxdata.johnsnowlabs.com/public/models/stopwords_ar_ar_2.5.4_2.4_1594742440256.zip)|

## Armenian - Models

|Model|Name|Build|Lang|Offline|
|:-|:-|:-|:-|:-|
|StopWordsCleaner|`stopwords_hy`|2.5.4|`hy`|[Download](https://s3.amazonaws.com/auxdata.johnsnowlabs.com/public/models/stopwords_hy_hy_2.5.4_2.4_1594742439626.zip)|

## Basque - Models

|Model|Name|Build|Lang|Offline|
|:-|:-|:-|:-|:-|
|StopWordsCleaner|`stopwords_eu`|2.5.4|`eu`|[Download](https://s3.amazonaws.com/auxdata.johnsnowlabs.com/public/models/stopwords_eu_eu_2.5.4_2.4_1594742441951.zip)|

## Bengali - Models

|Model|Name|Build|Lang|Offline|
|:-|:-|:-|:-|:-|
|StopWordsCleaner|`stopwords_bn`|2.5.4|`bn`|[Download](https://s3.amazonaws.com/auxdata.johnsnowlabs.com/public/models/stopwords_bn_bn_2.5.4_2.4_1594742440339.zip)|

## Breton - Models

|Model|Name|Build|Lang|Offline|
|:-|:-|:-|:-|:-|
|StopWordsCleaner|`stopwords_br`|2.5.4|`br`|[Download](https://s3.amazonaws.com/auxdata.johnsnowlabs.com/public/models/stopwords_br_br_2.5.4_2.4_1594742440778.zip)|

## Documentation and Notebooks

* New notebook for [Language detection and identification](https://github.com/JohnSnowLabs/spark-nlp-workshop/blob/master/jupyter/annotation/english/language-detection/Language_Detection_and_Indentification.ipynb)
* New notebook for [Classify text according to TREC classes](https://github.com/JohnSnowLabs/spark-nlp-workshop/blob/master/tutorials/streamlit_notebooks/CLASSIFICATION_EN_TREC.ipynb)
* New notebook for [Detect Spam messages](https://github.com/JohnSnowLabs/spark-nlp-workshop/blob/master/tutorials/streamlit_notebooks/CLASSIFICATION_EN_SPAM.ipynb)
* New notebook for [Detect fake news](https://github.com/JohnSnowLabs/spark-nlp-workshop/blob/master/tutorials/streamlit_notebooks/CLASSIFICATION_EN_FAKENEWS.ipynb)
* New notebook for [Find sentiment in text](https://github.com/JohnSnowLabs/spark-nlp-workshop/blob/master/tutorials/streamlit_notebooks/SENTIMENT_EN.ipynb)
* New notebook for [Detect bullying in tweets](https://github.com/JohnSnowLabs/spark-nlp-workshop/blob/master/tutorials/streamlit_notebooks/SENTIMENT_EN_CYBERBULLYING.ipynb)
* New notebook for [Detect Emotions in text](https://github.com/JohnSnowLabs/spark-nlp-workshop/blob/master/tutorials/streamlit_notebooks/SENTIMENT_EN_EMOTION.ipynb)
* New notebook for [Detect Sarcasm in text](https://github.com/JohnSnowLabs/spark-nlp-workshop/blob/master/tutorials/streamlit_notebooks/SENTIMENT_EN_SARCASM.ipynb)
* Update the entire [spark-nlp-models](https://github.com/JohnSnowLabs/spark-nlp-models) repository with new pre-trained models and pipelines
* Update the entire [spark-nlp-workshop](https://github.com/JohnSnowLabs/spark-nlp-workshop) notebooks for Spark NLP 2.5.x
* Update documentation for release of Spark NLP 2.5.x",1.0
fynxg5q,humsmk,"
I see you've posted GitHub links to Jupyter Notebooks! GitHub doesn't 
render large Jupyter Notebooks, so just in case here are 
[nbviewer](https://nbviewer.jupyter.org/) links to the notebooks:

https://nbviewer.jupyter.org/url/github.com/JohnSnowLabs/spark-nlp-workshop/blob/master/jupyter/annotation/english/language-detection/Language_Detection_and_Indentification.ipynb

https://nbviewer.jupyter.org/url/github.com/JohnSnowLabs/spark-nlp-workshop/blob/master/tutorials/streamlit_notebooks/CLASSIFICATION_EN_TREC.ipynb

https://nbviewer.jupyter.org/url/github.com/JohnSnowLabs/spark-nlp-workshop/blob/master/tutorials/streamlit_notebooks/CLASSIFICATION_EN_SPAM.ipynb

https://nbviewer.jupyter.org/url/github.com/JohnSnowLabs/spark-nlp-workshop/blob/master/tutorials/streamlit_notebooks/CLASSIFICATION_EN_FAKENEWS.ipynb

https://nbviewer.jupyter.org/url/github.com/JohnSnowLabs/spark-nlp-workshop/blob/master/tutorials/streamlit_notebooks/SENTIMENT_EN.ipynb

https://nbviewer.jupyter.org/url/github.com/JohnSnowLabs/spark-nlp-workshop/blob/master/tutorials/streamlit_notebooks/SENTIMENT_EN_CYBERBULLYING.ipynb

https://nbviewer.jupyter.org/url/github.com/JohnSnowLabs/spark-nlp-workshop/blob/master/tutorials/streamlit_notebooks/SENTIMENT_EN_EMOTION.ipynb

https://nbviewer.jupyter.org/url/github.com/JohnSnowLabs/spark-nlp-workshop/blob/master/tutorials/streamlit_notebooks/SENTIMENT_EN_SARCASM.ipynb

Want to run the code yourself? Here are [binder](https://mybinder.org/) 
links to start your own Jupyter server!

https://mybinder.org/v2/gh/JohnSnowLabs/spark-nlp-workshop/master?filepath=jupyter%2Fannotation%2Fenglish%2Flanguage-detection%2FLanguage_Detection_and_Indentification.ipynb

https://mybinder.org/v2/gh/JohnSnowLabs/spark-nlp-workshop/master?filepath=tutorials%2Fstreamlit_notebooks%2FCLASSIFICATION_EN_TREC.ipynb

https://mybinder.org/v2/gh/JohnSnowLabs/spark-nlp-workshop/master?filepath=tutorials%2Fstreamlit_notebooks%2FCLASSIFICATION_EN_SPAM.ipynb

https://mybinder.org/v2/gh/JohnSnowLabs/spark-nlp-workshop/master?filepath=tutorials%2Fstreamlit_notebooks%2FCLASSIFICATION_EN_FAKENEWS.ipynb

https://mybinder.org/v2/gh/JohnSnowLabs/spark-nlp-workshop/master?filepath=tutorials%2Fstreamlit_notebooks%2FSENTIMENT_EN.ipynb

https://mybinder.org/v2/gh/JohnSnowLabs/spark-nlp-workshop/master?filepath=tutorials%2Fstreamlit_notebooks%2FSENTIMENT_EN_CYBERBULLYING.ipynb

https://mybinder.org/v2/gh/JohnSnowLabs/spark-nlp-workshop/master?filepath=tutorials%2Fstreamlit_notebooks%2FSENTIMENT_EN_EMOTION.ipynb

https://mybinder.org/v2/gh/JohnSnowLabs/spark-nlp-workshop/master?filepath=tutorials%2Fstreamlit_notebooks%2FSENTIMENT_EN_SARCASM.ipynb



------

^(I am a bot.) 
[^(Feedback)](https://www.reddit.com/message/compose/?to=jd_paton) ^(|) 
[^(GitHub)](https://github.com/JohnPaton/nbviewerbot) ^(|) 
[^(Author)](https://johnpaton.net/)",1.0
fyn77u2,hucljm,"It's a very good framework, but the recent upgrade to Tf2.0 has broken too many things and including keras within tf itself was not a good option it seems..they could have developed keras as a standalone framework.
Also, the documentation is not that apt as compared to pytorch.",5.0
fyo44vx,hucljm,"keras started as a wrapper to make tensorflow simpler, now I feel we also need a wrapper for keras itself ...

All the model save/load APIs are confusing as hell. I have lost count how many times my model breaks because of keras and tf version mismatch, even with the same version number, tf.keras and standalone keras from pypi are sometimes not compatible, it's madness",4.0
fyqgxud,hucljm,It's looking like they're going to move Keras back out into a separate repo: [https://github.com/tensorflow/community/blob/c3d9d99a9df5741e705abaa2df7203e260671bf1/rfcs/20200205-standalone-keras-repository.md#standalone-keras-repository](https://github.com/tensorflow/community/blob/c3d9d99a9df5741e705abaa2df7203e260671bf1/rfcs/20200205-standalone-keras-repository.md#standalone-keras-repository),1.0
fyqrg4o,hucljm,"True, agreed.

There were a lot of things breaking in versions of TF1.0 as well, but it has  been highlighted on the internet very often. 

Nonetheless, TF makes not just deep learning but distributed computation in general more easily accessible.",1.0
fyn17ng,hucljm,Wholesome.,1.0
fyn5shl,hucljm,"Yep, they do a great job. But there is still a lot of bugs and lack in documentation..",1.0
fykwx7k,hu3ie1,"I couldn't find an tensorflow2 implementation of wide Resnet but found this   [https://github.com/dalgu90/wrn-tensorflow](https://github.com/dalgu90/wrn-tensorflow) as for other model suggestions i would suggest EfficientNet and few  augmentation techniques like cutout , cutmix etc",1.0
fyisblm,htlrx4,"&gt; keras.Model requires all inputs to have the same # in the first dimension.

That's surprising, can you be more specific about what the problem, is there?

Can you post some minmal code demonstrating the error?",1.0
fymicv9,htlrx4,"My inputs to the model are arrays of the follow dimensions: [1, *dimension of large vector*] and [sample_count, *anything*]. When I invoke *fit()*, I get the error

&gt;ValueError: All input arrays (x) should have the same number of samples",1.0
fymkz21,htlrx4,"Okay, I think I see it now.


So I quess you're passing the arrays is like this:

```
models.fit([samples, big_vector], labels, ...)
```

The problem may be that the model needs to slice and batch the input
Instead, try a `tf.data.Dataset()`, if you pass a dataset the model expects you to do the slicing and batching, and will take anything you pass it.

```
big_vector_repeater = tf.data.Dataset.from_tensors(big_vector).repeat()
sample_slices = tf.data.Dataset.from_tensor_slices(samples_array)

input_pairs = tf.data.Dataset.zip((sample_slices, big_vector_repeater))
```",2.0
fyh6dq9,hthvx2,Is there a clickable version?,5.0
fye42xa,ht0pdf,Check out [https://app.roboflow.ai/](https://app.roboflow.ai/) for an off the shelf solution which may or may not suit. The free tier should be enough for small datasets. It doesn't suit me atm but I check their blog daily because things are moving rapidly in this field.,1.0
fye46eh,ht0pdf,Thank you!,1.0
fye7uwi,hszm2r,I think it’s better if you put your codes on gist or pastebin and share the links,2.0
fyfgifi,hszm2r,"I see, I have put the codes on gist.",1.0
fyg755e,hszm2r,Use tf.data pipeline.. it will keep your GPU busy,1.0
fyevzr6,hszm2r,Use Torch,0.0
fydrdk4,hsx8pe,"Hi, 

You added train\_images instead of test\_images

`test_images = test_images / 255.0`",3.0
fydtb92,hsx8pe,"Oh, thanks!",2.0
fyd2yaw,hswm44,"Accuracy of 0.1 (10%) means no accuracy at all, since in your case you have 10 target classes. Your model is not training. 

I would go back and follow the tutorial more closely, pay special attention to the steps you skipped. Try to be able to explain to a stranger what is happening at each step. You’ll gain SO much more by figuring this out on your own, you can do it!

Quick edit:
I want to explain the intuition of the first part for you more clearly. If you flip a coin and guess that the outcome will be “heads” every time, given enough trials you should be correct about 50% of the time as you have two possible outcomes. With the dataset you are using, there are ten possible outcomes, so random chance means you should guess correctly 10% of the time. This is how I know that your model is not “fitting the curve”.",10.0
fyd4w0c,hswm44,"Thanks ! I switched to the official guide of tensorflow, I just realize that I followed a old tutorial on tensorflow beta, plus the guys wasn't so good at explaining. Thank you for your time !",3.0
fydmy0v,hswm44,"I just looked at your code. To me the problem seems to be big learning rate.

You are using sgd as your optimizer. sgd uses 0.01 as the learning rate, which is in your case too big. I changed it to a smaller value (0.001) and it works (85% accuracy). 

what happens when your learning rate is big? Answer is simple and you can find it with some simple googling. Also learning to create models is fun. But I will suggest also to spend a fare amount of time on optimizers and loss functions also. They play big role.

Hope it helps. :)",3.0
fyfxgu3,hswm44,"Hey u/Turbulent-Student,  
First of all welcome to TensorFlow and ML Experience.  I would like you to go through the TensorFlow documentation for getting inside knowledge and more.  


Now Talking about your problem here,   
1st  thing -  0.1 mean 10%  
2nd  point - You can play with No of Node in a layer / No of layers

3rd point - Play with No of Epochs and Learning Rate",1.0
fyciw81,hssumy,"I'd start here:

https://github.com/tensorflow/models/tree/master/official/vision
https://github.com/tensorflow/models/tree/master/research/object_detection/colab_tutorials",2.0
fycj1gk,hssumy,Ok Thanks im going to try that out,1.0
fyci346,hssumy,You have Multiple options but i would recommend to have a look at DETR which incorporates Transformer Components and is actually pretty easy to use.,1.0
fyci49u,hssumy,Thanks bro,3.0
fych4z0,hssumy,Have you tried the “make object detection” button?,-2.0
fybxuq5,hsksr2,"You need a separate tensor for each column `from_tensor_slices(dict(df))` FTW. 

But, why are you still using TF1?",2.0
fyc3rq4,hsksr2,"would it be something like:
`col_1 = tf.placeholder(tf.int64)`
`col_2 = tf.placeholder(tf.string)`
How do I use it with `dict`?",1.0
fycjt78,hsksr2,"I see now that my initial comment wasn't helpful.

you'll want to do something like 

```
placeholders = {}
for name, column in dict(df).items(): 
  a = np.array(column)
  dtype = tf.as_dtype(a.dtype)
  placeholders[name] = tf.placeholder(dtype=col.dtype, shape=[None]) 
```",1.0
fyqwnxl,hsksr2,"using [session.run](https://session.run) to feed\_dict and run the iterator, but getting an error:

GetNext() failed because the iterator has not been initialized",1.0
fyatkc3,hsjfeo,"Your best bet is to use transfer learning which is where you use a model pretrained on a large dataset and then retrain it on your smaller dataset. But since this can be complicated for a beginner I suggest that you upload the images to Google’s AutoML, they have a simple Interface for using their powerful pretrained models for image classification which might work on such small datasets and its much simpler than trying do implement a custom solution.

P.s. I think this forum is more to talk about the Tensorflow software in general rather than specific use cases but I don’t mind answering your question :)",1.0
fyav4rd,hsjfeo,"Excellent, thanks for the advice! Do you happen to know if there's a subreddit for questions about using TF?",1.0
fycidbv,hsjfeo,"I'd love to see a weekly question thread.

I'd a question last week that was too vague for StackOverflow but ideal for someone on here. It would also be a place to ask noob and basic questions because you see the same questions over and over.",1.0
fycmbws,hsjfeo,"Same!  I asked a question a month or 2 back when I was spec'ing out my PC build because my wife wanted a laptop and I wanted a desktop.  I felt bad asking it as its own thread because it was related to TF (ie can it work on a laptop without burning my house down), but not really what I'd call a good thread or question by any means.  The more I'm starting to dig in -- which I'm just barely scratching the surface -- the more stupid questions I feel like I'll have.  I should check out the discord server and see it'd make sense to ask there.",1.0
fyb2xld,hsjfeo,"You should google cats vs dogs classification, you'll find examples on how to load the data, augment the data and train a ConvNet to classify images. You can extend these examples to fit your particular problem.

&amp;#x200B;

&gt;As an aside, I have no idea if I have this set up properly on win10 to leverage my gpu (rtx 2060super).

On Windows 10, it may be easier to install Anaconda, create a virtual environment and then install tensorflow-gpu. This will straight up install most modules you will ever need for running deep learning experiments. You can then install pillow, opencv or whichever library you may need for image processing. You can use nvidia's app to update your gpu drivers. I'm not an expert on gpus, but I reckon an rtx 2060 should be easily able to deal with your sort of problem. To make sure your tensorflow can make use of the gpu, you can run some example code which prints which device is running the tensorflow code.",1.0
fyb5hcm,hsjfeo,"Thanks for the tips. I've been looking at those dog/cat tutorials and it did get me started, but they all seemed to use the predefined data sets. Also, I feel so dumb when I'm researching this which doesn't help. I'm a business/systems analyst by trade, so conceptually I understand everything, but my best coding days are behind me I fear.  But I'm far too stubborn to just give up on it!  
  
  
As far as the gpu, I actually used anaconda to get everything up and running so I think it's probably working. Just not 100% sure because it flashes some message about needing to use a ptaxs driver or something on windows since it isn't fully functional on non-linux environments. Who knows. Either way, it's plenty fast for what I need it to do right now.",1.0
fyc14uj,hsjfeo,"&gt;those dog/cat tutorials and it did get me started, but they all seemed to use the predefined data sets.

If your level of Python is sufficient, it may be more beneficial for you to look at code repositories on Github. Tons of people commit their deep learning projects to Github repos, along with their project writeup.

&gt;it flashes some message about needing to use a ptaxs driver or  something on windows since it isn't fully functional on non-linux  environments.

As is often the case for programming stuff, you can google this. I bet there's a stackoverflow post about this already, where you'll find experts' solution to your problem.",1.0
fybijv4,hsjfeo,you can check out this course on udemy it goes over googles autoML which only requires 10 images total to create a model. Of course the more images the better.  [https://www.udemy.com/course/architecting-a-scalable-machine-learning-pipeline/](https://www.udemy.com/course/architecting-a-scalable-machine-learning-pipeline/),1.0
fyci7d3,hsjfeo,"There's actually a new Tensorflow 2.0 tutorial/ Colab that transfers learning on just 5 objects:

[https://github.com/tensorflow/models/blob/master/research/object\_detection/colab\_tutorials/eager\_few\_shot\_od\_training\_tf2\_colab.ipynb](https://github.com/tensorflow/models/blob/master/research/object_detection/colab_tutorials/eager_few_shot_od_training_tf2_colab.ipynb)

I finally got things working using various tutorials and tweaking to my own needs but I'm not happy with results or do I fully understand what's going on. TF2 Object detection is &lt;1 week old so it will take time for people to understand it but it seems a lot easier and cleaner.

The biggest problem with using TF on your own machine is there are so many conflicts with various imports. I have TF CPU set up on my own machine but I do most of my training in Colabs for this reason. Colab gives you 1 2 hours use but you can make checkpoints and restart from where you left off. You also get some pretty decent GPU and TPU's.",1.0
fyci7x6,hsjfeo,"
I see you've posted a GitHub link to a Jupyter Notebook! GitHub doesn't 
render large Jupyter Notebooks, so just in case, here is an 
[nbviewer](https://nbviewer.jupyter.org/) link to the notebook:

https://nbviewer.jupyter.org/url/github.com/tensorflow/models/blob/master/research/object_detection/colab_tutorials/eager_few_shot_od_training_tf2_colab.ipynb

Want to run the code yourself? Here is a [binder](https://mybinder.org/) 
link to start your own Jupyter server and try it out!

https://mybinder.org/v2/gh/tensorflow/models/master?filepath=research%2Fobject_detection%2Fcolab_tutorials%2Feager_few_shot_od_training_tf2_colab.ipynb



------

^(I am a bot.) 
[^(Feedback)](https://www.reddit.com/message/compose/?to=jd_paton) ^(|) 
[^(GitHub)](https://github.com/JohnPaton/nbviewerbot) ^(|) 
[^(Author)](https://johnpaton.net/)",1.0
fycmeng,hsjfeo,Looks like a great tutorial from a quick glance.  I'll definitely be checking it out while stuck on some of my more pointless calls today!,1.0
fy977hq,hs9to2,"The answer to your question may lie with the hardware you are inferencing on. I have experienced a decrease in inference throughput performance with FP16 vs FP32 on CPU. The same models, however, on GPU have inference throughput improvements with FP16 compared to FP32. I do not know why CPU suffers with FP16.",3.0
fy98jyu,hs9to2,"Good suggestion, indeed I tried this code on a system without GPU. Strange!",2.0
fyaxuc7,hs9to2,Tried with GPU as well. FP32 is slightly faster than FP16 .,2.0
fyc35fi,hs9to2,"Which GPU did you use? Some do not support FP16. Also, it might be that the FP16 conversion needs to take place on the supported GPU.

Is the model file size at least smaller?",1.0
fycdaek,hs9to2,Model size being smaller ? What has this got to do with FP16?,1.0
fyci87c,hs9to2,"If the weights are FP16, that means they have less total digits in them than the FP32 weights. This will result in a smaller file size. It is a sanity check that the conversion was correct.",1.0
fyciy79,hs9to2,"Ah, yes the file size is halved.",1.0
fy7g7in,hry679,"Try using anaconda packaging, it's incredibly simple that way. Install anaconda (miniconda if you don't want all the beginner friendly features of anaconda) and run  
`conda install -c anaconda tensorflow-gpu`

I'm not familiar with your issue with pip sorry.

Edit: oh reading your question, I'm not sure if anaconda will have been updated to have tensorflow on py3.8 yet. I can check in a little bit if it works on my PC",3.0
fy7qdg0,hry679,"I finally got it to work by using ""python -m pip install tensorfow""  Why that works and ""pip install tensorflow"" doesn't,  I can't explain. Perhaps the direct ""pip"" is picking up an earlier install of Python that isn't supported by tensorflow? Anyway, I've got it working now, thanks for taking the time to look into this.",3.0
fy7rkor,hry679,"Just a quick tip (that I learnt from experience), always use `python -m pip install --user module_name`",3.0
fy83n74,hry679,"Tensorflow on Python 3.8 is highly problematic,  esp if you are going to use it for any image based projects, Because of PIL library. Best thing to do install Python 3.7.. everything is stable there.",1.0
fy8den9,hry679,"i had a lot of trouble on win 8.1 (https://stackoverflow.com/questions/62376660/installing-tensorflow-2-gets-a-dll-failed-to-load-in-pywrap-tensorflow-py).

best thing i came up with is to install python 3.8.3 and make a virtual environment. i was able to get tensorflow 2.2.0.",1.0
fy6162t,hrnojl,"It sounds like you know exactly what the difference between pass and fail are. If you can look at the images and tell which are pass, then don't even use IA or ML.  Just write an expert system and explicitly code the rules for telling which are pass and fail.

&amp;#x200B;

""When all you have is a hammer, everything looks like a nail.""",2.0
fy6uofx,hrnojl,could you use data augmentation for the fail variants?,1.0
fy2k3j4,hr8c22,"Are you running jupyter locally or on a server?

If you are running locally, it is recommended to create a virtual environment.

virtualenv -p python3 venv 

Python 3 comes with virtual environment (google this)

Then activate it 

source venv/bin/activate 

Once your environment is activated 

pip install tensorflow
pip install jupyterlab 

Then launch Jupyter 

Python -m jupyter lab 


You should be able to import Keras from tf.keras (google for tutorials). 

Inside jupyter notebooks, you can also install packages, you just need to start with ! 

Example 

! pip install [name of package here]",1.0
fy3hhn5,hr8c22,"I guess u haven't installed the supporting drivers properly can u pls check and confirm that u have done everything as mentioned below ??


[Deep learning Setup](https://github.com/rexdivakar/Deep-Learning-Setup)",1.0
fy2be8z,hr6sfl,I dont want to assume but based on your documentation on git this seems to be a real issue. There is no way for those weights to be updated if they arent listed under trainable\_variables. Your print results assert this?,2.0
fy2c4fm,hr6sfl,"Yeah, I directly compared this to the exact same model created with model subclassing, model subclassing has all the weights, the one created with the functional API does not. And to be absolutely sure, I tested inference of both models, they are exactly the same.",1.0
fy2cdid,hr6sfl,"Then this is a serious bug, no way around it. I have questioned the quality of tensorflow/keras for a while now, this seems like another example of why it needs to be totally revamped (again).",1.0
fy463p4,hr6sfl,Time to `import torch as tf` XD,1.0
fy176bg,hr18h3,"A Web extension that filters out NSFW images from websites.

It uses TensorFlow JS- a Machine Learning framework- to check NSFW images when they are loaded.

If the loaded images contain NSFW content as predicted by the algorithm, it is replaced by a random image from Unsplash.",1.0
fy0vi2z,hqz3gq,seems a bit redundant to the existing Paths library..?,3.0
fy0w7dy,hqz3gq,"Does the paths library let you save paths by names? does it let you save shortcuts to subdirectories? in the case that it does (which I don't know of), how is the syntax? I designed my module with syntax in mind so it can be easy to work with, the entire point of this module is to make your code understandable when working with paths and subdirectories.",1.0
fy15gsd,hqz3gq,"To me it seems you could do all that just with a dictionary... And it looks like thats exactly what your code is also doing.  

For project-wise paths that are declared in a file you can just use many existing solutions such as dotenv files.",2.0
fy17ui4,hqz3gq,"As far as I know you can’t set environment variables on runtime, as with my module where you can change things on runtime. Again, the entire point for this package is two things, 1) saving your paths in a SIMPLE file with SHORTCUTS. 2) SIMPLE SYNTAX that can be used with a SINGLE LINE.

In fact let me reiterate, the main key points of this module are:
1. You don’t need to hassle with configuration (although you can if you want).
2. The syntax is extremely simple, just one line.
3. You can save paths by name which makes it easier to remember and to understand the code.
4. You can set shortcuts to subdirectories with name, which again, makes it easier to remember and to understand the code.

The paths you save are meant to be used in ANY project in ANYTIME, it is not aimed to a specific project, the saved paths are globally available to every project.",1.0
fy1grkf,hqz3gq,"I'm still not fully convinced, sorry.

Anyway, something more constructive:  

Are you familiar with dotenv? I could see it as a more human-readable alternative for your json file. Usually one basically dumps a "".env"" file at the root of the project dir for things like DB passwords. Maybe that could be interesting for you.

[https://pypi.org/project/python-dotenv/](https://pypi.org/project/python-dotenv/)",1.0
fxzt1s2,hqo89m,[deleted],3.0
fxzy93w,hqo89m,"Yep, you are correct. One _function_ is what I should have used in the title -- unfortunately can't edit it :/",-1.0
fy13l99,hql2k8,"Tensorflow attention_ocr looks relatively new you can check at below link

https://github.com/tensorflow/models/tree/master/research/attention_ocr

Tesseract’s latest ocr is based on LSTM model you can try it. When I tried couple of months ago I got decent results.. 


https://github.com/tesseract-ocr/tesseract",1.0
fxxliz4,hqd0qd,[deleted],5.0
fxy257a,hqd0qd,"The exam had a lot of similarities to the TensorFlow in practice specialization, the questions are straightforward and if you completed the coursera courses you should be more then fine.",1.0
fzdvjka,hqd0qd,"I've run through the TensorFlow specialisation course any recommendations on how to consolidate that knowledge before taking the exam?

I've fairly confident on the image recognition side of things but a bit weak on the sequences and time series.

How much raw python knowledge is needed? There seemed to be quite a bit of focus on data preparation in the specialisation course.",3.0
g29hp3m,hqd0qd,"Data preparation is always most of the work.  
Pretty much anyone you ask this will answer you should train more models and tackle more datasets/problems. 

With that in mind, as someone who got lucky enough to be hired without much experience with pandas and numpy, I would say you should go for kaggle and try to go through what people did step by step. 

&amp;#x200B;

As time goes on you end up getting the hang of it but only practice will make you comfortable.

Another thing that would help if you don't have the time to practice is taking notes on the process and then going for it just relying on your notes. 

Python knowledge will help you make things faster and/or easier, it won't stop you from doing stuff if you know how to google your problems.

For me, knowing my way around pandas was possibly the most useful thing I learned.",5.0
g29759a,hqd0qd,"Thank you,

Is Tensorflow Specialization on Coursera sufficient for this certificate? I find it rather underwhelming to be honest... granted I have some previous Tensorflow experience, but still, this specialization only touches lightly on keras APIs...",2.0
g4jupsc,hqd0qd,"1. Does the certification ask you to build complex models?

2. Is there a minimum accuracy that is required for each questions?",2.0
g4jxica,hqd0qd,"1. What do you mean by complex models?
2. The way they evaluate your models is by testing them against some random data, so to answer your question, no there is no minimum accuracy required.",2.0
g4lwy9n,hqd0qd,"Do we need to create models having more than 10-15 layers?  
Ps:-I have a low end laptop and it takes too much time to train for models with more than 10 layers",2.0
g7f4hf6,hqd0qd,Use Google Colab to train your models.,1.0
fxxiq58,hqd0qd,Can you use the interwebs during the exam?,1.0
fxxjt79,hqd0qd,"Yes, you have the same resources as you would in a normal day in your work.",2.0
fxy0g6k,hqd0qd,"Just to clarify, you can use only official resources and documentation or even sites like stackoverflow.com and towardsdatascience.com?",2.0
fxy1udx,hqd0qd,"They don’t monitor you, you can use whatever you want, including stack overflow or towards data science.

Edit: I even asked a question on stack overflow during my exam :D",8.0
fxz79r8,hqd0qd,So is the test timed per question?,1.0
fy0p9y0,hqd0qd,"No, the entire length of the exam is 5 hours, you have to complete all 5 questions during that time.",1.0
fz2s2gl,hqd0qd,"Do you feel like you were pressed for time? I've done some exams where they give you like 8 hours, but most of the people who passed the exam did it in 3.",1.0
fz2uu0j,hqd0qd,"Not at all, I had a lot of spare time after I finished, the 5 hours is for people with slow computers who takes time to train models.",1.0
fxxno1w,hqd0qd,How powerful should the local machine be?,1.0
fxy1zb5,hqd0qd,Fast enough to train models in a reasonable amount of time.,1.0
fxy2c6f,hqd0qd,would cpu be enough? im on ryzen and my intel machine is to old and lacks an instruction set to use the Nvidia GPU with the stable tensor flow,1.0
fxy2scj,hqd0qd,"If you are able to train simple models without it taking too much time then yeah, but if it takes hours to train a single model the you should consider an alternative, I’ll update the post with an alternative you can use.

Edit: updated.",1.0
fybi8qq,hqd0qd,"u/TomerHorowitz, you took and passed the cert exam already, right? I don't see you on the TensorFlow Developer Network. [https://developers.google.com/certification/directory/tensorflow](https://developers.google.com/certification/directory/tensorflow)",1.0
fybx1xv,hqd0qd,"A. It takes about 10 days to appear on the developer network.

B. [yep](https://www.reddit.com/r/tensorflow/comments/hpubez/ysk_you_need_to_submit_each_question_during_the/?utm_source=share&amp;utm_medium=ios_app&amp;utm_name=iossmf)",2.0
fyd01pd,hqd0qd,Congrats! That's awesome that they worked with you on that. Thanks for all of the info.,1.0
fyn82bf,hqd0qd,For identification softcopy of the identity card is ok??,1.0
fz8ao6l,hqd0qd,What do you mean by a soft copy?,1.0
g16v3i8,hqd0qd,"I don't have my passport with me right now due to the lockdown but I have the images of it, so I can I upload them for verification and take the exam",1.0
fz81lw4,hqd0qd,"What are good free alternatives to the Tensorflow in Practice Specialisation on Coursera?

I’ve found the below (will update as people comment);

Part 1: Build and Train
* https://www.youtube.com/playlist?list=PLOU2XLYxmsII9mzQ-Xxug4l2o04JBrkLV

Part 2: Image Classification
* N/a

Part 3: NLP
* https://www.youtube.com/playlist?list=PLQY2H8rRoyvzDbLUZkbudP-MFQZwNmU4S

Part 4: Time Series
* N/a",1.0
g08ejhf,hqd0qd,The specialization can be audited completely for free :),4.0
g0azi9o,hqd0qd,What do you mean “audited completely for free” - I though students could only get it free (with a .edu email),1.0
g0bzen7,hqd0qd,"Coursera offer audit options on all their courses. It's a bit subtle, but it's there.

https://learner.coursera.help/hc/en-us/articles/209818613-Enrollment-options",2.0
fzp8kpf,hqd0qd,"How difficult is the exam? I have never done any serious work with Tensorflow (aside from small personal projects) and the requirements seemed pretty straightforward to me.

Also do you need solid pure Tensorflow knowledge or you can use Keras as well?",1.0
g08en1c,hqd0qd,"You can use keras. In fact the questions are written to use tf.keras.  


Check out the exam handbook (tensorflow.org/certificate)",2.0
fzxrji8,hqd0qd,I think we can use tf.keras,1.0
g1zbzzl,hqd0qd,Do you think knowledge required to pass this exam is sufficient to get a job related to it? Or at least an internship?,1.0
g27nknb,hqd0qd,The exam specifically state that it will use tensorflow 2.0. However my laptop use tensorflow 1.x.x with gpu since i have pretty old graphic card. My graphic card is not supported in tensorflow 2.0. What should i do?. Thks,1.0
g3jpk7p,hqd0qd,"TF 2.x uses same card NVidia Compute Capability as TF1.x, that is 3.5 by default, and 3.0 if you build your own wheel - no difference - if your card works in TF1 it will work in TF2 (I think, unless TF2 changed the minimum CC, but you may even then be able to build a wheel to CC 3.0/3.5).",1.0
g8kf1gc,hqd0qd,"The Exam instructions say ""You need to use TensorFlow 2.x"". Without specifying the exact ""x""!",1.0
g2s88jo,hqd0qd,whats a sample question?,1.0
g4pdklf,hqd0qd,"1.Are the datasets in certification similar to the courseera'sTensorflow specializations dataset size?

2.On an average how long does it take for each epoch?",1.0
g4sur6h,hqd0qd,Keep in mind that you have to use Python 3.7 only since the exam depends on TensorFlow 2.0.0 version.,1.0
g8kg24v,hqd0qd,"I posted a [*question here*](https://www.reddit.com/r/tensorflow/comments/j9kxhf/can_i_pass_the_tensorflow_developer_exam_with/) on whether a **Google Colab** is enough to run the training of the exam models.

If you had passed the exam, and used **Google Colab** during the exam, please share your experience for those who are *nervously* waiting in line...",1.0
g8kos7q,hqd0qd,"For those who passed the exam, did you really need GPU to finish the exam? 
I can't get TF2.0.0 (the exam's version) to use my GPU no matter what. (not locally nor using Google Colab). Please help",1.0
g8kzmcn,hqd0qd,"Try solving the “cats vs dogs” using the dataset from tfds, this can be used as a reference for how much time it takes to train a single model (or solve one of the five questions of the exam)",2.0
g8kzwee,hqd0qd,What is the amount of time to compare to?,1.0
g8l1ess,hqd0qd,"You’ve got 5 tasks during the exam and you’ve got 5 hours to complete all of them, from that we can say that you’ve got 1 hour to complete each task.

Let’s say it takes you 20 minutes to write the code for each task, this gives you 40 minute to train the model, in other words, if it takes you less then 40 minutes to train the model, your good.

Granted you may want to create multiple models for each task (I.e. polish your model) so I would say you’d need a training time of 15 minutes to be completely out of worry.

Hope this helps.",2.0
g8l3k6s,hqd0qd,Nice analysis! Thanks,2.0
fxwsmyj,hqbdhq,"
I see you've posted a GitHub link to a Jupyter Notebook! GitHub doesn't 
render large Jupyter Notebooks, so just in case, here is an 
[nbviewer](https://nbviewer.jupyter.org/) link to the notebook:

https://nbviewer.jupyter.org/url/github.com/arjun-majumdar/Lottery_Ticket_Hypothesis-TensorFlow_2/blob/master/Quantization_LTH_LeNet_300_100_MNIST.ipynb

Want to run the code yourself? Here is a [binder](https://mybinder.org/) 
link to start your own Jupyter server and try it out!

https://mybinder.org/v2/gh/arjun-majumdar/Lottery_Ticket_Hypothesis-TensorFlow_2/master?filepath=Quantization_LTH_LeNet_300_100_MNIST.ipynb



------

^(I am a bot.) 
[^(Feedback)](https://www.reddit.com/message/compose/?to=jd_paton) ^(|) 
[^(GitHub)](https://github.com/JohnPaton/nbviewerbot) ^(|) 
[^(Author)](https://johnpaton.net/)",1.0
fy087o4,hq91zb,"tflite classification example downloads the model and places under assets folder, As long as your food classification model matches the name of the file, input and output layer parameters of one of the 4 models, technically it should work, However i will recommend you to create a new class which extends Classifier say ""FoodClassifier"" and pass all the necessary data and update the activity",1.0
fy99pcs,hq91zb,"The tflite files can be found in the assets folder and it's use in DetectorActivity class.

I think you're trying to implement Image Classification in an app that expects Object Detection. It might be configurable but have a read of this guide: [https://github.com/makorowy/tensorflow-hotornot](https://github.com/makorowy/tensorflow-hotornot) and try and put your new tflite file into his code.

The tensor shape makes a huge difference and will probably crash your app if they're not the same. In the Android example, it expects a tflite model with the \[1, 300, 300, 3\], I think this means that the image it looks at must have the dimensions 300 x 300. As the tflite file you want to use is of shape \[1, 224, 224, 3\]  so you need to resize your image to 224 x 224.

If you get any crashes then look at the log.

I'm sort of stuck at the same problem as yourself only in Object Detection. I keep going up dead ends and running into problems.",1.0
fxv2jzz,hq0zbu,Did you try the [answers here](https://superuser.com/questions/1119883/windows-10-enable-ntfs-long-paths-policy-option-missing)?,1.0
fxv5p22,hq0zbu,I can not access gpedit.msc because im running windows home opposed to windows pro,1.0
fxvfyjs,hq0zbu,"Install tensorflow via conda, you don't need Windows Pro",1.0
fxw9ued,hq0zbu,i had a lot of trouble on win 8.1 (https://stackoverflow.com/questions/62376660/installing-tensorflow-2-gets-a-dll-failed-to-load-in-pywrap-tensorflow-py). what version of windows do you have?,1.0
fxwcd4j,hq0zbu,Windows 10 home,1.0
fy0bhun,hq0zbu,i had the best luck recently by installing python 3.8.3 and making a virtual environment (https://docs.python.org/3/library/venv.html).,1.0
fy6s194,hq0zbu,I recommend using Linux for ML,1.0
fy7g65z,hq0zbu,in the medium and long run and if you are serious Linux and preferably Ubuntu (Google's favourite) is the only way to go,1.0
fxzb2j7,hpzci1,I guess you gotta fix the height and width in your Keras network's input\_shape,1.0
fxwetjf,hpxhog,"Note: I am less than 1 year old in TF, but I am in to software development from 2005, below are my comments and questions

* If the train dataset is large, tensor\_from\_slices may have less performance when compared with dataset with cache. I believe you can add map function which returns your xh and xy 

[https://www.tensorflow.org/tutorials/load\_data/images](https://www.tensorflow.org/tutorials/load_data/images)

* I was experimenting autoencoder decoder model for one of our image based model and end up doing a GAN based model because, the gan based model gave us better results than a simple auto encoder 
* Some of the auto encoder based models also use fusion technique where, decoder will take input form encoder and classifier model, this also improves the prediction performance, if GAN is something which is not in to your consideration. 
* if you are planning to use the model for production its better to save the model as saved model(.pb) than keras model (.h5), you can use saved model with tf serving easily, saved models have many other benefits than this 

Questions:

* Why you have all the models saved in separately?
* Many examples i have seen earlier goes to (2 x 2) , but your model ends at (32, 32) did you tried going to 16,16 or 8,8?",2.0
fxwlh2u,hpxhog,"Thank you for your well made feedbacks.

*I did not know tensor_from_slices has poor performance compared to other methods that you mentioned in the link. I'll try them

*GAN is my next step after i have done playing with autoencoders.

*i was not aware of .pb version either. I did not even know .h5 is a keras thing. I will read.

*I saved them separately because i wanted to play with them individuallly. See what encoder returns, give some custom noise to decoder to manuplate output ect.

*In my earlier attemps i tried narrower bottlenecs like 8x8 but result was not  that good. I tought may be I shoud not compress data that much and switch it to 32x32.


I get some useful insights by your comment",2.0
fxuqiqd,hpxhog,I'm also in the same boat.  It would be good to have someone certified or well experienced in Tensorflow share their knowledge and expertise.,1.0
fxu8ix9,hpubez,oh god! i hope you get that fixed . i was planning on taking exam next month :\,5.0
fxue1r7,hpubez,I hope so too. Good luck!,2.0
fxuoypu,hpubez,[deleted],3.0
fxustzz,hpubez,"You’d know the content really well if you had taken the 4 Coursera courses, they teach you everything you need.",6.0
fxv5emx,hpubez,"Hi, which 4 courses are you referring to? The tensorflow in practice specialization?",3.0
fxv6tm1,hpubez,Yes,1.0
g8kp39v,hpubez,"did you need GPU to finish the exam? I can't get TF2.0.0 (the exam's version) to use my GPU (compute capability = 5) no matter what...not locally nor using Google Colab! (if I set TF in Colab to be 2.0.0 I can't get GPU)...any suggestions, please?",1.0
fxqtc2r,hp9vhl,"Tensorfow.contrib doesn’t exist in version 2+

You can use version 1.15 or see if the module you are trying to import is located in tensorflow.addons",2.0
fxocr69,hp9vhl,"As far as I know, contrib is a TF 2.x thing",1.0
fxpewdw,hp9vhl,"No. Think it's the opposite actually, and ops probably using one of the newer versions of tf",1.0
fxrmigs,hp9vhl,"Try searching the symbol on tensorflow.org since it may have moved into the core library or another package, like [tensorflow-addons](https://www.tensorflow.org/addons).",1.0
fxp4z6s,hp7bzp,"""trainable\_weights"" is an attribute of the tf.keras.Model class. You should be able to access this through `your_model_name.trainable_weights`

Try that and let us know how it works!",1.0
fxn1mdt,hp6hdh,Finally 😁,5.0
fxn2jdg,hp6hdh,Hopefully this makes the process a lot easier.,2.0
fxpy50r,hp6hdh,finally!! been waiting to get hands-on this.,2.0
fxn2loe,hp6hdh,Thanks for the link,1.0
fxor6t3,hp6hdh,Boy am I glad to hear this.  Needed to serve in TF2 - it was a PITA having to train in a completely different ecosystem than building the serving environment.,1.0
fxl97hm,hp07rk,"When I've loaded a tflite model I've  had to use an interpreter. Similar to this. https://stackoverflow.com/questions/50443411/how-to-load-a-tflite-model-in-script

You can only do inference with tflite model and are unable to train the model.",2.0
fxm0t01,houth0,"For tensorflow you can specify which version you want use within your code, i.e. downgrade 2.0 to 1.0. Also consider using docker to containerize what you are building. Virtual environments are good for when you are writing your neural net but they are really heavy in computing power. Docker containers are fairly easy to use plus if you have the docker container you can run that container on any computer as the requirements are built into the container.",2.0
fxkkx0s,houth0,"The compatibility list you found is valid for other installation methods, not just for build from source. So if, e.g., you were installing *tensorflow\_gpu-2.0.0* you would need cuDNN 7.4 and CUDA 10",1.0
fxkw5oh,houth0,Good luck,1.0
fxl1g3f,houth0,Thanks,1.0
fxi2lt2,hois7k,[deleted],2.0
fxjfnom,hois7k,"So I looked up reinforcement learning in Tensorflow and it does look like what I am trying to accomplish. It even looks like there's a whole Tensorflow Module and associated tutorial to do this!  ( [https://www.tensorflow.org/agents/tutorials/0\_intro\_rl](https://www.tensorflow.org/agents/tutorials/0_intro_rl) ) I am going to do the tutorial and try to apply it to my game. (Thank you! Haha like I said I'm pretty new - just picking up TensorFlow for fun) 

From your comment and a first glance of the tutorial, I think I have the gist of the components - The game is my environment; the game board is my observation; the models are my agents etc.",2.0
fxi3g96,hois7k,"If I follow correctly, you trained on an already trained dataset, so it follows that you win 100%, because there’s data leaking into your second model, so you’d have to retrain on unseen new data, also look into a validation dataset as an intermediate step, then you’d have multiple models which you can combine or pit against each other.",1.0
fxjd6l9,hois7k,"I think I understand. Because I appended the new training data onto the old training data the second model easily beat the first model because it saw everything the first model saw and did, but didn't really improve vs random because it was looking at the same random data.

To generate unseen data I could take the initial set of Random moves vs Random moves and split it into two and use it to train the first two generations? Then for future models, I could use combinations of model vs model or model vs random to generate the training data?",1.0
fxjs0ir,hois7k,"Yes, basically you need more data, splitting your existing dataset further might not get you there, so I’d go back to your original step and create another dataset.",1.0
fxiaxd3,hois7k,"Are you doing train, cross validate and finally test ? The last piece involves unseen data",1.0
fxfnec9,ho5bdk,"Check the weights as they change every iteration, they are likely not changing. I'd look for a nan somewhere, maybe cause by one of your activation functions.",2.0
fxg6h2t,ho5bdk,"Thanks for replying! 

Are you saying that even if the training reaches a converging point, the weights may not be changing at every iteration? 

Can you also please tell me more about the way I can view the change in weights?",1.0
fxg731p,ho5bdk,"You can just do a simple print out of the weights after doing 1 iteration, 10 iterations, and then 100 iterations, etc.

Also, have you looked at the training loss? How is it changing after every iteration, that can be easily done with changing the verbosity parameter.

Ps, to clarify when I said there is a nan somewhere I didn't mean a weight value that is a nan but that the output after one of the activation functions is a nan.",1.0
fxg7wh8,ho5bdk,"Okay, I will give it a try, and see if the weights are changing! 

Yes, the training loss is always monitored and plotted together with the validation loss. Both curves show decrease with increasing epochs. And the training stops with a callback ""EarlyStopping set to patience = 10.",1.0
fxg89lu,ho5bdk,"Do you mind sharing the plot of the loss, please?",2.0
fxgmc4o,ho5bdk,"Please check the uploaded plots in the question above. Somehow, I can't upload it here.",1.0
fxgy9cw,ho5bdk,"I initialized a model and got weights (initial).

After 50 epochs, i took again the weights (changed) and plotted them. 

Is it possible that weights are barely changing while the bias are changing significantly?",1.0
fxh3gra,ho5bdk,"&gt; Is it possible that weights are barely changing while the bias are changing significantly?

This makes sense if the model is just predicting the mean. I think this is a long shot but this is my recommendations:
Do any combination of those:


1. Change activation functions to something else, maybe ELU.

1. Add more layers to your model.

1. Increase the size of the layers.

1. Decrease the value of the dropout regularization.",2.0
fxhn25g,ho5bdk,Thank you! I will definitely try the options above!,1.0
fxg7pmy,ho5bdk,"Yes that usually happens when your model reaches a ""baseline"" ie. a mean or median. Can you share your train/validation history plot? Honestly it could be any number of things... did you scale your data? what's your learn rate? etc. etc.",2.0
fxgm4r6,ho5bdk,The optimizer is Adam with lr=0.0001.,1.0
fxgmbnu,ho5bdk,"Please check the uploaded plots in the question above. Somehow, I can't upload it here.",1.0
fxgodof,ho5bdk,"Hmm it does look like your model is learning something based on the plots... I would double check that separate inputs are indeed producing the same exact output.

A model predicting the mean basically means it has no predictive ability/something is actually wrong with your experiment. That's a bit different than the model maybe not getting the type of performance you want which can be due to any number of reasons. Might be worth to compute a baseline loss for your train and validation sets to see if your model is beating that.",1.0
fxgpcca,ho5bdk,"All the variations in the testing data basically producing the same y\_hat, which is very close to the mean values of my testing set.",1.0
fxgu2om,ho5bdk,"Could be that it is just a hard problem to model and need more data and bigger models. Could also be that the LR is too small, wrong loss function, etc. any number of things, it's really hard to tell without knowing all of the details. I'd try playing around with your model and training params.",1.0
fxgvhxt,ho5bdk,Thank you. I will play around and see where it will take me to.,1.0
fxf3ef8,ho1pt9,bro i can't understand your question 😂,1.0
fxfdmmg,ho1pt9,"Ah shoot! Sorry....No actually I want the code/materials so that I can extract the patches from a volume based dataset(say CT), whose size maybe in the format(F,R,C,W) for training process/or before feeding it to the any model architecture say UNet, ResNet etc. I want it this task to be done in Tensorflow. I hope now it clarifies.",1.0
fxf5kak,hnzyp2,I tried ur code on Tensorflow v2.0 and its working fine buddy,2.0
fxf5mjw,hnzyp2,"I'm using TF2 as well, weird...",1.0
fxf5u83,hnzyp2,Let me try running it again on ma local machine and check it,2.0
fxfrm4w,hnzyp2,Where are you getting the error? It's good to include the full error in a gist or similar code notebook website.,1.0
fxfrtyn,hnzyp2,"model.fit(train_dataset, epochs=20)",1.0
fxfs27l,hnsz2c,In short: Nothing prevents you from using a 10-dimensional input. It might be preferential to use multiple input-layers though if your inputs are different types.,1.0
fxfuqwr,hnsz2c,"Okay thanks, how do I train it and teach it that the whole CSV outputs 10 probabilities? My inputs aren't going to be the same length every time, but the same data format and rows will be present in every one.",1.0
fxg21fl,hnsz2c,"You don't feed the cvs, you train with a tf-dataset or a custom learning function.
I know that this isn't much help in itself, but you can't just plug a cvs with different variables into a model.",1.0
fxgf9tu,hnsz2c,"I don't want to discourage you, but it sounds like you might need a better understanding of what exactly you're wanting your model to learn and how you want it to learn before you are able to create a successful model. As far as I'm aware, all ANN solutions rely on fixed-size input space to successfully learn, so you'll need to find a way to alter your learning goals to that restriction. 

With very little knowledge of the overall problem and what kinds of solution you're looking for, my recommendation would be to use a LSTM network to learn what real gameplay should look like (predict the next frame from the current frame), then compare that to the actual next frame, and identify the difference level required to flag it as illegal gameplay.",1.0
fxgfxen,hnsz2c,"Even if I calculated the view angle delta from before and after the kill, then compiled a list of the deltas for each kill, not everyone has the same amount of kills. (cheater kill deltas would be way more) Does this mean there’s not a way to do this since it must be fixed input?",1.0
fxggif7,hnsz2c,"You need to narrow your problem down more so you can get something that actually works before trying to build a miracle machine. Focus on what cheating looks like, and get a network to learn that FIRST. Once you are able to do that, then you expand it out to monitoring multiple players at once.",1.0
fxgji8x,hnsz2c,So something like the viewangle 2 ticks before and after the kill? It can be calculated individually and is a set number of data points.,1.0
fy03bha,hnsz2c,"What I’m doing is 8 ticks before the kill, and 4 ticks after. Each kill will be exactly 12 ticks long therefore fitting the same data size requirement.",1.0
fxgi0hg,hnsz2c,"&gt;not everyone has the same amount of kills. 

You should focus on single kills. Don't plug a whole replay into the model, but focus on x amount of ticks before and after kills.",1.0
fxgjert,hnsz2c,"At that point I could just have a set rule and say if the delta is more than X for more than X total kills, they’re cheating. Unless I fed in the viewangle for 2 ticks before and after the kill for each kill? That would be a set number of data points.",1.0
fxgkl1i,hnsz2c,"&gt;At that point I could just have a set rule and say if the delta is more than X for more than X total kills, they’re cheating.

If an erratic change for the viewangle is a strong indicator of cheating, you don't really need tf/ML.

&gt; Unless I fed in the viewangle for 2 ticks before and after the kill for each kill?

Yeah, that is possible, 2 ticks might be a bit short though (CS:GO is running at 60ticks/second, right?)",1.0
fxgkz6g,hnsz2c,"Demos are 32 tick. matchmaking is 64 live though. The issue is view angle isn't enough by itself since sometimes you hit a lucky shot. I was hoping ML would help with that, being able to determine if it's consistently too large a swing.",1.0
fxgllkw,hnsz2c,"At first glance, this seems more or less like a purely statistical problem. ML could help you with that problem, but it may be a bit of an overkill.",1.0
fxd5hdx,hnrf86,"Isn't dropout kind of the same as pruning? Just interested, not trying to state anything.",1.0
fxdd8s2,hnrf86,"Hey, thanks for your comment. I'm also interested in discussing this.

In my head, dropout is randomly omitting units during the training process. 

When I think of pruning, I think of manually deciding how many of the units to prune based on some sort of percentage.

If anyone else has more thoughts, feel free to add here.",2.0
fxf06hq,hnrf86,"Yeah it's probably that. Never did pruning, just know it from random forest classifiers, but I guess when pruning the model is actively being decreased in size, while dropout only ""inactivates"" some neurons while still using them. So maybe that's a performance increase and a more targeted/rational approach instead of just randomly inactivating
*edit: to make it clear, I have no idea",1.0
fxcmrp4,hnosz1,"Keep in mind I am no youtuber and this may not be the best video in terms of sound or quality.

I’ll be happy to hear your feedback on the video, was it understandable? What didn’t you understand? Did it teach you the concepts from scratch or did you know them a bit beforehand? Do you think there are things I should’ve covered but didn’t?

Thank you!",3.0
fxcnbqm,hnjia7,I am not a pro but shouldn't you use fit_generator instead of fit,1.0
fxcnm6y,hnjia7,"Sorry I ended up fixing the error, should have deleted this after.

But no, that gave the same error. It came down the the bytes of color I was using, I had it at 1 and needed 3 apparently.",1.0
fxbo466,hnibbk,"Tried it, got an error trying to upload a file:

Application error

An error occurred in the application and your page could not be served. If you are the application owner, check your logs for details. You can do this from the Heroku CLI with the command
heroku logs --tail",2.0
fxbp2ac,hnibbk,Will check the logs. Thanks for the notification without hate my friend. I will see where the error happened.,3.0
fxbpj2i,hnibbk,"Figured it was good to let you know.  If there are any restrictions, I'm on mobile, android 10, Samsung galaxy s10.",2.0
fxbns2n,hnibbk,Pretty weird people downvote a fighting racism library.  People are weird.,2.0
fxbs0kl,hnibbk,"Its political, for good or bad.

Anything political,will get downvotes from one side, the other, or both.",2.0
fxboutx,hnibbk,"Yes, and not commenting why... Can't understand that...",1.0
fxblgjb,hnibbk,"There was a lecture on this problem last fosdem, curious to look at this, nice job!",0.0
fxbm0bf,hnibbk,Any links or material? We’re creating a totally new methodology and technology so I need as much info as possible,2.0
fxbnl0t,hnibbk,"I'm on my phone atm, but I can send you the name of the guy who did the lecture!",1.0
fxbora1,hnibbk,"https://fosdem.org/2020/schedule/event/ai_in_peoples_hands/

Mostly on the ""fairness"" aspect, but that was the main subject anyway !

I can't say I remember much of it, so I can't promise yiu it's 100% relevant...",1.0
fxbgsw1,hni34w,Uses Tensorflow Javascript on the browser with HandPose. Feedback appreciated.,1.0
fxazbmn,hne5wh,"You know something after all, Jon Snow",2.0
fx7ua87,hmwf7d,Sounds good to me! 👍🏻 I'm probably new to Tf  and all this stuff. I would like to read your guide.,2.0
fx8sgae,hmwf7d,"It’s actually a YouTube video, there are some guides out there but currently no YouTube tutorials.",1.0
fx8u54o,hmwf7d,Even better! Send me the link if it's finished.,2.0
fxcoh3u,hmwf7d,"Nice, I'll watch it tomorrow! But so far I can say I'm probably new to TF2.0. Right now I'm working on my Master-thesis, where I try to do  image segmentation on some wsi. (whole slide images)
I guess this tutorial is to come in handy for my project. 
Thank you for your effort! 😊",2.0
fxed9ug,hmwf7d,No problem! Please do leave some feedback after you’ve watched the video!,1.0
fxeswj3,hmwf7d,Saw your video and it's pretty good. 😊 It covers all you need as a beginner.,2.0
fxewbw8,hmwf7d,"I’m happy to hear! I am considering making more videos so I would be really happy if you could answer some of those:

Was it understandable?

What didn’t you understand?

Did it teach you the concepts from scratch or did you know them a bit beforehand?

Do you think there are things I should’ve covered but didn’t?

Don’t be afraid to say the truth, I need criticism to learn how to make better videos!",1.0
fxn2ncb,hmwf7d,"Actually it's fine at all! I already know the concepts but I'm completely new to Tf.
So im happy to finde stuff like your little tutorial! I would like to learn more about deep learning and working with image data, especially instance segmentation.
In conclusion your tutorial is pretty good. Thank you for your good work! 😊",2.0
fx95itc,hmwf7d,No problem!,1.0
fxcmiwz,hmwf7d,"Hey, just uploaded the video! You can watch it [here](https://youtu.be/fou31n3Win0).

Keep in mind I am no youtuber and this may not be the best video in terms of sound or quality.

I’ll be happy to hear your feedback on the video, was it understandable? What didn’t you understand? Did it teach you the concepts from scratch or did you know them a bit beforehand? Do you think there are things I should’ve covered but didn’t?

Thank you!",1.0
fx8z1wu,hmwf7d,"seems like there are some: https://www.tensorflow.org/guide/data
https://www.tensorflow.org/guide/data_performance
https://www.tensorflow.org/guide/data_performance_analysis
also:  http://cs230.stanford.edu/blog/datapipeline/",-1.0
fx8z36m,hmwf7d,YouTube tutorials,2.0
fxamoih,hmui4t,"Congratulations, this certification allowed me to get noticed by Google, so don't listen to people saying it's worthless!",8.0
fxd3i1f,hmui4t,"Thank you. That's good to hear :) 

 Your post from about a month ago definitely helped me a lot in my preparation process.",2.0
fxs5k8m,hmui4t,Dang!!! Congrats!!! Would you mind elaborating more on 'get noticed by Google' since Google is a lot of us aiming for 😂 thanks a lot!!!,2.0
fxtbmzt,hmui4t,I applied there and am in the hiring process (round 2 next week). The recruiter from Google mentioned the certification. Not saying I will get the job though as there must be a lot of competition but it's the first time I get interviews with FAANG so that's great (but so stressful!),2.0
fxuc02q,hmui4t,That's awesome!!! Competition is real but you made it through the first round and keep it up!!! Let us know if you got an offer!!! I'm rooting for ya!,2.0
fxwi29z,hmui4t,Thanks! Will do!,1.0
g0veyud,hmui4t,I got the job :-),5.0
g75e9qt,hmui4t,Did you have any professional experience before getting the certificate?,1.0
fx9bgn3,hmui4t,where did you learn everything that the exam contained? would love an official TF course,6.0
fxambp4,hmui4t,The 16-week coursera specialization is more or less the official source. The instructor (Laurence Moroney) is the same guy who made the TensorFlow Developer exam.,6.0
fy1f3gw,hmui4t,"That would be me! Thanks so much for the kudos, and congrats on passing the exam!",5.0
fyk727r,hmui4t,"&gt;5 days old   
&gt;  
&gt;One comment 

hmm",1.0
fyrhvkt,hmui4t,"Well if it's my first comment, it's not a bad one, right? :)",3.0
fyr1ofs,hmui4t,"Thanks a lot for doing this. It was a really great experience and even though I already work with TF, it was just the kind of impulse I needed to study a little bit further. I'm now the first in my company and the first in my country (Netherlands) to have the certification. It definitely helps me stand out in the crowd and show what kind of work I do.",1.0
fyrhxhf,hmui4t,"That's great. I'd love to know, over time, what impact it has on your career, if any :)",3.0
g0bzme9,hmui4t,Nice!,1.0
fx7j8k1,hmui4t,Apart from Tensorflow in Practice Specialization what resources you will recommend. I will give this exam next month.,7.0
fx8n0ui,hmui4t,"Hands-On Machine Learning with Scikit-Learn, Keras, and TensorFlow: Concepts, Tools, and Techniques to Build Intelligent Systems - it's a book, but pretty solid. 

Apart from that it's just practicing with different concepts from the handbook and the official documentation.",12.0
fxagij3,hmui4t,Thank you so much mate. I have that Deep Learning with Python book by François Chollete. I will surely refer that Hands-On Machine Learning too.,5.0
fx7t9ez,hmui4t,Did you use tf 2.0 or 1.0,3.0
fx8mdnr,hmui4t,The exam is in TF 2.0.,9.0
fxs6syt,hmui4t,"Congrats!! I've spent my last 3 weeks finished the course on Coursera and I'm about to take the exam next week!

I have one question and hoping that you could help :) I read your Medium post and it was AWESOME!!! In your blog, you mentioned that you once switched to Jupyter notebook due to a minor CUDA issue. I don't have a GPU, and my backup plan is to run the model on Colab,  download the model, and upload the h5 file to Pycharm. Do you have any suggestions about doing this? Or did you do the same with your Jupyter notebook?

Much appreciated in advance!!!",2.0
fx7qm8y,hmui4t,"yes but what have you gained from being certified?

testing experience is very low for me on a scale for things to consider.",2.0
fx8n6ov,hmui4t,"It's easier to motivate myself if I'm working towards something.

Honestly I doubt I'd get a raise over this at my current job, but it helps to signal what your skills are.",9.0
fx9af8v,hmui4t,Awesome,1.0
fxau3eq,hmui4t,"Did you get any low-level/advanced Tensorflow experience/knowledge?

Or is it just another keras pipeline?",1.0
fxd48zd,hmui4t,"I can't say that much about the exam itself (rules and such forbid it) but the coursera specialization covers keras-tensorflow pretty broadly. It's a lot of tf.keras.layers, but also custom callbacks, learning rate scheduling, lambda layers with some tf datasets thrown in.

I wouldn't ""look down"" on any of that. Since 2.0 it's part of TF, simple as.",2.0
fxdb17y,hmui4t,"It's not looking down on it, but it's a bit frustrating since it's really difficult to find sources for learning about the lower level stuff.",1.0
g1dkba7,hmui4t,How long did it take for them to put you on the certified directory ?,1.0
g1fk0ez,hmui4t,About a week and a half,1.0
fx72tvr,hmpic7,"Can you try to create another model and check the GPU memory usage? I think that value only indicates how much memory a process claims, and TF always claims as much as possible.",3.0
fx72x05,hmpic7,"Yeah even with Mobilenet it used the same amount of memory. Had to limit the memory from the guide. 

https://www.tensorflow.org/guide/gpu#limiting_gpu_memory_growth",1.0
fx74k0w,hmnfn4,Okay :),1.0
fx9okee,hmnfn4,"I have fixed those issues. by mistakenly I gave the name as 'tensorFlow-serving.lis' I missed ""l"" in the list word it should be 'tensorflow-serving.list'. so I removed that file and reinstalled then it's working fine.",1.0
fx230fk,hlx7z3,You could try tensorflow-lite. Its a version specifically optimized for single board computers.,6.0
fx283a3,hlx7z3,Awesome! Thanks.,2.0
fx2rj2q,hlx7z3,"You could use an edge TPU to get more fps. As the TPU usually runs on USB3, a Pi 4 would be better but the Pi 3 does work too. https://coral.ai/products/accelerator",2.0
fx3naet,hlx7z3,Thank you!,1.0
fx1x8wv,hlx7z3,could be,1.0
fx205gy,hlx7z3,"I'm wondering how choppy that would be. Probably be like, 5 FPS lol.",0.0
fx20brd,hlx7z3,it all depends on the accuracy and speed necessary. could you describe the use case?,1.0
fx286fd,hlx7z3,identification of faces only,1.0
fx29wtc,hlx7z3,how quickly would it need to identify faces is the question,1.0
fx37imf,hlx7z3,Why lol? For most use cases of face recognition 5 FPS is a reasonable setting to use even if you have computing power to do much more; and even 2 FPS can be completely sufficient for many practical applications.,1.0
fx2einy,hlx7z3,I did run on PI 2 .  It does get hot pretty quick and shuts down. I ran the unquantized model though.,1.0
fx2uw1k,hlx7z3,"Jou can also run it on pi's GPU in headless chrome, with tensorflow.js and WebGL.

I have not tried to measure performance for that mode yet, buy it works.",1.0
fx1at0o,hludju,"Hi in all honesty I don’t have experience with wsi or segmentation but what I can do is suggest TensorFlow dataset API, it can handle any types of data and you can do all sorts of pipelines with it and you don’t have to load all data into memory, you only load data when you need it.

You can check it out [here](https://www.tensorflow.org/api_docs/python/tf/data/Dataset), hope it helps.",1.0
fx1bwet,hludju,"Thanks for your reply, I will check it out! :) Memory isn't the problem. The wsi's have around 20000x20000 Pixel, to much for any model... The main challenge is you can't scale them down, to let's say 128x128 pixel. You would loose to much details of the picture, since the image provides a deep zoom level(20-40x). So you have to cut them into patches. 
But then again, I don't know how to annotat them or create the masks for training...",1.0
fx1fi65,hludju,"If I understood correctly, maybe [this](https://stackoverflow.com/questions/55665774/large-image-slicing-for-tensorflow-pipeline) answer on how to use the dataset API might help, he seems to have a similar problem, if not then I hope someone else could provide a better answer.

I would also suggest posting a question on stackoverflow and CrossValidated, the folks there could probably help out :)",1.0
fx092bf,hllley,What tutorial are you using? Perhaps try an up-to-date [image classification tutorial](https://www.tensorflow.org/tutorials/images/classification).,1.0
fwz7f7h,hlht5k,"Tensors need to have the same dimension on each rank. Typically, varying length data is padded for models that need to accept varying length inputs. Producing varying length outputs is more difficult and usually done using sequence-to-sequence models such as encoder/decoder.

I'm not sure what kind of ML you are trying to do here, it seems to me like you're only trying to flatten a 2D list, for which there already exist functions such as the NumPy ndrarray flatten function.

Edit: I now understand the last list in each list is the ground truth, and all lists for each example have the same dimension. This makes it a bit easier. I'd first split the dataset up since you cannot feed everything at once as you have it right now, such that you have a list of lists of lists as input and a list of lists as the output. In order to keep dimensionality consistent, I'd pad each list to a certain length. Finally, since you have one output per each input, you can simply use an RNN and have it make one prediction per time step, which you softmax between 0 and 1.

The final difficulty you have is 2 inputs for each item. I'd personally concatenate the two, such that

    [[1,2,3,4,5,6,7,8,9,10],[2,2,2,2,2,2,2,2,2,2],[0,1,0,1,0,1,0,1,0,1]]
    becomes
    [[1,2],[2,2],[3,2],[4,2],[5,2],[6,2],[7,2],[8,2],[9,2],[10,2]]
    as input and
    [[0,1,0,1,0,1,0,1,0,1]]
    as output",2.0
fwz7qgg,hlht5k,"I’m not trying to flatten, but the sample data I tried to come up with may seem that way. I’m trying to figure out how to take sensor data over a period of time, and create another reading over the entire period. So for example if I have a temperature sensor over time, I could use that same data to predict an individual’s proximity to the sensor. I wouldn’t want to classify the entire time series as one thing, but would want my model to spit out its predictions over the entire period of time (ie: at second 0, someone was there, so the value is true, at second 1, they left, so the value is false)

That would then spit out output that would look like (1,0,... etc)",1.0
fwz8ejo,hlht5k,"Perfect, thank you. RNN looks exactly like what I want, just couldn’t figure out the search term to get there. Appreciate the help!",1.0
fwz9rx9,hlht5k,"glad to help, thanks for the gold!

P.S.

what you need to do, as per, for example, LSTM ([https://www.tensorflow.org/api\_docs/python/tf/keras/layers/LSTM](https://www.tensorflow.org/api_docs/python/tf/keras/layers/LSTM)), is to \`return\_sequences=True\`. That way, instead of getting the output for the last time step, you get one output per each time step which you can pass through a dense layer (it gets applied to each time step individually) and you can get your list of softmax.",2.0
fwwdt7w,hl28da,"Keras is TensorFlow now. It's a part of the library, so learning Keras is learning TensorFlow. For most general tasks, the Keras API will be sufficient.

As far as learning lower-level TensorFlow, this is generally unnecessary unless you're doing something custom (i.e., novel loss functions, optimizations, etc.), which you'll usually just want to figure out as you go. It'll likely be a waste of your time to try to learn the entire library, in and out, since you'll likely not need to use most of it (and, like I said, when you do, you can just figure it out as you go).",18.0
fwwdo6q,hl28da,"Both, Keras is TensorFlow now. Wanna know how it’s like in the professional world? Take the TensorFlow certification exam.

Wanna know more about the lower level of TensorFlow? Learn how to use “functional keras”.",8.0
fwwh3sl,hl28da,"You are asking wether you should learn the full tensorflow or just the Keras part. 
I would argue from a use case perspective - if you can solve your problems.with Keras - you need not to bother with the rest to TF",3.0
fwx6bb9,hl28da,"Learning the Keras Layer API for TensorFlow2 first, makes understanding your NNs easier (nice summary function etc.) and you can take time to learn how to access TensorBoard and evaluate if your NN is overfitting or underfitting, and how to address this with dropout layers or other approaches.   
Then as you have gotten comfortable with TensorFlow2, and you need a more unusual NN model, then start learning the Keras Functional API for specifying TF2 NNs.",3.0
fwurh6f,hkt2i6,Both work the same as far as rpi is concerned. The difference is more about the len. Also the ir output makes thing look more black and white.,1.0
fwurm6i,hkt2i6,"Okay, so the bottom one is compatible with Tensor. Excellent.",1.0
fwtergo,hkk3d4,"So, you have to decide where you want to do the video processing and ML.  You're suggesting that you're using Tensorflow JS, so I'm guessing you're wanting to do it either of the clients (e.g., the user's browser or the admin's browser versus in a server), but that decision is important to deciding what information is being transmitted via websockets.

If it's on the user's machine, then TFJS will be examining the webcam data directly and sending it's processed results to the admin.  If it's on the admin's machine, then you will essentially need to transmit the raw webcam data (or some compressed form of it) and then do the processing there.

I think doing the processing on the user's machine makes the most sense from an efficiency perspective, since you're model can analyze results in real-time without network latency.  You can then send updates only when needed (or as frequently as needed/possible) with a huge reduction in data size.  Of course, this might not be possible or feasible depending on your project's requirements (i.e., if the user isn't expected to use your app or something).

The approach would be a whole question in itself (i.e., how to best transmit webcam data?) that should be asked to a more relevant community like r/webdev.  And, of course, all of this neglects a server in the middle, which will likely be necessary and might be the best place to handle processing, making Tensorflow JS unsuitable (I'm figuring that's not what you want to go with).",2.0
fwt0b0r,hkgn51,"AFAIK openAI  used convolutional network for their atari project. For this similar thing. They used miltiple consequtive frames to give a network a sense of time flow. without the use of RNNs.

Just as you would stack 3 dimensions of colour to represent one picture with shape: [height, width, 3]. 
You  just add another dimension and do convolution over this stack of images.
input shape :[height, width, 3, 2] for 2 frames.

I have a feeling of giving a shit explaination so please ask further questions if i were unclear or correct me if i misunderstood you.",3.0
fwtpnzj,hkgn51,"&gt;without the use of RNNs

seems to be in the direction I'm going!

&gt;input shape :\[height, width, 3, 2\] for 2 frames

Ah, makes sense, sort of like point 1 in my question. It's a relief to know something like this is doable. I think I can visualise the training pipeline now. Just have a normal for loop that gives the index of the frames and feed those frames to the network, while batch size can be anything. Will try and implement, and will also check out this project might find some more clues. Thanks a bunch! :D",2.0
fwvipk7,hkgn51,"Hey, would it be possible for you to post a link to this openAI project / paper, I found an [article](https://openai.com/blog/learning-montezumas-revenge-from-a-single-demonstration/) but not sure if this is it? Thanks!",2.0
fwvwmdy,hkgn51,"cant really find the paper, but this one explains it quite well.
Its a post on [towardsdatascience](https://towardsdatascience.com/atari-reinforcement-learning-in-depth-part-1-ddqn-ceaa762a546f), that has a section that explains why and how to stack images for time  awareness.
Hope that helps!",1.0
fwsyfq4,hkgn51,"Why not run the the feature extractor over each frame ones, extract feature 1, feature 2, and then pool, concat or something with those later to find some information.

We do this for our tooling.

This also uses less compute, as a CNN sees a single frame once. You see a frame twice. Is there something special about pairing you are doing that requires this? Does the output feature of a standalone frame not contain what you need?",2.0
fwt0f1z,hkgn51,"It might ve that they feed to frames from a video, to give the network ability to interpret sequence of events?",3.0
fwtaw41,hkgn51,"thats fair - I am assuming (potentially incorrectly) that a pair of single frame features roughly 'equals' a feature derived from two frames. 

However its clear to me if they are training a new feature extraction body it may learn things from the pair that aren't obvious in sequence of a standard image extractor network.

However you could maybe train a network to take in pairs of features and learn from that? 

So many ways to skin a cat.",2.0
fwtonop,hkgn51,So my idea is that the network should learn the flow between the frames. So looking at them individually wouldn't work. I'm not sure how taking features from individual frames and concatenating would be easier.. I would have to take concatenated features from pairs so again the confusion is same as before. Do I define a vector of tf.zeros of the shape of the desired final vector (as shown in diagram) and keep filling up everytime I get one concatenated feature from a pair of frames..or may be the other ideas. The problem is mainly with how to train the whole thing and keep saving the output vectors into one big vector. I hope I'm making some sense and thanks for helping!,2.0
fwsngbs,hkfb5w,"I think you need to access the data in order for it to execute, I.E. iterate over it

	for data in dataset:
	   	 ...",1.0
fwqhxg2,hk4n8x,"I suggest you read this articel =&gt; [Mount Google Drive in Colab](https://www.marktechpost.com/2019/06/07/how-to-connect-google-colab-with-google-drive/)

If you mounted the drive correct, you should be able to load the image from there. Happy coding my friend :)",3.0
g2jr4zc,hk4n8x,"from google.colab import files  
from io import BytesIO  
from PIL import Image  
uploaded = files.upload()  
content = Image.open(BytesIO(uploaded\['content.jpg'\]))  
style = Image.open(BytesIO(uploaded\['style.jpg'\]))

\# view  
import matplotlib.pyplot as plt  
fig, (ax1, ax2) = plt.subplots(1,2,figsize=(20,10))  
\# content and style images side by side  
ax1.imshow(content)  
ax1.set\_title('Content Image')  
ax2.imshow(style)  
ax2.set\_title('Style Image')  
plt.show()",1.0
fwqh3li,hk4n8x,"
I see you've posted a GitHub link to a Jupyter Notebook! GitHub doesn't 
render large Jupyter Notebooks, so just in case, here is an 
[nbviewer](https://nbviewer.jupyter.org/) link to the notebook:

https://nbviewer.jupyter.org/url/github.com/tensorflow/docs/blob/master/site/en/tutorials/generative/style_transfer.ipynb

Want to run the code yourself? Here is a [binder](https://mybinder.org/) 
link to start your own Jupyter server and try it out!

https://mybinder.org/v2/gh/tensorflow/docs/master?filepath=site%2Fen%2Ftutorials%2Fgenerative%2Fstyle_transfer.ipynb



------

^(I am a bot.) 
[^(Feedback)](https://www.reddit.com/message/compose/?to=jd_paton) ^(|) 
[^(GitHub)](https://github.com/JohnPaton/nbviewerbot) ^(|) 
[^(Author)](https://johnpaton.net/)",0.0
fws7n4w,hk34bg,I have ran into the same issue. I have not found anything to make the process less complicated.,1.0
fwojkkb,hjuhyc,"My current attempt is:

    def map_sequence():
        for sequence in input_sequences:
            yield sequence[:-1], keras.utils.to_categorical(sequence[-1], total_words)
    
    dataset = tf.data.Dataset.from_generator(map_sequence,
                                            (tf.int32, tf.int32),
                                            (tf.TensorShape(title_length-1), tf.TensorShape(total_words)))

But when I try to train this model:

    inputs = keras.layers.Input(shape=(title_length-1, ))
    
    x = keras.layers.Embedding(total_words, 32)(inputs)
    x = keras.layers.Bidirectional(keras.layers.LSTM(64, return_sequences=True))(x)
    x = keras.layers.Bidirectional(keras.layers.LSTM(64))(x)
    predictions = keras.layers.Dense(total_words, activation='softmax')(x)
    
    model = keras.Model(inputs=inputs, outputs=predictions)
    model.compile('Adam', 'categorical_crossentropy', metrics=['acc'])

I am getting this error: `ValueError: Shapes (32954, 1) and (65, 32954) are incompatible`",1.0
fwop6qd,hjuhyc,"&gt;map\_sequence

 Can you check the shapes of batches yielded using next. May be that will be give more information.

    it = iter(dataset)

print(next(it).numpy())",1.0
fwoqytr,hjuhyc,"`next(it)` returns a tuple so it doesn't have a shape property.

&amp;#x200B;

But if I run this code

    it = iter(dataset)
    a, b = next(it)
    
    print(a.numpy().shape, b.numpy().shape)

I am getting this output:   `(65,) (32954,)`",1.0
fwot9n1,hjuhyc,"Something is definitely wrong. Assuming you are doing supervised learning. It should be yielding (Samples, Label\_of\_Samples) and both shapes should be the same.",1.0
fwotduc,hjuhyc,What is the shape of the input sequences that you have shown in the figure?,1.0
fwotlj0,hjuhyc,"The shape of `input_sequences` is  `(569530, 66)`",1.0
fwotsse,hjuhyc,"Well you can see in my `map_sequence` function that I yield two variables

1. The X - Which is all values in that sequence except last one.
2. The Y - Which is the last value in the sequence converted to categorical using keras API.

what am I doing wrong with this?",1.0
fwow67i,hjuhyc,This seems to be yielding one sample at a time. Your data seems to have 65 features and  32954 labels.  So your model inputs should be set to 65  and predictions  should be set to 32954  in outputs=predictions .,1.0
fwowt0v,hjuhyc,"It was my mistake, I should have batched it, I got my answer [here](https://stackoverflow.com/questions/62694470/how-to-use-the-tensorflow-dataset-api-with-unknown-shapes-properly/62696738#62696738)",1.0
fwmh5an,hjcta2,What's the alternative?,4.0
fwnjtnw,hjcta2,I have a 3 state classification problem on my upcoming task list...,1.0
fwoj0zh,hj8y4z,You can use Keras Sequences to load your data and apply  **‘to\_categorical’**  the conversion when you are yielding the batch. If you want to pre-convert your labels then maybe use pandas or sets to get unique values and create a label mapping.,1.0
fwol2f3,hj8y4z,I tried it and encountered a different problem [here](https://www.reddit.com/r/tensorflow/comments/hjuhyc/how_to_use_the_tensorflow_dataset_api/?utm_source=share&amp;utm_medium=ios_app&amp;utm_name=iossmf),1.0
fwie1mu,hitoef,"You are missing something.
Practically whole google's AI infrastructure is based on TF.
maybe search for ""tensorflow serving"" if deployments are bothering you.
Also, no idea on your second question",2.0
fwig3nw,hitoef,"It's not exactly deployment that's my issue. Each client needs to make their resources available for private local computation that can be orchestrated by an external c
Server. I don't think that fits into the standard model server setup, right? Also, I'm sure Google has some way to do it since they look like they're pioneering FL with now playing and gboard; but I didnt understand much from the tutorials they had about how to build a practical federated learning system",1.0
fwinf9z,hitoef,Uff you are asking things that are out of my scope. I hope someone from the group knows more and can help you.,2.0
fwinssm,hitoef,Thanks anyway,1.0
fwgl28a,hihaah,"Nice article! It is worth mentioning that for pytorch there is a nice package called ""ignite"" which lets you handle the training in a much simpler way for beginners, although I still prefer writing the loops manually to have better control over what is going on. In my opinion, for a beginner keras is much simpler than pytorch. On the other hand, pure tf2 without keras is much more difficult than pytorch, but for most of the people (ie non researchers) keras is enough to do what you need to do.
One thing to consider about tf/keras is that you generally require less code to achieve the same thing for simple models and that you don't have to handle where the model is instantiated (gpu vs cpu) which is both a pro and a con. Furthermore tpu integration for keras is extremely simple and since we get free tpus with colab it's something worth mentioning.

In my opinion, if you can stick with already existing models (ie you don't need to define new layers which are extremely complex) tf2/keras is a better choice, if you are in the field of ML learning research on the other hand you will end up loving Pytorch for its flexibility, at the cost of having to think about each aspect of your NN (which for beginners may be a con) and you cannot just plug things together, you need to know what you are doing (which should be a given, but still..)

Edit: in my opinion having something ""not pythonic"" is not necessarily a con, as it forces you to think about what you are doing. Imo things being too pythonic sometimes encourage writing sloppy code and expecting it to work.",4.0
fwjxqth,hihaah,"Thank you for mentioning this, definitely gives me something to think about. Keras could be a better choice if working with already existing models and it is quite simple as well.",1.0
fwlop34,hihaah,"AFAIK Ignite/Lightening is Tensorflow modeling + Keras training loop?

For custom layers/network blocks, the difference between TF2 and PyTorch is minimal nowadays.",1.0
fwir7k7,hihaah,"I found Torch simpler to use, but I use TF(ver 2.2.0) as well",1.0
fwg95o0,hihaah,That was an interesting post,1.0
fwgjlhp,hihaah,Thank you!,1.0
fwe661q,hhyxvg,Neat side application for this might be command and control of malware-infected hosts to limit exposure and pattern-of-life observation.,1.0
fwbigo8,hho8n6,It inherits from [tf.keras.layers.Layer](https://www.tensorflow.org/api_docs/python/tf/keras/layers/Layer) and implements the [build](https://www.tensorflow.org/api_docs/python/tf/keras/layers/Layer#build) method.,1.0
fwbwhz7,hhl4co,"I like this idea, I don't think there's a subreddit just for the tensorflow exam like there is for CompTIA (https://www.reddit.com/r/CompTIA/) or (https://www.reddit.com/r/AWS_Certified_Experts/)",3.0
fwcxme0,hhl4co,"i am currently using this notion notebook to help me cover the exam essentials 

https://www.notion.so/Getting-TensorFlow-Developer-Certified-Curriculum-66e97512073f4ca79a6eea4b644b1a5d

ps: i didn't create this i am just using it , i got it from this youtube video
https://youtu.be/ya5NwvKafDk",1.0
fwrd59z,hhl4co,"hey there, I made that video (and curriculum)!

thanks for sharing :)",3.0
fws315m,hhl4co,well it is very helpful to say the least :D,1.0
fwb18ft,hhl4co,So u basically want all questions and answers so that u can memorise them and attend the exam ?,-8.0
fwb1cbl,hhl4co,"What? No. All questions that has been asked regarding the exam, not the actual question of the exam.. -_-",7.0
fwcxpg9,hhl4co,the exam doesn't have questions you have to create models you can't really cheat that,1.0
fwaix9a,hhhl52,Hi! I'm about to take the certification exam too.,2.0
fwanjhd,hhhl52,Me three. Want to start a band?,2.0
fwao5uv,hhhl52,"Sure, what should we call it?

(Side note: please check [this](https://www.reddit.com/r/tensorflow/comments/hhl4co/suggestion_lets_make_a_mega_thread_about_the/?utm_source=share&amp;utm_medium=ios_app&amp;utm_name=iossmf) suggestion I have made.",1.0
fwarr2b,hhhl52,"It's not a bad idea, but I suppose there are things you're not allowed to tell about the exam after you've taken it. Sooner or later it will have to be taken down because someone starts oversharing. 

Twisted Tensors?",2.0
fwb64zw,hhhl52,I’m in,1.0
fwam0l9,hhhl52,Cool! Wanna chat about it? Send me a PM,1.0
fw9b0c1,hh8gbf,You want your model can predict both images from ImageNet and your new dataset?,1.0
fw9fm4w,hh8gbf,yep,1.0
fw9gt2m,hh8gbf,"Then  you need to train your model in both datasets at once. In your case, the retrain model is a new model which does not have any information about the ImageNet. Try to combine these two datasets and train you model. Hope this help!",1.0
fw8n2ul,hh03g6,"&gt; So, I converted the above class_weights to a dict of dicts.

Why is that dictionary nested?

Are those 5 independent binary classifications?
class_weights is fir a single multi-class classification.

Does your model return multiple tensors or a single 5-element tensor?

Try returning a dictionary of tensors, one for each of the 5 classification problems, then maybe the dict of dicts will work. 

Otherwise... write your own train_step method?",1.0
fwoj8ta,hh03g6,"I'm trying to train on ChexNet data which is multi-label problem. I see many people using class\_weights for the Chexnet Data, since it can be treated as independent binary classification. 

One sample code is here:  [https://github.com/brucechou1983/CheXNet-Keras/blob/b80afc83a3b3550fae3d7acc27b4cfa75272517a/weights.py](https://github.com/brucechou1983/CheXNet-Keras/blob/b80afc83a3b3550fae3d7acc27b4cfa75272517a/weights.py)",1.0
fw55xvt,hgo8r5,"Tensorflow is hard and requires at least a medium level proficiency in programming. Maybe you could try Keras which is a Tensorflow abstraction easier to use. However if you decide to go with Tensorflow, you could look at Tensorflow tutorials in the official page.",3.0
fw566oz,hgo8r5,"&gt;Keras

Thanks! I'll look into Keras",1.0
fw6ix6j,hgo8r5,"Take a look through this tutorial: https://www.tensorflow.org/tutorials/keras/classification
Click the ""Run in Colab"" button to execute and play around.",2.0
fw8s99g,hgo8r5,"In all honesty I find this tutorial to be confusing for newcomers, especially ones without any programming or mathematical background",2.0
fwaby3r,hgo8r5,"Yes, with no programming background I'd probably start with the Coursera course or the [Hands-On Machine Learning book](https://www.amazon.com/gp/product/B07XGF2G87/)",1.0
fw56jbn,hgo8r5,"I think this may not be an easy task: recognizing handwritten digits is pretty simple, taking a picture, identifying the region where there is a number (semnatkc segmentation) and recognizing the number (classification) all of which live on a phone app is not something that everybody with no knowledge of ML and programming could do. As far as I know there are no way to build ML models visually that are that advanced.
If you could give up on the handwritten part and focus only on printed things, maybe the easiest solution for you would be to use qr codes and you could probably get away with much less work. Nonetheless you would need a proficient programmer to make such an app. Good luck with you project!",2.0
fw57nq2,hgo8r5,"I figured out I can use [https://teachablemachine.withgoogle.com/](https://teachablemachine.withgoogle.com/) to build the model using sample image database I have, but how do I use that to build an app is the question.  
Would making a responsive website or a webapp be easier / workable?",1.0
fw6dhi1,hgo8r5,"So, if you feel you can get the ML part working (which, to be frank, is probably going to be more difficult than you're imagining), then all that's left is the app which utilizes it. At that point, you're stepping into web dev and out of anything ML focused.

Basically, once you've trained a model, you'll have a function which takes in some input (i.e., images of handwritten digits, etc.) and returns some output (i.e., the predicted digit). If you give this to a web developer, they'd probably put it in an application which can be called via RESTful API. They'd probably build a front-end to interact with it (i.e., some simple HTML/JS site or React or something). The web dev doesn't need to know anything about the ML model other than what it expects as input (which would be given in the REST request) and what it returns as output (which would be provided in the REST response).

I'm being explicit here to try to show that this is essentially two different problems in two different domains, so you're better off treating it as such, i.e., don't expect r/tensorflow to help with the web dev portion of work. Granted, if you can figure out how to successfully create and train a model in TF, then the web dev portion should be easy.

To give some more pointed advice: the ""easiest"" solution would be to use something like AWS Lambda to serve your model. This is basically as lightweight as a backend can get. Then, you'd create your front-end (e.g., with React) and host it statically via S3. The app would hit the Lambda endpoint to perform inference with the model. This is the core functionality, where you can then add whatever nice features you want with it.

Learning AWS stuff may or may not be the path of least resistance depending on what experience you have. Another approach would be to build a standalone app using something like Flask which can handle both the front-end and the REST API. You can basically build the entire app, including the model, into a nice little package which you can run from anywhere. This can be hosted in AWS or something a little easier to deal with, like Heroku.",2.0
fw9mkqa,hgo8r5,That’s really detailed! Thanks!!!,2.0
fw5whad,hgnx1l," Format your code man, it’s unreadable",2.0
fw6hze2,hgnx1l,"just linked the stack post : ) sorry, it looked good on my phone .",1.0
fw3z5rb,hgau2r,"I came up with an idea to make mood-based music service into a business for a startup weekend years ago. At the time I knew the tech wasn't quite there yet but figured it could be by the time we were ready. Judges were like, ""nope, impossible. ML can't do that"".

And here we are.",1.0
fw44tso,hgau2r,I'm sure every great idea that has ever been made was had by thousands of people but was executed by just one.,4.0
fw4dflf,hgau2r,Brutal response but yeah true,1.0
fw5ldxp,hgau2r,Leibnitz would like a word,1.0
fw4mht0,hgau2r,"It was a fun exercise. I wasn't clear but my comment was about vindication, not missed opportunity. Far as I know there's still no one using the tech for business purposes. Spotify had been working on something but I don't use it so not sure where they're at.",1.0
fw5707w,hgau2r,"There are a few companies using music emotion recognition for their business. To name a few: Musimap, Musio, GrooveCat.",1.0
fw5wkws,hgau2r,"Don’t feel bad, here’s a gold",3.0
fw2t6v5,hfwuyg,"I just use model.load_weights(“weights.h5”)

I think there’s a way to call any Tf1 function in Tf2, you could try looking into that.",2.0
fvxvy8v,hfjhy4,Which OS are you using?,1.0
fvy2lbn,hfjhy4,"Need to know your OS, do you have a GPU? 

I’ll paste my general recommendation below for Linux and Nvidia users:

I would STRONGLY recommend giving Lambda Stack a try. It works best for me when I start from a fresh install of my OS (I use Ubuntu) because it will not play nice with Anaconda.

I have spent weeks battling conflicting package installations, but Lambda Stack will handle all of that for you including: Tensorflow (1), Keras, Pytorch, CUDA, Cudnn, openCV, Caffe/Caffe2 and Pytorch alongside the proper Nvidia driver for your GPU.
Anaconda is great, however Ubuntu users in particular are still very likely to experience problems especially if you aren’t very Linux savvy.

I do not work for Lambda Labs, this is not a shill, but I wish it was (send me free stuff please). Seriously, I highly recommend it.

https://lambdalabs.com/lambda-stack-deep-learning-software

Quick edit: my biggest complaint is the lack of Tensorflow2. Not the end of the world, but something I wish they would hurry up and update.",1.0
fw0nq6q,hfjhy4,Did you install the [Microsoft Visual C++ Redistributable](https://support.microsoft.com/en-us/help/2977003/the-latest-supported-visual-c-downloads) mentioned in the [install guide](https://www.tensorflow.org/install/pip)?,1.0
fw1jl54,hfjhy4,"i finally got something to work. a fresh install py 3.8.3 and one virtual environment. i am able to run some of the quickstart tutorials and some of the notebooks from hands-on machine learning.

thanks",1.0
fvxvxit,hfijfn,This is interesting. Thanks man !!,2.0
fvxtbgz,hfhwwm,"Your code is hard to read, please format it so it would be easier to understand",1.0
fvxvgsa,hfhwwm,"I realised when I tried to initially format it, some of the code got all messed up. I've fixed it all up now and should be readable. Thanks!",1.0
fvx0ndz,hf3bkl,"Once I have data sets that are beyond simple images, I typically write my own generators. You just need to create a generator that outputs two tuples of tensors, one tuple of input tensors &amp; one tuple of output tensors. Here's some skeleton code you can modify for own use: https://towardsdatascience.com/implementing-custom-data-generators-in-keras-de56f013581c

You can even import the ImageDataGenerator augmentation functions and use them in your own code; I've done this in the past, but have recently switched to using either imgaug library or nVidia DALI library depending on my application. If you're working with bounding boxes, keypoints, seg maps, etc, I'd take a good look at imgaug as it transforms image &amp; labels together. Here's a good example of imgaug on a segmentation project: https://imgaug.readthedocs.io/en/latest/source/examples_segmentation_maps.html

You should be able to normalize your input image via preprocessing function, as the dimensions shouldn't be changing.",1.0
fvue6bs,hez91g,"Then why is it producing so many batches of augmented data?

The ImageDataGenerator is a python generator. It does always yield a new picture. Your for-Loop doesnt stop, because the ImageDataGenerator yields unlimited amount of augumented pictures.  

Look at some generator tutorials [here](https://docs.python.org/3/howto/functional.html).

After that you should look into the [ImageDataGenerator](https://www.tensorflow.org/api_docs/python/tf/keras/preprocessing/image/ImageDataGenerator).

Then you should be able to use that kind of Data structure in python.",2.0
fvuebtr,hez91g,"Yeah, I am going to use a manual counter to keep track of the number of batches generated and then break out of it once done.

Thanks!",1.0
fvubsja,hez91g,"I want to help you but your post is unreadable. Make sure your code isn’t broken into lines, it’s really hard to understand it that way",1.0
fvucmun,hez91g,Formatted the code.,1.0
fvtwyxd,heueu8,"great work, thanks",2.0
fvvebqs,heueu8,Can you please share your exam question!!,-1.0
fvsb889,hemhde,Structure of any models is still like black magic... Nobady can say how it will perform until you try it.,5.0
fvscpxt,hemhde,"Got it. but because I'm new I am insecure, would you have used the same model or done something different?",1.0
fvsuusc,hemhde,do it bro just try it then think it over again,1.0
fvt2m50,hemhde,Without getting a feel for the data. It becomes really hard to know how much complexity the model should have. The only way to know for sure is to start at the lowest complexity and keep increasing until the model doesn't overfit/underfit by much.,1.0
fvt57xq,hemhde,Building a model is an iterative process. No one here can tell you how it will perform just by looking at this. Just try it out and see how it performs. All the best the idea seems quite interesting.,1.0
fvs1ym7,helm5m,i guess regression is the kind of model that might fit that problem,3.0
fvs62ou,helm5m,"thank you for your reply, would you mind also check out the model I am planning on using in [here](https://www.reddit.com/r/tensorflow/comments/hemhde/do_you_guys_think_this_model_design_would_suffice/) and tell me if you have any suggestions?",2.0
fvs1oma,helm5m,"I’d start with standard settings but because of the wide, positive range I’d try to predict the log of the number of votes.",2.0
fvs5wch,helm5m,"thank you for your reply, would you mind also check out the model I am planning on using in [here](https://www.reddit.com/r/tensorflow/comments/hemhde/do_you_guys_think_this_model_design_would_suffice/) and tell me if you have any suggestions?",1.0
fvr4q13,hegrx5,"Data augmentation shouldn't have anything to do with tf.GradientTape.  You're basically just creating extra data with your dataset.

[TensorFlow's Data augmentation tutorial](https://www.tensorflow.org/tutorials/images/data_augmentation#augment_a_dataset_and_train_a_model_with_it) is pretty good at walking through this, but you don't need to do anything fancy.",4.0
fvnlkjf,hdv2ek,"On the graph, click the drop-down and select CUDA

It's probably Memory bottlenecked.

Edit: after looking at the memory available, it only has 1GB. It's likely that it can't even fit the model, and therefore is not even using GPU at all.",4.0
fvnmiak,hdv2ek,"The model is small, only 46k params, and the batch size is small. There are telltale logs when the model can't fit on the GPU (I've seen them before).",2.0
fvnn60h,hdv2ek,"True, but Tensor flow will try and keep some of the GPU ram free at all times (to avoid crashing other programs, I believe). If the amount of ram available is less than that amount at the start, I have no idea what it would do.

In task manager: the Graph that says ""3D"" with a drop down, can you change it to CUDA and see if the graph is 0% or 100% etc. 

Low number of params may not matter, it's about the number of layers and the input/output size of those models when doing Back Prop.",1.0
fvpd5ww,hdv2ek,ah yes... the joys of tensorflow!,2.0
fvpihkn,hdv2ek,"Profiler is your friend. Make sure you have cupti and add a Tensorboard callback with profile_batch set to something like “0,100”",2.0
fvq7l79,hdv2ek,"What is definitely strange is that TaskManager doesn't show the full Model name of your GPU, it's like it's not properly recognized, maybe wrong driver?",2.0
fvnjbnn,hdv2ek,"what kind of problem/model are you using? from the look probably you're using your intel onboard gpu, try to put this

physical\_devices = tf.config.experimental.list\_physical\_devices('GPU')  
print(physical\_devices)  
tf.config.experimental.set\_memory\_growth(physical\_devices\[0\], True)

and change the physical\_devices' index to your nvidia gpu..",1.0
fvnkafj,hdv2ek,"This is in the logs:

`Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 507 MB memory) -&gt; physical GPU (device: 0, name: GeForce GPU, pci bus id: 0000:01:00.0, compute capability: 5.0)`

And the list of devices is:

`[PhysicalDevice(name='/physical_device:CPU:0', device_type='CPU'), PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]`

Plus I'm using `tensorflow-gpu` and I get errors when the GPU isn't available",1.0
fvpzta9,hdv2ek,Type `nvidia-smi` into your command line to see your cuda version. If there is no cuda version / the wrong version displayed you need a different driver.,1.0
fvpnqdi,hdv2ek,That’s what she said,0.0
fvonxfi,hdv2ek,"What does ""nvidia-smi"" tell you?",-1.0
fvn0jqs,hdqtyf,"pre written code shouldn't be a problem if you try to understand and play with each line/function yourself. I suggest you watch laurence moroney course on coursera, it has quite deep explanation but still understandable, and great hands-on project that push you to experiment yourself.",2.0
fvmb4uo,hdoeaq,"Link to blog post:

[https://medium.com/applied-data-science/the-google-vs-trick-618c8fd5359f](https://medium.com/applied-data-science/the-google-vs-trick-618c8fd5359f)",1.0
fvkkakt,hddl3r,"Which architecture would you like to use? CNN? Than you could duplicate the metadata into a 4th Channel, if you have RGB Images, und hope that the network could find out the use of the metadata through Convolution",2.0
fvkkhdi,hddl3r,"As I replied before, it’s not really about images I just over complicated it 😅",1.0
fvkkqgc,hddl3r,"I am not an NLP Expert, but I think you could concatenate the word embeddings with your metadata.",2.0
fvkkwgy,hddl3r,So you say I should use the output of an embedding layer and combine it with the meta data (which is post age) and pass it along to another model?,1.0
fvkkz53,hddl3r,I guess you definitely should give it a try,2.0
fvkjsm8,hddl3r,"I would train a CNN on the images, then use its output as a feature for another model downstream (i.e. another model whose input is [cnn_output, ...metadata]).",1.0
fvkkfzk,hddl3r,"Ok well it’s not really about images but about text, i thought it would be simpler but I guess I just over complicated it.

Anyway, I’m building a reddit post to upvotes predictor based on title, desc and post age and I’m just wondering how I would design that model.",1.0
fvkl9f1,hddl3r,"Use an embedding like word2vec for the text features. https://www.tensorflow.org/tutorials/text/word_embeddings is a good starting point to do that.

To actually make useful decisions with your model I don't think post age should be a feature. A redditor would want to find out how many upvotes their post might get in the future, not how many they have now.

Instead, I think you should filter your dataset to only include posts that have been up for x days. This would allow your model to predict how many upvotes a post might get after x days.",2.0
fvmbadd,hddl3r,AFAIK the best approahc to this right now is multi-headed networks/transformators,1.0
fvmbbmb,hddl3r,"I’m kinda new, can u dumb it down for me so I’d understand? 😅",1.0
fvmbu7j,hddl3r,"I can't do it much better than this video:   
[https://www.youtube.com/watch?v=S27pHKBEp30](https://www.youtube.com/watch?v=S27pHKBEp30)",2.0
fvmby47,hddl3r,"But basically there are approaches where you do not just dump all your data into the single input of your net but rather feed different ""heads"" of it with different but nevertheless codependent data. Basically you give your net different input variants. 

hence ""multi headed""

&amp;#x200B;

You could interpret it as different sensory organs(eyes, ears) but that would be a bit too much IMO",1.0
fvmcgw6,hddl3r,Thank you for the explanation! I’ll also take a look at the video :),1.0
fvk716s,hdblfb,"I use tensorflow on Win10, OSX, and on linux.   On linux I've used it on Raspberry Pi's (inference only), on generic ubuntu workstations (with and without GPUs), high end workstations, all the way up to NVidia DGX-1 servers.   

In short, it works well everywhere...... *once it is set up*.   

It can be a complete PITA.   TF 1.15 or lower?   TF 2.0 or higher?   Did you compile TF yourself?   What version of python?  What NVidia driver version?   What GPU family?   Pascal?  Volta?  Ampere?   System level python or Conda?   What packages do you need and what versions?    Installed with conda or installed with pip?    

I'll assume you'll be using Conda on Win10.  If you have admin rights it should be no problem to get everything installed.    Typically, you just install the latest NVidia driver for your gpu, install Conda (I prefer miniconda but YMMV) and then type:

`conda create --name tf_gpu tensorflow-gpu`",6.0
fvlhjh3,hdblfb,"The last time I checked (some 1 week ago), conda didnt have TF2.2.0 and so i had to update it using pip. 
But I use it on Manjaro KDE with nVidia drivers and it works flawlessly and the setup is alo quite easy.",4.0
g4fcml3,hdblfb,"now, it does have TF2.2.0
https://anaconda.org/anaconda/tensorflow",1.0
fvk8wrz,hdblfb,"I use tf with pip, but your right. If its setup once, its fine. Is the GPU setup easier in Linux?",2.0
fvkc0u0,hdblfb,"Given the number of times I've been frustrated by it, I would say no.",2.0
fvkivj5,hdblfb,"agreed with this.. but for me i have a problem where my tensorflow (win10) just cant use cuda for convnet normally for some reason, gotta use some tweakings like force gpu etc, but works absolutely fine after all the painful setup on ubuntu.",2.0
fvkqyt6,hdblfb,"use lambda stack

https://lambdalabs.com/lambda-stack-deep-learning-software",1.0
fvmp7jk,hdblfb,"It's easier to setup nvidia gpu's in SLI for CUDA on linux than it is to set them up to do actual graphics work. Granted both are harder than windows, Nvidia graphics cards are basically the only thing I can say that about anymore.",1.0
fvlkluc,hdblfb,"Conda simplifies things for model building, but its way too heavy for development and ops.",1.0
fvm17pl,hdblfb,"Due to hardware reasons (drivers, custom software), I have to run inference on Windows machines. Compiling Tensorflow on Windows is awful - it just does not work. I don't think Google cares about C or C++ tensorflow on Windows at all. we are stuck using the old precompiled C-API version 1.15, around which we wrote our own wrapper in C++. It's very simple, you cannot train with it, just inference - but that's all we need anyways.

I managed to copile the C-Api 2.2, but only without GPU support, which is pretty useless.",3.0
fvm1oo5,hdblfb,Isnt there a way to use a pre-build C++ Interface?,1.0
fvm2pu5,hdblfb,Where can I find these?,1.0
fvm2uq3,hdblfb,"IDK, I never used the C++ Interface yet",1.0
fvme85n,hdblfb,I use Linux and I can say that CUDA has a lot of dependencies that are a pain to get working properly.  It's also equally painful whenever you have to update the nvidia driver.,1.0
fvlvcv4,hdblfb,"Do nothing, just two chrome tabs, windows ram usage ~10GB, do nothing two chrome tabs linux ram usage &lt;= 3GB. Linux FTW.",-2.0
fvm10ey,hdblfb,"That's because Windows caches apps in background into the RAM, so that they can open fast when you launch them. In my experience, Windows is easier on RAM than Linux.

Case in point: my laptop is HP Stream, a $200 piece of poop with 4GB RAM, 64GB eMMC storage, and Pentium N4000 processor. When I got it, my first thought was - I better put Ubuntu on it, it's gonna be faster! Nope, maybe it's hardware acceleration, maybe it's drivers, but browsing the web and navigating the system was much, much slower than on Windows.",1.0
fvjqqjm,hd81zq,"Did you make sure that the preprocessing process is the same on both platforms?

Also did you check that the mode maintained its layers and output shapes properly? Are you sure you are using the same model?",1.0
fvpyhwt,hd81zq,"Yes sir I am using the same model.Problem seems like in the part where I am converting bitmap to bytebuffer 
Thanks",1.0
fvh10ht,hcrtys,"TFlLite model is quicker because of the optimization they do on the trained model, called quantization and pruning. It does have a small impact on accuracy, which depends, but from my experience it's usually less than 3% on accuracy for classification models, and it's mostly worth doing it for the speedups.

I don't know other details about the tflite format, but quantization and pruning can be used in models for production too, but when deploying in a server you're usually not constrained by the hardware like you are on edge devices.",6.0
fvh3e4i,hcrtys,"Thanks! But if I'm not wrong, quantization and pruning are not performed unless explicitly specified?",3.0
fvhcgrs,hcrtys,Here's an amazing [post](https://nervanasystems.github.io/distiller/algo_quantization.html) explaining everything you need to know to get started with quantization.,2.0
fvgvsgh,hcrtys,Interested too,1.0
fvhnu7j,hcrtys,Have you compared inference time with tf serving? Afaik you can actually set tf serving to use tf lite.,1.0
fvlta08,hcrtys,"TFLite mainly focus on on-device inference. It can be configured with Delegates to make use of hardware acceleration on different devices, eg. TPU/GPU/DSP. and the CPU kernel of TFLite is optimized for ARM arch.

On the other hand, TF is an all-in-one solution for AI. The stock version of TF use CUDA and nVidia GPUs.

For inference time comparison, there are so many factors that can affect the results, you need give more details.",1.0
fvgt6g3,hciqii,Video isn’t working in-app for me I had to follow the YouTube link. Who thinks to do stuff like this?,1.0
fve68m7,hc61ym,Keras is built on top of TF. It is at a higher level and lets you get started with less code and manual tweaking. Keras is built into TF now with TF 2.0.,2.0
fvgyun4,hc61ym,"Also, Francois Chollet himself recommends importing Keras through Tensorflow rather than importing Keras on its own. i.e. `import tensorflow.keras` instead of `import keras`",2.0
fveddt4,hc61ym,"Keras is a high level API of tensorflow. Less efficient but easier to learn. Start with keras, once you know what you are doing move to tensorflow for that sweet speedup.",1.0
fveon81,hc61ym,"Keras is not slower than Tensorflow; it is literally now a wrapper around Tensorflow, which itself invokes lower level cudnn functions.",2.0
fvezw2j,hc61ym,"So that means, if there is a video titled keras tutorial, it actually means TF tutorial right?",1.0
fvi0990,hc61ym,Depends on the date or the version of Tensorflow it is using.  Keras API is not integrated into Tensorflow until after 1.13 AFAIK.,1.0
fvfae5n,hc61ym,"I understand that.keras is a high level.api that is abstracted out to be easier to use for beginners, and by definition those APIs are slower then the APIs they abstract out.",1.0
fvhzgk9,hc61ym,"No, Keras runs at the same speed as TF.  And most of the time you will be using tf.keras.layers to write TF custom layers as well.",2.0
fviw1e3,hc61ym,I stand corrected. Thank you,1.0
fvcej2v,hc2e4c,"Hi all,

It takes a lot of clicking to label images with manual tools, especially for semantic and instance segmentation. At [Segments.ai](https://segments.ai), we're building a labeling platform to make image segmentation easy and fast. Our platform is free to use for public datasets.

We're just getting started, and we'd love to get some early feedback and ideas for improvement from the community.

Just create an account on [https://segments.ai/join](https://segments.ai/join), and let us know what you think!

\- Bert

P.S.: [Follow us on Twitter](https://twitter.com/segmentsai) for updates.",6.0
fvclh20,hc2e4c,Whoa. I have been looking for something like this... When are you planning on releasing this???,1.0
fvcn3n2,hc2e4c,You can start using it today! [https://segments.ai/join](https://segments.ai/join),3.0
fvefvzt,hc2e4c,I just signed up and I'll give it a shot.   For me it will be a non-starter if I cannot use it offline.,1.0
fvfz4t6,hc2e4c,Thanks for the feedback. Is there a specific reason you only want to use an offline tool?,2.0
fvg8l5x,hc2e4c,"All of our data is highly sensitive and proprietary.    We have special warranty agreements for the hard drives we buy.   If they fail, we get a new one and don't have to return the dead one.    Our systems are air gapped with no external network connectivity.",2.0
fvxrnsa,hc2e4c,"This is really cool, good luck!",1.0
fvcc969,hc20jb,Do you use the same pre-processing for Training and testing? Otherwise this is your problem.,1.0
fvccmlg,hc20jb,"I use image augmentation for my training only and not for testing, is this a problem?",1.0
fvccq4z,hc20jb,Which Augmentation?,1.0
fvccvo4,hc20jb,Like rescale rotation shear and stuff,1.0
fvcd208,hc20jb,"I think Rescale is necessary to reach the desired input size. 

This could lead to problems, but mostly this should be ok. What are your data about?",1.0
fvcdize,hc20jb,I did test the codes without backend and they’re like 85-90% acc. Its about car and bus,1.0
fvcdnjs,hc20jb,"Maybe your Training is not correct, maybe its overfitted to the training data instead of generalise for unknown data. For me its a sign of this",1.0
fvcjbm4,hc20jb,Have you try to compare the same prediction for loaded model and the otherone?,1.0
fvbdjyt,hbvjrr,"Sorry for brief answer but im drunk.

Use subclassing - https://www.tensorflow.org/guide/keras/custom_layers_and_models",1.0
fvb4b0w,hbu4g1,"I'm guessing you're attempting to activate your GPUs. This is not a big problem, just look in the logs when you try to run a model, it clearly states which dll files are missing. You can download these(simple google search), and store them in Cuda bin folder.",2.0
fvbaip8,hbu4g1,"I checked that after running : python -c ""import tensorflow as tf;print(tf.reduce_sum(tf.random.normal([1000, 1000])))""",1.0
fvb6gjd,hbu4g1,"Just download the stable conda release, which has the cudatoolkit bindings already installed.",2.0
fvc2aeh,hbu4g1,Confirmed! Conda does a great job on multiple platforms.,2.0
fvc2eyt,hbu4g1,"And the best thing is it has many envs, so if any build breaks you don't really have to reinstall python. 😊😊😊",2.0
fvbb73w,hbu4g1,Copy the required DLL files to the folder. You can find those DLL files in any DLL files finder. That solved my problem.,2.0
fvbc0vh,hbu4g1,"To which folder, the CUDA bin? That was the first thing I tried, thanks for your help",2.0
fvbckih,hbu4g1,Yes. Follow the Cudnn install procedures on the official website. Be sure you have 10.1 CUDA installed.,1.0
fvc488e,hbu4g1,"I would STRONGLY recommend giving Lambda Stack a try. It works best for me when I start from a fresh install of my OS (I use Ubuntu) because it will not play nice with Anaconda.

I have spent weeks battling conflicting package installations, but Lambda Stack will handle all of that for you including: Tensorflow (1), Keras, Pytorch, CUDA, Cudnn, openCV, Caffe/Caffe2 and Pytorch alongside the proper Nvidia driver for your GPU. 

Anaconda is great, however Ubuntu users in particular are still very likely to experience problems especially if you aren’t very Linux savvy. 

I do no work for Lambda Labs, this is not a shill, but I wish it was (send me free stuff please). Seriously, I highly recommend it.


https://lambdalabs.com/lambda-stack-deep-learning-software

Quick edit: my biggest complaint is the lack of Tensorflow2. Not the end of the world, but something I wish they would hurry up and update.",1.0
fveoss3,hbu4g1,Do *NOT* use the latest NVidia drivers. It breaks cuDNN.,1.0
fvbp8fu,hbtphq,And steps are?,2.0
fva7tof,hbjicf,"Cool.
I've been working in speech synthesis for 8 years now. DSP is definitely my weak point, so looking forward to it.
I think the main mistake many DL people make is treating spectrograms like regular images.
But isn't.
Translation invariance along the frequency axis is mostly a bad idea.",2.0
fvdqwwn,hbjicf,"I agree with that. Other typical mistake I've seen is to ignore perceptual features when deciding how to pre-process audio data, based on the problem at hand.",2.0
fva5707,hbjicf,"Amazing! Subscribed. Looking forward to learning more, though I don't have any prior knowledge on Mel spectrograms.",1.0
fvdqxp4,hbjicf,Thank you!,1.0
fv8tdbo,hbdo63,https://www.tensorflow.org/api_docs/python/tf/config/set_visible_devices,1.0
fv8w0ar,hbdo63,Forgot to mention that I’m using TF 1.15.2,1.0
fv5yzq5,havszr,"If your dataset has already been split into a training set and a test set, you shuffling them does not have any impact on the model 'memorizing' versus 'learning'. This is because the shuffling only changes the order in which examples in the training set are processed to fit the model. This is the case with the test set as well.

However, if your dataset has not been split yet, you should shuffle them and allocate each example to either the training or test set. Ideally, you would want your training set to be balanced (i.e. the same number of examples for each label are used for training). An unbalanced training set may fool the learning algorithm to favor the over-represented labels.",2.0
fv58rzl,havszr,"First at all, nice you found Sentex. He is very good. 

I suggest to shuffle the images. Maybe you could read in all filenames and store them in a list. Than you pick one Random from a list (which is quite easy) and delete this element from the list. Thats how I do this every time.",1.0
fv5pzbi,havszr,"You only need to shuffle on Train, for exactly this reason you said, and to have a uniform distribution of the classes. On validation and test the evaluation is done on the entire set, and the order doesn't matter.",1.0
fv8zfsf,havszr,"If possible can u please share the links to the tutorials u followed, I just started with object detection today",1.0
fv9cfz5,havszr,"Sentdex Tutorial Series (parts 3-6 for custom data):  [https://www.youtube.com/watch?v=COlbP62-B-U&amp;list=PLQVvvaa0QuDcNK5GeCQnxYnSSaar2tpku](https://www.youtube.com/watch?v=COlbP62-B-U&amp;list=PLQVvvaa0QuDcNK5GeCQnxYnSSaar2tpku) 

Medium Articles:

 [Training Tensorflow Object Detection API with custom dataset for working in Javascript and Vue.js](https://towardsdatascience.com/training-tensorflow-object-detection-api-with-custom-dataset-for-working-in-javascript-and-vue-js-6634e0f33e03) 

 [Custom Object Detection using TensorFlow from Scratch](https://towardsdatascience.com/custom-object-detection-using-tensorflow-from-scratch-e61da2e10087) 

Both these articles are very good and explain the steps pretty easily. 

Note: The object detection API is not updated for Tensorflow 2.0, so except hours (maybe days) debugging and adjusting files to suit your needs. If you are using MacOS, expect even MORE issues. But after a couple dozen stack overflow posts, you'll get through it. 

P.S

 It took me almost 2 days to get a custom model setup on my system.",2.0
fv9o728,havszr,https://stats.stackexchange.com/questions/245502/why-should-we-shuffle-data-while-training-a-neural-network,1.0
fv537qs,hau2gu,"It's better if you can use TensorFlow Python to train the model, and TensorFlow.js only to serve it, since TF.js API is very limited ( [https://js.tensorflow.org/api/latest/](https://js.tensorflow.org/api/latest/) ). If you don't need complex tools from the Python API, there are some good videos on the TF.js in [Coursera](https://www.coursera.org/learn/browser-based-models-tensorflow) that can be audited for free.

I don't understand what you're trying to predict, but usually regression problems use Mean Squared Error Losses, and classification uses Softmax activation on the last layer + Categorical Cross-entropy. And Adam is a good general optimizer.",6.0
fv564kf,hau2gu,"I didn't really know that I just thought that Tensorflow.js was slower but since I'm using the GPU bindings I thought I was fine. But I'm open to look into the Python implementation of it could help me. Im working with the layer API and I thought that wouldn't be that different from the Python implementation because it seems pretty high level, am I wrong?",1.0
fv5dw3x,hau2gu,"Depending on your project TF.js could be enough, but not all functions from TF Python are implemented in the js API.",2.0
fv4ypo2,hau2gu,[DeepLearning.ai](https://www.youtube.com/playlist?list=PLkDaE6sCZn6Hn0vK8co82zjQtt3T2Nkqc) has a great series of videos on these topics. Note that it's quite maths heavy but you'll get a better understanding from the visualisations.,2.0
fv655jo,hau2gu,"Start with hidden layers 2 layers, since hidden 2 layers can represent arbitrary decision boundary. As for numbers of nodes in hidden layers start from average between output and input number of nodes, use Adam or nadam or rmsprop, if you have problems with convergence, switch to sgd with nesterov and momentum. Loss function depends on kind of a task, for regression try mse, for classification sparse categorical crossentropy.

Sorry I didn't managed to look into your sources.",1.0
fv4ug36,haruwq,I dont anything directly but maybe look at this list of reddit bots: [https://www.reddit.com/r/autowikibot/wiki/redditbots](https://www.reddit.com/r/autowikibot/wiki/redditbots) Some of them involve ML.,1.0
fv3yxs7,hao97e,"Source : [https://www.tensorflow.org/js/guide/save\_load](https://www.tensorflow.org/js/guide/save_load)

The file that you will need is the json one. (tflite is for iot and not for ""in browser"" apps), below how to use your model in js : 

1) &lt;script src=""[https://cdn.jsdelivr.net/npm/@tensorflow/tfjs@latest](https://cdn.jsdelivr.net/npm/@tensorflow/tfjs@latest)""&gt;&lt;/script&gt;

2) const model = await tf.loadLayersModel('[https://mysrv/model.json](https://mysrv/model.json)');

3) var preds = model.predict(tensor);",2.0
fv508f5,hao97e,"This sounds correct to me. Keep in mind, this doesn't use Google Cloud ML, I'm pretty sure this just runs on the client.",1.0
fv542m1,hao97e,"well he didn't mention GC ML, also he is asking about tensorflow js (at least its the title of the post).

Also the link included in the post is related to android apps and there for not related to tensorflow js but tensorflow lite .... :(",1.0
fv56iqt,hao97e,"ya, sorry. I was trying to answer with more insight from one of his other posts",1.0
fv41tw8,hao1ws,"Without getting too much into detail. 
I would advice you to avoid Transformers and NetVLAD (maybe do some more research about them to see why they are not appropriate).

All the problems you are having are pretty natural,  not achieving 100% accuracy with machine learning is normal and many times the problem relies in fine tuningg the architecture to your needs. In regards to processing time, it depends on the size of your network and if you are using GPU or not.

GRU and LSTM are two different architectures with the same purpose, where GRU theoretically should be better.

In my opinion your task can be done with CNN + LSTM in a classification problem, there are some posts on that, that closely relate to your objective. Search ""video classification with LSTM"" (one of them linked below) and you will find them:
https://blog.coast.ai/continuous-video-classification-with-tensorflow-inception-and-recurrent-nets-250ba9ff6b85

Also there is a review paper about video classification with a lot of techniques for video classification:
""Deep Learning for Video Classification and Captioning"", 2018
https://arxiv.org/abs/1609.06782

And another cool paper as well:
""Beyond Short Snippets: Deep Networks for Video Classification"", 2015
https://arxiv.org/abs/1503.08909",2.0
fv4niyt,hao1ws,Thanks for the repley it helped a lot!,2.0
fv4shbq,hao1ws,"No problem, glad it helped!",2.0
fv3n1ig,ham7fv,"I am adapting a simulator built in Tensorflow v1 to work in a virtual environment with Tensorflow 2.1. It's taking a lot of effort and time due to numerous changes in the functions/classes used in the simulator from v1 to v2. Many of these issues have been asked on StackOverflow and on Github, some solutions proposed on StackOverflow work, some do not.

I am not bothering to learn Tensorflow v1. I've used v2 for a few deep learning projects already and I don't see any point in learning an outdated version of a library.",2.0
fv3nz78,ham7fv,"Yes, in your case there's no point learning V1. I have already started with V1. But yeah a part of me is like V2 is definitely what's needed, however the project requires V1. Iam a bit conflicted. I suppose I'll have to stick to V1, and then when the time comes, switch to V2. 

I think the main part would be getting the hang of coding good architectures anyways right? Switching would merely be simpler if I can code things in any version.",1.0
fv3p2jd,ham7fv,"I pretty much have the documentation open at all times. I don't even attempt to memorize anything, I only try to understand the principles to be able to implement the theory I need.

I don't know specifically what you're working on, but if you are building straightforward architectures like CNNs and doing regular training/testing/validation, your code will be practically the same with either Tensorflow version. Correct me if I'm wrong.",1.0
fv3q3yr,ham7fv,"Yes building basic architectures are similar. The idea remains the same, the implementation is just easier in tf 2, and reduces the amount of code too.
Iam working on implementing attention based models in reinforcement learning. So yeah I'll find out later how different the implementations are",1.0
fv4fvyv,ham7fv,"Just disable v2 behavior, but use the same API's. Makes the job a lot easier.",1.0
fv0o3y1,ha35ch,"Thank you for this, really thorough. I'm halfway through the coursera specialization and didn't even know about the Google certificate until yesterday. I'm going to give that a shot after I finish the coursera spec and do some additional prep for it.",2.0
fv0ubty,ha35ch,"How focused is the exam on TF-specific API questions vs. more ML theory type stuff?

Do think this exam would help you land a job without any prior ML experience?",1.0
fv0z4i3,ha35ch,"It is all hands-on but you'd need to have the basics in place. I don't think you should expect to land a job just on the basis of this certification. I'd recommend you work on your basics first, then pick up a few projects, get the certificate just to have that validation (not mandatory), apply for the job.",1.0
fv5vmbu,ha35ch,Would you say that the certification is worth it for the price for a high school student interested in ML? I have a decent background with multivariable calculus (taking differential equations and linear algebra next year) and I’ve worked on a couple a projects with tensorflow. My last and probably most complex project involved making urban sound classifications with a CNN (spectrograph conversion). I was planning on studying during summer break but I only want to do so if it’s worth the time.,1.0
fv72e9j,ha35ch,"for a high school student, this would be well worth it.",1.0
fvw06kh,ha35ch,"Hello,

Firstly congratulations on achievement and appreciate for taking time for the write up. I am planning to take the exam this very weekend and curious, if will be allowed to train the models in CoLab for faster training and submit the end results?

Because if we were to build models in CoLab we might be required to make some changes to code, which are quite different from their given approach and fill ups. So wondering if we have a better approach all together, will we be allowed to build the models from scratch (using pandas and other libraries), train them on CoLab and just submit the end result?",1.0
fvyao8k,ha35ch,"Yes, you can train your models in colab, download the h5 file and place it in the right directory for your question to be validated. More details in the blog post.",1.0
g7xp3ae,ha35ch,Can we just download the weight and load it instead of loading the whole model ?,1.0
g4gxee9,ha35ch,"Hi again,
I am having a hard time fixing bugs of my local machine's TF setup (e.g. my GPU can't handle Bidirectional(LSTM) layers)

I am thinking of buying Google Colab Pro just for one month to use, hopefully, in the exam.
Will that be possible or do I have to do everything on my PyCharm?? What are better alternatives you could advise for? (other than the expensive option of buying new hardware )",1.0
g8kp7uq,ha35ch,"did you need GPU to finish the exam? I can't get TF2.0.0 (the exam's version) to use my GPU (compute capability = 5) no matter what...not locally nor using Google Colab!

if I set TF in Colab to be TF2.0.0 I still can't get GPU...any suggestions, please? (TF2.2+ works fine on my local machine with GPU)",1.0
fuzus9d,h9zcif,"What type of activation function do you use? 
They say that 'tanh' should be used if you want to have cuda gpu support with lstm.",2.0
fuzvhw4,h9zcif,I used tanh only.,1.0
fuzwhq4,h9zcif,Maybe check if it really uses your gpu (nvidia-smi -&gt; gpu utilization and output of list_physical_devices('gpu')) and you don't have any warnings from tf.,1.0
fuzzzdf,h9zcif,"If you do have a cuda compiled TF2 version on your machine, please ensure that the layer has these arguments:

activation = tanh
recurrent_activation = sigmoid
recurrent_dropout = 0
unroll is False
use_bias is True",1.0
fva0xtb,h9tvgm,"Have you considered investing in a Google Coral coprocessor? I have the USB accelerator version: https://coral.ai/products/accelerator. They are designed to do real time inferencing for quantized models using tensorflow lite. Here are the models that they already made for it (you can compile your own): https://coral.ai/models/

For reference I can  do 20-30 FPS  object detection at 800x480 (official pi touchscreen resolution) on my raspberry pi 4b with it",1.0
fvao5jc,h9tvgm,"I hadn't heard of this before so thanks for mentioning it.

However, based on what I'm reading for instance here: [https://blog.raccoons.be/coral-tpu-jetson-nano-performance](https://blog.raccoons.be/coral-tpu-jetson-nano-performance) it doesn't seem to offer much improvement over my GTX 1080 GPU..

I might consider getting it anyway, it seems for certain tasks to be very efficient for inference.",2.0
fvdwlsb,h9tvgm,"Highly recommend either way, although your link suggests that you would get a slight improvement with it. I am going down a rabbit hole with TPUs and edge ML because I think they are the next big thing in hardware (Google thinks so too at least with all the capital they are putting into it - https://www.nextplatform.com/2018/05/10/tearing-apart-googles-tpu-3-0-ai-coprocessor/). I am working on a personalized security system with facial recognition that doesn’t have to rely on a cloud backend like a standard IoT architecture for the smarter stuff. Plan on posting a tutorial in the coming weeks.",1.0
fvgswlf,h9tvgm,"I'm currently down the same rabbit hole and looking into face recognition on the Coral dev board.  I've found face 'detection' works well (about 20ms detection time per frame downsized to 640x480) but actual 'recognition' is taking 70 to 80ms per face (certainly not good enough for real-time processing which is what I'm trying to achieve). I'm also not happy with the accuracy,  but I've only just stated.  Would be interested to hear any results you have as I haven't found a lot online for face recognition on Google's dev board.",2.0
fuyjhw3,h9rk2o,"Oh, great, I was planning to do that tutorial for sevaral days now, how did it go? How much time did it take to generate?

Link, BTW: [https://www.tensorflow.org/tutorials/generative/style\_transfer](https://www.tensorflow.org/tutorials/generative/style_transfer)  


Edit: tried it, with the model from hub it's almost instant.",3.0
fuze4y4,h9rk2o,Absolute nightmare fuel,2.0
fuwxend,h9hxk0,"Practice, Pay 100$ to register, use the PyCharm Addon to do the test, Pass, Certificate by Mail",8.0
fux8hio,h9hxk0,You passed exam??,2.0
fux8lur,h9hxk0,No but I informed myself about it. I plan to do it the next time I guess.,1.0
fuxbd3g,h9hxk0,Shell we start together? :),1.0
fuxwhpp,h9hxk0,I have no time for this atm. I think I will do it until I finished University,1.0
fuyzene,h9hxk0,Ok please message me when you pass exam!,1.0
fuxeao4,h9hxk0,"Currently also studying for it, taking the suggested coursera courses",2.0
fuxgd0j,h9hxk0,I’m finding exam questions!!,1.0
fuxie6m,h9hxk0,Cool! If you wanna chat about the exam or just questions feel free to hit me up on dis tomergt45#2020,1.0
fuz05x9,h9hxk0,Thank you very much!! :),2.0
fxg5m66,h9hxk0,Srikanth#9304,1.0
fuxsbuo,h9hxk0," https://www.reddit.com/r/tensorflow/comments/gyigwo/how_i_passed_the_tensorflow_developer/?utm_source=share&amp;utm_medium=ios_app&amp;utm_name=iossmf

There ya go'",2.0
fuyzz14,h9hxk0,Thank you buddy,1.0
fuytcng,h9hxk0,"In their website they suggest to study from a course in coursera by Andrew Ng, its a good course, I think right now is free for university students (I dont remember which universities can get it free), but there is also other resources from the same author that are free.",1.0
fuz01g5,h9hxk0,I get it!! Thank you for support,1.0
fuwa6qw,h9do3p,"I had to do something similar recently.  Depending on your setup, you may need to define [concrete functions](https://www.tensorflow.org/guide/concrete_function) in order to call your encoder/decoder.  I used this approach in order to create a servable variational autoencoder so that end users could get the encoding of some input or decode some latent representation, i.e., you can call `mymodel.encode()` to pass the input data through the encoder and return the latent representation and, separately, call `mymodel.decode()` to pass a latent representation through the decoder and return the reconstituted data.  It's a bit tricky to get setup and working correctly (you may need to adjust other aspects of your model code to get it to work correctly).",2.0
fuxzalr,h9blzf,"Love the content, subscribed!",1.0
fuxzfut,h9blzf,Thanks! Really appreciate it!,2.0
futz2vj,h8o4me,"There is no difference! It's just two ways of implementing the same principle.

If you look in the documentation of Keras in regards to Conv2D

[https://www.tensorflow.org/api\_docs/python/tf/keras/layers/Conv2D](https://www.tensorflow.org/api_docs/python/tf/keras/layers/Conv2D)

    tf.keras.layers.Conv2D(
        filters,
        kernel_size,
        strides=(1, 1),
        padding='valid',             
        data_format=None,
        dilation_rate=(1, 1),
        activation=None,
        use_bias=True,
        kernel_initializer='glorot_uniform',
        bias_initializer='zeros',
        kernel_regularizer=None,
        bias_regularizer=None,
        activity_regularizer=None,
        kernel_constraint=None,
        bias_constraint=None,
        **kwargs
    )

activation -&gt; Activation function to use. If you don't specify anything, no activation is applied.

Looking at your first example, the default of ""activation"" within Conv2D is None, so no activation is applied.

In the theoretical principle of Gradient Descent and Back propagation, the Activation is considered a ""layer"", therefore in the first example, it's more explicit to the eye, that indeed, is a layer.

In the second example, and this is why Keras is really simple to use, you can specificy within the Conv2D, Dense etc.. the activation function (ReLu in this case) you wish to follow the operation, in just one line of code.

Hope it helped!",4.0
furvl2l,h8n9lw,"Clear case of exploding gradients. Categorical cross entropy is fine as a loss function but try mse loss a try.
If didn't work, dm me anytime.",2.0
fuvdutc,h8n9lw,I tried this and it kinda worked. Also tried what u/akroma188 told me and this improved accuracy a little bit. Thanks.,1.0
fuve6ha,h8n9lw,Glad to hear!,1.0
futxidg,h8n9lw,"one problem maybe due to the the data type you are using with the Keras backend, the default value is float16 (if I'm not mistaken), and when the weights reach too high values, it overflows the maximum value capacity of the float16 resulting in the NaN values you are obtaining. One suggestion would be to try implementing ""keras.backend.set\_floatx('float32')"" or 'float64', but beware this will also require more memory.

&amp;#x200B;

Also, why are you checking the MSE value, if you are using the categorical crossentropy loss? Are you in a regression or classification problem?",2.0
fuu1x7e,h8n9lw,"Thanks, let me try that. I'm in semantic segmentation which technically is pixelwise classification",2.0
fuzugge,h8n9lw,"I had the exact same issue trying to do semantic segmentation on a VGG16 Segnet model. The problem came up when using mixed precision with “mixed_float16” dtype. 

The problem ended up being the dtype of the custom layers I was using. They were being automatically cast to float16 when they required float32. So setting the dtype of the custom layers by passing in dtype=“float32” fixed it. 

Your problem might be different, but if you’re using a Segnet implementation with MaxPoolingWithArgmax2D and MaxUnpooling2D you might want to try passing in dtype=“float32” to the constructors.",2.0
furvo7f,h8hb6v,"While using keras and core tensorflow together, try using tf.keras instead of keras.",2.0
fuse6gq,h8hb6v,"&gt; While using keras and core tensorflow together, try using tf.keras instead of keras

Let me try , but now error got changes and error is 
    ValueError: Input 0 of layer sequential is incompatible with the layer: expected axis -1 of input shape to have value 128 but received input with shape [32, 1]",1.0
fuv90ug,h8hb6v,"Error says, 128 features required, but got something else.

Share your model architecture.",1.0
fuw7lb7,h8hb6v,"import tensorflow as tf  


model = tf.keras.models.Sequential()  
model.add(tf.keras.layers.Dense(128, input\_shape=(128,), activation='relu'))  
model.add(tf.keras.layers.Dense(4, activation='softmax'))  
model.compile(optimizer='rmsprop', loss='categorical\_crossentropy', metrics=\['accuracy'\])  
history = model.fit(train\_data1, train\_labels1, epochs=10, batch\_size=32, verbose=1,  
 validation\_data=(test\_data1, test\_labels1))",1.0
fux0wiq,h8hb6v,"Perfect, you provided input shape = (128, ) which means (batch size, 128) but your input data is in shape (batch size, 32).

Solution: either you can change input shape = (32,) or you preprocess your data to be in shape = (batch size, 128)",1.0
fuxi1hr,h8hb6v,"I think you interpreted it wrong because in training it accepts 128 dimesnional input shape same images i am passing it and it is accepting but in predictions i have preprocessed it and converted it into 128 also because if i do feat.shape it gives me 128 .So where i am passing [32,1] ?",1.0
fwpfrvv,h8hb6v,plz reply,1.0
fusnaq5,h88ni3,"I've asked this on StackOverflow, hate it over there as you normally get flamed for being a noob but it's my last resort.

[https://stackoverflow.com/questions/62372149/finding-input-and-output-tensors-from-pb-file](https://stackoverflow.com/questions/62372149/finding-input-and-output-tensors-from-pb-file)",1.0
fuonbcw,h82t86,I think you have to wrap around that by yourself. Try to lead each np.array and store itbas tf weights,2.0
funb4dv,h7u5ka,"Im Interestes in this as well. My Research yields that is is Not that easy to geht tensorflow C++ API Working..

Edit: found a working Tutorial for Linux",2.0
fw47e9n,h7u5ka,"Hey there, I was not able to get tensorflow working in c plus plus, but i was able to deploy pre-trained models with onnx runtime",1.0
fw68hen,h7u5ka,I got my C++ API working and was Able to run a custom tflite model on raspberry pi!,1.0
fw8htcg,h7u5ka,Does the pi use ubuntu? I've currently only got it working on ubuntu for the Jetson Xavier NX,1.0
fw8tqu4,h7u5ka,"Ist uses raspberry pi os, so some Kind of Linux at least",1.0
fus4r7x,h7u5ka,You don't say exactly how you are using the ONNX model but another approach might be to use opencv which has the ability to read ONNX models.,1.0
fw47egf,h7u5ka,"Hey there, sorry for the late response. I was able to get this working with ONNX runtime on cplusplus",1.0
fumslst,h7pmwz,"Using a desktop for DL is preferred. For the same cost, you will get way better performance, especially when a laptop gets hot and throttles. I have a old Razer Blade 14 and it sounds like taking off when training a small CNN for 10 minutes.

Your old CPU might be too old depending on the dataset you're using. Sometimes preprocessing in the input pipeline can be CPU intensive. You usually want the GPU to be at 100% at all time, so the CPU should be reasonably fast to load and preprocess the data.",1.0
fun0tr7,h7pmwz,"Thanks for the reply! It's kind of what I was/am expecting to be honest. The house, to me, isn't a factor as I won't be around the whole time it would be doing its thing. I was more concerned with a laptop throttling and/or running too hot for longer periods of time since I know more advanced models can take a long time to train.   
  
A laptop has a lot of draws, but you can't beat the performance of a desktop (yet) for this stuff.   
  
If you don't mind since it seems like you might know, if I'm running on a gpu, how much ram should I have? 16? 32? Whatever I can afford that the board supports?",1.0
fun38mz,h7pmwz,"The amount of RAM depends on what dataset you will be working on. 

Ideally you want to have enough RAM to cache all preprocessed data (Google search `tf.data cache`). However this is sometimes not feasible since some datasets are huge like a couple terabytes. In this case, what you should be looking for is to cache all preprocessed data to a high-performance storage media like a NVMe SSD and to have enough RAM to load an prefetch at least a few batches. 

That being said, having more RAM almost always helps. Many of our servers have 128GB.",1.0
fun5bln,h7pmwz,"awesome, thanks so much for the advice!  I probably won't be doing anything too crazy since I just want to teach myself what's going on and try to leverage it in to more technical tasks at work (product owner / systems analyst who is more of a business product owner right now).  For now I might stick to 32gb and keep 2 slots open if I need to increase it.  I already planned on the NVMe(i think?  like i said, been awhile since I built a PC).  Sounds like I'm on the right track now!",1.0
fumcn01,h7pezr,"## Overview

We are very happy to release Spark NLP 2.5.2 with a new state-of-the-art LanguageDetectorDL annotator to detect and identify up to 20 languages. There are also bug-fixes and other enhancements introduced in this release which were reported and requested by Spark NLP users.

As always, we thank our community for their feedback, questions, and feature requests.

## New Features

* Introducing a new LanguageDetectorDL state-of-the-art annotator to detect and identify languages in documents and sentences
* Add a new param entityValue to TextMatcher to add custom value inside metadata. Useful in post-processing when there are multiple TextMatcher annotators with multiple dictionaries [https://github.com/JohnSnowLabs/spark-nlp/issues/920](https://github.com/JohnSnowLabs/spark-nlp/issues/920)

## Bugfixes

* Add missing TensorFlow graphs to train ContextSpellChecker annotator [https://github.com/JohnSnowLabs/spark-nlp/issues/912](https://github.com/JohnSnowLabs/spark-nlp/issues/912)
* Fix misspelled param in classThreshold param in  ContextSpellChecker annotator [https://github.com/JohnSnowLabs/spark-nlp/issues/911](https://github.com/JohnSnowLabs/spark-nlp/issues/911)
* Fix a bug where setGraphFolder in NerDLApproach annotator couldn't find a graph on Databricks (DBFS) [https://github.com/JohnSnowLabs/spark-nlp/issues/739](https://github.com/JohnSnowLabs/spark-nlp/issues/739)
* Fix a bug in NerDLApproach when includeConfidence was set to true [https://github.com/JohnSnowLabs/spark-nlp/issues/917](https://github.com/JohnSnowLabs/spark-nlp/issues/917)
* Fix a bug in BertEmbeddings [https://github.com/JohnSnowLabs/spark-nlp/issues/906](https://github.com/JohnSnowLabs/spark-nlp/issues/906) [https://github.com/JohnSnowLabs/spark-nlp/issues/918](https://github.com/JohnSnowLabs/spark-nlp/issues/918)

## Enhancements

* Improve TF backend in ContextSpellChecker annotator

## Pipelines and Models

We have added 4 new LanguageDetectorDL models and pipelines to detect and identify up to 20 languages:

## Models

|Model|Name|Build|Lang|Offline|
|:-|:-|:-|:-|:-|
|LanguageDetectorDL|`ld_wiki_7`|2.5.2|`xx`|[Download](https://s3.amazonaws.com/auxdata.johnsnowlabs.com/public/models/ld_wiki_7_xx_2.5.0_2.4_1591875673486.zip)|
|LanguageDetectorDL|`ld_wiki_20`|2.5.2|`xx`|[Download](https://s3.amazonaws.com/auxdata.johnsnowlabs.com/public/models/ld_wiki_20_xx_2.5.0_2.4_1591875680011.zip)|

## Pipelines

|Pipeline|Name|Build|Lang|Offline|
|:-|:-|:-|:-|:-|
|LanguageDetectorDL|`detect_language_7`|2.5.2|`xx`|[Download](https://s3.amazonaws.com/auxdata.johnsnowlabs.com/public/models/detect_language_7_xx_2.5.0_2.4_1591875676774.zip)|
|LanguageDetectorDL|`detect_language_20`|2.5.2|`xx`|[Download](https://s3.amazonaws.com/auxdata.johnsnowlabs.com/public/models/detect_language_20_xx_2.5.0_2.4_1591875683182.zip)|

* The model with 7 languages: Czech, German, English, Spanish, French, Italy, and Slovak
* The model with 20 languages: Bulgarian, Czech, German, Greek, English, Spanish, Finnish, French, Croatian, Hungarian, Italy, Norwegian, Polish, Portuguese, Romanian, Russian, Slovak, Swedish, Turkish, and Ukrainian

## Documentation

* Update documentation for release of Spark NLP 2.5.x
* Update the entire [spark-nlp-workshop](https://github.com/JohnSnowLabs/spark-nlp-workshop) notebooks for Spark NLP 2.5.x
* Update the entire [spark-nlp-models](https://github.com/JohnSnowLabs/spark-nlp-models) repository with new pre-trained models and pipelines

## Installation

**Python**

    #PyPI
    
    pip install spark-nlp==2.5.2
    
    #Conda
    
    conda install -c johnsnowlabs spark-nlp==2.5.2

**Spark**

    spark-shell --packages com.johnsnowlabs.nlp:spark-nlp_2.11:2.5.2

**PySpark**

    pyspark --packages com.johnsnowlabs.nlp:spark-nlp_2.11:2.5.2

**Maven**

    &lt;dependency&gt;
        &lt;groupId&gt;com.johnsnowlabs.nlp&lt;/groupId&gt;
        &lt;artifactId&gt;spark-nlp_2.11&lt;/artifactId&gt;
        &lt;version&gt;2.5.2&lt;/version&gt;
    &lt;/dependency&gt;

**FAT JARs**

* CPU: [https://s3.amazonaws.com/auxdata.johnsnowlabs.com/public/spark-nlp-assembly-2.5.2.jar](https://s3.amazonaws.com/auxdata.johnsnowlabs.com/public/spark-nlp-assembly-2.5.2.jar)
* GPU: [https://s3.amazonaws.com/auxdata.johnsnowlabs.com/public/spark-nlp-gpu-assembly-2.5.2.jar](https://s3.amazonaws.com/auxdata.johnsnowlabs.com/public/spark-nlp-gpu-assembly-2.5.2.jar)",1.0
fumc5jf,h7ovoy,Are you using this Google cloud ML integration with TensorFlow to do something real-time in your RN app?,1.0
funwfiu,h7ovoy,"Yes! I sent you a chat, please check it out!",1.0
fv4wn37,h7ovoy,"[https://www.reddit.com/r/tensorflow/comments/hao97e/any\_tensorflow\_js\_experts/](https://www.reddit.com/r/tensorflow/comments/hao97e/any_tensorflow_js_experts/)

please check this out!",1.0
fun602v,h7ovbp,"You can use `nvidia-smi` to adjust your GPUs power limit. How much power it draws corresponds to how much heat it generates.

You can see what your limit is by running `nvidia-smi -q -d power`.
* `Power Limit` tells you what the limit is currently set to.
* `Min Power Limit` and `Max Power Limit` tell you what you can set it to.
* `Power Draw` gives you the instantaneous power draw value.
* `Power Samples` will tell you the min/max/avg draw values.

To change the limit, do `nvidia-smi --power-limit=123`, changing `123` to the appropriate value.",2.0
fup3a1f,h7ovbp,"Thank you very much !

That is very useful :)",1.0
fumdz09,h7oezt,"It sounds like your doing basic image recognition. May I recommend a basic implementation using AlexNet [https://github.com/pytorch/vision/blob/master/torchvision/models/alexnet.py](https://github.com/pytorch/vision/blob/master/torchvision/models/alexnet.py)

&amp;#x200B;

&gt;Is this a correct application for TensorFlow/ml?

Yes",1.0
fuml4ze,h7oezt,"Thanks for this, 

My thinking has slightly changed to making a Classification for each hour of the day with mutiple data points",1.0
fuoj6hv,h7l2a6,You can try deep learning with python by francois chollet,1.0
fuwb5eo,h7l2a6,Looks like a good book. Thank you for the recommendation.,2.0
fyggob1,h7l2a6, En español: [http://machine-learning-con-tensorflow.thinkific.com/](http://machine-learning-con-tensorflow.thinkific.com/),1.0
fun27us,h7kx4q,"I'm not sure if I'm misunderstanding the code but to me it looks like for an input of different sequences of text written by different people, you're trying to predict one value. This doesn't seem to match what you said you were trying to do. Actually to me given the sequence length, not even sure it would train. Again, I might be misunderstanding what you wrote with a quick skim. What might help you is if you use the make_on_shot_iterator the tf data API provides and visualize what a single input &amp; output would look like.",1.0
fun4gtc,h7kx4q,"I think you are reading the same file 5 times. You should use 'chat' in the open function instead of filename.

`for i, chat in enumerate(os.listdir(DATA)):`

`print(""{} -- {}"".format(chat, i))`    

`text = open(DATA + ""/"" + filename,'rb').read().decode(encoding='utf-8')`",1.0
fuoo9n7,h7kx4q,"Thank you! it worked.

But when I try to predict the results it still just shows me the same numbers all the time (each one is about 0.2).

I updated the code up there, can you help me, please?",1.0
fuov337,h7kx4q,"I think you should follow ad\_2010's proposal and try to understand, how your input looks like. If you still have exactly 0.2 it is probably still seeing the same input. Otherwise you would see small fluctuations and some gain. And you shouldn't work without a test set, which gives you an impression how well your model will do with new texts. 

My general advice would be to use a different example. Authorship attribution is hard. Start with an example which is doing a content based classification or sentiment  analysis.  

I found Chollet's book Deep Learning with Python great and you can view his notebook online: [https://github.com/fchollet/deep-learning-with-python-notebooks/blob/master/3.5-classifying-movie-reviews.ipynb](https://github.com/fchollet/deep-learning-with-python-notebooks/blob/master/3.5-classifying-movie-reviews.ipynb)",1.0
fuov3kz,h7kx4q,"
I see you've posted a GitHub link to a Jupyter Notebook! GitHub doesn't 
render large Jupyter Notebooks, so just in case, here is an 
[nbviewer](https://nbviewer.jupyter.org/) link to the notebook:

https://nbviewer.jupyter.org/url/github.com/fchollet/deep-learning-with-python-notebooks/blob/master/3.5-classifying-movie-reviews.ipynb

Want to run the code yourself? Here is a [binder](https://mybinder.org/) 
link to start your own Jupyter server and try it out!

https://mybinder.org/v2/gh/fchollet/deep-learning-with-python-notebooks/master?filepath=3.5-classifying-movie-reviews.ipynb



------

^(I am a bot.) 
[^(Feedback)](https://www.reddit.com/message/compose/?to=jd_paton) ^(|) 
[^(GitHub)](https://github.com/JohnPaton/nbviewerbot) ^(|) 
[^(Author)](https://johnpaton.net/)",1.0
funilto,h7j9g4,Is this any different from a typical face detection algorithm?,2.0
ful7hcx,h7j9g4,Repo link:  [https://github.com/Jaldekoa/Replicating-Face-Mask-Detector](https://github.com/Jaldekoa/Replicating-Face-Mask-Detector),3.0
fumbz7b,h7j9g4,"Hi! Can you share your roadmap of learning 'deep learning ' ? 
It will be a great help for me !",1.0
fumilbj,h7j9g4,"Basically, I did the [deeplearning.ai](https://deeplearning.ai)'s Coursera courses like:

\-  [https://www.deeplearning.ai/deep-learning-specialization/](https://www.deeplearning.ai/deep-learning-specialization/) 

\-  [https://www.deeplearning.ai/tensorflow-in-practice/](https://www.deeplearning.ai/tensorflow-in-practice/) 

\-  [https://www.deeplearning.ai/tensorflow-data-and-deployment/](https://www.deeplearning.ai/tensorflow-data-and-deployment/)",7.0
fumiqzt,h7j9g4,"Were they enough? 
I am currently doing deep learning  specialization and tensorflow in practice specialization",1.0
fuml2u6,h7j9g4,"It is a good start. To learn more, I recommend you try to replicate some existing examples. In this example, I use OpenCV for face recognition (I've needed to search how OpenCV works and how I could to recognize faces).",3.0
fulb1tu,h7j9g4,Would it detect it if you are only wearing the mask halfway?,3.0
fuop3zy,h7j9g4,"Upvoted for adding replicated in the title.👍
We need more people like you.",1.0
fv5nd6x,h7j9g4,"Hello, thanks for sharing the code.

One question, what are key differences with the original code? Thanks.",1.0
ftr31rv,h79obq,"
I see you've posted a GitHub link to a Jupyter Notebook! GitHub doesn't 
render large Jupyter Notebooks, so just in case, here is an 
[nbviewer](https://nbviewer.jupyter.org/) link to the notebook:

https://nbviewer.jupyter.org/url/github.com/tensorflow/models/blob/master/research/object_detection/object_detection_tutorial.ipynb

Want to run the code yourself? Here is a [binder](https://mybinder.org/) 
link to start your own Jupyter server and try it out!

https://mybinder.org/v2/gh/tensorflow/models/master?filepath=research%2Fobject_detection%2Fobject_detection_tutorial.ipynb



------

^(I am a bot.) 
[^(Feedback)](https://www.reddit.com/message/compose/?to=jd_paton) ^(|) 
[^(GitHub)](https://github.com/JohnPaton/nbviewerbot) ^(|) 
[^(Author)](https://johnpaton.net/)",1.0
ftrgjgy,h79obq,"The tf.saved_model.load function needs the second parameter ""tags"" to be set to None. Supposedly that is the default, but doesn't work if you don't explicitly set it. If that doesn't work, try to upload Tensorflow to the latest version as well",1.0
fuqum6z,h79obq,"If I set tags to None I get:

&gt;model = tf.compat.v1.saved\_model.loader.load(sess, None, args.modeldir)   
  File ""/home/garrett/.local/lib/python3.6/site-packages/tensorflow/python/util/deprecation.py"", line 324, in new\_func   
    return func(\*args, \*\*kwargs)   
  File ""/home/garrett/.local/lib/python3.6/site-packages/tensorflow/python/saved\_model/loader\_impl.py"", line 269, in load   
    return loader.load(sess, tags, import\_scope, \*\*saver\_kwargs)   
  File ""/home/garrett/.local/lib/python3.6/site-packages/tensorflow/python/saved\_model/loader\_impl.py"", line 422, in load   
    \*\*saver\_kwargs)   
  File ""/home/garrett/.local/lib/python3.6/site-packages/tensorflow/python/saved\_model/loader\_impl.py"", line 349, in load\_graph   
    meta\_graph\_def = self.get\_meta\_graph\_def\_from\_tags(tags)   
  File ""/home/garrett/.local/lib/python3.6/site-packages/tensorflow/python/saved\_model/loader\_impl.py"", line 317, in get\_meta\_graph\_def\_from\_tags   
    if set(meta\_graph\_def.meta\_info\_def.tags) == set(tags):   
TypeError: 'NoneType' object is not iterable  
 

I instead set it to \['serve'\] based on the output of ""saved\_model\_cli show"":  
The given SavedModel contains the following tag-sets:   
serve.  


For some reason pip3 won't allow me to install a newer version of TensorFlow. I may have to do an OS upgrade sooner than I wanted.",1.0
ftqagre,h16g04,Tensorflow is a framework which primarily is used to build and train neural networks. How are you visualizing solving this problem?,7.0
ftqbsvx,h16g04,"Thanks for the reply. 

In my mind, I would use a classification system in a neural network to make job suggestions through to candidates. Open to suggestions of whether this is the right approach.

The first assumption is that the candidate is actively is looking for a job.

The associated attributes of a job would be run against the through the model and suitability above a certain score would mean the job is suggested to a candidate. 

Candidates could then accept or reject the interest in the job, helping to improve and train the model over time.

The next part of training would be whether the successfully got the job, training the model again.

The end goal of the model is to reduce the time spent looking for a suitable job. 

Excuse my lack of knowledge on TF specifics, I am approaching it as logically as I can.",1.0
ftqcopx,h16g04,"It sounds like you're overcomplicating the problem. This is something you can already do with just a regular computer program. A neural net would be an approach if something less tangible needs to be evaluated like a written text of both applicant and position.

Neural nets aren't always the solution (they should one of your last solutions) especially if you can already determine a match with normal programming.",5.0
ftqdp8o,h16g04,"The complication comes from having 1000s of candidates and 1000's of applicants. So I don't want to have my model suggesting the same job to 100 plus applicants.

I want it to be able to determine the best applicants for a specific job, while also servings the other candidates with suitable suggestions. 

Otherwise, the model or program has no real differentiation from say a basic search engine. 

In this context, the model needs to learn when it is appropriate to suggest a job, and also what the likelihood of a candidate applying and being successful is. 

And on the other side, the candidate can see quickly how they stack up vs the competition. 

The goal here is to eliminate the wasted time spent on job applications, and on the other side, reaching out to candidates unlikely to take the job or be successful.

I hope that provides some context for my thinking.",1.0
fukesks,h16g04,"So, you're saying it's a two-sided matching market scenario? If you have a function that predicts how much a particular company will value (how much they'll offer) a particular employees, you can solve the matching part programmatically (if you're looking for commission, you'd just make the pairings that maximize total valuation).  I'd probably pick a random forest approach with handcrafted features if it were my project though.",2.0
ftqe676,h16g04,"This could still be done with a ranking system I believe.

But let's say that you go for a neural net, you would need a tonne of example data and you would need to evaluate and preprocessor your features in a meaningful way.
By evaluate i mean you need to perform some form of statistical analysis of your available data in order to not have your neural net being fed irrelevant features.
I think it should be possible to create a system that does what you're describing but there's going to be a lot of work in it and there's no guarantee of success.",1.0
ftqfo17,h16g04,"Thanks alot for your help. 

Ok, so I think if I just start simply. 

Let's say I have the following on the candidate vs job side


Job X:

Salary: 100-120K

Location: NYC

Experience: 7-10 years

Managed people: No



Candidate 1:

Salary Expectations: 150-170k

Location: San Fran

Experience: 5 years

Managed people: No



Candidate 2:

Salary Expectations: 110-130K

Location: NYC

Experience: 6 years

Managed people: No



Candidate 3:

Salary Expectations: 100-120K

Location: NYC

Experience: 6 years

Managed people: No


So from this, you can probably make a quick guess at the two candidates you want to suggest the job too. 

Now imagine a series on both sides, but you also bring in additional inputs. Say languages, computer program proficiency, interests (for compatibility with the team). 

This is why I thought Tensorflow and a NN ML model would be appropriate for this. Most importantly over time, your accuracy for predicting and suggesting jobs will improve as use you less and less training data and more real-world features vs a basic ranking system. 

Is my thinking here inherently wrong?

And then also, if I was to use a TensorFlow model. Would I build up profiles of jobs and what the match was for the candidate to inform that going forward? Effectively how would it be structured?",1.0
ftqhb09,h16g04,"There are more steps to this than I care to explain on reddit honestly. You keep saying ""use Tensorflow for this"" and I'm getting some magic bullet vibe off it.
Your thinking is in the right ball park but you need data science experience to do this, which is not a short journey.",2.0
ftqlryf,h16g04,"So as mentioned in the previous replies, a ranking system would be more suitable, to be more precise a rule based system.
Say you mentioned 1 Candidate from SF and 2 from NYC, you can simply compare the expected location of the candidates and the actual location of the job and give  points to those candidates who have the same expectations, a tensorflow model, which  would be a supervised learning model would be too much for such a simple problem. 
And also for a classification model, how can are you thinking of generalising to any and every job opening? If you train it for 100 jobs with 100 different locations, it will never learn to  prefer a single candidate for a job.",1.0
ftqo9of,h16g04,"I am not thinking of it that simplistically. 

The way I look at it if I have a model that has results for 1m successful jobs and applicants with all my attributes.

I then introduce 1k unfilled jobs and searching applicants. Based on the data from those jobs I should be able to match candidates against their top 10 jobs (and vice versa). 

Over time I would want the model to learn the importance of the attributes and adjust (perhaps there is a variable that isn't considered properly). 

I don't understand your second question sorry. If your question is around generalisation of location, a neural network ML model should consider the effect that the location plays in decisions (for example, perhaps candidates in NYC are willing to travel further, or are actually more flexible on salary then they actually say).",1.0
ftqr1x0,h16g04,"I would recommend starting out with a tree-based /ensemble method, i.e. decision tree, random forest, etc. if your goal is to classify which candidates would be best. If you're interested in attrition which is somewhat related to suitability, consider using survival analysis methods, such as a Cox PH model or even a survival random forest. There are a few R packages which are perfect for these  tasks.

If you are absolutely deadset on a neural network, look into Bayesian neural nets, but I would only use that if it's necessary. They have been shown to perform well on smaller data sets (which I'm assuming you're likely working with, though correct me if I'm wrong and I'll update my prior assumption), but definitely try a few other methods out first.

What's the size of your data set?

&amp;#x200B;

Source: Work in people analytics",1.0
ftqiy02,h16g04,"You can, but [you shouldn't](https://www.reuters.com/article/us-amazon-com-jobs-automation-insight-idUSKCN1MK08G).",0.0
ftqog2u,h16g04,Thank you for that. The discussion around my idea is actually a placeholder. Biases and how you consider them is also important.,1.0
ftq3ubm,h13mm0,"Since you specified the shape as just `[1]`, the fit procedure considers any structure beyond this to be a batch dimension.  

Let's break it down a little bit.  The shape `[1]` actually corresponds to the shape `[1,]`.  It is a 1D-1D array (i.e., a 1D tensor representation of a 1D vector).  Let's look a little more into this.

```python
import numpy as np

scalar = np.array(5)  
vector1D_arr1D   = np.array([5])
vector5D_arr1D   = np.array([1,2,3,4,5])
matrix5D1D_arr2D = np.array([1,2,3,4,5]).reshape(-1,1)

# Look at shapes
scalar.shape            # ()
vector1D_arr1D.shape    # (1,)
vector5D_arr1D.shape    # (5,)
matrix5D1D_arr2D.shape  # (5,1)

# Reshape the scalar to `[1]` (like in OP's Dense layer)
scalar.reshape([1]).shape          # (1,)

# Reshape the 1D-1D vector to `[1]` (to see if shape changes) 
vector1D_arr1D.reshape([1]).shape  # (1,)
```

Above, we see that the shape `[1]` is equivalent to `(1,)`, so we can now confidently say that your Dense layer expects an input ""feature vector"" to be a 1D-1D array.  

In your first case, your input is what I called `vector1D_arr1D` in the above code; it has shape `(5,)`.  When you call `model.fit` it automatically assumes the `5` is the batch dimension since the Dense layer can only take inputs of shape `(1,)`.  

In your second case, your input is what I called `matrix5D1D_arr2D` in the above code; it has shape `(5,1)`. When you call `model.fit` it knows exactly what to -- no assumptions necessary. The `5` is in the placeholder for the expected batch dimension.

In both cases, `model.fit` interprets your input `xs` as being a batch of 5 (1,)-shaped inputs.  So, in this particular case, reshaping is not totally necessary.  However, my 2 cents is that you should always be explicit in your code and not rely on hope -- so I would recommend the reshape in the best practices sense.",1.0
ftq7y7j,h13mm0,"So my take is that input shape of [1] means theres a single column. And batch of 5 (1,) means [1],[2],[3],[4],[5] in my case.",1.0
ftqthug,h13mm0,"Yea, basically -- though a shape of `[1]` doesn't necessarily differentiate between a column vector and a row vector (e.g., try this: `arr1 = np.array([3]); arr2 = arr1.T; arr1.shape == arr2.shape`).

A few more details:

In your Dense layer, you specify that the input shape for a single data point is `[1]`, which is a synonym for the shape `(1,)`.  This creates a Dense layer that expects to receive batches of (1,)-shaped tensors.  In other words, the Dense layer expects to receive tensors of shape `(None,1)`, where `None` is a placeholder for the batch axis that indicates no restriction on batch size.

Next, you create a data array, `xs1 = np.array([1,2,3,4,5])`, that has a shape of `(5,)`.  When you feed this into the `model.fit` method, it is expecting a (None,1)-shaped tensor, so it infers that the 5 is the value to prescribe the batch axis, which basically induces a (5,1)-shaped tensor.",1.0
ftq84mr,h13mm0,"And what should be the input shape for 2D matrix having dimensions suppose (10,3). Should it be (None,3)?",1.0
ftrngcb,h13mm0,"If you were building a model for 2D matrices of shape `(10,3)` you could do the following:

```
import tensorflow as tf

(x_trn,y_trn),(x_val,y_val) = get_10x3_matrix_data()

visible = tf.keras.layers.Input((10,3))
flatten = tf.keras.layers.Flatten()(visible)
dense   = tf.keras.layers.Dense(units = 1)
model   = tf.keras.models.Model(visible, dense)
model.compile(loss='mean_squared_error', optimizer = 'sgd')
model.fit(x_trn, y_trn, epochs = 500, validation_split=0.2)
```

This model expects that `x_trn` has shape `(None, 10, 3)`, where `None` is a placeholder for the batch dimension that indicates that the model doesn't care if `x_trn` has shape `(1,10,3)` or `(3500,10,3)`.  Note that if you just plug in a single 10x3 matrix that has shape `(10,3)` you will get an error: you need to plug that matrix in with shape `(1,10,3)`, which you can get like: `single_input = x_trn[0][None,...]`",1.0
ftqlds0,h11a60,"Edit: Oopsie! My post below is incorrect.  I was in TF1 compatibility mode (`import tensorflow.compat.v1 as tf`); more info down the thread.

-----------------------------------------------------


Using TF2.2 on my MacBook Pro, I am able to get your desired progress messaging.

Method 1: Use `validation_split` parameter
```python
import tensorflow as tf

# Get some tinkering data
(x_trn,y_trn),(x_tst,y_tst) = tf.keras.datasets.mnist.load_data()

# Build and compile a model
model = get_model()  

# Train model (and look at progress bar!)
model.fit(
    x_trn, y_trn,
    epochs = 1, 
    validation_split = 0.2,
) 
```

Here is a copy-and-paste of the progress bar I captured during the training:

```
Train on 48000 samples, validate on 12000 samples
16352/48000 [=========&gt;....................] - ETA: 12s - loss: 0.6579 - accuracy: 0.7704
```

Method 2: Use `validation_data` parameter
```python
import tensorflow as tf
from sklearn.model_selection import train_test_split

# Get some tinkering data
(x_trn,y_trn),(x_tst,y_tst) = tf.keras.datasets.mnist.load_data()

# Build and compile a model
model = get_model()  

# Split a validation set off the training set
x_trn_,x_val,y_trn_,y_val = train_test_split(
    x_trn, y_trn, 
    test_size = 0.2, 
    shuffle   = True, 
    stratify  = y_trn,
)

# Train model (and look at progress bar!)
model.fit(
    x_trn_, y_trn_,
    epochs = 1, 
    validation_data = (x_val,y_val),
) 
```

And here again is a copy-and-paste of the progress bar I captured during the training:

```
Train on 48000 samples, validate on 12000 samples
19936/48000 [===========&gt;..................] - ETA: 10s - loss: 0.5918 - accuracy: 0.7947
```

So I guess my question would be: are you possibly forgetting to specify a validation set?  (If not, then I'm not sure.)",2.0
ftr19jr,h11a60,"Thanks for testing that out on your machine!

&amp;#x200B;

It's using validation data in both cases.  


Here's what I get in TF 2.2 on openSUSE:

`Total params: 43,412,052`

`Trainable params: 43,412,052`

`Non-trainable params: 0`

`__________________________________________________________________________________________________`

`Epoch 1/120`

`1057/1057 [==============================] - 336s 318ms/step - loss: 0.1552 - val_loss: 0.0507`

`Epoch 2/120`

 `716/1057 [===================&gt;..........] - ETA: 20s - loss: 0.0367`

And here's the same script, accessing the same data, running in TF 2.1 on windows:

`Total params: 43,412,052`

`Trainable params: 43,412,052`

`Non-trainable params: 0`

`__________________________________________________________________________________________________`

`Train on 33824 samples, validate on 3272 samples`

`Epoch 1/120`

`33824/33824 [==============================] - 116s 3ms/sample - loss: 0.1537 - val_loss: 0.0526`

`Epoch 2/120`

 `6080/33824 [====&gt;.........................] - ETA: 55s - loss: 0.0498`

I should have thought to check this before, but I'm just using whatever the default batch size is, I think 32.

33824/32=1057

So I guess it's just showing the number of batches instead of the number of samples. Odd it doesn't do the same thing for you in 2.2 though. Maybe it's linux specific.",2.0
ftrlrmp,h11a60,"Uh oh -- It just struck me that I led you astray!

When I ran the fit to check for you before,  I used an ipython session that was open in my terminal from earlier in the day... Well, the bad news is that earlier in the day, I found that a (temporary) fix for some crashes I kept getting was to do the following:

`import tensorflow.compat.v1 as tf`

Moments ago, I realized this in horror.  So I just re-ran the scripts outside of v1 compatibility mode and -- well, I guess you can figure out what happened: no message like ""Train on 48000 samples, validate on 12000 samples""

TLDR: you are right -- it seems to be missing from TF2.2.",1.0
fto4c5v,h0sl87,"1. Yes, you can.
2. No one can answer this.
3. 5 questions, first question being easy and difficulty grows along with questions.
4. Developers who owns that certification calls themselves in this network.
5. No one can answer this.",5.0
fto74ra,h0sl87,"Certainly, though, with #2, you can estimate.  I mean... with the old salesforce technical architect certification, you had to spend somewhere in the realm of $5,000.  If you got it, you could next-to guarantee a $250K per year consulting gig.  Worth it?  Maybe not from initial glance, but if you are in the business and understand the potential upside, then, yes, you know it is definitely worth it (though... it's salesforce, so... um... maybe not.  :-)   


Are you contacted more on linkedIn if you have the certification?  Do you work with a consultancy that charges end clients $650/hr for a resource with a TF cert?",1.0
ftojpos,h0sl87,"You might want to check this out :
I came across this guy who just got TF developer certificate

[TF developer ]

(https://youtu.be/ya5NwvKafDk)",2.0
ftms9od,h0l479,"Not tensorflow but I've made a tutorial on how to do this in Google Colab using Facebook's Detectron2 library (based on Torch) : https://github.com/Martin09/DeepSEM/tree/master/nanowire_yield

Hope this helps!",1.0
ftnzz0x,h0l479,https://engineering.matterport.com/splash-of-color-instance-segmentation-with-mask-r-cnn-and-tensorflow-7c761e238b46?gi=f7f9ac0bd966,1.0
ftm9113,h0fm0m,It may be kinda cheap but use a dummy ground truth and just drop it and replace it with the real one inside of the train step?,2.0
fto0hd2,h0fm0m,"Thanks for the idea, but I am still searching for a kind-of minimal working example which I could run with fit(), do you happen to know about something like this?",1.0
ftkiq9n,h011un,This begs for a website to try it out,2.0
ftktjw7,h011un,"Yeah, would love to give it a rip.",1.0
ftj2xyl,gzye1l,"Number of steps depends upon number of training images and batch size.

Eg. You have 1000 images and batch size is 32 then, 1000/32= 32 steps per epoch",1.0
ftj3nvj,gzye1l,"Ok but in my case I don't have 1000. I have 224/32 = 7, yet 7 is giving poor results, so i set the steps to 1000 and got good results. My other question was is my data be repeatedly trained during those extra steps?",1.0
ftj8j4z,gzye1l,"This field is because with generators you can't always know how many iterations it will take to get to the end. You are just running through your 7 examples more. Were you always doing 25 epochs? Try doing 7 steps per epoch with roughly 1000/2000 epochs to get the same training example passes. Not completely analogous w.r.t. gradient updates, but worth exploring.",2.0
ftj8qqj,gzye1l,Thank you,1.0
ftgkl0t,gzgha4,"Where do you see a regression problem there? 

The most common way of modeling the ground truth of sentiment is to treat it as a classification problem - positive or negative, with no gradation possible (which would turn it into a regression problem).",2.0
ftgmnhl,gzgha4,"In example i mentioned, the author use `Dense(1)` as last/output layer. AFAIK it's used for regression problem and we use `Dense(2, activation='softmax')` for classification problem.

Is it wrong?",1.0
ftgnbf2,gzgha4,"`Dense(n, activation='softmax')` can be used for any number of classes, including 2, but for the specific case of two classes (binary classification) it is more common to use single neuron with an appropriate activation function and a loss function e.g. binary cross entropy.  

You can't really do regression with binary cross entropy as the loss function.",2.0
ftgro4o,gzgha4,"I didn't know it's possible to do that. One last question, does tf.keras automatically convert the number to 2 possible category (for example &gt;=0.5 become 1 and &lt; 0.5 become 1 with sigmoid function) ?",1.0
ftgdphl,gzex8d,"Okay so it'll be difficult to diagnose from just reading the code but here a re a few things that stood out to me:

1) Using 1000x1000 images: Try to resize them down to a smaller size before feeding into the netwrok. Maybe try 240x240.

2) Dropout before the sigmoid unit: either try another fully connected layer before your sigmoid unit and add dropout between those layers or try removing dropout. This might improve the stability in the loss function.

And a few general guidelines:

1) try a simple architecture to start out with, that way you have a baseline for the problems that are occuring. If you have problems such as anomalies in the loss values due to the architecture you'll be able to tell because they might go away fro simpler architectures. Try fully connected, no regularisation and see how many of your problems persist

2) first try to overfit your model to the training set without regularisation. At this point you'll know that your network can learn decent enough function for the training set and adding regularisation and extending training time may help it generalise to new samples. So now you can add regularisation. But if performance is poor on the training set, you will need to look into different architectures",2.0
ftgk8b7,gzex8d,Also something I forgot to mention was to try transfer learning because the dataset size seems a bit small,1.0
ftghkh3,gzeum5,"sigmoid(x) + stop_grad(round(sigmoid(x)) - sigmoid(x))

This outputs 0s and 1s and is differentiable. You can replace rounding by bernouilli sampling if you wish stochasticity.",3.0
ftfz85h,gzeum5,"No, you have to sample. Look at restricted Boltzmann machines, which were the predecessor to modern DNNs. Or look at any generative model used on binary images like MNIST.",1.0
ftg1jrt,gzeum5,Wouldn't sigmoid also solve the issue?,1.0
ftg9c71,gzeum5,Sigmoid or binary-crossentropy?,1.0
fth4s73,gzdjvr,"Scroll up on the error traceback, thius is one of those double errors:

```
ValueError: The two structures don't have the same sequence length. Input structure has length 4, while shallow structure has length 5.


During handling of the above exception, another exception occurred:

...

TypeError: `generator` yielded an element that did not match the expected structure....
```

Are you returning 4 or 5 elements?",1.0
ftfuqvp,gzd80i,This is not supported.  Would TensorBoard.dev meet your use case?,1.0
ftfw4ca,gzd80i,"&gt;TensorBoard.dev 

I tried [TensorBoard.dev](https://TensorBoard.dev), it is good. Maybe I will try it later because users do not need to set ports and other manual settings.",1.0
ftdks8r,gyztyh,"Yes and no, that depends on your computational graph structure. Think of a river splitting into multiple branches. If you build a dam on one branch, the water will still flow through the other branches.",3.0
ftdmhel,gytjth,https://www.tensorflow.org/api_docs/python/tf/clip_by_value,2.0
fte7xde,gytjth,Thank you!,1.0
fthng8u,gytjth,This is very commonly done by means of activation functions like sigmoid. You can also use custom activation functions. I would generally recommend something that produces a continuous activation. Basic operations like tf.math.minimum and tf.clip\_by\_value will do it in a more crude way.,2.0
ftcrea0,gyss58,"Before Tensorflow 2 you had to install tensorflow-gpu instead of tensorflow. 

Now its automatic. Just have CUDA and Cudnn installed. They just be a specific version though. 
https://www.tensorflow.org/install/gpu",1.0
ftdzt1c,gyss58,Its already installed i just need to know how to use it. Its it automatic or is there a specific command I have to run? Also I want to know how to switch between the 2.,1.0
ftf3mpq,gyrtqu,I re-ran the job with no changes and was able to get my training loss to show up on tensorboard /***shrug***,1.0
ft9qimx,gyc9qy,"Not to worry, 

Difference in first two examples is because of you have trained model in python under numpy with 'float32', but in javascript you simply used primitive float type which is float64 in default, that's why there's a slight difference in values

&amp;#x200B;

For the last example, you normalized your data from -1 to 1, which is not how you pretrained the model (0 to 1).",1.0
ft9tn9l,gyc9qy,"Thanks, so back to first example, I found a [thread](https://stackoverflow.com/questions/56649680/tensorflow-vs-tensorflow-js-different-results-for-floating-point-arithmetic-comp) about how TFJS handle float precision under the hood.

I understood that it's mainly due to webgl and by switching to CPU as backend I should have same result as in python  (it was not the case :( ).

&amp;#x200B;

Anyhow thanks for your help.",1.0
ftajxnv,gy9nc6,"Dunno about documentation, but it sounds like you already figured it out. In math if `X` is an `M x N` matrix and `Y` is `U x V`, then `X * Y` is only defined if `N = U` in which case the result has the shape `M x V`.

With Tensorflow you can multiply matrices in batches, in which case you have 3D matrices of the shape `B x M x N` and `B x U x V`, where `B` is the batch size. Then this yields a new 3D matrix (or you can think of them as a set of 2D matrices) with the shape `B x M x V`.",3.0
ftbf6no,gy9nc6,"Thanks a lot for taking out time to write this. It would be nice if you can comment on how this generalizes and work for higher rank tensors, maybe with some examples. I really want to understand this through. It's such a basic operation and the lack of documentation or proper tutorial is making me crazy.",1.0
ft8tzfn,gy6kvz,"According to https://www.tensorflow.org/install/gpu, tf 2 only supports cuda 10.1. Your cudnn lib version is 11.

tf with gpu is very picky with cudnn lib version.

I would advise you to use the `conda` toolset to install and manage the tf versions and its dependencies.",6.0
ft96p93,gy6kvz,"Hi, once I hade similar problem. You can check my video instruction how to solve it. Maybe it helps you.

https://youtu.be/BQ6bxQ-7h8Y

.. and it doesn't need to be tensorflow-gpu anymore. They put everything together in tensorflow.",1.0
fthhfv9,gy6kvz,Like other comments I think the problem is cuda 11. At the moment tensorflow doesn’t support cuda 11. Try with 10.1,1.0
ft89npm,gy124p,very cool,1.0
ft7c1qk,gxxchw,"Hi [u/axelwang](https://www.reddit.com/user/axelwang/) \--

Sometimes different programming languages use different definitions of the FFT.  That is, they choose different conventions on where to put the normalization.  There are 3 fairly common conventions:

(i) all of the normalization is applied to the forward transform,(ii) all of the normalization is applied to the inverse transform, or(iii) the normalization is applied equally to both forward and inverse transforms

The FFT in these 3 cases looks like:

(i)     ∑ x\[k\]exp(-2πimk/N)

(ii)    (1/N)∑ x\[k\]exp(-2πimk/N)

(iii)   (1/√N)∑ x\[k\]exp(-2πimk/N)

I usually refer to these things as the under-normalized, over-normalized, and symmetric definitions of the FFT.  You run into this often when you switch between scientific computing platforms.

For example, in grad school, I used MatLab for some projects and another language called IDL for others (don't worry if you've never heard about IDL -- seems most people haven't).  When I was using MatLab, it was employing the under-normalized FFT convention (and, correspondingly, the over-normalized IFFT), whereas IDL uses the over-normalized FFT convention (and with it, the under-normalized IFFT).  I've never used Mathematica too much, but I've read it uses the symmetric FFT convention.  (This is all according to some notes I have in an old lab notebook, which I got out just to tell this story.)

In all three cases, if you apply a forward and inverse transform, you should more-or-less get the same answer back.  However, similar to your current situation, if you just apply the forward transform, the results can look wildly different in one FFT implementation versus another (but it should only differ up to a normalization constant).  This can seem confusing if you are unaware of the normalization convention being used.

Having said all this, I suspect your case might be different.

I didn't immediately find great documentation on TF's FFT implementation, so I just did a quick comparison test of NumPy's FFT w/ TensorFlow's FFT on a simple signal: they produced the same results.  Luckily, NumPy has decent documentation: ([https://numpy.org/doc/stable/reference/routines.fft.html#module-numpy.fft](https://numpy.org/doc/stable/reference/routines.fft.html#module-numpy.fft)).

Drum roll, please...

NumPy uses the under-normalized FFT convention:  ∑ x\[k\]exp(-2πimk/N)

This is the same convention that MatLab uses -- at least several years ago, when I was still using it.  Just to be sure, I pulled up their documentation and found that, yes, it's true -- MatLab uses the same FFT convention as NumPy ([https://www.mathworks.com/help/matlab/ref/fft.html](https://www.mathworks.com/help/matlab/ref/fft.html)).

And since TensorFlow seems to use the same normalization convention as NumPy, by the transitive property it uses the same normalization convention as MatLab.  So at least up to the normalization convention of the FFT, your MatLab and TensorFlow results should be the same...  However, there is one more convention to consider!

The next thing to figure out is how the FFT computation returns values with respect to the negative and positive frequencies.  NumPy spits out values for positive frequencies followed by the values for negative frequencies.  It was hard to find the MatLab documentation, but from several forum Q&amp;A's I saw during a quick Google search, it appears that MatLab's FFT spits out values for the negative frequencies first, followed by the positive frequencies.

So this could be your problem:  try looking only at the positive frequency values in TensorFlow (0:N/2, assuming it continues to follow NumPy's conventions) and in MatLab (N/2:N).",2.0
ft7jegw,gxxchw,"Thank you so much! I really appreciate all the diggings that you are doing to trying to help me out!

I added a figure in my original post, which is a direct comparison of FFT  results from MATLAB (red) and TF (blue). You can see it's nothing like a normalization or shifting issue. TF's result doesn't even look like a Fourier Transform as it only has one peak, at the wrong place and with the wrong magnitude.

I am actually able to confirm that MATLAB does spit out the positive frequencies first. See this [link](https://www.mathworks.com/help/signal/ref/hilbert.html) from MathWorks, scroll down to the Algorithms section. In fact, my bigger goal here is exactly to replicate this Hilbert transform algorithm in tensorflow. But the end results again are very different, and I was able to track it down to the differences of FFT. I have confirmed that the inputs to FFT functions in both platforms are exactly the same (so basically I just read in the MATLAB FFT input to tensorflow, removing even the 10\^-8 difference from calculating the mean, but as expected this didn't do anything).

Thank you so much for the help again!",2.0
ft7wzab,gxxchw,"Hilbert transform, eh?  Ok, so I apologize if my response was too basic!  You certainly have some background in this stuff.

In case it helps: Currently, I am using TF2.2 on my MacBook Pro.

I just did a simple test again (using both NumPy and TensorFlow) and things generally looked fine. 

```python
import tensorflow as tf
import numpy as np
import matplotlib.pyplot as plt

# Generate time series
#  - should more-or-less be zero-mean, but I'll 
#    subtract a mean just to better compare to yours
N=1001
t = np.linspace(-10,10,N)
signal = 3*np.sin(2*np.pi*20*t) + 7*np.sin(2*np.pi*9*t) + 11*np.cos(2*np.pi*2*t) + 17*np.cos(2*np.pi*(1/4)*t)
np_signal = signal - np.mean(signal)
tf_signal1 = signal - np.mean(signal)
tf_signal2 = tf.dtypes.cast(signal - tf.math.reduce_mean(signal), tf.complex64)

# Sanity check 1
plt.plot(t,signal);
plt.plot(t,tf.math.real(tf_signal2));
plt.plot(t,tf.math.imag(tf_signal2))

# Compute FFT Power for both NP and TF 
#  -- pretend for a moment we do not need a window function!
fftfreq = np.fft.fftfreq(N)
np_fft_power = np.power(np.abs(np.fft.fft(np_signal)),2)
tf_fft_power1 = tf.math.pow(tf.math.abs(tf.signal.fft(tf_signal1)),2)
tf_fft_power2 = tf.math.pow(tf.math.abs(tf.signal.fft(tf_signal2)),2)


# Sanity Check 2: Plot 'em
plt.plot(fftfreq, np_fft_power);
plt.plot(fftfreq, tf_fft_power1);

# Sanity Check 3: Do I get back expected amplitudes?
#  -- 3, 7, 11, 17
plt.plot(fftfreq, 2*np.sqrt(np_fft_power/N**2));
plt.plot(fftfreq, 2*np.sqrt(tf_fft_power1/N**2));
plt.plot(fftfreq, 2*np.sqrt(tf_fft_power2/N**2));
```

Everything works out as expected.",2.0
ftapmt6,gxxchw,"Thank you again! Your original answer was very informative! I definitely didn't approach this as systematically as you did. It was very helpful! 

I just noticed that actually tensorflow's FFT did NOTHING on my input. It returned exactly the same array as my input. It is very strange. My input array is a series of normalized numbers, with maximum equal to 1, but there are many small values like 10\^-6 as well. 

I ran your code and was able to confirm your result. Your input does not have as huge a range as mine, so I am not sure whether this could be the problem? Though I can't think of any reason to justify it. 

&amp;#x200B;

Really baffled now about what would cause TF's FFT to just do nothing.

&amp;#x200B;

Thanks.",2.0
ftb76el,gxxchw,"Problem solved! Turns out if you want to pass in an array to tf.fft(), then this array has to be a 1D NumPy array but not a 2D NumPy array with one of the dimensions = 1.",1.0
ftd9ja7,gxxchw,"Glad you figured it out.

Considering that you are dealing with a time series of high dynamic range, I was going to ask if you are using a hanning window or anything to help the FFT cope with it.  But the solution definitely came from an entirely different direction.

In related news:

Seems restrictive that TF's FFT demands a 1D array.  Yes, it's used to compute the 1D FFT, but it would be more useful if it could compute multiple 1D FFTs at once, e.g., if it could take an input array like NxC, where N is the time series length and C is the number of channels.  For example, when working with accelerometer data, you might want to compute three 1D FFTs on all three components at once.

Either way, the documentation can certainly use some work:

    fft(input, name=None)
    
        Fast Fourier transform.Computes the 1-dimensional 
        discrete Fourier transform over the inner-most
        dimension of `input`.
    
        Args:
            input: A `Tensor`. Must be one of the following 
                types: `complex64`,`complex128`. A complex 
                tensor. name: A name for the operation 
                (optional).
    
        Returns:
            A `Tensor`. Has the same type as `input`.

Edit: code formatting",1.0
fte9c62,gxxchw,"&gt;transform.Computes the 1-dimensional   
discrete Fourier transform over the inner-most  
dimension of \`input

I think this script from TF's doc might be the key. It should be able to compute over several 1D arrays, just we need to be careful about this  ""inner most dimension"". I found my mistake by comparing line by line with your earlier code, and noticed this array size difference in the inputs.",2.0
ftg9w91,gxxchw,"Oh, wow - how embarrassing for me.  Helping you sort through this has been my first time tinkering with TF's FFT.  I (mis)read its documentation and somehow interpreted incorrectly -- that it could only handle one 1D signal at a time.  Worse, I hadn't even tried to verify!

However, you're right:  TF's FFT can certainly do a stack of 1D signals simultaneously.  But with a slight shift from my expectation. 

When passing a stack of 1D signals to `tf.signal.fft`, my expectation is that it should be like passing a stack of 1D signals as an input to a Conv1D layer, which takes an input tensor with shape like (B,N,C) = (batchSize, timeSeriesLength, numChannels).  However, this is not the case.  Instead, TF's FFT takes an input like (B,C,N) = (batchSize, numChannels, timeSeriesLength).  

This inconsistency is semi-irritating, and it's potentially harmful: the user will not get an error or warning if they mistakenly assume the FFT takes time series inputs the same way a Conv1D layers does (NxC instead of CxN).  If this mistake is made, the FFT will spit out numbers without complaint. At first glance, things look right because the output dimensions align with expectation (e.g., a NxC). But as you noticed, upon closer examination, everything is wrong -- the numbers do not make sense.  Plotting the spectra will show a noisy mess.

I'll leave a code snippet here for any lurkers it might help down the line.

```python
import numpy as np
import tensorflow as tf

#----------------------------------------------------------
# Create two N-point signals sampled at 50Hz (0.02 seconds) 
#----------------------------------------------------------
N = 1001
t = np.linspace(-10,10,N)
freqs = np.fft.fftfreq(N, d=1/50)

amp1 = [3, 7, 11, 17]
signal1 = amp1[0]*np.sin(2*np.pi*12*t) + amp1[1]*np.sin(2*np.pi*9*t) + \
    amp1[2]*np.cos(2*np.pi*2*t) + amp1[3]*np.cos(2*np.pi*(1/4)*t)

amp2 = [2, 5, 12, 23]
signal2 = amp2[0]*np.sin(2*np.pi*17*t) + amp2[1]*np.sin(2*np.pi*5*t) + \
    amp2[2]*np.cos(2*np.pi*3*t) + amp2[3]*np.cos(2*np.pi*(1/10)*t)

#----------------------------------------------------------
# Create several sanity functions to re-use throughout
#----------------------------------------------------------
#  i. Sanity Plots
def sanity_plots(powers, amplitudes):
  ax=None
  for i,(power,amplitude) in enumerate(zip(powers,amplitudes)):
    ax = plt.subplot(1,2,i+1, sharey=ax)
    for amp in amplitude:
      ax.axhline(amp, color='red', linestyle='--')
    ax.plot(freqs, 2 * np.sqrt(power)/N, color='black')

# ii. Sanity Numbers
def sanity_numbers(power1, power2, compare_to=None, show=5):
  print('P1:', power1[:show])
  print('P2:', power2[:show], end='\n\n')
  if compare_to is not None:
    assert len(compare_to)==2 and isinstance(compare_to,(list,tuple)),\
      'Oops: comparisons = [compare_to_power1, compare_to_power2]'
    print('Comparison 1:', 
          (power1[:show] == compare_to[0][:show]).numpy().tolist())
    print('Comparison 2:', 
          (power2[:show] == compare_to[1][:show]).numpy().tolist())

# iii. Sanity Shapes
def sanity_shapes(signal, power, expected_shape):
  print(f'Does signal have expected shape of {expected_shape}?\n', 
        signal.shape == expected_shape)
  print(f'Does power have expected shape of {expected_shape}?\n', 
        power.shape == expected_shape)

# (A) Start simple:  2-sided power spectra using TF's FFT on single signals
#  -- no batch dimension, no channel dimension
f1 = tf.signal.fft(signal1)
f2 = tf.signal.fft(signal2)
p1 = tf.math.pow(tf.math.abs(f1),2)
p2 = tf.math.pow(tf.math.abs(f2),2)

# Define freqs for plotting
freqs = np.fft.fftfreq(N)

""""""
Try out the sanity functions.  Note that the
sanity plots and sanity numbers for these simple,
single-channel time series will be considered our
GOLD STANDARDS -- this is what things should look like
as we add more complexity (i.e., channel and batch
dimensions).
""""""
sanity_shapes(f1, p1, expected_shape=(N,)) 
sanity_plots(powers=[p1,p2], amplitudes=[amp1,amp2])
sanity_numbers(p1,p2)

#----------------------------------------------------------
# (B) Get slightly more complex:  Add Channel Dimension
#----------------------------------------------------------
""""""
In part (B), we want to figure out if we can use tf.signal.fft to compute
the 1D FFTs for each 1D channel in a multi-channel time series.  We only
consider a 2-channel time series, but the results generalize to any number
of channels.
""""""
# (B1) WRONG WAY:  Consider signal1 and signal2 as a NxC time series (as you would with Conv1D)
signal1_Nx1 = signal1[...,np.newaxis] 
signal2_Nx1 = signal2[...,np.newaxis]
signal_Nx2 = np.concatenate([signal1_Nx1, signal2_Nx1], axis=1)
# Could also do: signal_Nx2 = np.vstack([signal1,signal2]).T
f_Nx2 = tf.signal.fft(signal_Nx2)
p_Nx2 = tf.math.pow(tf.math.abs(f_Nx2),2)

# Quick Sanity Check on Shape
#  -- we intended to shape this N-point, 2-channel signal as Nx2 tensor,
#     like we would for Conv1D
sanity_shapes(signal_Nx2, p_Nx2, (N,2))

# Sanity Plots
""""""
This immediately shows that something is way off.  The powers are orders
of magnitude smaller than their expected amplitudes would suggest.  In 
fact, on this plot, the powers almost look like a flat black line near 
zero since the overplotted horizontal lines denoting the expected amplitudes 
are so much bigger (e.g., maxxing out near 20).
""""""
sanity_plots(powers=[p_Nx2[:,0],p_Nx2[:,1]], amplitudes=[amp1,amp2])

# Sanity Plots (Take 2)
""""""
Something is clearly wrong with the plots, so let's look a little closer.
Here, by setting the amplitudes to empty lists, we show the powers close 
up.  You can see that they looks nothing like the expected power spectrums,
both of which should have 4 clean peaks on each side of zero.
""""""
sanity_plots(powers=[p_Nx2[:,0],p_Nx2[:,1]], amplitudes=[[],[]])

# Sanity Numbers (just to be thorough!)
""""""
This shows that none of the numbers match the corresponding values
from the simple, single-channel spectra (shape=(N,)) we computed above.  Something
is definitely wrong... But what?  Read on to find out.
""""""
sanity_numbers(p_Nx2[:,0], p_Nx2[:,1], compare_to = [p1,p2])

# (B2) RIGHT WAY:  Consider signal1 and signal2 as a CxN time series (not a 
#    a NxC time series as you would with Conv1D)
signal1_1xN = signal1[np.newaxis,...]
signal2_1xN = signal2[np.newaxis,...]
signal_2xN = np.concatenate([signal1_1xN, signal2_1xN], axis=0)
# Could also do:  signal_2xN np.vstack([signal1,signal2])
f_2xN = tf.signal.fft(signal_2xN)
p_2xN = tf.math.pow(tf.math.abs(f_2xN),2)

# Quick Sanity Check on Shape
#  -- we intended to shape this N-point, 2-channel signal as 2xN tensor
sanity_shapes(signal_2xN, p_2xN, (2,N))

# Sanity Plots
""""""
This immediately shows us the exact plots we expected from
plotting out the simple, single-channel time series (shape=(N,))
in part (A).  
""""""
sanity_plots(powers=[p_2xN[0],p_2xN[1]], amplitudes=[amp1,amp2])

# Sanity Numbers (again, just to be thorough!)
""""""
This shows that all of the numbers match the corresponding values
from the simple, single-channel spectra (shape=(N,)) we computed above.  This
confirms it:
* TF's FFT can compute the 1D FFTs for a stack of 1D signals (i.e., a 
  multi-channel time series)
* you must stack the signals so that the resultant shape is (C,N),
  where C is the number of signals getting stacked (i.e., number of channels
  in the multi-channel time series) and N is the time series length (number of
  points per channel)
* this shape is not congruent with the shape used for tf.keras.layers.Conv1D,
  which expects the signals to be stacked such that the resultant shape is (N,C)
""""""
sanity_numbers(p_2xN[0], p_2xN[1], compare_to = [p1,p2])

#----------------------------------------------------------
# (C) Full complexity: Add a batch dimension
#----------------------------------------------------------
""""""
In part (B), we found that tf.signal.fft can work with multi-channel time 
series. Now, in part (C), we really want to know if tf.signal.fft can 
successfully work on batches of multi-channel time series at once.  For
example, this would come in handy if we have 3-axis accelerometer data and 
3-axis gyroscopic data from a mobile phone that has been sliced into 20-second 
windows stepped forward in time every 10 seconds over several hours of
recording.  In this scenario, we would have about 360 windows per hour.  
Obviously computing 1 spectrum at a time would be needlessly slow:  can we
compute a batch of them all at once?  Here, out input array will look like 
(B,C,N) = (batchSize, numberOfChannels, timeSeriesLength).

For simplicity, let's look at a 2-channel time series that is
sliced into 1001-point windows (like above) and where each window
has the same signals (so we can show that tf.signal.fft is 
computing things correctly across the batch).
""""""
signal_1x2xN_w1 = np.vstack([signal1,signal2])[np.newaxis]
signal_1x2xN_w2 = np.vstack([signal1,signal2])[np.newaxis]
signal_1x2xN_w3 = np.vstack([signal1,signal2])[np.newaxis]
signal_3x2xN = np.vstack([signal_1x2xN_w1, signal_1x2xN_w2, signal_1x2xN_w3])

f_3x2xN = tf.signal.fft(signal_3x2xN)
p_3x2xN = tf.math.pow(tf.math.abs(f_3x2xN), 2)

# Sanity Stuff
""""""
Everything works out!
""""""
sanity_shapes(signal_3x2xN, p_3x2xN, expected_shape=(3,2,N))

sanity_plots(
    powers=[p_3x2xN[0,0], p_3x2xN[0,1]], 
    amplitudes=[amp1, amp2]
)

sanity_plots(
    powers=[p_3x2xN[1,0], p_3x2xN[1,1]], 
    amplitudes=[amp1, amp2]
)

for i in range(3):
  sanity_numbers(p_3x2xN[i,0], p_3x2xN[i,1], compare_to = [p1,p2])
  print()
```

Great, but that's not enough, right?  Ultimately, we want to plug this thing into some convolutional or recurrent layers of some kind.  To do this, one has to make use of some Lambda layers (or some other trick).  Here is how I did it:",1.0
ftg9yi3,gxxchw,"(Above post exceeded maximum number of characters...right at the climax!)

As I was saying, here is how I got it all working together:

```python
import tensorflow as tf

# Define layers
visible = tf.keras.layers.Input((2,1001))
fft     = tf.keras.layers.Lambda(lambda x: tf.signal.fft(tf.cast(x, dtype=tf.complex64)))(visible)
power   = tf.keras.layers.Lambda(lambda x: tf.math.pow(tf.math.abs(x), 2))(fft)
reshape = tf.keras.layers.Lambda(lambda x: tf.einsum(""aij...-&gt;aji..."", x))(power)
conv1   = tf.keras.layers.Conv1D(filters=8, kernel_size=3, strides=2, activation='relu')(reshape)
conv2   = tf.keras.layers.Conv1D(filters=32, kernel_size=3, strides=2, activation='relu')(conv1)
flat    = tf.keras.layers.Flatten()(conv2)
dense1  = tf.keras.layers.Dense(128, activation='relu')(flat)
output  = tf.keras.layers.Dense(1, activation='softmax')(dense1)

# Create model
model   = tf.keras.models.Model(visible, output)

# Run simple test
model.predict(signal_1x2xN_w2)
```",2.0
fuvj69k,gxxchw,Wow! Just saw this and can't appreciate more for your knowledge and help!,2.0
ft53ukv,gxow9t,"Everyone with a brain does this. 

Computers can do it too. 

Neat.",4.0
ft926bv,gxow9t,Best thing is they do in milliseconds...,1.0
ft6v13u,gxow9t,"This will be great for photoshop, and also extracting objects to train for image generation. :D

But does this require a human to do the initial masking to train on?  
Can it handle split masking? like extracting a horse that's split in half due to a pole on the foreground. 

Can you you do masking and image recognition in one step? Or do you need to first perform image recognition first?",3.0
ft7ml22,gxow9t," the current model is trained on a public dataset, if you expect very precise then that data should be feeded again to make it better than its current state",1.0
ft91cbx,gxow9t,I tried to download your model. It looks like it requires permission. I've sent an email doing so thanks.,1.0
ft91t05,gxow9t,You can check now,1.0
ft93as6,gxow9t,Thanks. Getting ValueError: You are trying to load a weight file containing 164 layers into a model with 162 layers. I'm using dut\_omron416.h5,1.0
ft94znc,gxow9t,"Open the issue on the repo, so i can address it",1.0
ft95144,gxow9t,OK,1.0
ft27u56,gxdf9d,"As this is not a pattern detection problem, you should probably use Dense Layers",2.0
ft1ydqk,gxdf9d,But why do you want to use a convolution layer here?,1.0
fsz3ux2,gx4xdy,Could you please stop using the nod32 mascot 😄? I can't regard this stuff as serious with such images.,1.0
fsz5ssb,gx4xdy,"hahaha, yeah I get it :)
I will, thanks for the feedback",1.0
fsys02m,gx37z7,"Depending on your use-case, you could have the model running on Google Colab.  

However, if you need it callable as an API, then that's not the way to go.  You could use free credit on cloud platforms such as GCP, or AWS.  Can you give more details of what your use-case is?",2.0
fsysink,gx37z7,"Hi my model has been developed locally on a notebook and I have written a simple script for API calls with flask. I just want a lightweight, free solution for an Api endpoint. I've already tried heroku but the it exceeds the limit when the model is being loaded. Much thanks:)",1.0
fsz4juz,gx37z7,"GCP might be the way to go, since they do $1,200 worth of free credit, whereas AWS is only some classes or services which are free.  However, it might be worth emailing people at your school to see if they have any free credit available for any of the big cloud hosting providers, as there are often education grants that are given (e.g. [`https://edu.google.com/programs/credits/teaching/`](https://edu.google.com/programs/credits/teaching/)`)`",1.0
fsybwvy,gx062t,"Your code need some changes, first you don't need the Flatten layer because LSTM are already 1d array, fun fact you can actually use Conv1D for NLP, second you output number if the size of the vocabulary, here you should use sparse loss, if not you'll  create unnecessary array for you decoder\_targets arrays.  instead of MAX\_PADDING you should put None, you don't need to specify the length on a Embedding layer.

&amp;#x200B;

decoder\_outputs = Flatten()(decoder\_outputs)  # Remove this

decoder\_dense = Dense(vocabulary\_size, activation='softmax',name='decoder\_dense') decoder\_outputs = decoder\_dense(decoder\_outputs)

&amp;#x200B;

Pro tip:

Here I would recommend you to use sparse loss, create your dataset as in the tutorial, you could as BPE as an encoding method, much more efficient than working with words.",2.0
fsye2jh,gx062t,Thanks for your reply. I will try your changes.,1.0
fsz996v,gx062t,"I wrote an example you could take it and try to use it for yourself.

&amp;#x200B;

    import tensorflow as tf
    
    from tensorflow.keras.models import Model
    
    from tensorflow.keras.layers import Input, Embedding, Dense, LSTM
    
    import numpy as np
    
    from bpemb import BPEmb

&amp;#x200B;

    # Load models with embedding size of 100 and vocabulary size of 1000

&amp;#x200B;

    vocab_size = 3000
    
    emb_size = 100
    
    batch_size = 32
    
    num_samples = 1024 * 4
    
    latent_dim = 512
    
    epochs = 1024

&amp;#x200B;

    bpe_en = BPEmb(lang='en', dim=emb_size, vs=vocab_size)
    
    bpe_fr = BPEmb(lang='fr', dim=emb_size, vs=vocab_size)

&amp;#x200B;

&amp;#x200B;

    inputs, outputs = [], []

&amp;#x200B;

    lines = open('fra.txt', 'r', encoding='utf-8').read().lower().split('\n')[:num_samples]

&amp;#x200B;

    for line in lines:
    
    	inp, out, _ = line.split('\t')
    
    	inputs.append(inp)
    
    	outputs.append(out)

&amp;#x200B;

&amp;#x200B;

    # Convert sentences to bpe encodings
    
    input_seqs = [bpe_en.encode_ids_with_eos(x) for x in inputs]
    
    output_seqs = [bpe_fr.encode_ids_with_eos(x) for x in outputs]

&amp;#x200B;

    max_input_len = max([len(x) for x in input_seqs])
    
    max_output_len = max([len(x) for x in output_seqs])

&amp;#x200B;

    print('Max input sequence: ', max_input_len)
    
    print('Max output sequence: ', max_output_len)

&amp;#x200B;

    # Create data to pass to the model
    
    encoder_inputs  = np.zeros((num_samples, max_input_len), dtype=np.int64)
    
    decoder_inputs  = np.zeros((num_samples, max_output_len), dtype=np.int64)
    
    decoder_outputs = np.zeros((num_samples, max_output_len), dtype=np.int64)

&amp;#x200B;

    for i, sent in enumerate(input_seqs):
    
    	for k, sub in enumerate(sent):
    
    		encoder_inputs[i, k] = sub
    
    		
    
    for i, sent in enumerate(output_seqs):
    
    	for k, sub in enumerate(sent):
    
    		decoder_inputs[i, k] = sub
    
    		if k &gt; 0:
                        decoder_outputs[i, k - 1] = sub
    
    
    # see a little bit of the first sample
    print(encoder_inputs[0])

&amp;#x200B;

&amp;#x200B;

    # Create model

&amp;#x200B;

    encoder_input = Input(shape=(None,))
    
    encoder_emb = Embedding(vocab_size, emb_size)(encoder_input)
    
    encoder = LSTM(latent_dim, return_state=True)
    
    encoder_outputs, h, c = encoder(encoder_emb)
    
    states = [h, c]

&amp;#x200B;

    decoder_input = Input(shape=(None,))
    
    decoder_emb = Embedding(vocab_size, emb_size)(decoder_input)
    
    decoder = LSTM(latent_dim, return_state=True, return_sequences=True)
    
    outputs, _, _ = decoder(decoder_emb, initial_state=states)
    
    output = Dense(vocab_size, activation='softmax')
    
    fc = output(outputs)

&amp;#x200B;

    model = Model([encoder_input, decoder_input], fc)
    
    loss = tf.keras.losses.SparseCategoricalCrossentropy()
    
    metric = tf.keras.metrics.SparseCategoricalAccuracy('accuracy')
    
    model.compile(optimizer='adam', loss=loss, metrics=metric)

&amp;#x200B;

    model.fit([encoder_inputs, decoder_inputs], decoder_outputs, epochs=epochs)",2.0
ft00e3f,gx062t,Amazing! Thank you man.!!!!!!,1.0
fv11k8n,gx062t,"Hi, please, could you help me to write the predictor? I get an error that I don't understand. Many Thanks.

    Traceback (most recent call last):
      File ""predict\_seq\_to\_seq\_word\_based.py"", line 119, in &lt;module&gt; 
      output\_seqs = decode\_sequence(encoder\_inputs)
      File ""predict\_seq\_to\_seq\_word\_based.py"", line 89, in decode\_sequence
     output\_tokens, h, c = decoder\_model.predict( \[target\_seq\] + states\_value)
      ...
    ValueError: Data cardinality is ambiguous:
      x sizes: 1, 59, 59
    Please provide data which shares the same first dimension.

Seems that the dimension if input Tensor in the decoder are not good. 

From the code that you wrote,  I saved the trained model into h5 file. 

In this example I loaded this this way.

`model = load_model('./eng-fra.h5')`

Then, first I re-build the chain from the pre-trained model

1 - Encoder

    encoder_inputs  = model.input[0]
    encoder_outputs, h, c =  model.get_layer(""lstm"").output
    encoder_states = [h, c]
    encoder_model = Model(encoder_inputs, encoder_states)

2 - Encoder

    decoder_input = Input(shape=(None,))
    decoder_inputs = model.get_layer(""embedding_1"")(decoder_input)
    decoder_state_input_h = Input(shape=(latent_dim,))
    decoder_state_input_c = Input(shape=(latent_dim,))
    decoder_states_inputs = [decoder_state_input_h, decoder_state_input_c]
    
    decoder_lstm = model.get_layer(""lstm_1"")
    decoder_outputs, state_h, state_c = decoder_lstm( decoder_inputs, initial_state=decoder_states_inputs)
    decoder_states = [state_h, state_c]
    
    decoder_dense = model.get_layer(""dense"")
    decoder_outputs = decoder_dense(decoder_outputs)
    decoder_model = Model( [decoder_input] + decoder_states_inputs, [decoder_outputs] + decoder_states)

3 - Create the function to convert bpe id to word

    def reverse_target_word_index(word):
        return bpe_fr.decode_ids(word)

4 - Create the function to decode the sequence

    def decode_sequence(input_seq):
    	
        # get the status from input seq
        states_value = encoder_model.predict(input_seq)
        
        # Generate empty target sequence of length 1.
        target_seq = np.zeros((1 , 1, max_output_len))
        stop_condition = False
        decoded_sentence = ''
        while not stop_condition:
            output_tokens, h, c = decoder_model.predict( [target_seq] + states_value)   
    # PROGRAM BLOCKS HERE, CODE BELOW IS NOT TESTED YET &lt;---HERE---&gt;
    
            # Sample a token
            sampled_token_index = np.argmax(output_tokens[0, -1, :])
            sampled_word = reverse_target_word_index(sampled_token_index)
            decoded_sentence += sampled_word
    
    
            # to be improved
            if ( len(decoded_sentence) &gt; num_decoder_tokens) :
                stop_condition = True
    
            # Update the target sequence (of length 1).
            target_seq = np.zeros((1, 1, latent_dim))
            target_seq[0, 0, sampled_token_index] = 1.
    
            # Update states
            states_value = [h, c]
    
        return decoded_sentence
    
    
    # RUN THE CODE 
    to_be_translate = ""the car is blue""
    
    #convert the text in bpe
    input_seqs = bpe_en.encode_ids_with_eos(to_be_translate)
    
    #create the sequence
    encoder_inputs  = np.zeros((max_input_len), dtype=np.int64)
    for i in range(0,len(input_seqs)-1):
         encoder_inputs[i]=input_seqs[i]
    
    # run predictor
    output_seqs = decode_sequence(encoder_inputs)
    print(output_seqs)

&amp;#x200B;

the code is going to error in this line

    output_tokens, h, c = decoder_model.predict( [target_seq] + states_value) 

Seems that the dimension of **target\_seq** is not good ... 

Do you have any idea?",1.0
fv19pbw,gx062t,"Target seq should be (1, maxlen)",2.0
fv3tqhq,gx062t,"maybe there is an error in shaping the inputs of the model...

**target\_seq =** **np.zeros( (1, maxlen) )** doesn't work, but it *""works*"" with **target\_seq =** **np.zeros( (maxlen,1 ) )**

The shape of  **output\_tokens**  is (**maxlen,1,vocab\_size)**

at the end

*to get the most likely index*

**sampled\_token\_index = np.argmax(output\_tokens\[0, -1, :\])**

**Do you think that it is wrong?**",1.0
fsx1tec,gwsbk7,"You could take efficientNet and grab n first layers and fine tune for your task. How much speed you need in FPS given the hardware than you'll use for inference?

Other ways to improve in to quatatize or pruning the model and then convet to onnx to infer using caffe backend.",2.0
fsx5kkx,gwsbk7,"I have a constraint, I will be using TFJS in browser on mobile devices : typical device would be mid-market phone (android).",1.0
fsx8lo9,gwsbk7,What kind of image classification will you  be doing? Mobilenet runs very well on Android.,1.0
fsx9er9,gwsbk7,"labeled images (2 labels), a very ""simple"" classification. (labels &amp; images very domain specific, not available in mobilenet as is)",1.0
fsx9scx,gwsbk7,"Yes, it not available on mobinet, but you can take the pretrained model and fine-tune to your task.",1.0
fsytsrt,gwsbk7,thanks I will try mobilenet and  efficientNet.,1.0
ft7e8p5,gwsbk7,"u/limapedro I used VGG16 and built my model, it have an accuracy near 90%.

I did convert it to TFJS, and when comparing results for pictures ... prediction values looks different.

Below my code and result with an example  :

In notebook (python)  :

&gt;xtensor = xtensor.astype('float32') / 255  
&gt;  
&gt;prob = model.predict(xtensor)  
&gt;  
&gt;print(prob)  
&gt;  
&gt;=&gt;  \[\[0.63048106\]\]

In browser (chrome) with TFJS : (normalization hint found here [https://stackoverflow.com/a/55285965/12828362](https://stackoverflow.com/a/55285965/12828362) )

&gt;xtensor = xtensor.expandDims(0).sub(127).div(127);  
&gt;  
&gt;var prob = model.predict(xtensor);  
&gt;  
&gt;console.log(prob.print());  
&gt;  
&gt;=&gt;\[\[0.5954741\],\] (lower than value in python)

same ""normalization""  approach 

&gt;xtensor = xtensor.expandDims(0).div(255);  
&gt;  
&gt;var prob = model.predict(xtensor);  
&gt;  
&gt;console.log(prob.print());  
&gt;  
&gt;=&gt;\[\[0.6505585\],\]  (higher than value in python)

&amp;#x200B;

is this normal ? also I didn't use the exact operation for the normalization, does this have an impact on the prediction ?",1.0
fsx4a5h,gwkxwd,"Update:

Figured it out on my own. You can just use a lambda layer to use any function you want in a layer, in this case, tf.nn.local_response_normalization()

&gt; tf.keras.layers.Lambda(tf.nn.local_response_normalization)",2.0
fsvcsnk,gwh6me,"This is really cool, I’m assuming the other videos are on your YouTube channel? Would you post a link to the channel itself? 

Thanks in advance, I’d like to check out your series but the way Apollo handles YouTube links doesn’t tell me what your channel name is.",2.0
fsvxrn6,gwh6me,Thank you for your interest! This video is part of a playlist. Here's the link to my channel: https://www.youtube.com/channel/UCZPFjMe1uRSirmSpznqvJfQ,2.0
fswhtod,gwh6me,"hey, i've been trying to learn how to make tensorflow elevate someone's voice in an audio where everyone's voice is at equal decibel level. if you need ideas for a tutorial you might wanna try that. i'm sure stumped.",1.0
fsy3k2s,gwh6me,Thank you for the idea!,1.0
fsuuot2,gwgdal,"TF2 savedmodels don't save that style of signature by default.

I bet if you call the thing you loaded it will run.

If you want a savedmodel signature, see this section:
 
https://www.tensorflow.org/guide/saved_model#specifying_signatures_during_export",2.0
fsuvkzx,gwgdal,"Thanks for your response.

I did try to infer the saved model but it didn't work.

Further, I did try to export signature from the link you shared. But at `call = module.__call__.get_concrete_function(tf.TensorSpec(None, tf.float32))`, I didn't get what to replace `tf.TensorSpec(None, tf.float32)` with.",1.0
fsvj5dy,gwgdal,"&gt; I did try to infer the saved model but it didn't work.

Can you be more specific? what went wrong?

&gt; I didn't get what to replace tf.TensorSpec(None, tf.float32) with.

You need to describe the shape and dtype of the input, use `None` for a dimension of unknown size.",2.0
fsy1nvh,gwgdal,"While defining call of `module.__call__`, it raises `AttributeError: 'AutoTrackable' object has no attribute '__call__'`.

On loading the model without exporting with signatures, there is no way to pass the input image.

Thanks.",1.0
fstt7ur,gw4gaq,"I found this:
https://datascience.stackexchange.com/questions/11589/creating-neural-net-for-xor-function

Looks like your scenario is prone to converging on a local optimum.  Initial weights seem to be the key factor, but training data, learning rate and algorithm, etc. can also impact the result.",1.0
fstxsqp,gw4gaq,"Precisely. Thanks man, that's just what I was looking for.",1.0
fstnay5,gw4gaq,Add more neurons,0.0
fsqmpws,gvsk6i,"It's not actually 3D. You have to use tf.math.argmax (be careful with the axis argument) to get the the greatest value indices, and then you can plot, as you will have two unidimensional arrays, y\_test and predictions, that will have the size of the number of examples you have.

But as far as visualization goes, you can try to visualize it on [TensorBoard](https://www.tensorflow.org/tensorboard/image_summaries#building_an_image_classifier), or create it with the help of [Scikit Learn](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.confusion_matrix.html).",3.0
fsqmtse,gvsk6i,"Basically *argmax* then visualize?

Alright, thanks.",1.0
fsqmwr1,gvsk6i,Yes!,1.0
fsqnhwh,gvsk6i,"Problem.

    y_te = argmax(y_te)
    
    test_pred = argmax(test_pred)
    
    cm = confusion_matrix(y_te, test_pred)
    
    ---------------------------------------------------------------------------
    ValueError                                Traceback (most recent call last)
    &lt;ipython-input-50-bae4dfd00736&gt; in &lt;module&gt;()
    ----&gt; 1 cm = confusion_matrix(y_te, test_pred)
    
    /usr/local/lib/python3.6/dist-packages/mlxtend/evaluate/confusion_matrix.py in confusion_matrix(y_target, y_predicted, binary, positive_label)
         65     z = list(zip(targ_tmp, pred_tmp))
         66     for combi in product(class_labels, repeat=2):
    ---&gt; 67         lst.append(z.count(combi))
         68     mat = np.asarray(lst)[:, None].reshape(n_labels, n_labels)
         69     return mat
    
    ValueError: The truth value of an array with more than one element is ambiguous. Use a.any() or a.all()

Y Test:

    &lt;tf.Tensor: shape=(80, 2641), dtype=int64, numpy=
    array([[  0, 157,   2, ...,   0,   0,   0],
           [  0,   7,   1, ...,   0,   0,   0],
           [  0,  17,   1, ...,   0,   0,   0],
           ...,
           [  4,  50,   0, ...,   0,   0,   0],
           [ 35,   4,   0, ...,   0,   0,   0],
           [  0,   0,   0, ...,   0,   0,   0]])&gt;

Label Predictions:

    &lt;tf.Tensor: shape=(80, 2641), dtype=int64, numpy=
    array([[152, 157, 121, ..., 156, 156, 157],
           [ 44, 152,  74, ...,  15,  15,  15],
           [  5, 117, 143, ...,  14,  14, 119],
           ...,
           [ 13,  63,  98, ...,  77,  77,  77],
           [ 35,  13,   0, ...,  77,  77,  77],
           [ 50,  77,  51, ...,  50,  50,  50]])&gt;

Edit:

Wait, I forget that I use mlxtend for the confusion matrix. Maybe I should change that.

Edit 2:

Still the same.",1.0
fsqpe5b,gvsk6i,"Why are your Y test and predictions a list of arrays? You have to turn them into a single array, [using  tf.concat](https://stackoverflow.com/questions/27516849/how-to-convert-list-of-numpy-arrays-into-single-numpy-array), for example, and then using tf.argmax will turn each array into a unidimensional array, instead of the one hot configuration you have.

Then you will be able to plot the confusion matrix.",2.0
fsqqhkg,gvsk6i,"Alright, I *concat* them, then *argmax*, and lastly confusion matrix using *sklearn*.

It's successful.

    y_te = concat(y_te, 0)
    
    y_te = argmax(y_te)
    
    test_pred = concat(test_pred, 0)
    
    test_pred = argmax(test_pred)
    
    cm = confusion_matrix(y_te, test_pred)
    
    print(cm)
    
    [[ 447  964  113    0    0 1115    0    0]
     [   0    0    0    0    0    0    0    0]
     [   0    0    0    0    0    0    0    0]
     [   0    0    0    0    0    0    0    0]
     [   0    0    0    1    0    0    0    0]
     [   0    0    0    0    0    0    0    0]
     [   0    0    0    0    0    0    0    0]
     [   0    0    0    0    0    0    1    0]]

Now... how do I interpret this? How to plot it? I need the image.

There are three classes: B-NP, I-NP, and O.",1.0
fsqr1y1,gvsk6i,"The confusion matrix should have dimension \[num\_classes, num\_classes\], is it right? 8 classes? You need to be careful with tf.argmax, I think what you need is  y\_te = argmax(y\_te, axis=1). Checking the dimensions of the arrays you're getting to prevent errors like this can be more important than checking the arrays.

To visualize you can use matplotlib.pyplot command plt.imshow(cm).",2.0
fsqrjnz,gvsk6i,"There should be three classes: 'B-NP', 'I-NP', and 'O'.

My project is sequence chunking, similar to NER. Each word tagged with labels above.

The output is prediction of labels above.",1.0
fsqrxtm,gvsk6i,"&gt;\[1., 0., 0., ..., 0., 0., 0.\],

I assume this is an one hot encoding, meaning you have the first class of over 6 classes. Isn't that the case? what does the other zeros mean?",1.0
fsqsbrh,gvsk6i,"No, I'm using to\_categorical.

    n_tags = 3
    
    y = [to_categorical(i, num_classes=n_tags) for i in y]
    
    y[:3]
    
    [array([[0., 0., 1., ..., 0., 0., 0.],
            [1., 0., 0., ..., 0., 0., 0.],
            [0., 1., 0., ..., 0., 0., 0.],
            ...,
            [0., 0., 1., ..., 0., 0., 0.],
            [0., 0., 1., ..., 0., 0., 0.],
            [0., 0., 1., ..., 0., 0., 0.]], dtype=float32),
     array([[1., 0., 0., ..., 0., 0., 0.],
            [0., 1., 0., ..., 0., 0., 0.],
            [0., 0., 1., ..., 0., 0., 0.],
            ...,
            [0., 0., 1., ..., 0., 0., 0.],
            [0., 0., 1., ..., 0., 0., 0.],
            [0., 0., 1., ..., 0., 0., 0.]], dtype=float32),
     array([[1., 0., 0., ..., 0., 0., 0.],
            [0., 1., 0., ..., 0., 0., 0.],
            [0., 1., 0., ..., 0., 0., 0.],
            ...,
            [0., 0., 1., ..., 0., 0., 0.],
            [0., 0., 1., ..., 0., 0., 0.],
            [0., 0., 1., ..., 0., 0., 0.]], dtype=float32)]

To be honest, I was following code from a certain tutorial. It doesn't explain what zero means.",1.0
_,gvsk6i,,
fsqzh95,gvsk6i,"This Confusion matrix is not correct. I don't know how you get 8x8 matrix. It should be 3x3.

Ex. 

Class        B-NP      I-NP     O

B-NP          10         2           1

I-NP            2          8           0

O                 0          1          11

&amp;#x200B;

What you can get from this.

1. Users Accuracy
2. Producers Accuracy 
3. Kappa Coefficient.
4. Overall Accuracy
5. Precision
6. Recall 

Let me know if you have doubt.

Please Have a look s this [link](http://www.marcovanetti.com/pages/cfmatrix/)",2.0
fsr1ntm,gvsk6i,"Yeah, I just noticed this too.

Apparently, because I keep using y\_te, it affects the original and as a result, the original is lost. So it's my fault.

Anyway, I change it to y\_test and label\_predictions to avoid losing original again, but another problem appear.

    y_test = concat(y_te, 0)
    
    &lt;tf.Tensor: shape=(12640, 2641), dtype=float32, numpy=
    array([[1., 0., 0., ..., 0., 0., 0.],
           [1., 0., 0., ..., 0., 0., 0.],
           [1., 0., 0., ..., 0., 0., 0.],
           ...,
           [0., 0., 1., ..., 0., 0., 0.],
           [0., 0., 1., ..., 0., 0., 0.],
           [0., 0., 1., ..., 0., 0., 0.]], dtype=float32)&gt;
    
    y_test = argmax(y_test, 1)
    
    &lt;tf.Tensor: shape=(12640,), dtype=int64, numpy=array([0, 0, 0, ..., 2, 2, 2])&gt;
    
    test_predictions = concat(test_pred, 0)
    
    &lt;tf.Tensor: shape=(158, 80, 2641), dtype=float32, numpy=
    array([[[9.96229470e-01, 9.29005968e-04, 1.66210847e-03, ...,
             4.02127455e-07, 3.19974731e-07, 4.77790536e-07],
            [9.94982719e-01, 4.14145784e-03, 5.74989943e-04, ...,
             1.02821716e-07, 7.96793742e-08, 1.22003371e-07],
            [9.89627123e-01, 8.13264027e-03, 2.04260531e-03, ...,
             6.72297773e-08, 4.87309393e-08, 7.63322916e-08],
            ...,
            [1.79647323e-05, 4.89449633e-07, 9.99980092e-01, ...,
             7.04650394e-10, 4.61258060e-10, 7.12459092e-10],
            [2.89663585e-05, 1.05414006e-06, 9.99955773e-01, ...,
             7.03199765e-09, 4.84797313e-09, 7.01915992e-09],
            [2.61447305e-04, 9.57517113e-06, 9.98575449e-01, ...,
             4.83017175e-07, 3.80102705e-07, 4.90962464e-07]],
    
           [[9.92273629e-01, 5.43785887e-03, 5.75217593e-04, ...,
             6.00310273e-07, 4.72865366e-07, 6.94310529e-07],
            [2.51390360e-04, 1.30404183e-03, 9.97021377e-01, ...,
             5.97829739e-07, 4.49726684e-07, 5.89770480e-07],
            [1.88061131e-05, 7.78038611e-06, 9.99953270e-01, ...,
             9.75640368e-09, 7.13460224e-09, 9.67898295e-09],
            ...,
            [1.79647141e-05, 4.89449178e-07, 9.99980092e-01, ...,
             7.04650394e-10, 4.61257171e-10, 7.12459092e-10],
            [2.89663585e-05, 1.05414006e-06, 9.99955773e-01, ...,
             7.03199765e-09, 4.84797313e-09, 7.01915992e-09],
            [2.61447043e-04, 9.57516204e-06, 9.98575449e-01, ...,
             4.83017175e-07, 3.80101994e-07, 4.90962464e-07]],
    
           [[1.73268854e-04, 1.02408012e-05, 9.99597013e-01, ...,
             8.66266490e-08, 6.30321537e-08, 8.81902622e-08],
            [2.47051048e-05, 2.90316143e-06, 9.99960661e-01, ...,
             5.72899816e-09, 4.25109237e-09, 5.62221958e-09],
            [9.99531507e-01, 4.31903791e-05, 4.12378489e-04, ...,
             5.19061594e-09, 3.61263375e-09, 5.83517634e-09],
            ...,
            [1.79647141e-05, 4.89449178e-07, 9.99980092e-01, ...,
             7.04650394e-10, 4.61257171e-10, 7.12459092e-10],
            [2.89663585e-05, 1.05414006e-06, 9.99955773e-01, ...,
             7.03199765e-09, 4.84797313e-09, 7.01915992e-09],
            [2.61447043e-04, 9.57516204e-06, 9.98575449e-01, ...,
             4.83017175e-07, 3.80101994e-07, 4.90962464e-07]],
    
           ...,
    
           [[9.91900563e-01, 5.76081546e-03, 6.00212021e-04, ...,
             6.10806012e-07, 4.79644825e-07, 7.01841032e-07],
            [2.85376504e-04, 1.60415866e-03, 9.96568799e-01, ...,
             6.31596606e-07, 4.85352132e-07, 6.44464194e-07],
            [8.00649747e-02, 1.20275967e-04, 9.19024646e-01, ...,
             3.01590831e-07, 1.98364603e-07, 3.29633139e-07],
            ...,
            [1.79647141e-05, 4.89449178e-07, 9.99980092e-01, ...,
             7.04650394e-10, 4.61257171e-10, 7.12459092e-10],
            [2.89663585e-05, 1.05414006e-06, 9.99955773e-01, ...,
             7.03199765e-09, 4.84797313e-09, 7.01915992e-09],
            [2.61447043e-04, 9.57516204e-06, 9.98575449e-01, ...,
             4.83017175e-07, 3.80101994e-07, 4.90962464e-07]],
    
           [[5.94513081e-02, 3.04785632e-02, 8.22676301e-01, ...,
             3.55929660e-05, 2.73878431e-05, 3.58538600e-05],
            [9.29646373e-01, 4.98454459e-02, 1.06186047e-02, ...,
             3.72145837e-06, 2.73558112e-06, 3.92149650e-06],
            [9.04158733e-05, 8.85164336e-05, 9.99543965e-01, ...,
             1.13089435e-07, 8.36631671e-08, 1.14715540e-07],
            ...,
            [1.79647141e-05, 4.89449178e-07, 9.99980092e-01, ...,
             7.04650394e-10, 4.61257171e-10, 7.12459092e-10],
            [2.89663585e-05, 1.05414006e-06, 9.99955773e-01, ...,
             7.03199765e-09, 4.84797313e-09, 7.01915992e-09],
            [2.61447043e-04, 9.57516204e-06, 9.98575449e-01, ...,
             4.83017175e-07, 3.80101994e-07, 4.90962464e-07]],
    
           [[4.07273859e-01, 4.21999037e-01, 8.50238055e-02, ...,
             3.31613883e-05, 2.58093696e-05, 3.24174944e-05],
            [1.58844306e-03, 1.94849534e-04, 9.95591044e-01, ...,
             1.05000538e-06, 7.76917659e-07, 1.07605626e-06],
            [1.92444160e-04, 5.25802607e-05, 9.99649644e-01, ...,
             4.78434856e-08, 3.76877551e-08, 4.65229029e-08],
            ...,
            [7.79347647e-06, 5.04939771e-06, 9.99984503e-01, ...,
             1.26133548e-09, 9.16961340e-10, 1.25664812e-09],
            [4.93335456e-01, 4.02763078e-04, 5.02101779e-01, ...,
             1.64629500e-06, 1.11196471e-06, 1.68095050e-06],
            [5.39594657e-05, 1.42571036e-04, 9.98826444e-01, ...,
             3.99609206e-07, 3.36669672e-07, 4.09511500e-07]]], dtype=float32)&gt;
    
    test_predictions = argmax(test_predictions, 1)
    
    &lt;tf.Tensor: shape=(158, 2641), dtype=int64, numpy=
    array([[35, 60, 65, ..., 79, 79, 79],
           [ 4, 41, 52, ...,  0,  0,  0],
           [ 6, 10, 15, ..., 79, 79, 79],
           ...,
           [ 4,  5, 15, ...,  1,  1,  0],
           [11, 18, 14, ...,  0,  0,  0],
           [17, 11, 19, ...,  0,  0,  0]])&gt;
    
    cm = confusion_matrix(y_test, test_predictions)
    
    ---------------------------------------------------------------------------
    ValueError                                Traceback (most recent call last)
    &lt;ipython-input-191-d238b71a70e1&gt; in &lt;module&gt;()
    ----&gt; 1 cm = confusion_matrix(y_test, test_predictions)
    
    2 frames
    /usr/local/lib/python3.6/dist-packages/sklearn/utils/validation.py in check_consistent_length(*arrays)
        210     if len(uniques) &gt; 1:
        211         raise ValueError(""Found input variables with inconsistent numbers of""
    --&gt; 212                          "" samples: %r"" % [int(l) for l in lengths])
        213 
        214 
    
    ValueError: Found input variables with inconsistent numbers of samples: [12640, 158]

The test predictions all wrong. Not 0, 1, 2, but a high number.

Edit:

Actually, can I visualize them manually? I have the flat classification report.

&amp;#x200B;

|| precision|recall|f1-measure|
|:-|:-|:-|:-|
|B-NP| 0.95 | 0.90 | 0.92 |
|I-NP| 0.89 | 0.81 | 0.85 |
|O| 0.98 | 0.99 | 0.99 |",1.0
fsr8z8g,gves0t,"This will be easier to debug if you use a subclassed model instead of the keras functional style. If you just write out the `Model.call` you'll havce a chance to see what's happening.

Basically, your datasets are zip-transposed.

Keras models assume the dataset produces `(example, label)` pairs. but you're producing `((example, labels),(example, labels),(example, labels))` to make this work you'll need `((example,example,example),(labels,labels,labels))`.

So you'll need to `Dataset.map` something like:

```
def transpose_zip(left, right, mouth):
  return (left[0],right[0], mouth[0]),(left[1],right[1], mouth[1]) 
```

or less readable:


```
def transpose_zip(*args):
  return tuple(zip(*args)) 
```",1.0
fspqgs6,gv9g60,"&gt; but the yielded element was [array([[112, 121, 148, ..., 68, 64, 68],

That leading ""["" is suspicious.

Is your generator returning lists or tuples? `tf.data` treats tuples as structure, but lists as an array/tensor.",1.0
fspqh45,gv9g60,"**I found links in your comment that were not hyperlinked:**

* [tf.data](https://tf.data)

*I did the honors for you.*

***

^[delete](https://www.reddit.com/message/compose?to=%2Fu%2FLinkifyBot&amp;subject=delete%20fspqgs6&amp;message=Click%20the%20send%20button%20to%20delete%20the%20false%20positive.) ^| ^[information](https://np.reddit.com/u/LinkifyBot/comments/gkkf7p) ^| ^&lt;3",0.0
fso1ry5,gv9492,"Might be obvious, but:

https://www.tensorflow.org/tutorials


The tutorials are well described and cover numerous topics, from very basic stuff to more complex, generative tasks.",3.0
fsoj80f,gv9492,"To op:

Do you already have tensor flow set up and are you using PC ?

If you're not set up but are on PC, what resources have you found that are useful for this ?

Asking because I've tried to get into it too but just setting up has been a bit challenging",1.0
fsqkuhh,gv9492,"At which step do you run into problems? To set up tensorflow (without CUDA) simply use pip/conda install tensorflow.

Tensorflow-GPU is a bit more tricky, but you could always use Google Colab.",2.0
fsrhq1x,gv9492,"I used cuda, and when I followed their tutorial I wasn't able to see any graphs or results beyond what shows on the pycharm console and some numbers on the cmd also my tiny laptop at the time got really hot",1.0
fsrlyjs,gv9492,"&gt; I wasn't able to see any graphs

Well, why would you see any graphs?

&gt;also my tiny laptop at the time got really hot

Are you sure that your tiny laptop supports cuda?

Sorry, but ""i see some numbers on the cmd"" is not really helpful.",2.0
fsti3vv,gv9492,"The tutorial showed images of graphs

I think the numbers on my cmd were output results

*Keep in mind I'm new to this just like op",1.0
fsu7bzn,gv9492,"Then worry about Cuda later. Learn tensorflow basics and then try to get Cuda working when you know what you are doing.

And in case you are new to python, get python basics down before you try to get into ML.",2.0
fsv4trn,gv9492,"I see

What would be a reasonable way to judge that ""ive got the python basics down"" ?

For example, Ive been coding for roughly 1 year now pretty consistently. Usually small stuff to practice and try out different ideas.

So Im comfortable with classes and functions and dictionaries, Im somewhat comfortable with PEP8 formatting but I think I need alot more practice. I can comfortably get data in and out of excel through my code, as long as Im running it through the pycharm or cmd or python console. I have failed multiple times to manipulate excel data using a tkinter gui. I did learn tkinter really well and also learned to turn my tkinter guis into exe files. I still cant make my gui edit excel successfully, ive paused that in favor of learning other skills hoping ill eventually come back to this issue and solve it.

Currently im learning sqllite. Ive got the basics but I feel like I need to build a few databases before I can say im comfortable.

In any case, those are examples of my current skill level, and from that Id say at best im a beginner, what do you think ?

At what point beyond my current skill level does learning ML start to really become feasible ?

Thanks for sharing!",1.0
fsv9cc3,gv9492,"While it is preferable, you don't need to be particularly advanced to start getting into ML/Tensorflow.

The 2 libraries that you will run into almost every tutorial are matplotlib and NumPy:

For most use-cases, your input&amp;output will be NumPy-arrays and you visualize your results with matplotlib.

Knowing how to read&amp;write cvs or json-files (or any other format, but cvs/json are most common) is also needed if you want to create your own dataset.

So if you are able to load data from a file, convert it to a numpy-array and plot it, you are good to go.

And finally, and this is probably pretty controversial, if you are a beginner, maybe use anaconda-python with Spyder.
Spyder is an IDE with an integrated IPython-console, so you don't have to switch between an IDE and a console.

E.g. i use VisualStudio &amp; PyCharm for work, and they are great IDEs, but when i want to learn something new or just fuck around, i use Spyder. But everyone has its own preferences.",1.0
fsvizt2,gv9492,"Ok so I need:

numpy - I think I started learning some basic stuff for this but Ill have to dive deeper for sure but I definitely have it installed on my pycharm

matplotlib - I heard this doesnt work quite well with win10, but Ill have to try it I think I have a few tutorial links saved up somewhere for this also pretty sure I installed it to my pycharm

anaconda-python - I used this a few times with a jupyter notebook for a tutorial, Im pretty sure its set up on my pc, but I suppose I need more practice. Is this directly accessible within pycharm ?

spyder ide - I just checked out their website and they say ""stick w anaconda unless youre an experienced user"" I dont know much about this but essentially if I can stick with my pycharm IDE thatd be great. If not where can I learn about this one ?

Btw thanks for all the advice, this makes the ""road ahead"" a much clearer picture

**EDIT: A few minutes after I posted this comment I went to ""download anaconda"" but it turns out I already have it lmao im such a noob! Just gotta learn numpy and matplotlib thanks, i suppose spyder is the next step

**EDIT TO MY LAST EDIT: lol so yeah anaconda is not only installed already but also gives me access to spyder... oh boy my future sure looks bright HAHA",1.0
fsvlqae,gv9492,"You don't *need* Spyder, but it allows you to do [this](https://i.imgur.com/ffon5Uu.jpg) really easily. I can write my script in the text editor (left side), run the script in the IPython-Console and call functions (bottom right), can look at my variables, and can save my plots (top right).

If you already installed Anaconda, you can install Spyder through the Anaconda Navigator (you may have installed PyCharm the same way).",2.0
_,gv9492,,
fsvmx5x,gv9492,"Also, you seem to have a view misconceptions about how python works.

It seems like you installed anaconda python for windows. Numpy and matplotlib are packages for python, that you installed (these 2 packages are actually included) to your anaconda-python. You don't install packages in PyCharm.

PyCharm is an IDE and in your case, it uses anaconda-python and therefore all packages included in anaconda-python. If you now install Spyder, your anaconda-python stays the same.",1.0
g3yu313,guyv61,"[https://www.tensorflow.org/tutorials/keras/keras\_tuner](https://www.tensorflow.org/tutorials/keras/keras_tuner), am also trying to find out the same. In the given link, they mentioned that Hparams is interactive, i do not really understand what it means. Would be great help if somebody can give details differences and what to use when? and another useful link [https://www.gitmemory.com/issue/keras-team/keras-tuner/169/555187007](https://www.gitmemory.com/issue/keras-team/keras-tuner/169/555187007)",1.0
fslv904,guukl7,"It basically and usually indicates that the Optimizer can’t optimize the gradients. Try training the network using gradient tape or enfore the training variables as tf.Variable. 
Hope it helps.",1.0
fsiqvsy,guiup8,"I'm not sure if there is a method for LSTM based methods, but if you used transformers, you could show the self attention matriced Q, K, V to show where the model attends to in the classification.",2.0
fsiuq9w,guiup8,"Check out lime and shap, but not sure if those apply to deep learning",1.0
fsl9aqn,gug9w6,This is very out-of-date,1.0
fsgbwmx,gu5l36,"Off the top of my head, you might use something like openCV to mask out the majority of the image where motion isn't present, then just pass the areas with motion or the masked image to your classifier.",2.0
fsgccou,gu5l36,"Do you even need an object detector? isnt any big change from recent background a positive.

Can’t you check the box coordinates?",1.0
fsgcs89,gu5l36,What's the best way to do that?,1.0
fsfywq7,gu0rrx,Nice work! Love the Ataturk detail ♥️,3.0
fsfzltx,gu0rrx,&lt;3,2.0
fsff3lx,gu0rrx,"🚀link: [https://mburakerman.github.io/ai-profile-picture-maker/](https://mburakerman.github.io/ai-profile-picture-maker/)

🦄examples: [https://github.com/mburakerman/ai-profile-picture-maker#examples](https://github.com/mburakerman/ai-profile-picture-maker#examples)",1.0
fshs1qw,gu0rrx,fenasın,1.0
fszid8g,gu0rrx,nice pic!,1.0
fsfetze,gtxhnn,Could you maybe show what is your desired output ?,1.0
fsem4sk,gtv311,Have a look at https://github.com/karolzak/keras-unet,3.0
fseplys,gtv311,"nice! super cool repo, exactly what I was looking for! thank you :)",1.0
fsepo75,gtv311,do you know by chance any good 3D image augmentation repos for tensorflow?,1.0
fsi3qpi,gtv311,"Assuming you’re working with single-channel 3 data I‘d just use keras data augmentation and pass the 3rd dimension as the channel axis. Otherwise a more sophisticated option would be https://github.com/MIC-DKFZ/batchgenerators
.",2.0
fs9z702,gt7e7d,"You should train one yourself because that would be the best approach. False Positives are a difficult thing to overcome for COCO. You may try the Detection Transformer (De:Tr) by Facebook AI and now it has been open sourced too. It specifically uses an Encoder Decoder structure to mitigate the same. 
 [Paper to DeTr](https://arxiv.org/pdf/2005.12872.pdf) 
[colab demo](https://colab.research.google.com/github/facebookresearch/detr/blob/colab/notebooks/detr_demo.ipynb)",6.0
fsbs5dz,gt7e7d,"I am fearful to train one myself because I am just getting into this, but I will check out those links, thank you!",1.0
fsadlyo,gt7e7d,"In my testing, YOLO V3 and Mask RCNN outperform most others. SSD mobilenet V3 small also seemed pretty decent for the speed.",4.0
fsb13le,gt7e7d,"Same here.  


In my testing, MaskRCNN is incredibly powerful, but requires a heavy amount of hardware and system resources in both training and inference. This is due to the nature of model itself, and the premise of image segmentation using deep belief networks.  


YOLO, while less powerful (in terms of accuracy) gives pretty decent frame-rates during real-time inference. I don't think I've encountered a scenario or example where MaskRCNN was used in real-time.",2.0
fsadyo7,gt7e7d,(rookie answer:) I've been keen to try [EfficientDet](https://github.com/google/automl/blob/master/efficientdet/README.md). You can try some of your images on their colab example. Also [YoloV4](https://github.com/AlexeyAB/darknet) or maybe [MobileNetv3 SSD](https://github.com/tensorflow/models/blob/master/research/object_detection/g3doc/detection_model_zoo.md). If nothing works well you could just transfer learn on the same Coco dataset but drop classes other than people and add some of your images.,1.0
fsbrwk5,gt7e7d,"I looks like the example I followed has me using MobileNetv1 SSD, coco\_ssd\_mobilenet\_v1\_1.0\_quant\_2018\_06\_29. I'll check out EffcientDet and Yolo!",1.0
fsbazbl,gt7e7d,"Potentially a dumb quetion:

&gt;I am using the standard pre-trained COCO model

The model you are testing is SSD, Faster RCNN; inception, resnet, etc.?",1.0
fsbrnnz,gt7e7d,"Not a dumb question at all. Truthfully I have just dipped my toes into this arena. I am using this model, so I am assuming SSD:  

    coco_ssd_mobilenet_v1_1.0_quant_2018_06_29.",1.0
g27150d,gt7e7d,"I think that depends on the requirement you want,

&gt;  if you want a object detection model, [EfficientDet: Scalable and Efficient Object Detection](https://paperswithcode.com/sota/object-detection-on-coco-minival)  would be a most up-to-date one


&gt; if you want segmentation, [DeepLabV3](https://arxiv.org/pdf/1802.02611v3.pdf) might be a balanced one.",1.0
fs4o7nr,gsbekj,"Hey I had gotten tripped up project id before. Google appends a series of numbers to the name you give your project and stores it in the id. So when you say your project id is correct, do you mean project-id=project-name-GOOGLENUMBERS or project-id=project-name.",2.0
fs5u249,gsbekj,"Hey. I'm part of the same project so I can fill in.
He meant project-id=project-name-GOOGLENUMBERS",1.0
fs62s8y,gsaj2g,"Lots of resources here: https://www.tensorflow.org/resources/learn-ml

Then work through some of the [site tutorials](https://www.tensorflow.org/tutorials). But it's a big ecosystem so the sooner you have a goal the more likely you'll find the path to take (i.e. build a mobile app, research models, etc.)",1.0
fva5n68,gsaj2g,agree. the tutorial are very good.,1.0
fs46pm6,gsairh,[deleted],1.0
fs49wwk,gsairh,"It'll come out in the next video, when I'll explain how to sample a melody from the network. Stay tuned!",1.0
fs4b4lv,gsairh,"Well alright, but why not give your audience a taste of what's coming? There's a good deal of prior art (OpenAi, Magenta...) so I'm wondering how your outputs compare.

I'm tinkering with some hand-rolled GANs for the same task at the moment (I got fired up by a [related thread on StackOverflow](https://stackoverflow.com/questions/61964836/classifying-64x4-images-representing-piano-rolls-as-real-or-fake)). Anyway, I'd be interested to hear some of your melodies if you have links!",1.0
fs4di21,gsairh,"This is a multi-part series (we're already at vivode # 7) that teaches people how to get to a functioning generative music system using LSTM. I'm not that focused on melody quality, rather on instructional impact. So, I don't expect for this system to be as good as Magenta. Next series, I'll include a little teaser of what's to come. Thank you for the idea!",1.0
fs2wpix,gs3yg1,Have you tried StackOverflow?,2.0
fs2wu7n,gs3yg1,"Yes, no answer. I didnt made a new questions there and just edited the old one with new information. [Stackoverflow Question](https://stackoverflow.com/questions/62025258/unicodedecodeerror-when-trying-to-start-the-training)",2.0
fs2yb3y,gs3yg1,"This shows us the encoding. You get the error during decoding? or at some in the encoding step?

WHat's the code that throws the error?",2.0
fs2ysye,gs3yg1,"I get the error when I try to start the training. So after the .tfrecord file is already created. It seems like it tries to read the file, but crashes right at the start. To you need the full error message?

Here are more Informations:
 [Stackoverflow Question](https://stackoverflow.com/questions/62025258/unicodedecodeerror-when-trying-to-start-the-training)",1.0
fs28dxl,gs0ik9,"This smells like a compatibility problem. It looks like you're running Windows 32 bit and I'm not sure if TensorFlow can run on 32 bit. So, first step, research that. But my next question to you is, are you trying to use the GPU or is this just CPU?",1.0
fs28s49,gs0ik9,"just cup, in not 100% sure",1.0
fs491qp,gs0ik9,Hmm ok. If you're not sure then it'll be CPU because running GPU is not for the faint hearted to say the least (it's a mission!) It's probably due to the 32 bit thing or what e4d6 says. Maybe try using python 3.6 or 3.7.,1.0
fs2dph5,gs0ik9,What version of TF? Python 3.8 requires TensorFlow 2.2,1.0
fs1qsup,grv5h6,The difference between GUI and CLI applications.,1.0
fv9tzap,grv5h6,"i am using miniconda. after a huge hassle, i was able to get py 3.7 and tf 2.1.0 (cpu version): https://stackoverflow.com/questions/62376660/installing-tensorflow-2-gets-a-dll-failed-to-load-in-pywrap-tensorflow-py",1.0
fs1g457,grv5h6,It only works on 3.7 and below,0.0
fs1hft8,grv5h6,On the site it says it supports 3.8 if I install tensorflow 2.2 or higher,5.0
fs2cw1j,grv5h6,"Yep, did for me, python 3.8 installed tensorflow 2.2 via pip",2.0
fz73qzb,grv5h6,"How did you do this? I have python 3.8 installed, but cannot install tensorflow using pip install tensorflow",1.0
fz8hx5w,grv5h6,Have you tried updating pip itself first?,1.0
fz8rlg4,grv5h6,"Yup. Pip is up to date. 
From the things I've read, tensorflow still has some bugs with python 3.8",1.0
fs1avkd,grv5h6,Why are you ignoring tensorflow python requirements? Google that phrase.,-1.0
fs1bl7s,grqtwy,"That is how it’s supposed to work.

https://www.tensorflow.org/guide/data#resampling

Bigger than the original sounds impossible.",2.0
fs6spb1,grqtwy,"Yeah that's what I thought, but adding just a single line with rejection resampling somehow increases the size. I'm just going to switch to using sample from datasets with a few extra lines to do the same thing. Thanks anyway",1.0
frzj2vl,grioys,Try adding a softmax activation function in the last Dense layer,1.0
frzmio9,grioys,I tried. It didn't work,1.0
frzx6gd,grioys,Then try changing the loss to 'categorical\_crossentropy',1.0
fswe6xt,grioys,"from_logits=True or some such similar arg to the loss fun you are using, sparse_categorical_crossentropy(from_logits=True)",1.0
fryu685,grhebg,"have you tried this? it's quite straightforward.

Edit: sorry, forgot the link.  [https://www.tensorflow.org/tensorboard/get\_started](https://www.tensorflow.org/tensorboard/get_started)",1.0
frzflnp,grhebg,"Hope that works by using tf summary. I will try to implement in my custom code now.

Thanks for resources.",1.0
fsp22y6,grc50r,"Here is a pointer to the first model in use:  [https://icollect.money/mlPredict](https://icollect.money/mlPredict) 

 

Here is how I built the first rudimentary model. Still researching ideas (per above) if there are any out there. 

import numpy as np

import tensorflow.keras 

from tensorflow.keras.models import Sequential, Model

from tensorflow.keras import datasets, layers, models

from tensorflow.keras.layers import Dropout, Input

from tensorflow.keras.layers import Dense, Flatten

from tensorflow.keras.optimizers import Adam

from tensorflow.keras.metrics import categorical\_crossentropy

from tensorflow.keras.preprocessing.image import ImageDataGenerator

import itertools

import matplotlib.pyplot as plt

%matplotlib inline

\#Use InceptionV3

IMG\_SHAPE = (250,250, 3)

\# Create the base model from the pre-trained model

base\_model = tensorflow.keras.applications.InceptionV3(input\_shape=IMG\_SHAPE,

include\_top=False,

weights='imagenet')

base\_model.trainable = False

global\_average\_layer = tensorflow.keras.layers.GlobalAveragePooling2D()

prediction\_layer = tensorflow.keras.layers.Dense(92)

model = Sequential()

model.add(base\_model)

model.add(tensorflow.keras.layers.GlobalAveragePooling2D())

model.add(layers.Dense(92, activation='softmax'))

train\_path = r""C:\\temp\\coins\\AllUSCoins\\trainx""

valid\_path = r""C:\\temp\\coins\\AllUSCoins\\testx""

BATCH\_SIZE = 32

IMG\_HEIGHT = 250

IMG\_WIDTH = 250

training\_datagen = ImageDataGenerator(rescale = 1./255, rotation\_range=45, Horizontal\_flip=True,zoom\_range=0.5)

validation\_datagen = ImageDataGenerator(rescale = 1./255)

train\_batches = training\_datagen.flow\_from\_directory(train\_path, target\_size=(IMG\_HEIGHT, IMG\_WIDTH), classes=\['005\_1793HalfCent', '005\_Braided Hair Half Cent', '005\_Classic Half Cent', '005\_Draped Bust Half Cent', '005\_Liberty Cap Left Half Cent', '005\_Liberty Cap Right Half Cent', '005\_Liberty Cap Right Half Cent small head', '01\_Braided Cent', '01\_Chain Cent', '01\_Classic Cent', '01\_Coronet Cent', '01\_Draped Bust Cent', '01\_Flying Eagle Cent', '01\_FugioCent', '01\_Indian Cent', '01\_Liberty Cap Cent', '01\_Lincoln Cent', '01\_Wreath Cent', '02\_TwoCent', '03\_Cent Nic', '03\_CentSil', '05\_1792halfdisme', '05\_BuffaloNickle', '05\_CappedHalfDIme', '05\_DrapedHalfDimeLE', '05\_DrapedHalfDimeSE', '05\_FlowingHalfDime', '05\_Jefferson', '05\_LibNic', '05\_SeatedHalfDime', '05\_ShieldNic', '1000\_gold\_capped\_SE', '1000\_gold\_drapped\_bust\_right\_capped\_LE', '1000\_gold\_indian', '1000\_gold\_liberty', '100\_DrapedBustDollarLE', '100\_DrapedBustDollarSE', '100\_FlowingHair', '100\_gold\_dollar\_type1', '100\_gold\_dollar\_type2', '100\_gold\_dollar\_type3', '100\_Morgan', '100\_Peace', '100\_SeatedDollar', '100\_TradeDollar', '10\_BarberDime', '10\_Capped10Lg', '10\_Capped10Sm', '10\_Draped10LE', '10\_Draped10SE', '10\_MercuryDime', '10\_RooseveltDime', '10\_Seated10', '2000\_gold\_liberty\_head', '2000\_gold\_st\_gaudens', '20\_cent', '250\_gold\_capped\_head\_left', '250\_gold\_classic\_quarter\_eagle', '250\_gold\_drapped\_bust\_right', '250\_gold\_Indian', '250\_gold\_liberty', '25\_BarberQuarter', '25\_Capped25Lg', '25\_Capped25Sm', '25\_Draped Bust Quarter Small Eagle 1796', '25\_Draped25LE', '25\_Draped25SE', '25\_Seated25', '25\_SQL', '25\_SQLe', '25\_SQLT1', '25\_Washington', '300\_gold', '50 kennedy', '500\_gold\_capped\_bust\_left', '500\_gold\_capped\_head\_left', '500\_gold\_classic\_half\_eagle', '500\_gold\_drapped\_bust\_right', '500\_gold\_drapped\_bust\_right\_small', '500\_gold\_indian', '500\_gold\_liberty', '50\_Barber', '50\_Capped', '50\_drappedLE', '50\_drappedSE', '50\_flowinghalf', '50\_Franklin', '50\_Reeded', '50\_Seated', '50\_Walker', 'OakTree', 'PineTree'\], batch\_size=BATCH\_SIZE,shuffle=True, class\_mode=""categorical"")

valid\_batches = validation\_datagen.flow\_from\_directory(valid\_path, target\_size=(IMG\_HEIGHT, IMG\_WIDTH), classes=\['005\_1793HalfCent', '005\_Braided Hair Half Cent', '005\_Classic Half Cent', '005\_Draped Bust Half Cent', '005\_Liberty Cap Left Half Cent', '005\_Liberty Cap Right Half Cent', '005\_Liberty Cap Right Half Cent small head', '01\_Braided Cent', '01\_Chain Cent', '01\_Classic Cent', '01\_Coronet Cent', '01\_Draped Bust Cent', '01\_Flying Eagle Cent', '01\_FugioCent', '01\_Indian Cent', '01\_Liberty Cap Cent', '01\_Lincoln Cent', '01\_Wreath Cent', '02\_TwoCent', '03\_Cent Nic', '03\_CentSil', '05\_1792halfdisme', '05\_BuffaloNickle', '05\_CappedHalfDIme', '05\_DrapedHalfDimeLE', '05\_DrapedHalfDimeSE', '05\_FlowingHalfDime', '05\_Jefferson', '05\_LibNic', '05\_SeatedHalfDime', '05\_ShieldNic', '1000\_gold\_capped\_SE', '1000\_gold\_drapped\_bust\_right\_capped\_LE', '1000\_gold\_indian', '1000\_gold\_liberty', '100\_DrapedBustDollarLE', '100\_DrapedBustDollarSE', '100\_FlowingHair', '100\_gold\_dollar\_type1', '100\_gold\_dollar\_type2', '100\_gold\_dollar\_type3', '100\_Morgan', '100\_Peace', '100\_SeatedDollar', '100\_TradeDollar', '10\_BarberDime', '10\_Capped10Lg', '10\_Capped10Sm', '10\_Draped10LE', '10\_Draped10SE', '10\_MercuryDime', '10\_RooseveltDime', '10\_Seated10', '2000\_gold\_liberty\_head', '2000\_gold\_st\_gaudens', '20\_cent', '250\_gold\_capped\_head\_left', '250\_gold\_classic\_quarter\_eagle', '250\_gold\_drapped\_bust\_right', '250\_gold\_Indian', '250\_gold\_liberty', '25\_BarberQuarter', '25\_Capped25Lg', '25\_Capped25Sm', '25\_Draped Bust Quarter Small Eagle 1796', '25\_Draped25LE', '25\_Draped25SE', '25\_Seated25', '25\_SQL', '25\_SQLe', '25\_SQLT1', '25\_Washington', '300\_gold', '50 kennedy', '500\_gold\_capped\_bust\_left', '500\_gold\_capped\_head\_left', '500\_gold\_classic\_half\_eagle', '500\_gold\_drapped\_bust\_right', '500\_gold\_drapped\_bust\_right\_small', '500\_gold\_indian', '500\_gold\_liberty', '50\_Barber', '50\_Capped', '50\_drappedLE', '50\_drappedSE', '50\_flowinghalf', '50\_Franklin', '50\_Reeded', '50\_Seated', '50\_Walker', 'OakTree', 'PineTree'\], batch\_size=BATCH\_SIZE, class\_mode=""categorical"")

base\_learning\_rate = 0.0001

model.compile(loss='categorical\_crossentropy',

optimizer='adam', #tensorflow.keras.optimizers.RMSprop(lr=base\_learning\_rate),

metrics=\['acc'\])

history = model.fit(

train\_batches,

steps\_per\_epoch=train\_batches.samples/train\_batches.batch\_size ,

epochs=100,

validation\_data=valid\_batches,

validation\_steps=valid\_batches.samples/valid\_batches.batch\_size,

verbose=1)

📷

📷",1.0
frxui2l,gram75,\_\_mod__ ? It’s not perfect but it will be close.,2.0
frxux8z,gram75,What's __mod__ ?,1.0
fry18l4,gram75,Not sure what the exact syntax would be but mod gives a remainder after division. 5 mod 2 = 1 for example. So generate a list of random numbers between 0 and 10^6 or something and then mod by a list of your max values.,2.0
fry27rp,gram75,"Brilliant, that worked!",1.0
frwpa4i,gr3tks,What skillset is required for the same ?,1.0
frxpx31,gr3tks,I think basic pytorch and/or tensorflow would be good enough to help in the tasks.,1.0
frwup5v,gr3tks,Maybe look into the group over at www endcoronavirus org,1.0
fry4gco,gr3tks,Tell me more about this.,1.0
fry5x6j,gr3tks,"We're mostly using the semantic scholar corpus and transformer models to develop query-&gt; document models, focusing on covid-19 papers. Here's one of our previous projects to give you an idea of our group https://github.com/Santosh-Gupta/NaturalLanguageRecommendations",1.0
fryerdf,gr3tks,"Hey I’m interested in participating, how do I start? Is there a discoed/slack?",1.0
frzu02s,gr3tks,"Sure, pm me your slack email and I can take you through a tour of the project there, and see if it's something you'd like to be involved in.",1.0
frvwx04,gr0n6i,"## Overview

We are very excited to extend Spark NLP support to 6 new BERT models for medical and clinical documents. We have also updated our documentation for 2.5.x releases, notebooks in our workshop, and made some enhancements in this release.

As always, we thank our community for their feedback and questions in our Slack channel.

## New Features

* Add Python support for PubTator reader to convert automatic annotations of the biomedical datasets into DataFrame
* Add 6 new pre-trained BERT models from BioBERT and ClinicalBERT

## Models

We have added 6 new BERT models for medical and clinical purposes. The 4 BERT pre-trained models are from BioBERT and the other 2 are coming from ClinicalBERT models:

|Model|Name|Build|Lang|Offline|
|:-|:-|:-|:-|:-|
|BertEmbeddings|`biobert_pubmed_base_cased`|2.5.0|`en`|[Download](https://s3.amazonaws.com/auxdata.johnsnowlabs.com/public/models/biobert_pubmed_base_cased_en_2.5.0_2.4_1590487367971.zip)|
|BertEmbeddings|`biobert_pubmed_large_cased`|2.5.0|`en`|[Download](https://s3.amazonaws.com/auxdata.johnsnowlabs.com/public/models/biobert_pubmed_large_cased_en_2.5.0_2.4_1590487739645.zip)|
|BertEmbeddings|`biobert_pmc_base_cased`|2.5.0|`en`|[Download](https://s3.amazonaws.com/auxdata.johnsnowlabs.com/public/models/biobert_pmc_base_cased_en_2.5.0_2.4_1590489029151.zip)|
|BertEmbeddings|`biobert_pubmed_pmc_base_cased`|2.5.0|`en`|[Download](https://s3.amazonaws.com/auxdata.johnsnowlabs.com/public/models/biobert_pubmed_pmc_base_cased_en_2.5.0_2.4_1590489367180.zip)|
|BertEmbeddings|`biobert_clinical_base_cased`|2.5.0|`en`|[Download](https://s3.amazonaws.com/auxdata.johnsnowlabs.com/public/models/biobert_clinical_base_cased_en_2.5.0_2.4_1590489819943.zip)|
|BertEmbeddings|`biobert_discharge_base_cased`|2.5.0|`en`|[Download](https://s3.amazonaws.com/auxdata.johnsnowlabs.com/public/models/biobert_discharge_base_cased_en_2.5.0_2.4_1590490193605.zip)|

## Enhancements

* Add unit tests for XlnetEmbeddings
* Add unit tests for AlbertEmbeddings
* Add unit tests for ContextSpellChecker

## Documentation

* Update documentation for release of Spark NLP 2.5.x
* Update the entire [spark-nlp-workshop](https://github.com/JohnSnowLabs/spark-nlp-workshop) notebooks for Spark NLP 2.5.x
* Update the entire [spark-nlp-models](https://github.com/JohnSnowLabs/spark-nlp-models) repository with new pre-trained models and pipelines

## Installation

**Python**

    #PyPI
    
    pip install spark-nlp==2.5.1
    
    #Conda
    
    conda install -c johnsnowlabs spark-nlp==2.5.1

**Spark**

    spark-shell --packages com.johnsnowlabs.nlp:spark-nlp_2.11:2.5.1

**PySpark**

    pyspark --packages com.johnsnowlabs.nlp:spark-nlp_2.11:2.5.1

**Maven**

    &lt;dependency&gt;
        &lt;groupId&gt;com.johnsnowlabs.nlp&lt;/groupId&gt;
        &lt;artifactId&gt;spark-nlp_2.11&lt;/artifactId&gt;
        &lt;version&gt;2.5.1&lt;/version&gt;
    &lt;/dependency&gt;

**FAT JARs**

* CPU: [https://s3.amazonaws.com/auxdata.johnsnowlabs.com/public/spark-nlp-assembly-2.5.1.jar](https://s3.amazonaws.com/auxdata.johnsnowlabs.com/public/spark-nlp-assembly-2.5.1.jar)
* GPU: [https://s3.amazonaws.com/auxdata.johnsnowlabs.com/public/spark-nlp-gpu-assembly-2.5.1.jar](https://s3.amazonaws.com/auxdata.johnsnowlabs.com/public/spark-nlp-gpu-assembly-2.5.1.jar)",1.0
frup82h,gqrgem,"You need to set allow_memory_growth = TRUE, depends on if you're using R or Python to how you do it but just googling that should get you the answer you need.

This stops tf/keras using all the GPU memory instantly and it just uses whatever it needs at the time. 

(If you're in R shoot me a dm, it's a right ballache and I have the code somewhere)",2.0
frxw3u9,gqrgem,"Thanks, I was able to find the answer following your keyword.

One more question though, I noticed about 50% of my available GPU memory is allocated even if I don't run any graphic intensive program. Does this mean I can only use the rest of the memory for training? Does it help if I switch to Linux?",2.0
fs6elxz,gqrgem,"I dont think I've had that issue myself tbh, and I've not used Linux before, sorry I cant be anymore help",1.0
fruc062,gqqbyl,"You're probably doing something wrong however it is possible the validation set just contains ""easier"" samples.  I would do some EDA on your datasets to see if anything is amiss.",3.0
frufgz3,gqqbyl,"I shuffle the data before testing, so it seems strange that the validation would be consistently easier than the rest.

Also, it's probably worth noting that my dataset is modifying their data to create new data, from what I understand.

https://www.kaggle.com/datamunge/sign-language-mnist",3.0
frv1ddw,gqqbyl,"Data augmentation is a big issue - it must be done *after* any train/validation/test split, otherwise you are measuring how well you can recognize the automatically created variations, which gives a high score with no relation to reality. So the thing ""worth noting"" likely is the actual cause.",4.0
fruylys,gqqbyl,"I had the same issue on another model. If you have Dropout it's normal see val\_accuracy higher than train\_accuracy. This happens because when the model checks the validation data the Dropout is not used for it, so all neurons are working and the model is more robust , while in training you have some neurons affected by the Dropout.

Anyway, having a val\_accuracy of 1.0 is still a lot and possibly a case of Overfitting, although it might not be too, you have to be very careful with this. I hope it helps.",3.0
frua6qu,gqqbyl,"Might be that the validation data is similar to the test data, or there is less validation data.",2.0
fru9s4n,gqqbyl,Can we get to know losses for both?,1.0
frueyaq,gqqbyl,"I didn't keep track of the loss in the examples in my original post but I retrained it and got this:

**training**

loss: 0.0161 - accuracy: 0.9980 - val_loss: 0.0021 - val_accuracy: 1.0000

**test** 

loss: 0.8013 - accuracy: 0.8330",2.0
frufaf2,gqqbyl,Training loss too low and testing loss too high. Classic case of overfitting. Try adding dropout layers and/or leaky ReLu. Or add some noise to the data,3.0
frufmxu,gqqbyl,I do have dropout layers but I haven't messed around with them too much. They're both at 0.2 right now. I haven't used leaky ReLu. I'll mess around with those. Thanks!,1.0
frudfk0,gqqbyl,Try increasing the validation_split,1.0
fruf6ug,gqqbyl,Maybe need to stratify?,1.0
frug0fa,gqqbyl,"I'm new to this. What exactly does that mean?

I do shuffle the data before training. Should I be taking equally as many samples for each label?",1.0
frumr7b,gqqbyl,"So stratify is important when in a classification problem, some label classes have less data than the others. For e.g. cats are like 10% and dogs are like 90% in your pictures due to data source or some other reasons, prior to any machine learning stuff. Then when you split training, testing (and maybe validation), you want to make sure that in each of those split data, they are represented in the same proportion (10% and 90%). This is important mostly when number of data is not too big, and I think if size of data is  big enough, you might be fine doing regular test train split randomly. 

I assume you are labeling certain sign language pics as some word/letter or something? Could you check if in the original dataset, each label class is present in uniformly or check how they are distributed?",2.0
frujwbh,gqqbyl,https://keras.io/getting_started/faq/#why-is-my-training-loss-much-higher-than-my-testing-loss,1.0
frvkjcw,gqqbyl,"- dropout is a good explanation for Val acc being higher then train like one other answers points out
- if you have batch norm are you sure youre not training those params during validation
- try using a fixed seed (see tf.set_random_seed) and switching your test and Val set and monitor if your training loss follows a similar trend in both runs.",1.0
frr6d4d,gq7iwl,"I'm new too, but usually if it's a constant, you can't change it. You'll have to set it to a variable. To change a variable, the usual way of modifying it is var.assign(value). You shouldn't have to define dtype everywhere, but it's a good practice anyway. create a python variable dtype= tf.float32 and just use that everywhere, so that you don't mix up. 

 Also, from TF2.0 onwards, you can run code ""eagerly"", i.e. like normal python code, so no need for sessions. Additionally, if you're not using numpy, no need to import it. 

The final line will be valid for constants, but not for variables. 

Feel free to correct me if something doesn't look right",3.0
frrcv4u,gq7iwl,"It calculated m,c using tf.Constant",1.0
frrgtgo,gq7iwl,Why not use TensorFlow 2?,1.0
frrgwip,gq7iwl,I'm on tf2. But some time ago I got to know sessiins are not required,1.0
frrhm24,gq7iwl,"`tf.Session` is banished only available as `tf.compat.v1.Session` in tf2. Are you sure you're using the version you think you're using?

```
import tensorflow as tf
print(tf.__version__)
tf.Session
```

Yes. everything will be much easier if you stop using `tf.Session`",2.0
frrudlk,gq7iwl,"Same code on TF2 worked for me without sessions.

`import tensorflow as tf`

`print(tf.__version__)`

`X = tf.cast(tf.constant([1,2,3,4,5]),tf.float32)`

`y = tf.cast(tf.constant([10,20,30,40,50]),tf.float32)`

`m = tf.constant(0,dtype=""float32"")`

`c = tf.constant(0,dtype=""float32"")`

`a = 0.1`

&amp;#x200B;

`def dm(X,y,y_hat):`

`dm = tf.constant(0, dtype = ""float32"")`   

`for i in range(5):`

`dm += (y_hat[i] - y[i])*X[i]`

`return dm/5`

&amp;#x200B;

`def grad_desc(X,y,m,c,a):`

`for i in range(1000):`

`y_hat = tf.multiply(m,X)+c`

`c = c - tf.reduce_sum(y_hat - y)*(a/5)`

`m = m - tf.cast(a*dm(X,y,y_hat),tf.float32)`

`print(m,c)`

&amp;#x200B;

`grad_desc(X,y,m,c,a)`",1.0
frrvd3a,gq7iwl,Thanks :),1.0
frnt4rh,gpirkf,"Geron's book is good for tf. For tfrecord files I made this little repo to help:    
https://github.com/ericthomson/tfrecord-view",5.0
frog3o9,gpirkf,"Hello, I have found the documentation on TFRecords lacking and I've had to do quite a lot of search in the past weeks. In the next days I'll write a tutorial on how to create a TFRecord dataset from numpy arrays and how to load and use it in keras. If you are interested keep an eye on [techytok.com](https://techytok.com) (I'll also make a post on this subreddit when I'm done).",3.0
frmcwdd,gpirkf,"RemindMe! 10 hours ""tfrecord post""",1.0
frmcxbl,gpirkf,"I will be messaging you in 10 hours on [**2020-05-24 15:14:53 UTC**](http://www.wolframalpha.com/input/?i=2020-05-24%2015:14:53%20UTC%20To%20Local%20Time) to remind you of [**this link**](https://np.reddit.com/r/tensorflow/comments/gpirkf/tfrecord_and_tfexample/frmcwdd/?context=3)

[**CLICK THIS LINK**](https://np.reddit.com/message/compose/?to=RemindMeBot&amp;subject=Reminder&amp;message=%5Bhttps%3A%2F%2Fwww.reddit.com%2Fr%2Ftensorflow%2Fcomments%2Fgpirkf%2Ftfrecord_and_tfexample%2Ffrmcwdd%2F%5D%0A%0ARemindMe%21%202020-05-24%2015%3A14%3A53%20UTC) to send a PM to also be reminded and to reduce spam.

^(Parent commenter can ) [^(delete this message to hide from others.)](https://np.reddit.com/message/compose/?to=RemindMeBot&amp;subject=Delete%20Comment&amp;message=Delete%21%20gpirkf)

*****

|[^(Info)](https://np.reddit.com/r/RemindMeBot/comments/e1bko7/remindmebot_info_v21/)|[^(Custom)](https://np.reddit.com/message/compose/?to=RemindMeBot&amp;subject=Reminder&amp;message=%5BLink%20or%20message%20inside%20square%20brackets%5D%0A%0ARemindMe%21%20Time%20period%20here)|[^(Your Reminders)](https://np.reddit.com/message/compose/?to=RemindMeBot&amp;subject=List%20Of%20Reminders&amp;message=MyReminders%21)|[^(Feedback)](https://np.reddit.com/message/compose/?to=Watchful1&amp;subject=RemindMeBot%20Feedback)|
|-|-|-|-|",1.0
frmietk,gpirkf,"I assume you've seen this? https://www.tensorflow.org/tutorials/load_data/tfrecord

I agree that the documentation feels lacking. In this case the docs feels bad because the API is unintuitive. Protobufs (what the TFExample class is) are unintuitive and seem unnecessarily complicated at first. I'd recommend just not using them until you really wanna squeeze some performance out of your data pipelines or want to have nice production feeling code. While you're learning, I'd recommend using numpy arrays if possible.

If you are set on using them the best way to get a feel for them is the colab notebook in the linked page and just tinkering around.",1.0
frmjmw4,gpirkf,PyTorch doesn't require building a graph. Would you suggest learning PyTorch First and then TF? I've basic understanding of TF (not much) but I'm hesitant to learn PyTorch because it'll require to learn from the beginning again.,1.0
frmkfo0,gpirkf,"Depends why you want to use TF. 10/10 would recommend pytorch if you're learning. I used TF on and off for 3 years and switched to pytorch a few months ago and I'm very happy with that choice. 
TF now has eager mode things and in theory that basically makes it the same as pytorch as far as interacting with your code, but in practice it felt like a hack on top of the old TF to keep up with pytorch (while at the same time ruining the old TF that I came to like). I found myself wanting to make use of all the high level apis TF has to offer and then getting annoyed when it was hard to dig deep into things or modify anything off the beaten path of load, shuffle, augment, train, etc.",2.0
frmkkv3,gpirkf,"I'm just an undergrad student trying to learn skills before i start MS (2021-2023). Since Tf is difficult to learn than PyTorch, I thought I should get past this and then start with PyTorch. Also i love keras",1.0
frml1tc,gpirkf,"I have fun writing code with pytorch and I did not have as much fun with TF and that makes it easier for me to learn. Learning new things is difficult enough as it is, I wouldn't recommend doing the harder thing first just to get it out of the way.",2.0
frml64z,gpirkf,Hmm makes sense. As long as the purpose is being served :),1.0
frlnvqs,gpfx23,Try transforming the pandas dataframes you're using for your data to numpy arrays before passing them to your .fit function,1.0
frlurje,gpfx23,"Yea, I figured that out... I just don't know how to exactly do that. Could you help?",-1.0
frlyhzl,gpfx23,I think you just use dataframe.numpy() or something. It'll take you like two seconds to find the answer on stackoverflow or the panda docs though.,3.0
frm29ft,gpfx23,"Got it thanks! Just to make sure, I need to change (for example) TRAIN\_DATA to a numpy array?",1.0
frm3idk,gpfx23,An array of an array to be precise. Just read the values of thedataframe by DATAFRAME.values that itself returns a np array.,2.0
frm4q03,gpfx23,"I don't understand the second part, could you please clearify?",1.0
frm53mg,gpfx23,Use dataframe_name.values to get your dataframe without the column names into a numpy array.,2.0
frm7wyx,gpfx23,"Got it, I see what you mean. Thank you!",1.0
frmd8hh,gpfx23,"So I tried turning it into a numpy array, but I am still getting the same errors. Here's my code:  
 

`import tensorflow as tf`  
`import pandas as pd`  
`import numpy as np`  
`# import numpy as np`  
`train_data_path = ""C:/Users/User/Desktop/Machine_Learning/Neural_Network/BTCUSD.csv""`  
`TRAIN_DATA = pd.read_csv(train_data_path)`  
`train_target = TRAIN_DATA.pop(""Close"")`  
`TRAIN_DATA = np.array(TRAIN_DATA.values)`  
`train_target = np.array(train_target.values)`  
`eval_data_path = ""C:/Users/User/Desktop/Machine_Learning/Neural_Network/BTCUSD_eval.csv""`  
`EVAL_DATA = pd.read_csv(eval_data_path)`  
`eval_target = EVAL_DATA.pop(""Close"")`  
`EVAL_DATA = np.array(EVAL_DATA.values)`  
`eval_target = np.array(eval_target.values)`  
`model = tf.keras.models.Sequential()`  
`model.add(tf.keras.layers.Flatten(input_shape=(1973, 8)))`  
`model.add(tf.keras.layers.Lambda(`  
 `lambda x: tf.expand_dims(model.output, axis=-1)))`  
`model.add(tf.keras.layers.LSTM(128, activation=""tanh""))`  
`model.add(tf.keras.layers.Dense(1))`  
`model.compile(`  
 `optimizer=tf.keras.optimizers.Adam(),`  
 `loss=tf.keras.losses.mean_absolute_error,`  
 `metrics=['Accuracy']`  
`)`  


`train = model.fit(`  
    `TRAIN_DATA, train_target,`  
 `batch_size=32,`  
 `epochs=10`  
`)`",0.0
frmmt2y,gpfx23,I'm not sure without seeing your data. You'll probably have to debug a little. My guess is your data is not the correct format but I can't be sure. You might try casting the data (ex. Train data = traindata.astype(np.float32)),1.0
fropxgm,gpfx23,"Okay, thank you.",1.0
frnw1p9,gpfx23,"Can you print the converted data and post a picture ?
Both the attributes and the target variable.",2.0
frp0l0r,gpfx23,"Here are the pictures:

The Converted Data:

[https://ibb.co/S3KHk0s](https://ibb.co/S3KHk0s)

&amp;#x200B;

With target variable:

[https://ibb.co/bdHnsfw](https://ibb.co/bdHnsfw)",1.0
frow2pi,gpfx23,"If your dataframe has an n-dim array in a cell, you can try to do something like that:
X=df[colname].values
X=tf.convert_to_tensor(list(X), dtype=tf.float32)",2.0
frp2o5k,gpfx23,"Okay, two questions. What should be the ""colname"" and in the ""fit"" method, do I pass ""x"" as the training data?",1.0
frp4hxs,gpfx23,"I'm not sure what exactly you are trying to do, but you can check this repo 

https://github.com/CloseToAlgoTrading/CodeFromVideo/tree/master/episode_12

I convered some data for lstm model. Solution is a bit ugly, but it works :)",2.0
frp4slm,gpfx23,Thank you so much!,1.0
frpi3f9,gpfx23,"Okay, I think I fixed the problem. I have a question which is kind of out of context. Let's say I have created a model to predict the price of Bitcoin on the next day, what would be my input data? I am not sure what to give into the ""predict"" method. Someone help me out please.",1.0
fuxob24,gpfx23,"What you can do is take a window of x samples i.e from the last days. So your input is 3 dimensional and looks like this: (batch_size, window_size, features). For each window, your model output the prediction for the next day. So you can train in supervised fashion. LSTM are well-suited for this task. To go from 3d to 2d data with LSTM use `return_sequences=False`.",1.0
frqmuxd,gpfx23,"Well you have String, float and time stamps. This is practically raw data. You need to preprocess this data. Convert the string into OHVs, convert time stamps into time steps and then into float and only then feed it into a network.",1.0
frx4815,gpfx23,"I see, what are OHV's? And I just to be clear, I first need to convert time stamps which are just integers into time steps, and then into float. How should I turn them into a float?",1.0
fryi540,gpfx23,"OHV-One Hot Vector Encodings

https://www.tensorflow.org/api_docs/python/tf/one_hot

And time steps are int values and they would do fine. No need to convert to float. Even then if you want you can by casting it to tf.float32 .",2.0
fs9q38u,gpfx23,"Okay, thanks!",1.0
frltj2d,gpfld1,"bottlenecks in data science are every time data is collected, transformed, analyzed or distributed.",2.0
frkswzy,gp95gt,"yes, and the middle layers should have more nodes. the input layer will stay the same if you have the same image size.",1.0
frkucnw,gp95gt,"Ok, thank you! How do I separate the letters? Do you have a link to a python tutorial?",1.0
frjrv1f,gp40nf,"You're not initializing a new context for each request, I hope?",2.0
frjs106,gp40nf,"No, the model is loaded once and queried by a small number of threads",1.0
frjsg87,gp40nf,"If you're running on CPU, I assume that you've quantized most of the ops to int8 rather than float32?",2.0
frjuy20,gp40nf,"Hmm, I'll need to check that. I doubt it. I have included a link to a raw dump of graph operations above.
I'm not sure what all the 'save' operations are for. We do not modify the graph in any way once it's loaded.
The model is output from BigQuery, I'm not sure how much control we have over the operations it uses and how.",2.0
frjy5q3,gp40nf,https://developer.nvidia.com/gtc/2020/video/s21664,1.0
frixrsn,gozfzo,"You have to schedule your optimizer using build-in modules. Refer here:

[https://www.tensorflow.org/api\_docs/python/tf/keras/optimizers/schedules](https://www.tensorflow.org/api_docs/python/tf/keras/optimizers/schedules)",2.0
frjky5h,gozfzo,"Use tf.Variables:

```
import tensorflow as tf
lr = tf.Variable(0.01)
mom = tf.Variable(0.2)
opt = tf.optimizers.SGD(learning_rate=lr, momentum=mom)
print(opt.get_config())
lr.assign(0.1)
mom.assign(0.999)
print(opt.get_config())
```

&gt; \_\_call__

Don't you need to use one of the `on_*` methods here?",2.0
frjnq2i,gozfzo,That makes sense thank you,1.0
frjz2zo,gozfzo,"Sorry, noob here. But tensorflow does have a momentum attribute for the SGD optimizer. Or am I confusing between tf.keras.optimizer and tf.optimizer ?",1.0
frh5e36,gop9v0,"TensorFlow Datasets is not automatically installed with TensorFlow.

`!pip install tensorflow_datasets`, just like the first line under that link.",2.0
frist31,gop9v0,"You have to install tensorflow_datasets seperately
pip install tensorflow_datasets - - user",1.0
frfxb4a,gocgp1,"""43 classes on training and 19 classes for testing"" is not appropriate. You must have a particular encoding of classes (e.g. a one-hot vector of length 43) at the output layer, and that encoding must be the same for both training and testing as the same network is used for both training and testing.",2.0
frgg1cs,gocgp1,"It worked, thanks. For I thought it would be fine if test classes is below training classes.",1.0
frghedi,gocgp1,"It's not about the number of classes, but about having a single, well-defined interpretation of what the class number means - for example, if in an image classification task, in training data class #12 means camels and class #13 means cats, then if your test data does not have any camels, then you don't want to interpret class #12 as cats during testing,  because all the neuron weights will be configured to point camel-like features towards #12 and cat-like features away from #12.",1.0
frmgpun,gocgp1,Ohh. Thanks for clarifying that for me.,1.0
frmguyz,gocgp1,"I tried changing my model from mobilenet to resnet 50 v2, using this script. As a result, it seems that mobilenet is more accurate than resnet 50. I was expecting that resnet would give me more accurate results than mobilenet, what do you think the problem is? is the script doing it wrong?",1.0
frf0v5m,go16tj,"LSTM isn't different than any other layer in the sense that however many nodes your output layer is, will be the final amount of values predicted.",2.0
frfngdp,go16tj,"You can also add a sense layer with 2 neurons as a last layer with more lstm cells.
If you have different tasks, let's say one is classification and one regression, you can define multiple outputs in tf.keras with different activation functions",1.0
frhe8x7,go16tj,"What would that translate to in the code?  I'm having a hard time digesting what each of the keras layers does.

For example, here is my code that defines the model:

`multi_step_model = tf.keras.models.Sequential()`  
`multi_step_model.add(tf.keras.layers.LSTM(32,`  
`return_sequences=True,`  
`input_shape=train_multi_features.shape[-2:]))`  
`multi_step_model.add(tf.keras.layers.LSTM(16, activation='relu'))`  
`multi_step_model.add(tf.keras.layers.Dense(FUTURE_TARGET))`  
`multi_step_model.compile(optimizer=tf.keras.optimizers.RMSprop(clipvalue=1.0), loss='mae')`

`multi_step_history = multi_step_model.fit(train_data_multi, epochs=EPOCHS,`  
`steps_per_epoch=EVALUATION_INTERVAL,`  
`validation_data=val_data_multi,`  
`validation_steps=50)`

My Dense layer takes a parameter of 200, because that is how many data points I want to predict into the future.  train\_multi\_features is (9800,20,2), so the input\_shape fed into the LSTM layer is 20x2.  The 2 features are the pairs that represent the final dimension of this data's shape.  I want to predict them both as a regression with LSTM from the same model.

Right now I'm getting an error on the call to .fit(...) that is saying:

`tensorflow.python.framework.errors_impl.InvalidArgumentError:  Incompatible shapes: [64,200] vs. [64,2,200]`

So I know it's not expecting to be returning 2 results for each of the 200 future predictions, but I don't understand why.",1.0
frhll9v,go16tj,"What is your y_train.shape?  
You might need to make 400 outputs and reshape them.",1.0
fs4bar2,go16tj,"I figured it out now.  You hit the nail on the head with the 400 outputs and reshaping them.  I also took your original advice of adding the Dense layer for 2 outputs.  I'm not sure if I did this the most efficient or effective way, but basically this is how I changed my previous code.  Thanks for pointing me in the right direction!

&amp;#x200B;

`multi_step_model = tf.keras.models.Sequential()`  
`multi_step_model.add(tf.keras.layers.LSTM(32,`  
 `return_sequences=True,`  
 `input_shape=train_multi_features.shape[-2:]))`  
`multi_step_model.add(tf.keras.layers.LSTM(16, activation='relu'))`  
`multi_step_model.add(tf.keras.layers.Dense(FUTURE_TARGET*2))`  
`multi_step_model.add(tf.keras.layers.Reshape((FUTURE_TARGET, 2)))`  
`multi_step_model.add(tf.keras.layers.Dense(2))`  
`multi_step_model.compile(optimizer=tf.keras.optimizers.RMSprop(clipvalue=1.0), loss='mae')`",2.0
fs4bmnn,go16tj,I am glad you figured it out. I had my final exams yesterday so I didn't had the time to write more.,1.0
frjtz16,go16tj,"I don't totally understand some of these data structures (probably half of the problem).  train\_data\_multi is a RepeatDataset.

It is:

&lt;RepeatDataset shapes: ((None, 20, 2), (None, 2, 200)), types: (tf.float64, tf.float64)&gt;

It was created with these lines of code:

`train_data_multi = tf.data.Dataset.from_tensor_slices((train_multi_features, train_multi))train_data_multi = train_data_multi.cache().shuffle(BUFFER_SIZE).batch(BATCH_SIZE).repeat()`

train\_multi\_features.shape is (9800, 20, 2)

train\_multi.shape is (9800, 2, 200)

EDIT - I thought maybe this last bit was the problem.  I think my train\_multi should be (9800, 200, 2).  I fixed this and reshaped the data, but I still get an error on the call to the fit function.

`ValueError: Dimensions must be equal, but are 200 and 2 for '{{node mean_absolute_error/sub}} = Sub[T=DT_FLOAT](sequential/dense/BiasAdd, Cast)' with input shapes: [?,200], [?,200,2].`",1.0
frem302,gnzmyv,If at one point A=1 you  take the log(0) which could cause the problem,2.0
frcvqjx,gnzmyv,"Not sure about tf, but do you not have to pass in values to your cost function?

    loss = compute_cost(prediction_var, label_var)",1.0
frd0emb,gnzmyv,"I was trying custom loss function and refered  [this](https://www.youtube.com/watch?v=4eIlvlP-8wk&amp;t=973s) video.

Here he hasn't passed the values to the cost function.",1.0
frdon9o,gntr5d,"i love the work on this site, good job!",2.0
frdoqlw,gntr5d,Thanks!,1.0
fraknhd,gnlzmq,"That link returns a 404 error

Try his directions in the Readme here: https://github.com/fchollet/deep-learning-models",1.0
fradqcb,gnjgfr,"Well, you'd want to start by installing the NVidia driver, currently version 440, rather than CUDA.

Since you're likely to require multiple versions of CUDA and cuDNN, and multiple versions of Tensorflow, side by side, you might want to install CUDA and cuDNN with these instructions instead: https://gist.github.com/mikaelhg/cae5b7938aa3dfdf3d06a40739f2f3f4#file-cuda-install-md",1.0
fr87dmf,gn4abx,There is a ML course by Google. Google it and you'll find the link,2.0
fr8r54x,gn20nx,"[tf.data](https://tf.data) has a better interface with the training loop. While Sequence read from disk and cause a break for the GPU, [tf.data](https://tf.data) has multiple options for caching, prefetching data which makes it way more optimized for training.

I actually migrated some codebase from Sequences to [tf.data](https://tf.data) months ago for a one-shot learning library ([Github](https://github.com/few-shot-learning/Keras-FewShotLearning)), and training time reduced drastically (over 50% faster).",1.0
fr7f6fc,gn1efy,"You can use tensors with a cpu. They are like I dunno 30x slower than a regular gpu though. 

If you want really high end heavy computational stuff, the. You can buy gpu’s. Expect to spend thousands of dollars, not hundreds.",3.0
fr745e1,gn1efy,"If by tensor you mean tensorflow than... kind of. You are going to need the whatever hardware supports the drivers (CUDA version x) that the tensorflow environment needs.

Hope this helps.",2.0
fr607zl,gmvpku,"The [AV1 Image File Format](https://en.wikipedia.org/wiki/AV1#AV1_Image_File_Format_(AVIF)), AVIF in short, is a new image format based on the AV1 video codec. [libavif](https://github.com/AOMediaCodec/libavif) can be used to encode and decode AVIF images, among others.",1.0
fr6hc7p,gmvnt1,"The fit_on_texts method of the tokenizer doesn’t overwrite the old dictionary, it updates it.",1.0
fr7jgwo,gmo1q6,"Please do tune in today people!
Live at 11.30 AM, IST",1.0
fr4lh3x,gmfzxf,"Tensors are closer to Numpy arrays. They are a specialized type of array that Tensorflow uses as the basic building block of most of what it does. Datasets do have functionality that tensors don’t. There is a whole Data API in tensorflow for ingesting and working with data. These are functions that work on it with datasets, and not tensors in general.",1.0
fr50lyc,gmfzxf,"I see, thank you for your answer!

Would you say Datasets work as a sort of collection of tensors with a different API that adds functionality?  

I'm also having trouble understanding when I should use a Tensor and when I should use a Dataset.",1.0
fr58xtl,gmfzxf,"Datasets are higher level. It’s not a perfect analogy but Datasets are to tensors as pandas dataframes are to Numpy arrays. Datasets end up putting your data in tensors anyways, but there’s a lot of functionality for doing so that you would have to create yourself if you are solely trying to work with tensors. There are times to use one, and times where you will be using both. Generally, I think Datasets are the best way to set up the data you will be feeding to your model.",1.0
fr5tr5g,gmfzxf,"Makes perfect sense, thank you!",1.0
fr3eptu,gmdybo,Have a look on this? https://github.com/deezer/spleeter,5.0
fr3f0zh,gmdybo,"not exactly it, but pretty close to what i need. thank you!",2.0
fr4ehxq,gmdybo,[deleted],1.0
fr4eipb,gmdybo,"I will be messaging you in 2 days on [**2020-05-21 10:54:04 UTC**](http://www.wolframalpha.com/input/?i=2020-05-21%2010:54:04%20UTC%20To%20Local%20Time) to remind you of [**this link**](https://np.reddit.com/r/tensorflow/comments/gmdybo/does_anyone_know_of_any_tutorials_of_a_voice/fr4ehxq/?context=3)

[**1 OTHERS CLICKED THIS LINK**](https://np.reddit.com/message/compose/?to=RemindMeBot&amp;subject=Reminder&amp;message=%5Bhttps%3A%2F%2Fwww.reddit.com%2Fr%2Ftensorflow%2Fcomments%2Fgmdybo%2Fdoes_anyone_know_of_any_tutorials_of_a_voice%2Ffr4ehxq%2F%5D%0A%0ARemindMe%21%202020-05-21%2010%3A54%3A04%20UTC) to send a PM to also be reminded and to reduce spam.

^(Parent commenter can ) [^(delete this message to hide from others.)](https://np.reddit.com/message/compose/?to=RemindMeBot&amp;subject=Delete%20Comment&amp;message=Delete%21%20gmdybo)

*****

|[^(Info)](https://np.reddit.com/r/RemindMeBot/comments/e1bko7/remindmebot_info_v21/)|[^(Custom)](https://np.reddit.com/message/compose/?to=RemindMeBot&amp;subject=Reminder&amp;message=%5BLink%20or%20message%20inside%20square%20brackets%5D%0A%0ARemindMe%21%20Time%20period%20here)|[^(Your Reminders)](https://np.reddit.com/message/compose/?to=RemindMeBot&amp;subject=List%20Of%20Reminders&amp;message=MyReminders%21)|[^(Feedback)](https://np.reddit.com/message/compose/?to=Watchful1&amp;subject=RemindMeBot%20Feedback)|
|-|-|-|-|",1.0
fr0qg0u,gm0afh,"Check out this talk from GOTO Copenhagen 2019 by Kaz Sato, staff developer advocate at Google Cloud. You can give the full talk abstract a read below:

TensorFlow Lite is TensorFlow’s lightweight solution for Android, iOS and embedded devices. It enables on-device machine learning inference with low latency and a small binary size. TensorFlow Lite also supports hardware acceleration with the Android Neural Networks API and Apple Core ML. In this session, we will discuss how developers can use TensorFlow Lite to overcome the challenges for bringing the latest AI technology to production mobile apps and embedded systems.",1.0
fr0cziy,glxo0d,Highly recommend it.,2.0
fr0e9br,glxo0d,Is it done in tensorflow 2?,2.0
fr0egwm,glxo0d,I believe so,2.0
fr0iznh,glxo0d,"Nope, Tensorflow1 sadly. But still an amazing course !",2.0
fr2vvi7,glxo0d,"I've finished all 3 Sepecializations from [deeplearning.ai](https://deeplearning.ai) on Coursera. Andrew Ng's specialization does not use Tensorflow 2, but it's great for theoretical foundations and building intuition about Deep Learning. The two other Tensorflow Specializations (Tensorflow in Practice and Tensorflow Data and Deployment) are taught with Tensorflow 2. I'd highly recommend doing all of them, starting with Andrew Ng's specialization followed by Tensorflow in Practice and finally Tensorflow Data and Deployment.

Also, if you spend 6-7 hours a day learning through the week, you'll be able to finish both Tensorflow in Practice and Tensorflow Data and Deployment specializations within the trial period of one week (i.e two weeks). Andrew Ng's specialization took me a bit longer (3 weeks) and I paid for a month.",2.0
fr0rnqy,glxo0d,"You can also do ""Tensorflow in practice"" specialization course. I am doing it rn and it's really good.",2.0
fr0rpw8,glxo0d,"Oh, and I forgot, it's a mix if tf1.x and tf2.x",2.0
fr2dbye,glxo0d,"My boyfriend got me “Hands-on Machine Learning with Scikit-Learn, Keras and Tensorflow” and I have found it very useful. I learned by trying to do a project for research which is another option. Videos are great too!",2.0
fr2dpap,glxo0d,Is that on Coursera?,2.0
fr2e0ak,glxo0d,Unsure.,1.0
fr1nket,glxo0d," [https://developers.google.com/machine-learning/crash-course](https://developers.google.com/machine-learning/crash-course) this is a crash course from Google, the creators of TF. They teach most of the core concepts you need to get going but it might be too basic for you. Definitely recommend trying it out though.",1.0
fr1ookf,glxo0d,Thanks a lot. Also how is Stanford ML MOOCs on YouTube?,1.0
fqz2n75,glpg9m,Search: Keras,8.0
fqz2sjc,glpg9m,Alright,1.0
fqz1e0r,glpg9m,"I think you should first understand the basics of machine Learning before dealing with tensorflow
This one are good courses
Ibm basic ml 
Or ml andrew ng",2.0
fqz2t9n,glpg9m,I’ll look into it,1.0
fqzpxyg,glpg9m,"Tensorflow is not so much about the code as the concepts. I'm a high school junior and I picked up tensorflow from the Google crash course when quarantine started. Within 3 weeks I learned enough to make a covid 19 classifier for lung CT scans. The best part is that most of my code was copied from previous lessons, just tweaked to get what I wanted out of it. I learned the concepts really well from Google so I recommend going through with it, searching terms you don't know along the way.",2.0
fqzy0yy,glpg9m,can you share the link tk that course? thanks,0.0
fr01559,glpg9m,https://developers.google.com/machine-learning/crash-course,1.0
fr01o6x,glpg9m,Can’t thank you enough my plan is to learn how to use them freely so I don’t have to sacrifice myself to the gods of stack Overflow,3.0
fr004jk,glpg9m,Google has something called machine learning crash course and it's really great imo. That's where I started and it really helped me. Just google that should be first result. Starts with videos and there are lots of examples and quizzes and programming tasks and stuff it's great,1.0
fr01r17,glpg9m,Damn I wish they did that with Scrapy that woulda been nice thanks for the suggestion,2.0
fr02f6p,glpg9m,"Start with classic machine learning using [sklearn](https://scikit-learn.org/stable/). Then when you understand what it is all about, transition to keras, and when that isn't powerful enough switch to the underlying tensorflow (or pytorch)

(Before I would suggest statistics as a first step, but it seems nobody has the patience for that step anymore.)",1.0
fr1fbfp,glpg9m,I know Keras is one of the building blocks of tensorflow so how similar to tensorflow is it? If it’s to similar I could just jump into the deepend,1.0
fr1h49d,glpg9m,"You got it the wrong way. Keras is a layer on top of TensorFlow (or PyTorch). It makes TensorFlow behave more like normal machine learning tools, like sklearn. In fact there is a sklearn ""API"" in Keras which mimics how you do things in sklearn.

In essence Keras just makes it simpler to make ANN models, and has standardized ways of doing things which would be a wall of code to do in TensorFlow directly.",1.0
fr1h9in,glpg9m,Oh I see,1.0
fqz2u28,glpg9m,"Tensorflow uses a lot of flashy terms and jargon nonsense (google engineer staple to get promotions) when in reality, it's much simpler. I would look into machine-learning and AI in general and the algorithms before even touching tensorflow.

OpenCV is a good place to start though its pretty outdated now. It came before tensorflow and it trained for image recognition by breaking pictures into matrixes of pixels and then crunching the numbers. Tensorflow takes that same concept but instead of just breaking images into matrixes, it allows you to break *anything* into matrixes like say stock market data or whatever. At the end of the day, its just matrixes of numbers that you are trying to find patterns with and then predict/extrapolate using those patterns.",1.0
fqz34mn,glpg9m,I never knew opencv was machine learning because I always see opencv and tensorflow paired together thanks I’ll check it out,1.0
fr01vrt,glpg9m,"It isn't really, although it does have some basic functionality in a couple modules.  That post was written by someone who sounds like CV was described to them at a bar one time and now they're trying to relay it to you.",2.0
fqxsydl,gliu1j,"If you are using Ubuntu simply do a:

find / -name tensorflow\_backend.py

On my system:

/home/ed/.local/lib/python3.6/site-packages/keras/backend/tensorflow\_backend.py

&amp;#x200B;

However in a virtual environment likely elsewhere. The above is for tf 2.0.

the ""find"" command from bash however will locate it!",1.0
fqy2s4m,gliu1j,"Thanks for the reply, but I get Permission denied in the output, also running sudo gives a similar result. Actually I use tensorflow.keras, that's the keras library which comes with tensorflow version 2.0. Does it have the tensorflow_backend.py file or it's equivalent? I need to make few changes to boost my gpu performance. Sorry for the long message",1.0
fqzx7aj,gliu1j,"Try running find ~ -name tensorflow_backend.py

The file is most likely somewhere in your home folder. It is normal for find / to be denied by certain folders only root can access.",1.0
fr00osp,gliu1j,"Yes, that worked thanks a lot",2.0
fr0hzgf,gliu1j,"Sorry yes I should have realized this, however as you were using sudo I assumed that would have given you root privileges on the entire filesystem...  however even then you can get a permission denied!",1.0
fr0ig8n,gliu1j,I would now remember what to do next time  thank u for ur help resident,1.0
fqycvv2,gliu1j,"hi there, ed",1.0
fqskroc,gkpdll,"Its okay to get to know the basics of tithe never used tf before, but if you've used tf before the best source is actually the documentation, specifically the advanced examples",6.0
fqsywx7,gkpdll,"I find the course materials to be shallow in general. However, it might work for you if you never used TensorFlow/Keras before.

On the point of outdated materials. The course extensively relies upon the abstraction layer provided by Keras. Since this abstraction layer did not change significantly between tf 1.X and 2.X, the materials covered in the course is applicable for both versions (at least they claim so).",1.0
fqt1cv2,gkpdll,"So, what approach do you recommend to a person who has some good programming knowledge, DL theory covered to learn tensorflow from scratch",1.0
fqtchhe,gkpdll,"To be honest, I am in no position to recommend a ""proper"" way of learning tf since I am still learning it myself. I can just comment on this particular specialization.

This specialization and documentation tutorials on the same topics contain similar information (loosely speaking). Ultimately, it depends on your learning style. I would recommend giving this specialization a try to figure out whether you like his teaching style. (If you already know the concepts then I think that the first course is doable in one day)",2.0
fqt8btr,gkpdll,"There should have never been a TensorFlow 2, just TensorFlow. There should be no version at all. Some people decided to do it just because they think PyTorch is going to be the next big thing, not TensorFlow. Those kind of people should just die.",-3.0
fqrxsbu,gkma3g,Work through geron's book on machine learning (2nd edition) like it is your new bible.  you probably don't probably don't need tensorflow first half of his book is about scikitlearn and other bits of machine learning,3.0
fqryvfr,gkma3g,Ordered and should be on it's way soon!  ty!!,1.0
fqrz4jd,gkma3g,Sentdex's neural networks from scratch is a good starting point,1.0
fqs01yl,gkma3g,"If you have very big data, and you considering prediting outliers like someone made a move in the house that he shoudn't be doing you can also check on anomaly detection models.",1.0
fqwdpms,gkma3g,"Properly using ML requires at least some basics in stats/math to properly reason about the different entities. Go ahead and have fun reading and using the API, but keep this in mind.

More to the point, you could model this using normal statistical software from 20 years ago.",1.0
fqzk3s4,gkma3g,"Thanks, yeah, my dive down the rabbit hole preparing for the above mentioned book to arrive led me (after a few hops) to ""Linear algebra for data analysis"", so I'm *trying* to read through and understand that now - then ""ML basics"" such as ""What is a recursive model"" etc. - *then*, if I understand correctly, I should be prepared to start through the above book.

I'm honestly shocked all that is required if I just want to feed in data and get a model that can tell me ""if this motion sensor, then this motion sensor fire, and it's x:00 [AP]M on yday, there is a 75% chance that motion sensor z will fire next"" ... but, it is what it is!  I can use this learning for work too, so I'd might as well do it properly I suppose!

I'm not sure what ""normal statistical software from 20 years ago"" would be, but if you know something specific - that I can incorporate into my code such that it can be rapidly consulted on what the expected next step will be in the above described pattern as it is happening, I will look into that for sure!  Thanks!!",1.0
fqzl9v6,gkma3g,"(First of all, I wasn't trying to be smarmy with the 20 year old stats software comment, I just meant it's not something that requires TF).

I think the first recommendation I have is to formulate your question into a statement that can fit inside Y=f(x). Where Y is the thing you want to predict, and X is the information you have to make that prediction. Can you state this clearly? In this case Y would be a vector Nx1, and X would be a NxM matrix.

Once you can state this clearly, your problem may actually be easy to put into ML software without needing to understand much stats/math.",1.0
fqzm3we,gkma3g,"Ironically it sounds to me like I need to understand some stats/math to simply answer *that* question :-D

And I took your 20 year old stats software comment to be literal - I have never done anything like any of this, so I wouldn't be surprised at all if you could point me at something 20 years old that could easily do this for me!

I believe I will have to do some more reading before I am able to formulate my question as instructed.  I shall return once I can!  :-)

Edit: (and seriously, I'm looking up ""What the hell is this big E shaped thing I keep seeing in formulas?!"" and trying to figure out with this damn R is where when I search for R I just get the programming language, lol - so yeah, *that's* the level I'm at ... I have a ways to go ... grade 12 math at best)",1.0
fqzm8v0,gkma3g,"Cool! Trying to learn some things to solve a problem is a great way to start, since that way when you need to learn a little math there is a end goal. Good luck.",1.0
fqppgr7,gk9bmy,"If this image was an input, what would be the output you’re trying to attain?",1.0
fqpqryn,gk9bmy,"The output is for the text annotations such as 1,2, etc. The conv net should recognise and differentiate between these unique numbers",1.0
fqpub7n,gk9bmy,"If I understand correctly, the output for the provided image should be integers 1 through 18? I would take a look at the MNIST examples for written numbers. I think a CNN should be able to accomplish this. 

One difficulty I could see is that not all images have the same number of label numbers. One could be 1-5 and another 1-20. For this reason I might change the output to be multi-class, multi-label classification; a list of 1/0 for if the number is present or not. Edit: This is called one-hot encoding

Edit2: [example](https://towardsdatascience.com/journey-to-the-center-of-multi-label-classification-384c40229bff)",1.0
fqpwkl5,gk9bmy,"I have already coded [MNIST code](https://github.com/arjun-majumdar/Lottery_Ticket_Hypothesis-TensorFlow_2/blob/master/LeNet_MNIST.ipynb) (you can see here). The idea is to automatically fill in text related to different components in the given image. For example, for component number 4, it should fill in text for it. And for this, it has to first identify the different numbers within the given image.",1.0
fqpwll0,gk9bmy,"
I see you've posted a GitHub link to a Jupyter Notebook! GitHub doesn't 
render large Jupyter Notebooks, so just in case, here is an 
[nbviewer](https://nbviewer.jupyter.org/) link to the notebook:

https://nbviewer.jupyter.org/url/github.com/arjun-majumdar/Lottery_Ticket_Hypothesis-TensorFlow_2/blob/master/LeNet_MNIST.ipynb

Want to run the code yourself? Here is a [binder](https://mybinder.org/) 
link to start your own Jupyter server and try it out!

https://mybinder.org/v2/gh/arjun-majumdar/Lottery_Ticket_Hypothesis-TensorFlow_2/master?filepath=LeNet_MNIST.ipynb



------

^(I am a bot.) 
[^(Feedback)](https://www.reddit.com/message/compose/?to=jd_paton) ^(|) 
[^(GitHub)](https://github.com/JohnPaton/nbviewerbot) ^(|) 
[^(Author)](https://johnpaton.net/)",1.0
fqq1t81,gk9bmy,"You may want an object-detector to get the bounding box for each image, then crop out the bounding boxes and pass them to an image -&gt; text module. 

Find numbers, for each number you found tell me what it is.",1.0
fqq4s07,gk9bmy,"Can you point me to some Tensorflow tutorials?
Thanks!",1.0
fqp7moq,gk66hu,"    FileNotFoundError                         Traceback (most recent call last)
    &lt;ipython-input-5-2d224e8903a9&gt; in &lt;module&gt;()
          1 print(tf.executing_eagerly())
          2 BATCH_SIZE = 5
    ----&gt; 3 images, attributes, shuffled_images, shuffled_attributes = DataLoader.load_dataset('./sketches', './encoded_data.csv', batch_size=BATCH_SIZE)
          4 
          5 data = tf.data.Dataset.zip((images, attributes, shuffled_images))
    
    5 frames
    /usr/local/lib/python3.6/dist-packages/pandas/io/parsers.py in __init__(self, src, **kwds)
       1889         kwds[""usecols""] = self.usecols
       1890 
    -&gt; 1891         self._reader = parsers.TextReader(src, **kwds)
       1892         self.unnamed_cols = self._reader.unnamed_cols
       1893 
    
    pandas/_libs/parsers.pyx in pandas._libs.parsers.TextReader.__cinit__()
    
    pandas/_libs/parsers.pyx in pandas._libs.parsers.TextReader._setup_parser_source()
    
    FileNotFoundError: [Errno 2] File ./encoded_data.csv does not exist: './encoded_data.csv'

Apparently some file is missing",1.0
fqp8aam,gk66hu,"That's the second link at the top of the notebook. I wasn't really sure about how to share it on Colab. So I just shared the links at the top of the notebook. Those are:

1. [The link to the sketch images](https://drive.google.com/drive/folders/1Lm6_SGsTTf_btfQQcruqeAxh31woww-L?usp=sharing)
2. [The link to the encoded data in CSV format](https://drive.google.com/file/d/1iA2caczbQ2ttOJnBGST14vEe0OqogRO2/view?usp=sharing) 

Hope this helps.",1.0
fqnllun,gjwufv,What is your OS? How did you install Tensorflow? Did you use Pip? You have to provide more information for us to be of any use.,1.0
fqp3jlq,gjwufv,"My OS is Windows 10 Home, I installed Tensorflow through Pip in Command Prompt.",1.0
fqp3y0d,gjwufv,"I always recommend using anaconda and then using \`conda install  tensorflow\`  
This takes care of all the dependencies in the background  
If you want to work on your GPU as well just replace tensorflow with tensorflow-gpu",1.0
fqpaccy,gjwufv,I downloaded it through anaconda and it still returns me the runtime error.,1.0
fqn2qqs,gjscod,"Look up in the tf.keras.image library the ImageDataGenerator and the flow_from_dir method. 

https://www.tensorflow.org/api_docs/python/tf/keras/preprocessing/image/ImageDataGenerator

It will automatically detect your classes (label is based on folder name) and potentially augment the images inline. It’s an incredible tool and can work with tf2.

Here’s an example:

https://www.tensorflow.org/tutorials/images/classification


It works for any number of directories too.",2.0
fqnc8cc,gjscod,"for some gaps in my own knowledge... 

once you have trained a NN and have a folder of images you wish to be classified... do you know how to use the libraries you just mentioned? I have a hack that I use for classifying single images but I dont believe that it is correct or an efficient use of resources.",2.0
fqn0e70,gjscod,"Are you training/ re-training a NN?

If yes then my experience is you just plug in the directory that contains all of the subdirectories and your good to go. TFLow will automatically use the subdirectory folder names as classes.

Hope this answers your question.",1.0
fqn0kvh,gjscod,Any example tutorial or code?,1.0
fqnc00l,gjscod, [https://www.tensorflow.org/tutorials/images/transfer\_learning\_with\_hub](https://www.tensorflow.org/tutorials/images/transfer_learning_with_hub),1.0
fqzb4oz,gjlbn0,"To answer my own question, this happens when the dims of your input tensors aren't correct. In my case, the model had inputs that took either a single float or a single string. The dims required for this to work were

std::array&lt;int64_t, 1&gt; dims{1};
TF_AllocateTensor(...,dims.data(), dims.size(),...)",1.0
fqkls8q,gjcapc,"Not Keras specifically, but maybe you're looking for [tf.raw_ops](https://www.tensorflow.org/api_docs/python/tf/raw_ops) ?",1.0
fqjog4n,gj9u5e,"which c# port are you using ?

SciSharp seems to support Tensorflow 2.1 [https://www.nuget.org/packages/SciSharp.TensorFlow.Redist/](https://www.nuget.org/packages/SciSharp.TensorFlow.Redist/)",0.0
fqjyr34,gj9u5e,"I'm using this:  [https://www.nuget.org/packages/TensorFlow.NET/](https://www.nuget.org/packages/TensorFlow.NET/) 

Thank you for the recommendation, I can try to write a C# wrapper around the dll",2.0
fqmz58w,gj9u5e,I would be intrested on your feedback (good or bad :D) on how it went.,1.0
fqjj107,gj9d03,"Just fork the imgdupes repo? You'll mainly be interested in the common/imagededuper.py file. At the bottom is the delete_image method. Find where it's used, and replace the logic appropriately? Or just replace the logic in that method for a quick and dirty fix?",1.0
fqjja7r,gj9d03,That's the smartest thing I've heard all day,1.0
fqjkndu,gj9d03,"I downloaded it and am having trouble running it, I kind of a noob to forking python github repos, do you know how to install all the dependencies and stuff",1.0
fqjljmd,gj9d03,"I've been a bit out of the loop and out of practice with Python, and I'm on my phone, but I'll give it a try.

Forking is usually done with a Git tool, either as a CLI or GUI. You could also just download and unzip the zip, tho that wouldn't really be forking, but you'd still be able to run the code and modify it. 

You should probably use virtual env or venv or whatever, if you are not already.

Installing dependencies is usually done with the requirements.txt file, which is provided here. Probably best to Google how to use that file with the chosen environment manager.

I also see a Docker file, so you may also give that a shot. This might not be the most practical approach if you're going to be editing the code a lot.

I don't know if Jetbrains' Pycharm IDE is available for Mac? They have a free version, and it might also have some useful plugins for what I mentioned above.",1.0
fqhvoib,givcmj,"Good job. I wonder, if one would split test set in two parts(and train model with one part as val set), would starting testing loss be the same for both test parts?",1.0
fqhwrl7,givcmj,"It should be. starting loss and/or starting accuracy indicates that the sub-network is better at generalising from the beginning after just one epoch of training.

And thanks!",2.0
fqkp7kw,givcmj,"I think it is possible, that we fit masks of layers to our test set. And that is the reason starting testing loss lower than starting training loss. Interesting to see starting loss on a data, that model did not see.",1.0
fqkplaw,givcmj,"Think of masking as a process of passing information from training back to the unwanted weights. As the ""winning tickets"" are found, consequently better masks are found and this increases starting accuracy and starting loss.

Read: ""Deconstructing Lottery Ticket Hypothesis"".",2.0
fqkqgf4,givcmj,"Thanks, I will look into it.",1.0
fqkp7uf,givcmj,"I agree, this does seem possible.",1.0
fqct97i,ghz9g6,Is it just me or is it hard to see any benevolent usage for this?,5.0
fwprl5n,ghz9g6,"I figure you're joking, but here's a little light reading of concerns https://builtin.com/cybersecurity/facial-recognition-technology

""Some say this controversial tech could eventually replace fingerprints."", ""in a world where identities are increasingly leveraged for profit and worse."", ""The only benefit of facial recognition he can think of is, maybe, added convenience. But that’s greatly outweighed by its intrusiveness.""

If abuse of online tracking hasn't taught you anything, then you're unaware.

It's inevitable, the development and it's authoritarian use.",1.0
fqb7pk6,ghproa,"&gt; Allocation of 16823566556 exceeds 10% of system memory.

That's not an allocation error. That's just telling you that it's using a lot of memory. Allocation succeeded perfectly fine.",2.0
fqbd79z,ghproa,"Okay, but the kernel crashes every time I see this message",1.0
fqc8df8,ghproa,"The kernel crashes, or the application crashes? If the kernel is crashing (a panic) then I would suspect the issues are unrelated.

Assuming Linux, if the app were using too much memory, the kernel would invoke the OOM killer and kill the application. If it is indeed a kernel panic, then that's not going to be any fault of your application. That's either a kernel bug, or a hardware problem. If you could post a screenshot or something of the issue, that would help diagnosis.

If it is the app crashing (being killed due to OOM), then it likely is not your dataset pipeline, though it is possible. `tf.data.Dataset` only retrieves one sample at a time. If you use `.batch`, all that does is make it grab multiple samples and merge them into one (by adding a dimension). Now if you're using `Dataset.cache()`, then that could be causing problems if you're not using a file-backed cache, as then it will try to shove your whole dataset into memory.",2.0
fqcx5iy,ghproa,"Sorry for the confusing description - I'm working in a Jupyter Notebook, and their python engines are called *kernels*, and those are crashing. And the last console output is always""Allocation of 12535..."" so I assumed this an error log.",1.0
fqgcyi2,ghproa,"Ahhh, sorry but don't use Jupyter much, so can't really help there.
I occasionally get that same error running tensorflow on my local system when I'm working with complex models, and they work fine (10% of my system memory is insignificant).",2.0
fqa2oxi,ghproa,"I'm a bot, *bleep*, *bloop*. Someone has linked to this thread from another place on reddit:

- [/r/learnmachinelearning] [\[x-post \/r\/tensorflow\] Conceptional question about tf.data: Isn't dataset.batch() supposed to work similar to a Keras Generator and not load a whole dataset into memory at once?](https://www.reddit.com/r/learnmachinelearning/comments/ghpvwq/xpost_rtensorflow_conceptional_question_about/)

&amp;nbsp;*^(If you follow any of the above links, please respect the rules of reddit and don't vote in the other threads.) ^\([Info](/r/TotesMessenger) ^/ ^[Contact](/message/compose?to=/r/TotesMessenger))*",1.0
fq96deo,ghjz6v,"## Overview

When we started planning for Spark NLP 2.5.0 release a few months ago the world was a different place!

We have been blown away by the use of Natural Language Processing for early outbreak detections, question-answering chatbot services, text analysis of medical records, monitoring efforts to minimize the virus spread, and many more.

In that spirit, we are honored to announce Spark NLP 2.5.0 release! Witnessing the world coming together to fight coronavirus has driven us to deliver perhaps one of the biggest releases we have ever made.

As always, we thank our community for their feedback, bug reports, and contributions that made this release possible.

## Major features and improvements

* **NEW:** A new AlbertEmbeddings annotator with 4 available pre-trained models
* **NEW:** A new XlnetEmbeddings annotator with 2 available pre-trained models
* **NEW:** A new ContextSpellChecker annotator, the state-of-the-art annotator for spell checking
* **NEW:** A new SentimentDL annotator for multi-class sentiment analysis. This annotator comes with 2 available pre-trained models trained on IMDB and Twitter datasets
* **NEW:** Support for 14 new languages with 80+ pretrained models and pipelines!
* Add new PubTator reader to convert automatic annotations of the biomedical datasets into DataFrame
* Introducing a new outputLogsPath param for NerDLApproach, ClassifierDLApproach and SentimentDLApproach annotators
* Refactored CoNLLGenerator to actually use NER labels from the DataFrame
* Unified params in NerDLModel in both Scala and Python
* Extend and complete Scaladoc APIs for all the annotators

## Bugfixes

* Fix position of tokens in Normalizer
* Fix Lemmatizer exception on a bad input
* Fix annotator logs failing on object storage file systems like DBFS

## Models and Pipelines

Spark NLP `2.5.0` comes with 87 new pretrained models and pipelines in 14 new languages available for all Windows, Linux, and macOS users. We added new languages such as Dutch, Norwegian. Polish, Portuguese, Bulgarian, Czech, Greek, Finnish, Hungarian, Romanian, Slovak, Swedish, Turkish, and Ukrainian.

The complete list of 160+ models &amp; pipelines in 22+ languages is [available here](https://github.com/JohnSnowLabs/spark-nlp-models/).

## Featured Pretrained Pipelines

## Dutch - Pipelines

|Pipeline|Name|Build|lang|Description|Offline|
|:-|:-|:-|:-|:-|:-|
|Explain Document Small|`explain_document_sm`|2.5.0|`nl`||[Download](https://s3.amazonaws.com/auxdata.johnsnowlabs.com/public/models/explain_document_sm_nl_2.5.0_2.4_1588546621618.zip)|
|Explain Document Medium|`explain_document_md`|2.5.0|`nl`||[Download](https://s3.amazonaws.com/auxdata.johnsnowlabs.com/public/models/explain_document_md_nl_2.5.0_2.4_1588546605329.zip)|
|Explain Document Large|`explain_document_lg`|2.5.0|`nl`||[Download](https://s3.amazonaws.com/auxdata.johnsnowlabs.com/public/models/explain_document_lg_nl_2.5.0_2.4_1588612556770.zip)|
|Entity Recognizer Small|`entity_recognizer_sm`|2.5.0|`nl`||[Download](https://s3.amazonaws.com/auxdata.johnsnowlabs.com/public/models/entity_recognizer_sm_nl_2.5.0_2.4_1588546655907.zip)|
|Entity Recognizer Medium|`entity_recognizer_md`|2.5.0|`nl`||[Download](https://s3.amazonaws.com/auxdata.johnsnowlabs.com/public/models/entity_recognizer_md_nl_2.5.0_2.4_1588546645304.zip)|
|Entity Recognizer Large|`entity_recognizer_lg`|2.5.0|`nl`||[Download](https://s3.amazonaws.com/auxdata.johnsnowlabs.com/public/models/entity_recognizer_lg_nl_2.5.0_2.4_1588612569958.zip)|

## Norwegian - Pipelines

|Pipeline|Name|Build|lang|Description|Offline|
|:-|:-|:-|:-|:-|:-|
|Explain Document Small|`explain_document_sm`|2.5.0|`no`||[Download](https://s3.amazonaws.com/auxdata.johnsnowlabs.com/public/models/explain_document_sm_no_2.5.0_2.4_1588784132955.zip)|
|Explain Document Medium|`explain_document_md`|2.5.0|`no`||[Download](https://s3.amazonaws.com/auxdata.johnsnowlabs.com/public/models/explain_document_md_no_2.5.0_2.4_1588783879809.zip)|
|Explain Document Large|`explain_document_lg`|2.5.0|`no`||[Download](https://s3.amazonaws.com/auxdata.johnsnowlabs.com/public/models/explain_document_lg_no_2.5.0_2.4_1588782610672.zip)|
|Entity Recognizer Small|`entity_recognizer_sm`|2.5.0|`no`||[Download](https://s3.amazonaws.com/auxdata.johnsnowlabs.com/public/models/entity_recognizer_sm_no_2.5.0_2.4_1588794567766.zip)|
|Entity Recognizer Medium|`entity_recognizer_md`|2.5.0|`no`||[Download](https://s3.amazonaws.com/auxdata.johnsnowlabs.com/public/models/entity_recognizer_md_no_2.5.0_2.4_1588794357614.zip)|
|Entity Recognizer Large|`entity_recognizer_lg`|2.5.0|`no`||[Download](https://s3.amazonaws.com/auxdata.johnsnowlabs.com/public/models/entity_recognizer_lg_no_2.5.0_2.4_1588793261642.zip)|

## Polish - Pipelines

|Pipeline|Name|Build|lang|Description|Offline|
|:-|:-|:-|:-|:-|:-|
|Explain Document Small|`explain_document_sm`|2.5.0|`pl`||[Download](https://s3.amazonaws.com/auxdata.johnsnowlabs.com/public/models/explain_document_sm_pl_2.5.0_2.4_1588531081173.zip)|
|Explain Document Medium|`explain_document_md`|2.5.0|`pl`||[Download](https://s3.amazonaws.com/auxdata.johnsnowlabs.com/public/models/explain_document_md_pl_2.5.0_2.4_1588530841737.zip)|
|Explain Document Large|`explain_document_lg`|2.5.0|`pl`||[Download](https://s3.amazonaws.com/auxdata.johnsnowlabs.com/public/models/explain_document_lg_pl_2.5.0_2.4_1588529695577.zip)|
|Entity Recognizer Small|`entity_recognizer_sm`|2.5.0|`pl`||[Download](https://s3.amazonaws.com/auxdata.johnsnowlabs.com/public/models/entity_recognizer_sm_pl_2.5.0_2.4_1588532616080.zip)|
|Entity Recognizer Medium|`entity_recognizer_md`|2.5.0|`pl`||[Download](https://s3.amazonaws.com/auxdata.johnsnowlabs.com/public/models/entity_recognizer_md_pl_2.5.0_2.4_1588532376753.zip)|
|Entity Recognizer Large|`entity_recognizer_lg`|2.5.0|`pl`||[Download](https://s3.amazonaws.com/auxdata.johnsnowlabs.com/public/models/entity_recognizer_lg_pl_2.5.0_2.4_1588531171903.zip)|

## Portuguese - Pipelines

|Pipeline|Name|Build|lang|Description|Offline|
|:-|:-|:-|:-|:-|:-|
|Explain Document Small|`explain_document_sm`|2.5.0|`pt`||[Download](https://s3.amazonaws.com/auxdata.johnsnowlabs.com/public/models/explain_document_sm_pt_2.5.0_2.4_1588501423743.zip)|
|Explain Document Medium|`explain_document_md`|2.5.0|`pt`||[Download](https://s3.amazonaws.com/auxdata.johnsnowlabs.com/public/models/explain_document_md_pt_2.5.0_2.4_1588501189804.zip)|
|Explain Document Large|`explain_document_lg`|2.5.0|`pt`||[Download](https://s3.amazonaws.com/auxdata.johnsnowlabs.com/public/models/explain_document_lg_pt_2.5.0_2.4_1588500056427.zip)|
|Entity Recognizer Small|`entity_recognizer_sm`|2.5.0|`pt`||[Download](https://s3.amazonaws.com/auxdata.johnsnowlabs.com/public/models/entity_recognizer_sm_pt_2.5.0_2.4_1588502815900.zip)|
|Entity Recognizer Medium|`entity_recognizer_md`|2.5.0|`pt`||[Download](https://s3.amazonaws.com/auxdata.johnsnowlabs.com/public/models/entity_recognizer_md_pt_2.5.0_2.4_1588502606198.zip)|
|Entity Recognizer Large|`entity_recognizer_lg`|2.5.0|`pt`||[Download](https://s3.amazonaws.com/auxdata.johnsnowlabs.com/public/models/entity_recognizer_lg_pt_2.5.0_2.4_1588501526324.zip)|

## Documentation

* Update documentation for release of Spark NLP 2.5.0
* Update the entire [spark-nlp-workshop](https://github.com/JohnSnowLabs/spark-nlp-workshop) notebooks for Spark NLP 2.5.0
* Update the entire [spark-nlp-models](https://github.com/JohnSnowLabs/spark-nlp-models) repository with new pre-trained models and pipelines",1.0
fq9l3o6,ghikzt,generics in python...smh,1.0
fq888m7,ghd73f,"Yes. Nearly all TensorFlow functions expect batches if inputs.

It's much more efficient to run batches because you because you do more with a weight value each time you load it.",1.0
fq8gizr,ghd73f,Ideas/example how to go about it?,1.0
fq8hxyn,ghd73f,"It will happen naturally, any tutorial worth reading will be setup to run in batch mode.",1.0
fq93c2c,ghd73f,It is more difficult to not batch for inferece. I think is at least 2 lines of extra code for inference on a single image.,1.0
fqwg34t,ghd73f,"This is the repo I’m using to do inference [deeplab_ros](https://github.com/ethz-asl/deeplab_ros)

Not sure how I would go about batching",1.0
fq8762h,ghcwcj,"You're mixing two incompatible APIs.

`keras.Input` is for symbolically building [keras functional](https://www.tensorflow.org/guide/keras/functional) models.

`optimizer.minimize` is takes a function that returns a **value**, and tries to minimize that function. your function generates some sort of symbol, and it's confused.

To make this work, your loss function needs actual values for x and y. It should be more like this:

```
def my_loss():
  y_pred = model(x_value)
  return mse(y_pred, y_value)
```",2.0
fq8x31h,ghcwcj,"Thank you for your reply. The larger problem I'm working on is multivariate regression where training must be done by way of the TensorFlow C API (actually using Rust which provides a thin layer on top). I was trying to define multiple optimizer operations which I could call through C/Rust. I imagine I could do this using low-level TensorFlow operations, but in reality my regression needs to find complex features using convolutional layers, so defining the model in Keras would be much more convenient.

Is there a ""keras"" way of doing multivariate regression that would be accessible from the C API? I tried defining multiple outputs and multiple losses, but they did not seem to appear as operations, thus I was interested in using the optimizer directly.",1.0
fqbx7pk,ghcwcj,"Tensorflow’s saved_model is meant to be the main interchange format. It’s possible to use one from the cpp api, but apparently it’s not easy, I haven’t tried.

At that level everything is tf ops.",1.0
fqbz59s,ghcwcj,FYI I don't know about CPP but in C you can load savedmodel serialized models using \`TF\_LoadSessionFromSavedModel\` which populates a \`Graph\` structure.,1.0
fq9g9ul,ghcwcj,"The y inputs  are not connected to anything on the model graph, thats why the error.

Do a tf.keras.utils.plot\_model(model) to check on that.",1.0
fqbbzfr,ghcwcj,How do the true values of y get into the model so the loss can be calculated? Do I somehow need to add the loss function to the graph? That's the only thing that would connect y to anything.,1.0
fqcx08z,ghcwcj,"I guess you are trying to do a basic fit on some data? If thats the case the following will do.

&amp;#x200B;

x = Input(shape=(1,), name='x') 

y\_pred = Dense(1, name='y\_pred')(x) 

model = Model(inputs=x, outputs=y\_pred) 

loss = MeanSquaredError(reduction=tf.keras.losses.Reduction.NONE) 

model.compile('Adam', loss=loss)

[model.fit](https://model.fit)(x=x\_data, y=y\_data)",1.0
fqgnj8q,ghcwcj,"Yes, the \`y\` was unnecessary since it gets fed in during \`fit\`. I was trying that because in my actual problem I have multiple regression outputs that I need to be able to train independently. I discovered that you can train only some of them at a time, while the others seem to be left alone, by passing a dictionary to \`fit\`.",1.0
fq9ki6d,gh9etl,"It's really good that you've done this video, and I'd recommend that you take a look at this https://gist.github.com/mikaelhg/cae5b7938aa3dfdf3d06a40739f2f3f4 and do a followup.",1.0
fq8n1jv,gh9etl,"No offence but I'll recommend not using 20.04. If you look at analyzer, GUI takes a lot of processes. Stick with either 16.04 or 18.04.

&amp;#x200B;

In addition, you can just install Nvidia driver (which is pre-installed in 20.04) and use Anaconda for installation. (condo install tensorflow-gpu)

It'll take care of CUDA, CUDNN, CUDA-Toolkit etc because they are not available for 20.04 yet.",1.0
fq8zzbo,gh9etl,"Hi, not sure about the anaconda package, but for the pip you don't need to install tensorflow-gpu, they already put everything in tensorflow package. I mean support of GPU.",1.0
fq5pcjo,ggy5f2,"1. download [https://www.anaconda.com/products/individual](https://www.anaconda.com/products/individual)
2. install it
3. create env
4. activate env
5. conda install tensorflow-gpu

ps: I forgot to mention i think it helps installing the latest nvidia drivers first for your distribution and gpu.",1.0
fq5ps5w,ggy5f2,"Oh so anaconda isn’t optional? I’ll give it a shot, thanks!
Edit : I have tried anaconda however I still get the same error message except now its : from versions : (none)",0.0
fq5up2p,ggy5f2,"Anaconda is optional, but you should learn to use it, it'll help you with multi-versions situations, as the one you're experience.

The main issue is that it should be pip install tensoflow-gpu==1.14.0 and not just 1.14.",1.0
fq5ut0x,ggy5f2,"Yeah, now that I’ve got it, might aswell use it. I will try out what you said, hopefully it works and thanks for your reply ^^",1.0
fq5vkfa,ggy5f2,"It didnt work, I still get the same error message ): If its any help, I have a screenshot of the error, I am using the latest version of pycharm community edition btw. https://imgur.com/JFTTb1M

Found the issue, I was using the wrong python version, the problem is solved now, thanks",1.0
fq5ojpj,ggwcfe,"Now with the newer versions of tensorflow, you are supposed to use .fit()",1.0
fq64hl2,ggwcfe,yes but its not working properly,1.0
fq63910,ggwcfe,"&gt; generator using model.fit() crashes my kernel

Could you be more specific?",1.0
fq64quw,ggwcfe,"I've created a custom generator based on Sequence() which outputs an X and a Y np.arrays, where the first dimension is length: batch\_size. 

&amp;#x200B;

documentation says use [model.fit](https://model.fit)(generator, ....) rather than [model.fit](https://model.fit)(x,y, ....), but when i do that it doesn't seem to work properly. Namely, I'm crashing my kernel from RAM usage, so its not properly generating.

model.fit\_generator(generator, ... ) seems to work as expected",1.0
fq65ej5,ggwcfe,"&gt; Sequence()

I don't know much about those. My goto is:

```
tf.data.Dataset.from_generator(make_generator_function, output_types=..., output_shapes=...)
```

https://www.tensorflow.org/api_docs/python/tf/data/Dataset#from_generator",1.0
fq4t533,ggo5t8,"Try ‘return_sequences=True’ on the
LSTM layer.

Normally an lstm only returns the last output.",2.0
fq4x2za,ggo5t8,"I remove ""return\_state"" and add ""return\_sequences"", but...

\----&gt; 8 encoder\_outputs, forward\_h, forward\_c, backward\_h, backward\_c = encoder(embed)

TypeError: Cannot iterate over a tensor with unknown first dimension.

Edit:

So I change it to

    lstm = encoder(embed)

This works just fine. Though, I'm pretty sure this is wrong.

The next problem will be the Concatenated and Average layers.

    # Input
    inputs = Input(shape=(max_length,), name=""Input"")
    
    # Embedding
    embed = Embedding(input_dim=n_words+2, output_dim=embedding_size, input_length=max_length, name=""Embedding"")(inputs)
    
    # Bi-LSTM
    encoder = Bidirectional(LSTM(units=hidden_state_encoder_size, return_sequences=True, name=""LSTM""), name=""Bi-LSTM"")
    lstm = encoder(embed)
    
    # Concatenated
    state_h = Concatenate(name=""Concat_1"")([forward_h, backward_h])
    state_c = Concatenate(name=""Concat_2"")([forward_c, backward_c])
    
    # Average
    average = Average()([state_h, state_c])
    
    # Outputs
    outputs = Dense(n_tags, activation=""softmax"", name=""Output"")(average)

Edit 2:

So I print the lstm output:

    Tensor(""Bi-LSTM/concat:0"", shape=(None, 80, 200), dtype=float32)

So I think it's already concatenated? I never tried return\_sequences before.",1.0
fq65vx0,ggo5t8,"Sorry, my first comment wasn't very helpful. 

I has assumed you were using the outputs (not the states) farther down. I forget what effect ""return_sequences"" has on states.

Anyway, overall it sounds like you need to slow and print/inspect the shape of each intermediate symbolic tensor, and make sure you understand what the dimensions are.",1.0
fqbsnfq,ggo5t8,"I still need to ask about the output of Bidirectional LSTM.

When I print it, it said:

 Tensor(""Bi-LSTM/concat:0"", shape=(None, 80, 200), dtype=float32) 

So it's already concatenated, right?",1.0
fqbxjv0,ggo5t8,"I agree, that is what it looks like.",2.0
fqbypr8,ggo5t8,"OK. That's one down. The next problem is the Average.

The paper I'm using only mentioned, ""Average(·) computes the average of the input vectors.""

It didn't mention if it's a layer or tf.math.reduce\_mean which makes me confused.

What do you think?

Edit:

If I have to use the Average layer, I need a list.

If I have to use reduce\_mean, then the input 0 will be a problem in dense.",1.0
fqc1wuf,ggo5t8,"That Average(.) looks like pseudo code. Either way we’re talking about a mean. That should not make a difference.

Input 0 a problem? I don’t quite understand.",1.0
fqc2nvh,ggo5t8,"Here.

    # Input
    inputs = Input(shape=(max_length,), name=""Input"")
    
    # Embedding
    embed = Embedding(input_dim=n_words+1,
                      output_dim=embedding_size,
                      input_length=max_length,
                      name=""Embedding"")(inputs)
    
    # Bi-LSTM
    encoder = Bidirectional(LSTM(units=hidden_state_encoder_size,
                                 return_sequences=True,
                                 dropout=dropout_rate,
                                 name=""LSTM""),
                            name=""Bi-LSTM"")
    
    hidden_states = encoder(embed)
    
    # Average
    average = tf.math.reduce_mean(hidden_states)
    
    # Outputs
    outputs = Dense(n_tags,
                    activation=""softmax"",
                    name=""Output"")(average)

Error:

    ---------------------------------------------------------------------------
    ValueError                                Traceback (most recent call last)
    &lt;ipython-input-53-76f07904adbf&gt; in &lt;module&gt;()
         22 outputs = Dense(n_tags,
         23                 activation=""softmax"",
    ---&gt; 24                 name=""Output"")(average)
    
    2 frames
    /usr/local/lib/python3.6/dist-packages/keras/engine/base_layer.py in assert_input_compatibility(self, inputs)
        356                                      self.name + ': expected min_ndim=' +
        357                                      str(spec.min_ndim) + ', found ndim=' +
    --&gt; 358                                      str(K.ndim(x)))
        359             # Check dtype.
        360             if spec.dtype is not None:
    
    ValueError: Input 0 is incompatible with layer Output: expected min_ndim=2, found ndim=0",1.0
fqc320x,ggo5t8,"Oh, you need to tell it which axis you want it to average over. Use the  axis= argument.",1.0
fqc40ey,ggo5t8,"I tried giving the axis 0, 1, and 2, but when I build the model...

    AttributeError                            Traceback (most recent call last)
    &lt;ipython-input-65-2bcc26a5c331&gt; in &lt;module&gt;()
    ----&gt; 1 model = Model(inputs, outputs, name=""Seq2Seq Chunking"")
    
    5 frames
    /usr/local/lib/python3.6/dist-packages/keras/engine/network.py in build_map(tensor, finished_nodes, nodes_in_progress, layer, node_index, tensor_index)
       1391             ValueError: if a cycle is detected.
       1392         """"""
    -&gt; 1393         node = layer._inbound_nodes[node_index]
       1394 
       1395         # Prevent cycles.
    
    AttributeError: 'NoneType' object has no attribute '_inbound_nodes'",1.0
_,ggo5t8,,
fq2wsna,ggn2zm,Look into onnx.,1.0
fq2ta07,ggn2zm,[deleted],1.0
fq3tjmr,ggn2zm,Cmon man. Smh.,1.0
fq0yozh,gggki1,"Just use conda to install tensorflow, it will take care the dependencies for u.

Conda install tensorflow-gpu 


I just did it in Ubuntu 

One thing to note, you need to choose the right version of graphics driver under additional driver.

Hope it helps.",5.0
fq0pl6f,gggki1,"I had [this article](https://linuxconfig.org/how-to-install-cuda-on-ubuntu-20-04-focal-fossa-linux) ready for installing cuda, but I didn't end up having any trouble. I let ubuntu install the graphics drivers during install, downloaded cuda 10.1 for 18.04 which ran without problems, then added cudnn on top using the deb files. I installed tensorflow with gpu in an anaconda environment using pip and that went perfectly fine. I haven't had issues so far.",2.0
fq14ohj,gggki1,"I would very much recommend, that you install the Ubuntu NVidia driver 440 package, docker.io, and https://github.com/NVIDIA/nvidia-docker.

The do your training and evaluating inside a Docker container that has all of the correct CUDA libraries and other libraries correctly configured by the software and hardware vendors.",2.0
fq1xg11,gggki1,"I just installed the proper Nvidia driver for my card (RTX 2060 in my case) and followed the steps on the official TensorFlow documentation for CUDA, worked smoothly.",1.0
fq1qt74,gg8ris,"I was having a similar issue, in the end the easiest solution is to use anaconda as the tensorflow distribution comes with all required DLLs. You just need to ensure you have the correct driver",1.0
fq89zak,gg8ris,"I will try that. Thank you. 

Which driver?",1.0
fpv2n3v,gfpztg,"PyImageSearch
Machinelearningmastery",2.0
fpva3ra,gfpztg,Thank you,1.0
fpvyfbo,gfotdo,"Don't know if you're the author of the website but I just wanted to say: amazing job! I've been looking for a place where I could check up to date AI news and articles, this is good stuff, hope they (or you) keep up the good work",2.0
fq8ywyh,gfotdo,"Thanks, I am really glad you like it!",1.0
fpudnby,gfc4tx,"Do you know the length of that last dimension? It needs to be constant for this to work.

You can use “tensor.set_shape” to to tell a tensor what you know it’s shape is.",1.0
fpvf1nl,gfc4tx,"Ok so when I query the model structure right after the flatten layer I get:

str(model)
Model
Model: ""sequential_38""
________________________________________________________________________________________________

Layer (type)                               Output Shape                          Param #        
================================================================================================
conv2d_133 (Conv2D)                        (None, None, None, 32)                320            
________________________________________________________________________________________________
max_pooling2d_127 (MaxPooling2D)           (None, None, None, 32)                0              
________________________________________________________________________________________________
conv2d_134 (Conv2D)                        (None, None, None, 64)                18496          
________________________________________________________________________________________________
max_pooling2d_128 (MaxPooling2D)           (None, None, None, 64)                0              
________________________________________________________________________________________________
conv2d_135 (Conv2D)                        (None, None, None, 128)               73856          
________________________________________________________________________________________________
max_pooling2d_129 (MaxPooling2D)           (None, None, None, 128)               0              
________________________________________________________________________________________________
conv2d_136 (Conv2D)                        (None, None, None, 256)               295168         
________________________________________________________________________________________________
max_pooling2d_130 (MaxPooling2D)           (None, None, None, 256)               0              
________________________________________________________________________________________________
dropout_36 (Dropout)                       (None, None, None, 256)               0              
________________________________________________________________________________________________

flatten_23 (Flatten)                       (None, None)                          0              
================================================================================================
Total params: 387,840
Trainable params: 387,840
Non-trainable params: 0
________________________________________________________________________________________________



For ds:

str(ds)
&lt;RepeatDataset shapes: ((?, ?, ?), (30,)), types: (tf.float32, tf.float32)&gt;

For ds train:

&lt;PaddedBatchDataset shapes: ((?, ?, ?, ?), (?, ?)), types: (tf.float32, tf.float32)&gt;

For ds val:

 str(ds_val)
&lt;PaddedBatchDataset shapes: ((?, ?, ?, ?), (?, ?)), types: (tf.float32, tf.float32)&gt;",1.0
fpwr4z3,gfc4tx,"So the model is setup to work with an unknown (variable?) image size, and the dataset has an unknown image.

Without knowing the image size “flatten” can’t know it’s output size.

Replace the flatten with a GlobalAveragePooling2D, who’s output size doesn’t depend on the input image size.

if you really want to use flatten...

If your images are a fixed size, set that in the input_shape argument to the first layer of the model.

If the images have variable sized, resize them to a fixed size or you can’t use flatten.",1.0
fpwymaw,gfc4tx,"Ok so I tried to add that:

%&gt;%
  #layer_flatten() %&gt;%
   kerasR::GlobalAveragePooling2D()

And it said: 

Error in modules$keras.layers.pooling$GlobalAveragePooling2D(data_format = data_format) : 
  attempt to apply non-function",1.0
fpx04fj,gfc4tx,"That sounds like a problem on the R side, I don’t know how to help with that.",1.0
fpx1yc5,gfc4tx,Ok thank you. Do you know a good source to learn more of the basics of these types of models (that's not 500 pgs long)?,1.0
fpxif8m,gfc4tx,Nothing specific. I think the only way is to continue struggling. That’s how we all learn.,1.0
fqbyva3,gfc4tx,"UPDATE: The problem with the flatten layer had to do with my python install and environment variables. Make sure you call reticulate FIRST:

library(reticulate)

use_python(""/usr/local/bin/python"")

library(keras)

use_implementation(""tensorflow"")

-----------------------------------------------------------

Ok thank you. By the way, I fixed the R error and now its asking me for the data shape:

Error in as.vector(x, ""list"") : 
  cannot coerce type 'closure' to vector of type 'list'

Here is the updated snip of code:

layer_dropout(rate = 0.2) %&gt;%
  kerasR::GlobalAveragePooling2D(data_format=None)

also tried data_format = 'channels_last' with the same error


Updated model:

Model: ""sequential_3""
________________________________________________________________________________________________
Layer (type)                               Output Shape                          Param #        
================================================================================================
conv2d_12 (Conv2D)                         (None, 98, 257, 32)                   320            
________________________________________________________________________________________________
max_pooling2d_12 (MaxPooling2D)            (None, 49, 128, 32)                   0              
________________________________________________________________________________________________
conv2d_13 (Conv2D)                         (None, 49, 128, 64)                   18496          
________________________________________________________________________________________________
max_pooling2d_13 (MaxPooling2D)            (None, 24, 64, 64)                    0              
________________________________________________________________________________________________
conv2d_14 (Conv2D)                         (None, 24, 64, 128)                   73856          
________________________________________________________________________________________________
max_pooling2d_14 (MaxPooling2D)            (None, 12, 32, 128)                   0              
________________________________________________________________________________________________
conv2d_15 (Conv2D)                         (None, 12, 32, 256)                   295168         
________________________________________________________________________________________________
max_pooling2d_15 (MaxPooling2D)            (None, 6, 16, 256)                    0              
________________________________________________________________________________________________
dropout_3 (Dropout)                        (None, 6, 16, 256)                    0              
================================================================================================
Total params: 387,840
Trainable params: 387,840
Non-trainable params: 0",1.0
fqc2ufc,gfc4tx,"I don’t know r but googling that error it looks like wherever that as.vector is being called it’s getting a function, but it wants a list. 

Maybe you wrote obj.shape where you needed obj.shape(), or something like that.",1.0
fqc40qb,gfc4tx,It turns out that once I fixed my environment/python issues that the original flatten layer worked out fine. Thank you!!,2.0
fptmzoj,gf90qs,"Maybe I should use np.array(y\_tr)?

But I will run to another problem.

Error when checking target: expected Output to have 2 dimensions, but got array with shape (631, 80, 2641)",1.0
fpr5fh6,gf36eg,Can you provide the compete error gist. In order to troubleshoot.,1.0
fpr5jfa,gf36eg,"Mostly:

external/com_google_protobuf/src/google/protobuf/map.h:502:24: error: cannot call member function 'bool google::protobuf::Map&lt;Key, T&gt;::InnerMap::TableEntryIsList(google::protobuf::Map&lt;Key, T&gt;::size_type) const [with Key = std::__cxx11::basic_string&lt;char&gt;; T = int; google::protobuf::Map&lt;Key, T&gt;::size_type = long unsigned int]' without object
         return m_-&gt;TableEntryIsList(bucket_index_);
         ~~~~~~~~~~~~~~~^~~~~~~~~~~~~~~
ERROR: /home/ashunt/tensorflow/tensorflow/core/kernels/BUILD:1976:1: output 'tensorflow/core/kernels/_objs/gather_functor_gpu/gather_functor_gpu.cu.pic.o' was not created
ERROR: /home/ashunt/tensorflow/tensorflow/core/kernels/BUILD:1976:1: not all outputs were created or valid
Target //tensorflow/tools/pip_package:build_pip_package failed to build
Use --verbose_failures to see the command lines of failed build steps.
ERROR: /home/ashunt/tensorflow/tensorflow/python/tools/BUILD:311:1 not all outputs were created or valid
INFO: Elapsed time: 450.778s, Critical Path: 57.61s
INFO: 4013 processes: 4013 local.
FAILED: Build did NOT complete successfully

And 


Server terminated abruptly (error code: 14, error message: 'Socket closed', log file: '/home/ashunt/.cache/bazel/_bazel_ashunt/9dece6dda0187269e4b463c8258cd8d7/server/jvm.out')

But the second was solved by limiting the resources bazel should use

But also a few of those 

/home/ashunt/tensorflow/tensorflow/core/kernels/BUILD:275:1: output 'tensorflow/core/kernels/_objs/conv_2d_gpu/conv_2d_gpu_int.cu.pic.o' was not created
ERROR: /home/ashunt/tensorflow/tensorflow/core/kernels/BUILD:275:1: Couldn't build file tensorflow/core/kernels/_objs/conv_2d_gpu/conv_2d_gpu_int.cu.pic.o: not all outputs were created or valid


ERROR: /home/ashunt/tensorflow/tensorflow/contrib/reduce_slice_ops/BUILD:12:1: output 'tensorflow/contrib/reduce_slice_ops/_objs/python/ops/_reduce_slice_ops_gpu/reduce_slice_ops_gpu.cu.pic.o' was not created
ERROR: /home/ashunt/tensorflow/tensorflow/contrib/reduce_slice_ops/BUILD:12:1: not all outputs were created or valid
Target //tensorflow/tools/pip_package:build_pip_package failed to build
Use --verbose_failures to see the command lines of failed build steps.
INFO: Elapsed time: 261.798s, Critical Path: 21.54s
INFO: 2494 processes: 2494 local.
FAILED: Build did NOT complete successfully",1.0
fprou7f,gf36eg,"Yes. You absolutely should be building in a Docker container. The Tensorflow Git repo has the Dockerfiles. 

You need to use the specific Dockerfile from the branch of the specific version you're building. 

Instead of vanilla Bazel, you should install Bazelisk to your image.

For certain branches, you need to tinker the build manually to get things to build, but for 2+ that shouldn't be necessary.

Watch out for the CUDA 10.2 transition.

When practising your builds, be sure to set the compute capacity setting to a single value, so that you'll only be building for that one capacity, rather than a bunch of alternatives.",1.0
fpsiyvk,gf36eg,"I have built tf with bazel many times, but never unless it was necessary (i,.e. for a CC 3.0 card or a non SSE4 capable CPU from yonks ago) so I am puzzled as to why you need to manually build? As the other contributor stated bazelisk is useful (needs go and other stuff though).

Surely you could install  the appropriate CUDA/cuDNN and tf combinations (such as 10.1, 7.6 and a tf 2.x build)  natively, also the Python (and hence Conda if you use) need to be the correct version - pain in the ass, pip3 usually pulls anything else outside of Conda you may need.

I don't use docker though, but surely a prebuilt docker image has also GPU pass-thru capabilities? If so that'd be pretty simple solution.",1.0
fq66vde,gf36eg,Try to use version 2.0.0 for Bazel. It works for me,1.0
fpqhvbp,geydlf,"I think I found my answer.

    # Input
    inputs = Input(shape=(max_length,), name=""Input"")
    
    # Embedding
    embed = Embedding(num_encoder_tokens, embedding_size, name=""Embedding"")(inputs)
    
    # Bi-LSTM
    encoder_outputs, forward_h, forward_c, backward_h, backward_c = Bidirectional(LSTM(hidden_state_encoder_size, return_state=True), name=""BI-LSTM"")(embed)
    
    # Concatenated
    state_h = Concatenate(name=""Concat_1"")([forward_h, backward_h]) state_c = Concatenate(name=""Concat_2"")([forward_c, backward_c])
    
    # Average
    average = Average()([state_h, state_c])
    
    # Outputs
    outputs = Dense(num_decoder_tokens, activation=""softmax"", name=""Output"")(average)",1.0
fpo39ew,gekotd,"TensorFlow needs to be able to compute gradients based on the loss.  Your *fancy\_algorithm()* needs to be written using TensorFlow functions, otherwise TensorFlow won't be able to construct the computation graph needed to compute and apply the gradients.  So if your *fancy\_algorithm()* is setup properly, then yes this will work as you described.  If it is not, then you'll need to re-write appropriately using TensorFlow functions.  If this isn't possible (i.e., you can't compute gradients for your function), then back-propagation won't work here and you'll have to use a non-gradient based optimization method.",9.0
fpo4tpk,gekotd,"That’s what I was afraid of, the algorithm performs some **for** iteration, and even calls another program with Popen. It just can’t be written as TensorFlow functions.",2.0
fpo5tvp,gekotd,"Yeah, that's a problem lol.  The [for-loop isn't a deal-breaker](https://www.tensorflow.org/api_docs/python/tf/while_loop), but you'd have to rewrite whatever calculations are occurring with the external program as TensorFlow functions for this to work.  This also assumes that you'd be able to calculate the gradients of said function, which is likely possible given the context but not guaranteed.

There may be other approaches that I'm not aware for doing something like this, but they certainly won't be ""out-of-the-box.""  If you can't write the loss function using TensorFlow, then neural networks likely won't work for you and you'll need to look into non-gradient based methods such as Bayesian optimization, etc.",5.0
fpo6jnh,gekotd,I’m actually trying to create a chess engine that learns like alpha zero. This *fancy_function()* actually is performing some cool tree search inside. I don’t think I can write that using Keras backend functions.,2.0
fpoesce,gekotd,"So, AlphaZero uses deep reinforcement learning, which basically allows for arbitrary reward functions to be used to train the neural network.  This isn't the same as using a black-box loss function, but can potentially be used, in your situation, to train your agent's policy without needing to calculate gradients directly.

If this sounds like the approach you want to take, you'll need to look into deep reinforcement learning.  AlphaZero uses a form of actor-critic, so if that's of interest to you in particular, look into the algorithm for Advantage Actor-Critic (A2C).",3.0
fpohyns,gekotd,What you think about the comment of aTairyHesticle? Can GradientTape work on this problem?,2.0
fpojnwy,gekotd,"No.  You'd need to use GradientTape if using a custom training loop, but this will still require your loss function to be defined in TensorFlow's computational graph which you can't do since your loss is computed elsewhere.

The issue you're facing is, specifically, that you have a measure of cost without being able to compute gradients.  This very issue is where reinforcement learning comes into play.  I'm not sure how familiar you are with such details, but [an article like this](https://towardsdatascience.com/policy-gradients-in-a-nutshell-8b72f9743c5d) might shed some light on why reinforcement learning is needed in your situation.  Specifically, the gradients of your loss needs to look like [this](https://miro.medium.com/max/1400/1*hYy_v_WOr_6IRqmoj0n5BQ.png), which requires a policy network to be properly defined.

Essentially, you need to train a neural network based on the value of some reward/cost which isn't computed by the neural network itself.  Your black-box loss function would work as the reward/cost function here (assuming it's configured appropriately), so that you can train your neural network without directly computing gradients based on the loss (I'll add that there are other frameworks with similar approaches, but obviously you're looking for RL).

The issue, here, isn't a limitation in TensorFlow's functionality.  It's intrinsic to the underlying mathematics of neural networks.  So, basically, there's a way to use the value of your black-box loss function to train the neural network, but it's not going to be direct.  If you want a formal explanation of how this works, [Sutton's paper from 1999](https://papers.nips.cc/paper/1713-policy-gradient-methods-for-reinforcement-learning-with-function-approximation.pdf) is where you should look.",3.0
fpojuz3,gekotd,"Omg this is the kind of explanation that I was looking for, thank you.",2.0
fpo6sj5,gekotd,And neural networks are necessary for a good result on this problem.,1.0
fpo7r21,gekotd,"I'm thinking of making a video on YouTube about this problem, I just didn't want to get there and say ""hey I can't use gradient optimization here"" and make a mistake.",1.0
fpnz0pl,gekotd,"The inputs to your loss function are input image (what size?) and output (an 8x8)? 

Typically, the inputs to a loss function are predicted output and true output; also known as y_hat and y respectively for linear regression. I’m not sure without more information but I think you should calculate a full set of true outputs for your inputs and then use mse or the like for your loss function. Good luck",2.0
fpo03ry,gekotd,"Yes, the input of the network is a 8x8 image and the output is a 8x8 image. And yes the function takes the input and the prediction of the network and tells how good the prediction was.

The thing is, I don't have a “y_true”. I can only calculate the y_pred loss, in other words, I can only tell the network how good the prediction was. It sounds like reinforcement learning but at the same time I don’t have an agent.

I’m afraid that I can’t use usual gradient optimization on this problem, maybe the only way to solve this is to create several different networks that are consecutively better than each other, like a GA or particle swarm. But I’m not sure about this. I need advice of someone that knows better than me about this.",1.0
fpoqgdc,gekotd,"If i understand correctly, you have a analogous to rewards in RL setup and you have a reward function which is not differentiable wrt to your network prediction. This is exactly what rl solves, you can take a look into policy gradient or actor-critic.",3.0
fpoy7wr,gekotd,"Thanks, I’m going to check this out!",1.0
fpo2gan,gekotd,"you can definitely do that. if you create your custom loss function it gets passed y\_true and y\_pred, usually you'd do some operation between those. You can just pass it dummy data as y\_true and perform your computation based on y\_pred.

edit: it might not be trivial to do depending on your task, but it's definitely doable. Here's a snippet that trains:
```python
import tensorflow as tf
import numpy as np
    
X = tf.random.uniform((10000,1))
    
model = tf.keras.Sequential()
model.add(tf.keras.layers.Dense(1))
    
def my_loss(y_true, y_pred):
    t = tf.constant(np.array([[1]]), dtype=tf.float32)
    return tf.math.square(y_pred-t)

model.compile(""adam"", loss=my_loss)
model.fit(X,X,epochs=5)
```
as /u/Nater5000 said, it is important to use tf functions, otherwise the gradients cannot be computed and the loss cannot be applied.

I've never done something similar to what you suggest (calling popen in the loss function), but perhaps at least if you use GradientTape you can send y\_pred through the process, get the result, create a constant out of it and return the difference between the two.",4.0
fpogpl3,gekotd,"That’s nice, I'm going to do some research on what you said, about using GradientTape. Thank you.",1.0
fpo2vdt,gekotd,"Creating your own loss function, it seems like that’s what you’re looking for.",1.0
fpnecyk,geeyum,"You could set up the problem as an unsupervised learning problem with the goal of creating a generative model.

Let me break that down for you: unsupervised learning is when we don't have labels for our data. I'm assuming you don't have good and bad recipes, so all the data you have is assumed to be good (enough).

A generative model is a system that is given a random ""seed"" and produces an output that should be indistinguishable from a sample from some ""ideal"" distribution. An example will help: if you have a dataset of images of faces, and you want to generate new faces, then your model would try to imitate the distribution of faces in the set.

There are a couple of ways of doing this, and TF is a good choice (more specifically keras). However, you can checkout other libraries such as PyTorch.

You might be able to adapt [this tutorial](https://medium.com/coinmonks/celebrity-face-generation-using-gans-tensorflow-implementation-eaa2001eef86) where you create Generative Adversarial Networks (GANs) for facial generation. Alternatively, you could adapt [this](https://towardsdatascience.com/implementing-an-autoencoder-in-tensorflow-2-0-5e86126e9f7) and create an Autoencoder. Might be a better option if you don't have much data.

The tf code will be pretty much the same - you will just need to make sure to get your data in an adequate format. I would suggest that each recipe is represented by a vector of all possible flavours, where elements contain the percentage of their corresponding flavour.

&gt; How many existing recipes would I need for training?

Really, the more, the better. I can't give you hard numbers. The less data you have, the smaller your model should be.

**Word of Warning**

Do not expect fantastic results - this is a hard problem. You're quite likely to make a system that generates nonsensical recipes. [Here's a blog post](https://aiweirdness.com/post/190569291992/ai-recipes-are-bad-and-a-proposal-for-making-them) from someone who trained a system to generate food recipes. Idk how they did it, or how seriously they took their project, but you should look at their results. [Here](https://futurism.com/ai-food-research-better-recipes) is another more serious looking project, but it looks like the AI system was embedded in the recipe iteration process of a research project, rather than an ""end user"" tool.

It will ultimately depend on how sensitive the outcomes are to the exact balance of flavours and how much data you have.",3.0
frbt9mx,geeyum,"Thanks a lot, it's a starting point.",1.0
fpl2odi,ge2alc,"Cool stuff, thanks for sharing.",1.0
fpl2tnn,ge2alc,Thanks!,1.0
fpkvfp6,ge1j2e,"Hands-on machine learning with sci-kit learn, keras, and tensorflow.",3.0
fpmdxlj,ge1j2e,This one is great. Make sure to get the 2nd edition,2.0
fpt2fjo,ge1j2e,What's different in the 2nd edition?,1.0
fpu5ndd,ge1j2e,Updated for TensorFlow 2,1.0
fpu9en2,ge1j2e,Welp. Guess I'm buying the second edition too. 🎉,1.0
fpkz0zr,ge1j2e,Deep Learning with Python. F. Chollet,1.0
fpineo7,gdnwjv,"This may not be the solution you’re looking for, but I found setting tensorflow up with Anaconda to be more straightforward. It’s easy to create new environments and also easy to replicate them for portability.",3.0
fpillru,gdnwjv,try [https://www.tensorflow.org/install](https://www.tensorflow.org/install),2.0
fpilz2p,gdnwjv,That Pip error is more of just a warning in my experience although upgrading can't hurt. No matching distributions usually means you're trying to install it in a python environment that is not supported. Maybe check if you have 32 bit python installed?,2.0
fpipvht,gdnwjv,"You need the latest version of pip to install TensorFlow.

If it seems like you have two different versions installed, it’s because there can be a difference between the system pip and the python pip.

Are you using a virtualenv?

AFAIK the ‘python -m pip’ trick makes sure you’re using the python pip.",1.0
fpjhwnp,gdnwjv,How do I upgrade the correct one then?,1.0
fpjvryu,gdnwjv,"I think you have it installed.
Have you tried:

Pip -V

Python -m pip -V

Python -m pip install tensorflow",1.0
fpjxgl0,gdnwjv,"Ive done it now and it said that all requirements were satisfied, so I went to pycharm and added it again and this time it worked but when I imported in the code and tried to print what they said on the site to prinrr to verify installation two errors were raised when i ran the code:

ImportError: DLL load failed: The specified module could not be found.

And:

Failed to load the native TensorFlow runtime.

Any ideas? And thank you so much for your help!",1.0
fpiz7x1,gdnwjv,try this..conda create --name tf_gpu tensorflow-gpu,1.0
fpiqlku,gdnf27,"&gt; multi label text classification

&gt; loss = “binary_crossentropy”

There’s your problem.",3.0
fpjdrlt,gdnf27,"Even if each label is binary?

Each entry in the dataset is composed of a `text` and a `binary vector`. 

 `""a b c text"" -&gt; [0,0,1,0,]`",1.0
fpjj46h,gdnf27,"I'm not the poster above, but binary as in the classification problem only has two possible options. Spam or non-spam, 0 or 1, etc. Check  [https://www.tensorflow.org/api\_docs/python/tf/keras/losses/CategoricalCrossentropy](https://www.tensorflow.org/api_docs/python/tf/keras/losses/CategoricalCrossentropy)

Outside of that, there are multiple things that have gone wrong with your model but it's guesswork without knowing more. Also, do you really mean **multi-label** (e.g. multiple class labels are assigned to a single entry in your data set - you'd likely use Sigmoid activation in your last layer) or **multi-class** (e.g. each entry only has one label, but there might be hundreds of possible labels - you'd likely use Softmax activation)",3.0
fpjjp9c,gdnf27,"Yes, you are right, I described wrong my scenario. I am in a multi-class case.

Each entry has 1 class over 5 possible classes.

The last layer is  like this `Dense(OUTPUT, activation=""softmax"")(x_model)`",1.0
fphxcqp,gdkx1y,Maybe just use radon transform?,1.0
fpgreh5,gde5hv,Yeah it doesn’t affect anything when you don’t use it. It’s just like any other python module. Good luck!,1.0
fpgrrc4,gde5hv,"Thanks man, this doubt alone was pretty much holding me from starting. THANK YOU

DANKE

OBRIGADO

ARIGATO

GRACIAS",2.0
fpgsakv,gde5hv,"Use anaconda and use this command:

&gt;conda install tensorflow-gpu

It'll take care of all cuda, cudnn and cudatoolkit given you've installed nvidia-drivers",1.0
fpkge32,gde5hv,"I discovered tat after installing by the long and boring way, but soon-ish I will need to format my PC, so then I will use the Conda method",1.0
fphw4uz,gde49v,I'm quite new myself. I believe you need to convert your model to a tflite model. (Look into tflite for Android),2.0
fpsj1cp,gde3cm,"Nice. However I think it's usually a good idea to separate monitoring from your computation job (you can have a separate tmux pane, etc.) The time needed for executing gpustat is not expensive, but multithreading also can hurt your performance by a little amount.

Also your stats never gets cleared so it will eat up much memory unnecessarily -- you may want to use deque or some clever windowing methods.

NIT:  
\- Use \`gpustat.new\_query()\` because this is the only public API.  
\- Use gpuname\_width option.  
\- Do formatting of numbers. Who wants to see 10 digits past the dot?",2.0
fs6z092,gde3cm,"Thanks for the feedback u/wookayin, very relevant, I've started to integrate it into the library",1.0
fpgjjyz,gdcuou,Convert them to NumPy and write them to file.,2.0
fpgjzg5,gdcuou,Hidden in the obvious. Thanks.,2.0
fph2xqr,gdccmq,"Every input instance should have same number of occurance.
In your example input A have 500 rows but input B have only 2 rows. 
Consider checking your input B again. It should have shape (None, 500, anything but predefined) .",1.0
fphktg3,gdccmq,"This is the culprit. InputA are particles in an event and InputB are global event variables. So they are supposed to have these shapes. However I want be able to give my custom model a list of Inputs and then access the list inside the call function of the model, to treat them completely seperately and merge the outputs at a later point of the model.",1.0
fpiwqcg,gdcapo,Keras is already part of TF 2.0. You are importing K consistent with TF 1.5,1.0
fpjjcf3,gdcapo,"so in TF 2.1, I dont need to import Keras?",1.0
fpjkxzo,gdcapo,"The syntax has changed

Import tensorflow as tf

From tensorflow import Keras


Go to tensorflow.org to get details",1.0
fpgal1n,gdai6y,sounds cool!,2.0
fpgcif7,gdai6y,Thank you!,1.0
fpg0j3h,gd6rh0,"1.   YOLOv4: Optimal Speed and Accuracy of Object Detection
2.   ResNeSt: Split-Attention Networks
3.   Training with Quantization Noise for Extreme Model Compression",7.0
fpeypvn,gd2kgh,"The problem is with the shape of Xtest. Instead of numpy array, you are passing a list. May be try: model.predict(Xtest) if this doesn’t work you have to setup your input data to a proper numpy ndarray",3.0
fpewrh8,gd2kgh,"Dont know if this will help but here is the entire traceback:

    2020-05-03 19:36:06.513616: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX AVX2
    Traceback (most recent call last):
      File ""C:/Users/Desktop/this/ImageRecognition/TFTestLoad.py"", line 13, in &lt;module&gt;
        predictions = new_model.predict([x_test])
      File ""C:\Users\anaconda3\envs\ImageRecognition\lib\site-packages\tensorflow_core\python\keras\engine\training.py"", line 1013, in predict
        use_multiprocessing=use_multiprocessing)
      File ""C:\Users\anaconda3\envs\ImageRecognition\lib\site-packages\tensorflow_core\python\keras\engine\training_v2.py"", line 498, in predict
        workers=workers, use_multiprocessing=use_multiprocessing, **kwargs)
      File ""C:\Users\anaconda3\envs\ImageRecognition\lib\site-packages\tensorflow_core\python\keras\engine\training_v2.py"", line 426, in _model_iteration
        use_multiprocessing=use_multiprocessing)
      File ""C:\Users\anaconda3\envs\ImageRecognition\lib\site-packages\tensorflow_core\python\keras\engine\training_v2.py"", line 646, in _process_inputs
        x, y, sample_weight=sample_weights)
      File ""C:\Users\anaconda3\envs\ImageRecognition\lib\site-packages\tensorflow_core\python\keras\engine\training.py"", line 2346, in _standardize_user_data
        all_inputs, y_input, dict_inputs = self._build_model_with_inputs(x, y)
      File ""C:\Users\anaconda3\envs\ImageRecognition\lib\site-packages\tensorflow_core\python\keras\engine\training.py"", line 2572, in _build_model_with_inputs
        self._set_inputs(cast_inputs)
      File ""C:\Users\anaconda3\envs\ImageRecognition\lib\site-packages\tensorflow_core\python\keras\engine\training.py"", line 2647, in _set_inputs
        inputs = self._set_input_attrs(inputs)
      File ""C:\Users\anaconda3\envs\ImageRecognition\lib\site-packages\tensorflow_core\python\training\tracking\base.py"", line 457, in _method_wrapper
        result = method(self, *args, **kwargs)
      File ""C:\Users\anaconda3\envs\ImageRecognition\lib\site-packages\tensorflow_core\python\keras\engine\training.py"", line 2686, in _set_input_attrs
        input_shape = (None,) + tuple(inputs.shape[1:])
    AttributeError: 'list' object has no attribute 'shape'",1.0
fpf5jcy,gd2kgh, [https://stackoverflow.com/questions/47068709/your-cpu-supports-instructions-that-this-tensorflow-binary-was-not-compiled-to-u](https://stackoverflow.com/questions/47068709/your-cpu-supports-instructions-that-this-tensorflow-binary-was-not-compiled-to-u),0.0
fpfal11,gd2kgh,Awesome thanks. This fixed it,1.0
fpdv5m8,gcw07p,"&gt; graph

Whatever you’re trying to do here will be easier in tf2 where you don’t have to worry about the graph (much).

&gt; access in the next iteration of the loop

Either assign the value to a variable, or treat it like an ebb.",1.0
fpdyuhd,gcw07p,"the problem is that i dont know how to assign it to a variable that gets accessed every run.

i tried something like this for the end of my code:

    output = Dense(257, activation='sigmoid')(x)
    regfft = tf.Variable(tf.shape(output))
    regfft.assign(output)

beginning of my code looks like:

    try:
        b = regfft*2
        print(b)
    except:
        print(""1. except"")",1.0
fpdz5e7,gcsifs,Check out r/datascience \- we've had a few threads so far on this.,2.0
fpefy6b,gcsifs,"You're right, there's a [thread](https://www.reddit.com/r/datascience/comments/gc29zj/passed_tensorflow_developer_certification/) right now.",1.0
fpcgfdw,gcd2pu,"Which dataset are you using? A recall of \~0.3 is a pretty good outcome on most datasets.

I suppose you use a basic log-loss to train the auto-encoder? You could try to optimise for losses that are better proxies for ranking metrics (see [https://maciejkula.github.io/spotlight/losses.html](https://maciejkula.github.io/spotlight/losses.html) for example). Also try a different model/architecture altogether (like a multi-class classifier instead of an auto-encoder). Never forget to always baseline your models against simple heuristics (such as most popular products) that are often not trivial to beat!",2.0
fpciznz,gcd2pu,"Thank you for the tips!

We are using the Movielens 1M dataset at this stage, with some modifications to fit our needs.

Will look into your suggestion about loss functions. Right now we're using RMSE to be able to compare to our SVD solution that also uses the same error function. :)",1.0
fpcgfie,gcd2pu,"
With .999 accuracy you should check if your data is not linearly separable and/or if there is overlap/duplicate.
Also autoencodeurs are not that good with sparse data. ( In my experience  sometimes it works sometimes it doesn't )
Regarding your question, It feels like you are over fitting. You can use a more impactful regularisation than dropout, reduce the size of your model.",1.0
fpcj5yi,gcd2pu,"Would reducing the size of the model imply discarding products with low few ratings, for example, or something else?

What signs other than 0.999 precision would you recommend we be on the look out for to identify overfitting? :)",1.0
fpqmpgn,gcd2pu,"I didn't see the .2 recall. That's explain enough the accuracy. 

You could plot the Roc curve or the accuracy and recall given the prediction threshold and look for strange pattern. 

I was thinking about messy thing in your data but as you are using a standard dataset this is mostly out :)

Concerning the ae size. You should aim for the smallest layer that give you good result, Especially for the bottleneck one. 
It might lead to discard information, but it mostly will force the ae to learn a relevant representation and focus on meaningful information.",1.0
fp9krce,gc6abl,You can run CUDA 9 or even 8 with the latest driver. The driver is backward compatible with order CUDA and cuDNN.,2.0
fp9l46i,gc6abl,"Are you sure? So I just need to rename/make symlinks for binary files, right?",1.0
fpa71t9,gc6abl,"Yes, I'm sure. It you're on Linux, you can either change the environmental variables or  create proper symlinks.",2.0
fpapl24,gc6abl,"Have you tried removing line 116 `""--bin2c-path=%s"" % bin2c.dirname` from `tensorflow/third_party/nccl/build_defs.bzl.tpl` before building?",1.0
fpg0z2h,gc6abl,"Yes, I also encounter error while compiling with Cuda 10.2 from the branch v1.15.2

See : https://github.com/tensorflow/tensorflow/issues/34429#issuecomment-574296455

The fix was not applied to the branch v1.15.2 so I had to manually apply it:

    git checkout tags/v1.15.2
    git config merge.renamelimit 3000
    git cherry-pick 67edc16326d6328e7ef096e1b06f81dae1bfb816 --no-commit

With this I manage to build tf v1.15.2 with Cuda 10.2 , tensortRT 7, cuDNN 7.6.5 on Ubuntu 18.04",2.0
fp94zsh,gc44o0,"
I see you've posted a GitHub link to a Jupyter Notebook! GitHub doesn't 
render large Jupyter Notebooks, so just in case, here is an 
[nbviewer](https://nbviewer.jupyter.org/) link to the notebook:

https://nbviewer.jupyter.org/url/github.com/devm2024/nmt_keras/blob/master/base.ipynb

Want to run the code yourself? Here is a [binder](https://mybinder.org/) 
link to start your own Jupyter server and try it out!

https://mybinder.org/v2/gh/devm2024/nmt_keras/master?filepath=base.ipynb



------

^(I am a bot.) 
[^(Feedback)](https://www.reddit.com/message/compose/?to=jd_paton) ^(|) 
[^(GitHub)](https://github.com/JohnPaton/nbviewerbot) ^(|) 
[^(Author)](https://johnpaton.net/)",1.0
fpbc33x,gc44o0,"I figured out the answer.

    from keras.layers import Input, LSTM, Embedding, Bidirectional, Concatenate
    
    # Define an input sequence and process it.
    encoder_inputs = Input(shape=(None,)) 
    X =  Embedding(num_encoder_tokens, embedding_size)(encoder_inputs) 
    encoder = Bidirectional(LSTM(latent_dim, return_state=True)) 
    encoder_outputs, forward_h, forward_c, backward_h, backward_c = encoder(X)
    
    #Concatenated
    state_h = Concatenate()([forward_h, backward_h])
    state_c = Concatenate()([forward_c, backward_c])
    
    #Discard encoder_outputs and only keep the states.
    encoder_states = [state_h, state_c]",1.0
fp8j4j9,gc0c9o,"
I see you've posted a GitHub link to a Jupyter Notebook! GitHub doesn't 
render large Jupyter Notebooks, so just in case, here is an 
[nbviewer](https://nbviewer.jupyter.org/) link to the notebook:

https://nbviewer.jupyter.org/url/github.com/devm2024/nmt_keras/blob/master/base.ipynb

Want to run the code yourself? Here is a [binder](https://mybinder.org/) 
link to start your own Jupyter server and try it out!

https://mybinder.org/v2/gh/devm2024/nmt_keras/master?filepath=base.ipynb



------

^(I am a bot.) 
[^(Feedback)](https://www.reddit.com/message/compose/?to=jd_paton) ^(|) 
[^(GitHub)](https://github.com/JohnPaton/nbviewerbot) ^(|) 
[^(Author)](https://johnpaton.net/)",1.0
fp8o25g,gc0c9o,"I just figure it out. I mistyped. It should be...

    encoder_outputs, state_h, state_c = Bidirectional(LSTM(latent_dim, return_state=True))(X)",1.0
fp8703y,gbxqzj," First time messing with machine learning, some background in video. Compiled 280 frames to make this video. Started with 1080p 29.97 footage then exported the frames as TIFs @ 23.97. For final render exported at 4k 50 bitrate to prevent compression on YouTube. Looking for more fluid solutions for compiling frames and possibly faster scripts/sources for rendering each frame. More detail on layers used on the actual YouTube video. Thanks in advance!",1.0
fp7avk8,gbmvjm,"I’ve read that the default learning rate for adadelta is different for the tf and plain Keras implementations, can’t confirm but worth checking.",11.0
fp7cisl,gbmvjm,"You were right, Adadelta in keras has a default lr=1, while in tf it is lr=0.001, explicitly stating the lr solves the problem!",10.0
fp6rtfu,gbmvjm,No it is a well known bug and tensorflow seems to turn a blind eye to it.,-6.0
fp8it9l,gbmvjm,Got any citations for this? I have a hard time believing that tensor flow released a known broken version of keras..,4.0
fp94baw,gbmvjm,"Sure brother here you. 
[Check here for the bug](https://github.com/tensorflow/tensorflow/issues/15831)",1.0
fp6tfun,gbmvjm,So should I use keras instead of tf.keras for the time being? On the keras website they advise us to move to tf.keras...,1.0
fp94bwq,gbmvjm,Use tf.keras.,1.0
fp7aw8v,gbmvjm,Why is there a bug like this?,1.0
fp94ftc,gbmvjm,Because apparently they thought of bringing keras under the tensorflow environment and changing a lot of things except for the previous function names existing in keras. That causes a clash.,0.0
fp3mygh,gb43wg,The CUDA version you see from nvidia-smi is the maximum supported version for that driver. You can run CUDA 10.1 with driver 440 since 440 supports CUDA 10.2 or older.,2.0
fp3qlko,gb43wg,"You're right. It works. I was typing the wrong command. Should have been uppercase GPU. 

 Just get TensorRT errors but I don't think it's needed to use the GPU.",1.0
fp4wf9h,gb43wg,Tensorflow 2 and Cuda compatability was such a nightmare for me to get right.,2.0
fp4y9vu,gb43wg,I can't solve this problem so I just use CUDA 10.1 with TF.,2.0
fp5c980,gb43wg,You can compile tensorflow from source with support of cuda 10.2. It will take about 2 hours :),2.0
fp6b0l5,gb43wg,"For me the best way to install TF 2 is using conda. It also installs required packages for GPU.

conda install tensorflow-gpu",2.0
fp1dfia,gahrx4,"I want to try more sophisticated architecture search strategies, but every time that I read about an available package (AutoML, or AutoKeras, for example), they don't seem to be flexible enough for my needs.  I end up writing programs which run [experiments like this one](https://www.reddit.com/r/neuralnetworks/comments/8wybo5/hyperparameter_grid_search/).  I think this one took three days to run on my GPU-equipped home PC.  I probably could have done that particular experiment without filling out the full grid, but I did find it informative that there was a global minimum in the configurations I studied.",2.0
foye659,ga8oxf,"Are you certain that you are using 2.x? What is the output of ""tf.\_\_version\_\_""?",2.0
foyf754,ga8oxf,yes i am sure version is 2.0.0,1.0
foyk2lz,ga8oxf,Can you try importing tensorflow.compat.v1 as tf and use gfile as you would in v1,1.0
foykwov,ga8oxf,"if i use this it says

AttributeError: module 'tensorflow\_core.compat.v1.compat' has no attribute 'v1'",1.0
foxifvx,ga3nqj,"I have experienced this behaviour while loading images from filenames using data api.
By default shuffle is set to None and i dont know why it still shuffles if its set to None.
But as you mentioned shuffle = False doesn't shuffle.
And yes this is expected behaviour.",1.0
foyfoqc,ga3nqj,"While data ""Pipeline"" is often used to describe the Dataset API at a high level it does not really describe the Dataset implementation.

A Dataset is an object that can generate an Iterator object. This Iterator is then used to iterate over the Data. I like to view a Dataset as little more than a blueprint on how to generate Iterators.

The returned Dataset is a DAG and looks like:

          +--&gt; img_batch -&gt; img_map --+
    zip --+                           +-&gt; (shuffle) -&gt; tensor 
          +--&gt; gt_batch -&gt; coord_map -+

The Iterators produced by the Dataset however form a tree and look like:

          +--&gt; img_batch -&gt; img_map --&gt; (shuffle) -&gt; tensor
    zip --+                   
          +--&gt; gt_batch -&gt; coord_map -&gt; (shuffle) -&gt; tensor 

As each shuffle iterator is independent they randomly shuffles the data in a different way.

There are several ways to reformulate the Dataset above to form a tree (best) or shuffle only after the image and ground\_truth are combined. (This will break if tf.data.Dataset.from\_tensor\_slices is replaced by a nondeterministic Dataset)",1.0
fou93at,g9iwub,"What you’re saying definitely makes sense. I don’t know for sure if there has been research on an optimal lambda value though. 

From my experience working with CNNs, applying weight regularization (L1 or L2) hasn’t shown improvement or decreased overfitting. I’m sure it could be different for different applications but just know adding it won’t always make improvements.",1.0
fosbo9s,g98d4y,[deleted],1.0
fosmnkt,g98d4y,"There is a 1 hour delay fetching comments.

I will be messaging you in 5 days on [**2020-05-02 22:46:17 UTC**](http://www.wolframalpha.com/input/?i=2020-05-02%2022:46:17%20UTC%20To%20Local%20Time) to remind you of [**this link**](https://np.reddit.com/r/tensorflow/comments/g98d4y/is_there_a_way_to_add_gaussian_noise_to_the/fosbo9s/?context=3)

[**CLICK THIS LINK**](https://np.reddit.com/message/compose/?to=RemindMeBot&amp;subject=Reminder&amp;message=%5Bhttps%3A%2F%2Fwww.reddit.com%2Fr%2Ftensorflow%2Fcomments%2Fg98d4y%2Fis_there_a_way_to_add_gaussian_noise_to_the%2Ffosbo9s%2F%5D%0A%0ARemindMe%21%202020-05-02%2022%3A46%3A17%20UTC) to send a PM to also be reminded and to reduce spam.

^(Parent commenter can ) [^(delete this message to hide from others.)](https://np.reddit.com/message/compose/?to=RemindMeBot&amp;subject=Delete%20Comment&amp;message=Delete%21%20g98d4y)

*****

|[^(Info)](https://np.reddit.com/r/RemindMeBot/comments/e1bko7/remindmebot_info_v21/)|[^(Custom)](https://np.reddit.com/message/compose/?to=RemindMeBot&amp;subject=Reminder&amp;message=%5BLink%20or%20message%20inside%20square%20brackets%5D%0A%0ARemindMe%21%20Time%20period%20here)|[^(Your Reminders)](https://np.reddit.com/message/compose/?to=RemindMeBot&amp;subject=List%20Of%20Reminders&amp;message=MyReminders%21)|[^(Feedback)](https://np.reddit.com/message/compose/?to=Watchful1&amp;subject=RemindMeBot%20Feedback)|
|-|-|-|-|",1.0
fotd1m1,g98d4y,Im little bit too scared to actually modify the keras source code itself. So will you be able to share the code with me? Thanks,1.0
fosj56h,g98d4y,"Why would you want that?

Also, this would be pretty trivial in Torch.",1.0
fotcoih,g98d4y,Because it has been found that adding noise to the weights generalize better than adding noise to the input features.,1.0
fotcr44,g98d4y,"Aside from supervised learning, adding noise to the weights help the agent explore better in reinforcement learning setting too",1.0
fotyliv,g98d4y,"You might want to look into curiosity-based RL systems, where you reward the model for showing it something that a second model couldn't accurately predict. It does a better job than just ruining any precise weights.

If you did want to do it at the parameter level, I'd maybe consider adding dropout layers first.",1.0
forv7yn,g93mn9,"Regular conv2d will have 2x2x10xdepth as the shape of the kernel. Each individual filter is 2x2x10x1. When you convolve, each filter keeps multiplying with 2x2x10 patches of the original 40x40x10 input, i.e. basically just going along the height and width but along all channels always.  Finally leading to 39x39xdepth output.

All that the separable convolution does, is break up the same convolution operation by first applying a depthwise filter 2x2x10xsome_intermediate_number followed by a pointwise filter 1x1xsome_intermediate_numberxdepth. This leads to the same 39x39xdepth output. The difference between the depthwise filter and normal conv is that the filter is applied differently, a single output point does not get calculated from multiplications involving more than one input channel. It's a little difficult to explain but there are some great visualizations out there.

Tldr; depthwise is meant to achieve the same thing as a normal convolution except with a more efficient computation.",1.0
fotdegm,g93mn9,"So regular Conv2D, by default, convolves over the entire depth? how can I make it s.t. it convolves separably from the depth? i.e. depth of 1? i.e. same as xception, where xception does depthwise separable convolution followed by a pointwise convolution, but basically perform Conv2D that only does depthwise separable convolution WITHOUT the pointwise convolution?",1.0
fotwma7,g93mn9,"1. Yes, default conv goes over the entire depth
2. Checkout the depthwise_conv function to do a stepwise separable conv, I'm not sure what you meant by depth of 1. It uses separate filters for separate channels",1.0
fotn270,g93mn9,"so for xception layer, given N filters, with kernel size \[A,B\], with input depth of M, do you know how many trainable parameters are there for xception layer?",1.0
foqcrgm,g8zpxq,"See the project here! [https://github.com/paruby/snake-face](https://github.com/paruby/snake-face)

I use the tensorflow.js model [MediaPipe Facemesh](https://github.com/tensorflow/tfjs-models/tree/master/facemesh) to estimate the head pose in real time using the device's camera. When the game starts, the direction in which the head is pointing is estimated as a reference point. Subsequent estimates during game play are compared to this to decide which direction to steer the snake.

The head direction is estimated by calculating the vectors connecting the centre of the lips to the left and right cheeks. These two vectors lie on a plane that approximates the surface of the face. The cross product of these vectors is normal to this plane and thus points approximately in the direction of the head.",2.0
foqgrvi,g8zpxq,[deleted],2.0
foqzxj9,g8zpxq,thanks!,1.0
forizq9,g8zpxq,why tho ...,-1.0
foq4o5d,g8tgw3,"It all depends on data you have, You have to train more for more number of parameters.

I would suggest you to read resnet research paper.",2.0
foqlcdf,g8tgw3,"I agree with this. If you have multiple layers, increasing the number of channels will dramatically increase the number of trainable parameters. More trainable parameters typically means you’ll need more training to get to the same or better loss. Check the model summary to see how many trainable parameters your models have",1.0
foti4xn,g8tgw3,"I might have the culprit in my case, which was blowing out the training loss. It was the batchNorm layer in between. So, basically, removing some of them, especially in the first few layers 'remediated' the problem I had earlier.",1.0
fopr45v,g8remb,"It depends on what algorithms you want to run. If you're trying to run someone's algorithm, stick with whatever version they are using. On the other hand, if you are doing your own experiments, installing the latest one should be fine.",1.0
fp512rk,g8remb,"I'm running tensorflow 2.x on Windows/Anaconda. The Tensorflow instructions (https://www.tensorflow.org/install/gpu) are fairly thorough in terms of getting drivers and software up to date.

The instructions don't mention tensorflow-gpu (available as 2.x) but I had to install that as well for the GPU to be recognized after double checking that my software was setup correctly.

Tensorflow is supported in both conda and pip which might make life easier for you depending on your specific setup.",1.0
foq601v,g8remb,Torch 1.5.0,0.0
fvbtddp,g8nuw3,Server looks pretty dead,1.0
fxfdp6e,g8nuw3,"🤣🤣, Indeed",1.0
fop536c,g8mzb8,Depends on how you want your recommender system to work...!as in what you want as input and what you want as an output. If you just want to base it on 1 statistic like previous watch history video tags then yeah sure tf will do fine... but if you want multiple statistics then a hard coded algorithm would probably work better. Again really depends on requirements and use case for large implementation.,3.0
fopcg7x,g8mzb8,"Try factorizing a matrix using BPR Loss.
In my experience this algorithm does very well.",1.0
fooiij1,g8mzb8,"I am asking myself for over a year if a NN can beat e.g. an a priori algorithm.

Input dimesions would be huge, output dimensions would be huge. Recoursions could be needed.

But then recommendations are just functions to be optimized.

Edit: algorithm name",0.0
foojv89,g8mzb8,A priori,-1.0
fomnat3,g8b6lr,It's gonna be really difficult to help you if you don't share your code. I suggest posting a github link with sample code to reproduce the issue,1.0
foms745,g8b6lr,Had some similar issue. Be sure to use model.save when training (not model.save_weights) and model.load when predicting.,1.0
fokrne8,g80kfv,Have you check the axis= is correct?,2.0
fokshy6,g80kfv,"Yes

When I use tf.expand_axis(data, axis=-2) I my shape goes from (batchsize, 500, 3) to (batchsize, 500, 1, 3) and with tf.squeeze(data) it just reverts back from (batchsize, 500, 1, 3) to (batchsize, 500, 3).

However note that this is only when I use model(data) as this is the only case it runs through.

In the case of model.predict(data) I get shape &lt;unknown&gt; after the tf.expand_axis(data, axis=-2). Same goes for squeeze. Note that here then the initial shape differs slightly as it is (None, 500, 3).",2.0
fokvy9z,g80kfv,"It's trying to compile the graph but can't because it doesn't know how many dimensions the output of that `squeeze` has:

&gt;  tf.squeeze(data) 

Never use squeeze without specifying an axis. The number of dimensions may change depending on the input:

```
squeeze(zeros([5, 3, 1]])).shape # =&gt; [5, 3]
squeeze(zeros([5, 1, 1]])).shape # =&gt; [5, 2]
squeeze(zeros([5, 1, 1]])).shape # =&gt; [5]        # Oups!
```


```
squeeze(zeros([5, 3, 1]]), axis=-1).shape # =&gt; [5, 3]
squeeze(zeros([5, 1, 1]]), axis=-1).shape # =&gt; [5, 2]
squeeze(zeros([5, 1, 1]]), axis=-1).shape # =&gt; [5, 1]
```",2.0
fokxkur,g80kfv,"I think I tried that as well with the output shape still being &lt;unknown&gt;. I will retest it to make sure and post the results here. 

Is there a way to just sraight up delete a dim? 

I picture something like data[:, :, 0,:] could give you a tensor with one dimension less as well?",2.0
fol2k4w,g80kfv,"Yes, indexing works too.

Squeeze is equivalent, but asserts that the dimension has length=1. 

Indexing can hide errors:


Z=zeros([5,1,3])

Z[:,:,0]  # oups

Z.shape # [5,1]",1.0
fou2qrb,g80kfv,"I added the solution.
Thanks for the advice :)",1.0
fou2ghd,g80kfv,"For completion :
So in the end I could make it work with always specifying axis in all statements.
Thanks a lot for everyone that helped :)",1.0
foig9bd,g7ktw8,Go for Bert.,1.0
fofn5ta,g792km,Are you asking why the model can train better on normalized data? If you're asking why after your model has been trained when you feed it un-normalized data why it doesn't behave similarly that's because you've trained it on normalized data. It doesn't know anything about the raw dataset and your output is probably random and has no correlation to the output from normalized data.,1.0
fog1w90,g792km,"No, it's that the the output predictions are scaled so that instead of 100, the prediction might be 0.1 (just an example). There is a reverse-scaler method that can convert a frame back to its non-normalized values.

For the predictions to be useful, they need to be un-normalized. But if you calculate the error between predictions and actual values after they are un-normalized, error improvements between different models don't show the same pattern as when you calculate prediction error on normalized columns.

 I use this function and THEN calculate the predictive error, the resulting loss do",1.0
fog6537,g792km,"I think something else is going on because you can do the math for yourself and see that loss history will be proportionally equivalent.

&amp;#x200B;

`import numpy as np`  
`from sklearn.metrics import mean_absolute_error`  
`from sklearn.preprocessing import MinMaxScaler`  


`true = np.random.rand(1, 5)[0]`  
`prediction_history = np.random.rand(5, 5)`  
`scale_factor = 3`  
`error_steps = np.array([mean_absolute_error(true, prediction_step) for prediction_step in prediction_history])`  


`true *= scale_factor`  
`prediction_history *= scale_factor`  


`error_steps_scaled = np.array([mean_absolute_error(true, prediction_step) for prediction_step in prediction_history])`  


`print(np.array_equal(MinMaxScaler((0, 1)).fit_transform(error_steps.reshape(-1, 1)),`  
 `MinMaxScaler((0, 1)).fit_transform(error_steps_scaled.reshape(-1, 1))))`",1.0
foe0ur8,g6p5g6,Curious why not use SageMaker though,1.0
foe1qh7,g6p5g6,"Didn't look at the tutorial in depth, but I'm curious what made you recommend the use of sage maker? Looking at the stack (flask use) i figure OP was interested in exposing consumable apis. My understanding of sage maker is a scaled up jupyter notebook that can process large amount. So SageMaker may not be the best scalable solution to deploy ML APIs.",1.0
foe29xs,g6p5g6,"I recommended it because what you're both describing is exactly what SageMaker does. You're not wrong, but a Jupyter notebook is only one of many things that it now offers, including model hosting with a consumable HTTPS API: [https://docs.aws.amazon.com/sagemaker/latest/dg/how-it-works-hosting.html](https://docs.aws.amazon.com/sagemaker/latest/dg/how-it-works-hosting.html)

Plus, if anyone knows anything about platform scalability, it's AWS. They practically invented it.",1.0
foe40vo,g6p5g6,"Nice TIL https://youtu.be/KFuc2KWrTHs

Is it correct to state that running sageMaker instances are not server less? The video i referenced above shows integration with lambda APIs (serverless), but you would still be paying for EC2 instances sage maker is running that would still be up even when not in use?

I've been scratching my head for a way to deploy my model in a cost effective platform. I tried layered lambda functions but kept hitting the package size limit (500mb) with just the tensorflow library (pip wheel 480MB). So i've resulted in spinning up low cost kubernetes pods. 

Inferences dont consume more than 2cpu and 1g of ram. What has screwed me over in settling with a platform solution is the bulk size of tensorflow lib (even omitting tensorboard packages) and my weight size (200MB - looking to prune it to smaller size with optimization).

Haha im at the point of possibly porting my model to tensorflow mobile if there's no significant decrease in accuracy and coding effort.",1.0
foe5jq9,g6p5g6,"You are correct. Scroll to the bottom where the pricing examples are: [https://aws.amazon.com/sagemaker/pricing/](https://aws.amazon.com/sagemaker/pricing/)

Training / processing / monitoring hosts are only billed for the amount of time your job runs, but deployment hosts are not serverless, so you're paying for the amount of time the hosts are online, even if no requests are being served. However, this is only for real-time inferences.

If you are willing to sacrifice latency, Batch Transform may be the way to go. You can use a Batch Transform job to run batch inference, and those jobs are only billed for the duration the jobs are running. See Pricing Example #3 above. So, save up a bunch of incoming requests, then when you've queued up N requests, run inference on them all in one go. This will be an order of magnitude cheaper, but obviously it will no longer be in real-time. That said, this could be cheaper than rolling your own EC2 hosts.",1.0
foecmcv,g6p5g6,"After loosing some sleep just now i think I've found the product suited for my needs https://cloud.google.com/run/pricing

The pricing model seems similar enough to lambda but with the dockerized deployment. I'll need to evaluate it's performance/limitstions after a POC deployment but so far it seems painless enough https://youtu.be/nJ0L28ZfmUA

Might need to freeze weights in the container so to reduce overhead in downloading them from s3 each time though.",1.0
foittxp,g6p5g6,What about ECS fargate?,1.0
foj6uf7,g6p5g6,"That was actually my first option. Their pricing scheme just appeared way more expensive though (about 5 times more than gcloud run) https://aws.amazon.com/fargate/pricing/?nc=sn&amp;loc=2

Also aws doesn't seem to offer a free tier option for it so to test out it's capabilities. A colleague mentioned it's boot up time wasn't too optimal either. Another thing that deterred me was the description section stating your ""billing"" starts counting time from the moment it initiates download of your docker image, vs actually charging me for literal cpu/ram job execution. 

My thought is gcloud run is googles solution to aws lambda alternative hence the dirt cheap pricing compared to fargate.

**edit**

You could argue that one of my other requirements to server less is cost effective proto typing.",1.0
foit2d8,g6p5g6,Why not use tensorflow serving and ECS?  I watched and learned a lot from your series. Thank you!,1.0
fomaivz,g6p5g6,"Glad you liked the series! I went for EC2 for a couple of reasons. I like the total flexibility that it gives you, and also because it's a widely used service.",2.0
foet1th,g6o43g,"It can either show the number of elements or the number of batchs. If you are using a batch size of 32, it is normal to display 60000 / 32 = 1875",2.0
foetrw9,g6o43g,"Yes you are right, i noticed yesterday 
Thank you for comment",3.0
fob9ine,g6o43g,This means you're not loading the full dataset - give your code a lookthrough,1.0
foba4ri,g6o43g,"https://www.tensorflow.org/tutorials/keras/classification
These are codes that i used. Where tf downloands data set? I can check if there is a problem",1.0
fopxgsd,g6nrz2,No one has ever combines tensorflow with sklearn???,1.0
fo9df3s,g68mwt,"Your post leaves a lot to be desired in terms of information. Firstly, you should probably always consider whether that loop has to be inside your model. Unless it's a recursive neural network or some form of LSTM window which you are allowing the network to break out of, there aren't very many reasons to have the loop in the model and not outside the model. That's just a best practices type thing.

If you insist that you need the loop, or don't want to follow my advice, then I recommend looking into [tf.cond](https://www.tensorflow.org/api_docs/python/tf/cond). They have a good example that should explain it much better than I could!

Hope that helps!",3.0
fopqkf2,g5y1o5,"Very nice work, thanks for sharing.

I wonder if adding stochastic regularization (e.g. \[DropBlock\]([https://arxiv.org/abs/1810.12890](https://arxiv.org/abs/1810.12890))) to EvoNorm S0 could make it behave like EvoNorm B0 (slower progress at the beginning but higher final accuracy).",1.0
foqiaca,g5y1o5,"Might be a way to slow down the learning of v\_1 and alpha parameter. It seems implemented in [https://github.com/DHZS/tf-dropblock/blob/master/nets/dropblock.py](https://github.com/DHZS/tf-dropblock/blob/master/nets/dropblock.py), might try a training to see what happens. Will keep you posted if I have time to run it!",1.0
fo5zuzm,g5vc14,"Really great idea, how is Tensorflow used for this? I’ve only learnt of how signal similarity can be computed procedurally using things like cross correlation.",4.0
fo8zjwz,g5vc14,"Hey, Samply's ML guy here. We build on traditional DSP approaches like you mentioned with deep learning. We're using Tensorflow to create an audio embedding that is then visualized in our interactive plot view.",2.0
fo9qn1c,g5vc14,"Ah okay, so you extract the characteristics and feed those into the network? Really cool.

I have a lot of friends who would love your application; having folders filled with 1000s of samples is a serious problem! 🤪",2.0
fokgazf,g5vc14,Please feel free to share far and wide! We want to get as much feedback on our beta as possible :),1.0
fo615y9,g5vc14,"Music producer here, does anyone knows how this compares to Algonaut Atlas? Seems like both use machine learning to classify your sample library. Would be unbelievably helpful if either worked well https://www.algonaut.tech",3.0
fo8xzcn,g5vc14,"We like to think we are better than Atlas, but you can download our early Beta right now for free if you want to give it a shot, https://samply.app/downloads",2.0
foit46q,g5vc14,"Thanks for the reply! If u don’t mind me asking, what are some specific differences as far as features/workflow? But yah I’ll definitely it out when I get the chance!",1.0
fokg61i,g5vc14,"One of our main distinctions is that we are gearing up to support far more than just drum samples / oneshots. Atlas and others like XO do a great job at helping with drum sequencing. We want to create a declarative file browser for audio.

We've got the starts of what is going to be a more robust ""table view"" to help users sort their samples without having to use the heatmap / plot. 

We're trying to be as unobtrusive as possible, existing outside your DAW and acting as a sort of ""side car"" to any audio processing program. 

When you get the chance to try it out, please let us know what you would use it for and what improvements could make it the best tool for producers!",2.0
fo7mc56,g5v0ji,You should split the dataset into train/test-data *after* creating a vocab.,1.0
fo9b3gf,g5v0ji,"The data are separate from the beginning: train data from CoNLL2000 and test data from another.

Unless you mean I combine both of them and then make vocabulary.",1.0
fo4k2s7,g5mben,"Dude I have had nothing but problems with tensor aids for the last 6 months... what got me up and working was to just use it in google colab where the handle all of that for you.

Not sure if it helps but it helped me.",5.0
fo5e7kd,g5mben,Did you just call an ML framework “Tensor aids”? Are you five?,2.0
fo5kbd2,g5mben,"Hey. I was doing some great things with my thesis until they formally adopted 2.0 and raised hell on earth in my code. 

I said what I said.",2.0
fo4cd57,g5mben,Anyone else having the same problem or got any solutions?,1.0
fo4d59j,g5mben,"Install linux. There's a learning curve, but you'll need to know it for training on the cloud.",6.0
fo4dfzp,g5mben,I don't want to move to linux because all my stuff is on windows...  Is there no way to keep going on windows?,1.0
fo4dwpa,g5mben,There probably is a way to fix it. I don't know it. I'm just saying you need to also think long-term.,5.0
fo4fu3h,g5mben,This a 100%. Basically the more advanced you go the more important Linux is especially for scientific research,3.0
fo4csow,g5mben,There are answers on stack that you'll get quicker googling then someone typing it out. It has to do with your Windows version I think and the binary you are trying to use,2.0
fo4czcn,g5mben,I’m not allowed to ask questions on stack as I’ve reached my monthly limit 😂.  Could it be the version I downloaded ?,1.0
fo4dpud,g5mben,"I didn't say ask. I said Google. There are posts that already talk about it

Edit: wasn't trying to sound like a dbag sorry",2.0
fo4dt7l,g5mben,Or atleast from what I saw,2.0
fo4e6b6,g5mben,This isn't specific to TF from what I am getting From what I am seeing it could be a host of things including the python version you have downloaded. There are 64 and 32 bit versions,1.0
fo4edw1,g5mben,"Just checked the version installed of pythan an it says Python 3.7.2 (tags/v3.7.2:9a3ffc0492, Dec 23 2018, 22:20:52) \[MSC v.1916 32 bit (Intel)\] on win32.  

Does the win32 mean im using windows 32 bit or....?",2.0
fo4fjsp,g5mben,Yessir. My only advise is to install Linux hahaha,2.0
fo4r9hs,g5mben,"I fixed it!  Well, you did!",2.0
fo4shmi,g5mben,"So you installed Linux? 
Jokes
I didn't do anything. But nice job",2.0
_,g5mben,,
fo4dsas,g5mben,"Ooof ok lol, I’ve already had a look and no one seems to get the same problem as me",1.0
fo4ewhf,g5mben,[deleted],1.0
fo4f0de,g5mben,So should I reinstall python as 64bit?,1.0
fo4zto8,g5mben,I found using conda through the command line in pycharm to work better. Or use WSL.,1.0
fo5kfso,g5mben,"This is a conda error. A stackoverflow solution seems to be to clean up your Python installation in your AppData folder.

[https://stackoverflow.com/questions/58651671/anaconda-orange3-produces-oserror-winerror-193-1-is-not-a-valid-win32-applic](https://stackoverflow.com/questions/58651671/anaconda-orange3-produces-oserror-winerror-193-1-is-not-a-valid-win32-applic)",1.0
fo0kuxw,g50p72,"
I see you've posted a GitHub link to a Jupyter Notebook! GitHub doesn't 
render large Jupyter Notebooks, so just in case, here is an 
[nbviewer](https://nbviewer.jupyter.org/) link to the notebook:

https://nbviewer.jupyter.org/url/github.com/sachinruk/deepschool.io/blob/master/DL-Keras_Tensorflow/Lesson%2019%20-%20Seq2Seq%20-%20Date%20translator%20-%20Solutions.ipynb

Want to run the code yourself? Here is a [binder](https://mybinder.org/) 
link to start your own Jupyter server and try it out!

https://mybinder.org/v2/gh/sachinruk/deepschool.io/master?filepath=DL-Keras_Tensorflow%2FLesson%2019%20-%20Seq2Seq%20-%20Date%20translator%20-%20Solutions.ipynb



------

^(I am a bot.) 
[^(Feedback)](https://www.reddit.com/message/compose/?to=jd_paton) ^(|) 
[^(GitHub)](https://github.com/JohnPaton/nbviewerbot) ^(|) 
[^(Author)](https://johnpaton.net/)",1.0
