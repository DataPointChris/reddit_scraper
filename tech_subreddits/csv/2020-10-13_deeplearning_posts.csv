post_id,post_title,post_body,upvotes,subreddit,date
jagizr,Female Pioneers in Computer Science You May Not Know - Part 2,,1,deeplearning,2020-10-13
jafhtj,Calculate Optimum / Best Batch Size?,"Batch sizes are supposed to be proportional to the GPU/TPU memory size.

Experts recommend that we keep them as powers of 2. So, 8, 16, 32, etc.

There are useful [threads](https://stackoverflow.com/questions/46654424/how-to-calculate-optimal-batch-size) with partial answers,

&gt;*Max batch size= available GPU memory bytes / 4 / (size of tensors + trainable parameters)*

but I could not find a full calculation of how to get the perfect value for a given input image resolution.

&amp;#x200B;

Say, we have a colab TPU with RAM of 8 GB.

And we are training MNIST on it, with a ResNet50 model.

MNIST has 60,000 images of size 128x128.

Then how to estimate the optimum batch size?

Please show every step of the calculation.

&amp;#x200B;

Also, lets break it down into sub problems:

If we take the Keras ResNet50 model, how much memory does it occupy on the GPU/TPU? I guess this has to do with 16, 32 and 64 bit integer and float data types of the tensor.

What other things in the program take up considerable memory on the TPU?

&amp;#x200B;

Thanks in advance!",1,deeplearning,2020-10-13
jacdk8,PC and GPU recommendations,"I'm looking forward to buying a new PC to run my deep learning models. I´m relatively new to deep learning, so I don´t know which specific atributes I need to analyze for my PC. I'm asking for recommendatios for a specific PC or to which things I need to look into when deciding which PC I´m buying. I also want to buy a NVIDIA GPU, so recommendations for which one I should buy are also welcome.",0,deeplearning,2020-10-13
jacbs8,Mura Dataset,"Hello guys, how're you?
Guys I downloaded a dataset of bone fractures to build a CNN to classify if has or no fractures.
I downloaded a zip file with the images dataset and I can't put it in a variable to build a CNN, could you guys help me please?",1,deeplearning,2020-10-13
jabsdc,What layers to use for one hot encoded vectors,"Hello all, 
I have a dataset which contain sentences and context and other metadata related to  it. The metadata has to be one hot encoded. I was wondering is there any way we can include one hot encoded vectors in a deep learning model. Are there any special layers for it ?",1,deeplearning,2020-10-13
jaaza1,How do I gain confidence while coding models ?,"I am quite familiar with the theory and understand it well. Although I have been facing difficulties while building and coding the model. How can I get better at it ? I have been practicing by building models, but I usually get stuck at points in between.",1,deeplearning,2020-10-13
jaaeoo,Is any problem in the Cuda configuration in Nvidia GPU with an AMD CPU?,"

[View Poll](https://www.reddit.com/poll/jaaeoo)",0,deeplearning,2020-10-13
jaa1au,How to extract data from forms using deep learning,Time-consuming manual data entry of digitized forms is a bottleneck in numerous internal processes of any insurer. We wrote a blog to help you automate this step for a popular type of form - ACORD. Hope it's helpful! Link: [https://nanonets.com/blog/ocr-extract-data-from-acord-forms/](https://nanonets.com/blog/ocr-extract-data-from-acord-forms/),1,deeplearning,2020-10-13
ja91e2,Recruiting GPU Container Tester in goormIDE (https://ide.goorm.io),"Hi Everyone!

&amp;#x200B;

We provide Cloud IDE Service called goormIDE ([https://ide.goorm.io](https://ide.goorm.io)) like AWS Cloud9.

Free plan? Of course we provide.

&amp;#x200B;

This time, the GPU container support has been opened in goormIDE, but testers are being recruited because the actual performance and usability needs to be verified before opening as a paid model.

&amp;#x200B;

To those who have been selected as testers, we plan to deliver a GPU container with an NVIDIA Tesla V100 model connected to it free for two weeks and receive reviews. If you are interested in testing GPU containers, please go to [https://goor.me/gEuwP](https://goor.me/gEuwP) and apply!

&amp;#x200B;

The more detailed the purpose of use, the more likely it is to be selected, so please refer to this point :)

We ask for your interest!

Thank you!",0,deeplearning,2020-10-13
ja5sct,Understanding Deep Learning Theory Papers,"Could you recommend a good textbook or source that will help engineering majors (like me) understand deep learning theory papers?

I know somewhat about Bayesian inference, MLE/MAP, basics of Monte Carglo estimation of expectation, that we are trying to learn “good” representations, and also multivariate calculus.

Yet, when I meet terms such as point estimates, Lipschitz smoothness, universality, or Riemann manifolds, I need to consult Wikipedia, which often talks such gibberish that I am left thinking “I’d rather study a textbook than crawl through this”.

Thanks!",45,deeplearning,2020-10-13
ja1e1e,Let's say the circle nodes were empty. Does anyone know how to calculate the state value function for each node?,,16,deeplearning,2020-10-13
ja0ka0,Pytorch vs Tensorflow for freelancing in the future?,"I would like to dive in to deep learning for future freelancing projects, what would be the best bet for the future in work, pytorch or tensorflow? :)",0,deeplearning,2020-10-13
j9ysy8,HPC in the Cloud - Python Package Management - Thursday Evening Livestream,,1,deeplearning,2020-10-13
j9tf3x,Dealing with the Concept Drift. State of practice.,"For ML applications it comes difficult to manage some special kind of changes, that we call concept drift or covariate shift or data drift.

These can be detrimental to your model performance in prod as **most concept drift related methods are very subjective to the nature of the problem.**

So, how to prevent concept drift?

There are various strategies, including:

* Online learning
* Model re-training
* Re-sampling using instance selection
* Ensemble learning with model weighting
* Feature dropping

However, my question is – have you found any methods you personally use that might not be ""conventional"" but they work?

We dive deep into the topic in [this article](https://neptune.ai/blog/concept-drift-best-practices?utm_source=reddit&amp;utm_medium=post&amp;utm_campaign=blog-concept-drift-best-practices).",2,deeplearning,2020-10-13
j9taxk,Multi-View Transfer Learning,"Hello folks, need a little help.

I am working on a multi-view image classification problem. I have a small dataset of two classes with each class having 208 and 220 images respectively in the training set and 48 and 52 images in the validation set respectively. Each class has two images of the same object so it effectively reduces the number to 104 and 110 images effectively for each class. I can not train a full CNN on this. 

So, can anyone help me to figure out how can I use transfer learning to accomplish this task? Any good resources or advice will be very helpful.",1,deeplearning,2020-10-13
j9t5l6,Choosing between big cnn for object detection or smaller piped with image classification,"Hello everybody!  
 I'm pretty new to the field of deep learning and I'm working at a project involving a smart traffic assistance.  
 The first task involves object detection and recognition.  
 Objects can be divided in three main classes as follows: traffic lights,  traffic signs and other traffic participants (vehicles).

I have two possible approaches: 

* train a big dataset that contains every subclass element like: stop  sign, red traffic light left, truck, bike, and every other traffic  light/traffic sign from the data bases.
* train a smaller dataset capable of recognising fewer classes, crop the recognised element and then use a classifier.

Why I would use the second approach:

&amp;#x200B;

1. I have a uniform dataset containing all the main classes.
2. I have different number of samples in each dataset, different format and annotations.
3. There are some subclasses with small representation thus is harder to train object detection than classification.

Why I wouldn't use it:

&amp;#x200B;

1. It has to run real time ( I guess this approach would be more computational demanding ?).

What would you choose?  
 Thanks!",1,deeplearning,2020-10-13
j9r82n,An Image is Worth 16x16 Words:Transformers for Image Recognition at Scale (Paper Explained),,24,deeplearning,2020-10-13
j9r6jk,"[Article] Evaluating Deep Learning Models: The Confusion Matrix, Accuracy, Precision, and Recall","This article gives an intuitive and thorough explanation of deep learning metrics like accuracy, precision, recall, and the confusion matrix. Topics covered include the confusion matrix for binary and multi-class classification; how to calculate the confusion matrix with Scikit-learn; a discussion of accuracy, precision, and recall; and when to use either precision or recall. 

Article link: [https://blog.paperspace.com/deep-learning-metrics-precision-recall-accuracy/](https://blog.paperspace.com/deep-learning-metrics-precision-recall-accuracy/)",2,deeplearning,2020-10-13
j9pvnr,The `Hello World` of Deep Learning in fastai,,5,deeplearning,2020-10-13
j9pgn3,How To Use DeepCognition To Build Drag And Drop Deep Learning Models Without Coding?,,1,deeplearning,2020-10-13
j9o3f2,GPT3 inference,"Hi.

Does anybody knows or have there been a paper done on how GPT3 inference works.

I mean one can view GPT3 as very high dimensional auto-regressive model. I am curious if it is soo good because it has seen insane amount of data and have capacitibility to just remember everything, or it can actually infer (understand) input data. Understand is not the proper word, i hope you know what I mean... Does it like for example calculate some statistics of the inputs (very simply put) and then based on them return the output or its like, ha i ve seen this already, this is what follows...? 

I hope i express my question articulately enough, english is not my first language..",0,deeplearning,2020-10-13
j9mgs3,Back to Machine Learning Basics - Regularization,,2,deeplearning,2020-10-13
j9lfwd,Download Project Management Solutions,,0,deeplearning,2020-10-13
j9jvgl,Need Ideas For NLP based Machine Learning or Deep Learning Projects,"Actually, I am an NLP enthusiast. I was looking for some project ideas regarding NLP Based on either Machine learning or deep learning. Can someone give any ideas regarding Such Projects, or and new NLP based Module Launched recently for making interesting projects or What websites or resources you would suggest that you personally prefer for making NLP based Projects?  


Interested Developers and NLP Enthusiasts, we can even collab to discuss and work together on amazing NLP projects",1,deeplearning,2020-10-13
j9iwqz,Activation Function And Loss Function,"Hi,

Is there any one to one correspondece between activation function in the last layer and the loss function? For example using softmax with categorical\_crossentropy.

Thanks",11,deeplearning,2020-10-13
j9ivsw,Interview with Tim Dettmers: Which RTX 3000 GPU(s) to get for Deep Learning?,"Hi Everyone! 

I run a non-monetised, Ad-free interview series as a service to the ML Community where I interview my ML Heroes. 

I had interviewed Tim Dettmers about his GPU advice now that the 3000 series is released:

[Audio](https://anchor.fm/chaitimedatascience/episodes/Tim-Dettmers-Which-RTX-3000-GPU-to-get-for-DL--3090-FAQ--CTDS-Show-108-ekeue8), [Video](https://www.youtube.com/watch?v=CaoQLrSBk0o)

I hope you find this useful and if you've any feedback for me, or guest suggestions, I'd be very grateful. Thanks!",37,deeplearning,2020-10-13
j9hbho,Create new features from hierarchical clustering,"Is it normal to generate a new type of ""group"" feature on the training data by applying hierarchical clustering, to then use it as a feature in a deep learning model ?",1,deeplearning,2020-10-13
j9bi9v,Unpooling function keras," Hi everybody!

I  start by saying that I'm kinda new to deep learning. I'm trying to  write a segnet in keras that uses pooling indices to upsample. I'm using  this function with a Lambda Layer to perform a max pooling and save  pooling indices:

    def pool_argmax2D(x, pool_size=(2,2), strides=(2,2)):
        padding = 'SAME'
        pool_size = [1, pool_size[0], pool_size[1], 1]          
        strides = [1, strides[0], strides[1], 1]          
        ksize = [1, pool_size[0], pool_size[1], 1]          
        output, argmax = tf.nn.max_pool_with_argmax(                  
            x,                  
            ksize = ksize,                  
            strides = strides,                  
            padding = padding          
        )           
        return [output, argmax] 

It seems working. In my model summary it returns a tensor of shape **(None, h/2, w/2, channels)**. However I'm having some issues to find or write a working unpooling function. I'm unable to return a tensor of shape **(None, 2h,2w, channels)** (None for batch size)

I  have already tried some unpooling function but with no results. The  main issue is not the unpooling process itself but it's returning a  tensor with None as first axis. Any suggestions or help would be useful,  thank you!",7,deeplearning,2020-10-13
j9bgtl,Is there something like www.respeecher.com (dont have to be online website),,2,deeplearning,2020-10-13
j9av18,"GauGAN/SPADE UI, feel free to use","[https://github.com/deduble/gaugan-gui](https://github.com/deduble/gaugan-gui)

&amp;#x200B;

Hello everyone,

I created that GUI long ago before Nvidia published their demo. Now I see that theirs is down, so I decided to publish mine.

For people who don't know (really? Do you exist?), Nvidia SPADE creates photo realistic images from basic segmentation images. (basic drawings).

Feel free to implement this anywhere. Just mention my github. Most importantly, I don't have much place for now for testing. I am open to PR and fixing issues.

Have good day.",3,deeplearning,2020-10-13
j95938,Reason behind classification in one or two classes only?,"Hi,

Please observer following output for the given model.

base\_model = tf.keras.applications.Xception(

        include_top=False,
        weights=""imagenet"",
        input_shape=(150, 150, 3),
        classifier_activation='softmax',
    )
    
    base_model.summary()
    # Freeze the base_model
    base_model.trainable = False
    
    # Create new model on top
    inputs = tf.keras.Input(shape=(150, 150, 3))
    #x = data_augmentation(inputs)  # Apply random data augmentation
    x = inputs
    # Pre-trained Xception weights requires that input be normalized
    # from (0, 255) to a range (-1., +1.), the normalization layer
    # does the following, outputs = (inputs - mean) / sqrt(var)
    norm_layer = keras.layers.experimental.preprocessing.Normalization()
    mean = np.array([127.5] * 3)
    var = mean ** 2
    # Scale inputs to [-1, +1]
    x = norm_layer(x)
    norm_layer.set_weights([mean, var])
    
    model_1 = Model(inputs=base_model.input, outputs=base_model.get_layer('add').output)
    model_2 = Model(inputs=base_model.input, outputs=base_model.get_layer('add_1').output)
    model_3 = Model(inputs=base_model.input, outputs=base_model.get_layer('add_2').output)
    model_4 = Model(inputs=base_model.input, outputs=base_model.get_layer('add_3').output)
    model_5 = Model(inputs=base_model.input, outputs=base_model.get_layer('add_4').output)
    model_6 = Model(inputs=base_model.input, outputs=base_model.get_layer('add_5').output)
    model_7 = Model(inputs=base_model.input, outputs=base_model.get_layer('add_6').output)
    model_8 = Model(inputs=base_model.input, outputs=base_model.get_layer('add_7').output)
    model_9 = Model(inputs=base_model.input, outputs=base_model.get_layer('add_8').output)
    model_10 = Model(inputs=base_model.input, outputs=base_model.get_layer('add_9').output)
    model_11 = Model(inputs=base_model.input, outputs=base_model.get_layer('add_10').output)
    
    x = model_6(x, training=False)
    
    x = keras.layers.GlobalAveragePooling2D()(x)
    outputs = keras.layers.Dense(7, activation='softmax')(x)
    model = keras.Model(inputs, outputs)
    model.summary()
    
    epochs = 40
    
    model.compile(
        optimizer=keras.optimizers.Adam(),
        loss=keras.losses.CategoricalCrossentropy(from_logits=True),
        metrics=['accuracy'],
    )

https://preview.redd.it/i1a3vqlltgs51.png?width=515&amp;format=png&amp;auto=webp&amp;s=22b89ec6973a38b383f2c2d2ac49175bae83dbb7

    Class Dist For Train: [3996. 3770. 3878. 4426. 3880. 3656. 5382.]
    Class Dist For Valid: [432. 324. 646. 648. 108. 538. 972.]
    Class Dist For Test: [ 646.  108. 1124. 1126.  910.  864. 1331.]
    
    [[   0    0    0    0    0    0  646]
     [   0    0    0    0    0    0  108]
     [   0    0    0    0    0    0 1124]
     [   0    0    0    0    0    0 1126]
     [   0    0    0    0    0    0  910]
     [   0    0    0    0    0    0  864]
     [   0    0    0    0    0    0 1331]]
    
    Why everything is being classfied to one class only?",1,deeplearning,2020-10-13
j93gok,100-off-python-certification-training-beginner-to-expert/,,0,deeplearning,2020-10-13
j92tlz,"PCIe connections and riser cables for high performance workloads like RNDR / OctaneRender (Ribbon, USB, M.2, PLX, MSI, Splitters)",,4,deeplearning,2020-10-13
j927ey,Where to collect image datasets for classifier?,"Hi,

I am pretty new and don't know any resources to collect thousands of images required for my classifiers. 

I wanna collect mainly recyclable objects for my project.

Can you please tell me where to collect these images?",10,deeplearning,2020-10-13
j8zbbu,Hosting neural networks in one place," Hey guys, Is it possible to host many ml/dl models that do different tasks on one place and potentially create a network of classification and routing AIs that can narrow down the problem and route it to the appropriate specialized AI? in simple, how do i host many neural networks that do different tasks in one place and create a system that will classify the problem and route it to the specialized ai {ex: computer vision, nlp}?",5,deeplearning,2020-10-13
j8x0rp,Advice for a teen learning deep learning?,"I have finished the introduction to PyTorch by audacity last month, where I learned about linear neural networks, cnns, and rnns. I have since then stopped learning about deep learning and now I don't remember a lot of things I once knew.

I want to get back into deep learning, and get good enough to the point where I can make my own models that can be put to good use.

What courses, would you recommend to a person who has a good understanding of how deep learning works, but doesn't know how to make one for himself? thanks",0,deeplearning,2020-10-13
j8vc46,Should I return the Nvidia Jetson Nano 4GB for the 2GB,I'm trying to develop on the nano and will be using a GAN on it. Would it be smart for me to return the 4gb one that I just bought for 2gb. Is the extra ram going to be useful for inference?,0,deeplearning,2020-10-13
j8tb9y,Architecture for deploy custom models for multiples customers?,"Hi

I am confidente using ML, DL and NLP techniques, however I am new in cloud architecture design, what  I want to know is which one is the architecture for deploy custom models for multiples customers?, I mean a customer A has a trained model, a customer B has another one, 

Each customer own their own API to consume their model

Any Idea how to approach to the problem? thank you",0,deeplearning,2020-10-13
j8s3dn,Available pre-trained Super-Sampling Neural Networks,As per the question,0,deeplearning,2020-10-13
j8lk2h,Object Detection from 9 FPS to 650 FPS - on-GPU tuning case study,,28,deeplearning,2020-10-13
j8leeg,Best practices for handling large datasets,"Hello, since I got into deep learning, I've been working with small datasets to create models in `tensorflow` / `keras` functional api. What I'm used to do is to preprocess and clean / manipulate / visualize the data using `pandas` and later create a tfrecord that I use for training. Recently I started working with stock data (1min frequency) so, I currently have somewhere between 10,000 - 30,000 stock signs for 10+ years of data that I stored in the following fashion: I got the data from [polygon](https://polygon.io/) api and for each stock sign I create a separate `.parquet` file and I have the files in a `GCP` bucket. Now, if I'm going to create a dataset that will include most of the signs I have the following concerns:

* Variable length and frequency files which implies for example: `AAPL` df has 2,566,598 rows and `AMZN` has 1,928,479 rows for the same period, and some signs have fewer than 10,000 rows. What is a proper way of dealing with `NAN` values?
* For calculating technical indicators, lagged returns and many other computations efficiently, I was thinking maybe I could use Google BigQuery and store the data and perform necessary computations using `SQL` queries, is there a better way? should I store all signs in 1 table with multiple indices? or use one table for each sign?

And for those who worked with intraday stock data before:

* What frequency do you recommend to avoid overfitting and get good results?
* What technical indicators work best for data with this frequency(1min)? I'm asking because `moving averages`, `MACD` and many other indicators calculate over periods of days and I'm not sure whether this can be applied to this frequency as well.",8,deeplearning,2020-10-13
j8jfjn,DeepFakes in 5 minutes. Understand how deepfakes work and create your own!,,49,deeplearning,2020-10-13
j8gb26,Wrote a simple C# program to draw images on Paint (Source in the comments),,7,deeplearning,2020-10-13
j8g6on,"[P] Reproducible Pytorch Implementation of ""FixMatch"" with trained models.",,1,deeplearning,2020-10-13
j8cm5k,Unsupervised Multi-Document Summarization using Neural Document Model | Research Paper Walkthrough,,2,deeplearning,2020-10-13
j8a0gy,Next step on deep learning,"Hi folks
I have just finished Andrew Ng's neural network course on coursera. What should be the next step? I don't want to lose myself while I found my pace.
Have a nice day",9,deeplearning,2020-10-13
j87swm,DDPG in Stock. Looking for Teammates :),"Hi,

Hope this finds you well guys!

Recently I am trying to implement the paper  [""Adversarial Deep Reinforcement Learning in Portfolio Management""](https://arxiv.org/abs/1808.09940) with one of the methods mentioned in the paper -- Deep Deterministic Policy Gradient. The code of the paper can be found [here](https://github.com/liangzp/Reinforcement-learning-in-portfolio-management-). It also includes the dataset.  I am using TensorFlow 2.0 / Keras. I created a small network instead of a full network in the paper for debugging purposes. My code could be found [here](https://github.com/XimingFeng/ddpg-stock). You can open to Jupyter notebook ""[DDPGTest2.ipynp](https://github.com/XimingFeng/ddpg-stock/blob/master/DDPGTest2.ipynb)"" for the running result.

My issue right now:  somehow the actor starts to produce high confidence with only one class/stock after a few steps, then it stays that way forever unless I set the noise on the actor output to be really high. Even if I force the network to learn the same dataset for multiple episodes, still does not make any change. I tried different types of networks such as CNN, Fully-Connected. With that, I don't think the network type is the issue. I have also tried different sets of hyper-parameter. I feel stuck right now. Not sure what to check next. If you are interested in the project, please let me know. Any help is appreciated!",1,deeplearning,2020-10-13
j87evq,CUDA using AMD processor,"Hello everybody!

Currently I am setting up a new computer, I would like to train some DL models . I am deciding which processor should be buy between AMD or Intel together with a NVIDIA GPU. I want use the GPU to train some models using Pytorch, however I don't know if CUDA works with an AMD processors properly (I only used it with Intel + NVIDIA GPU). 

&amp;#x200B;

I would like to know if some of you have worked with AMD + NVIDIA to train models?  

Any recommendations?

Thank you very much!",0,deeplearning,2020-10-13
j855sv,PwC-Powered Code Tab Added to arXiv ML Papers,"Tired of searching for and copying GitHub links in arXiv papers to find the code? Papers with Code (PwC) is here to help! PwC and arXiv jointly announced their partnership yesterday, [unveiling](https://blog.arxiv.org/2020/10/08/new-arxivlabs-feature-provides-instant-access-to-code/) a convenient new Code tab on the abstract page of arXiv Machine Learning articles. PwC says the new feature will make it much easier for researchers and practitioners to access and build on the latest machine learning research.

Here is a quick read: [PwC-Powered Code Tab Added to arXiv ML Papers](https://syncedreview.com/2020/10/09/pwc-powered-code-tab-added-to-arxiv-ml-papers/)",25,deeplearning,2020-10-13
j846pf,Understanding gini index and information gain in decision tree,,1,deeplearning,2020-10-13
j7z0v0,"Image Matting with state-of-the-art Method “F, B, Alpha Matting”","Image matting has been traditionally done using a green or blue screens. With advances in AI, we can now get rid of the green screen and still create high quality outputs for images with natural backgrounds.  


Without further ado, let's go over the state of the art image matting algorithm in the post below.  


[https://www.learnopencv.com/image-matting-with-state-of-the-art-method-f-b-alpha-matting/](https://www.learnopencv.com/image-matting-with-state-of-the-art-method-f-b-alpha-matting/)  


We have also shared code.

https://preview.redd.it/pf0axi5jn2s51.jpg?width=600&amp;format=pjpg&amp;auto=webp&amp;s=5915a0bba2c27cb578b1d6bf3fcb960def784eac",3,deeplearning,2020-10-13
j7xf0x,Anyone have experience with yolov5. I'm facing an issue with coreml export.,[https://github.com/ultralytics/yolov5](https://github.com/ultralytics/yolov5),0,deeplearning,2020-10-13
j7wfme,Finally a storage benchmark tool to include GPUs (Feedback/suggestions welcome),,10,deeplearning,2020-10-13
j7v57i,Variational Autoencoders : which losses to use ?,"Hello community. I'm currently implementing a VAE solution . In TensorFlow 2.0 examples , I saw that they used `sigmoid_cross_entropy_with_logits` as the reconstruction loss.

I didn't understand this choice , I would instead use MSE or RMSE errors to reconstruct the loss ,and use the `KL Divergence` for the latent loss.

I want to precise that in my task ,images don't have classes ,they are just a bunch of images that cannot be classified . I can simply say that I have one class.,what loss should I use instead of `sigmoid_cross_entropy_with_logits` does `MSE` would do the job ?",13,deeplearning,2020-10-13
j7u34o,Filter learning with unsupervised learning,“Filter Learning with Unsupervised Learning” - Tekin Evrim Ozmermer tarafından https://link.medium.com/Vc07ppe7qab,1,deeplearning,2020-10-13
j7u327,Filter learning with unsupervised learning,“Filter Learning with Unsupervised Learning” - Tekin Evrim Ozmermer tarafından https://link.medium.com/Vc07ppe7qab,1,deeplearning,2020-10-13
j7tuft,Randomly changing weights of CNN in between training,"Hi,

Can I randomly change weights of CNN in between training in keras? It is for the case if there is no change in accuracy.

Thanks",0,deeplearning,2020-10-13
j7tijb,How to formulate custom learning rate pytorch?,"I'm working with transformer based model and want to schedule custom learning rate i.e.

```bash
lrate = d_model ^ 0.5 * min( step_num ^ 0.5, step_num * warmup_steps ^ -1.5)
```

How to formulate this in pytorch?",1,deeplearning,2020-10-13
j7nwje,Network Saliency Maps,"I would like to ask if there is a way to acquire network saliency maps for applications like object detection (aside from classification)? For example if we take the standard gradient-based saliency maps, how can we do this if our output is an image map and each pixel is classified rather than having a single predicted value?   
Thank you very much.",2,deeplearning,2020-10-13
j7nm83,Is Quantum Machine Learning the next thing?,,0,deeplearning,2020-10-13
j7nkby,Is Quantum Machine Learning the next thing?,,0,deeplearning,2020-10-13
j7mng0,[R] ‘Farewell Convolutions’ – ML Community Applauds Anonymous ICLR 2021 Paper That Uses Transformers for Image Recognition at Scale,"A new research paper, *An Image Is Worth 16×16 Words: Transformers for Image Recognition at Scale,* has the machine learning community both excited and curious. With Transformer architectures now being extended to the computer vision (CV) field, the paper suggests the direct application of Transformers to image recognition can outperform even the best convolutional neural networks when scaled appropriately. Unlike prior works using self-attention in CV, the scalable design does not introduce any image-specific inductive biases into the architecture.

Here is a quick read: [‘Farewell Convolutions’ – ML Community Applauds Anonymous ICLR 2021 Paper That Uses Transformers for Image Recognition at Scale](https://syncedreview.com/2020/10/08/farewell-convolutions-ml-community-applauds-anonymous-iclr-2021-paper-that-uses-transformers-for-image-recognition-at-scale/)

The paper *An Image Is Worth 16×16 Words: Transformers for Image Recognition at Scale* is available on[ OpenReview](https://openreview.net/pdf?id=YicbFdNTTy).",0,deeplearning,2020-10-13
j7liwh,Machine Vision Anomalous Spray Pattern Problem Detection Problem,"I'm hoping to get some direction on a problem I'd like to try to solve using deep learning. The problem is a machine vision problem. I need to detect anomalous spray patterns in a spray drying application.

Specifically, the spray dryer has multiple spray nozzles that atomize the product (concentrated milk) before it is introduced into a hot air stream. Occasionally, a build-up occurs on the nozzle body causing an anonymous spray pattern. The real danger here is the build-up, which has been termed ""bearding"". The ""beard"" can smolder and drop off of the nozzle and cause a dryer explosion. To help monitor and prevent this, the spray dryer is equipped with cameras that allow an operator to spot the issue and take action.

My hope is to utilize the camera footage to train a deep network to recognize an abnormal spray pattern and alert the operator (or take action). I have a PC equipped with an Nvidia 2080 GTX video card and is running the latest version of Ubuntu. The PC can be set up with various deep learning platforms, but my thought was to use Keras as well as TensorFlow and/or MxNet and whatever else is required to conduct training. 

I should mention that I'm almost quite inexperienced in deep learning. I've read a couple of books, followed along on some exercises, and tried a few small projects. With all of that said, I was wondering if this approach, [""Anomaly Detection in Videos using LSTM Convolutional Autoencoder""](https://github.com/hashemsellat/video-anomaly-detection) will work for this application? Here's the [GitHub link](https://github.com/hashemsellat/video-anomaly-detection) to the same. My thought is that this is not a difficult problem compared to other machine vision problems, but not sure what other more experienced practitioners think? Thanks in advance for any thoughts, comments, suggestions, etc...

# 

[Typical spray pattern](https://preview.redd.it/np10qfhrqxr51.jpg?width=898&amp;format=pjpg&amp;auto=webp&amp;s=8994cc8c6372ff71dfb4a35a95e83a613bb1ffbc)

&amp;#x200B;

[Build-up and slightly disturbed spray pattern](https://preview.redd.it/byieyj62rxr51.jpg?width=300&amp;format=pjpg&amp;auto=webp&amp;s=0ec67d8e0227af89148cd80c7dd730a831e6c6c3)",1,deeplearning,2020-10-13
j7k3dm,Is Attention a technique or an architecture ?,"I was recently reading articles and the original paper of Attention, where the paper defines Attention as

&gt;An attention function can be described as mapping a query and a set of key-value pairs to an output

This led me into confusion whether Attention is an architecture, a fixed layer by layer design, or a technique, which involves implementing a basic idea, to bring the model's attention to the important parts, as it is said for Attention models ? If it is a technique, what is the idea based on code that it tries to incorporate ?",7,deeplearning,2020-10-13
j7jvn3,Building a chatbot with google's universal sentence encoder (Open Source),"Hi everyone,

I recently built a simple chatbot with Google's universal sentence encoder using it as a sentence embedding and finding the best response with cosine similarity. I wrote about it a bit more in my [blog post](https://www.papercups.io/blog/chatbot). I tried to simplified some of the explanation since I had trouble understanding embeddings when I first learned it

You can also play around with the chatbot by feeding it your own questions and answers [https://app.papercups.io/bot/demo](https://app.papercups.io/bot/demo)

with the source code for the backend [https://github.com/papercups-io/papercups-simple-chatbot](https://github.com/papercups-io/papercups-simple-chatbot)

the source code of the client side is [https://github.com/papercups-io/papercups/blob/master/assets/src/components/demo/BotDemo.tsx](https://github.com/papercups-io/papercups/blob/master/assets/src/components/demo/BotDemo.tsx)

Would love any feedback!",7,deeplearning,2020-10-13
j7inbs,Handling matrix dimensions problem,"Hi folks,

I am a newbie and trying to implement neural network model from scratch. I am confusing dimension of matrix most of the time. I mean sometimes I need to take transpose a matrix while multiplying or doing element-wise multiplication instead of dot product, etc. One of the thing why I confuse is the convension in different courses or implementations I guess. Do you have any suggestion for placing this idea into mind clearly?

Thanks",0,deeplearning,2020-10-13
j7ig7y,"Google, Stanford, &amp; MIT Top NeurIPS 2020 Accepted Papers List","After months marred by controversies over poorly-explained [desk-rejects](https://syncedreview.com/2020/07/16/poorly-explained-neurips-2020-desk-rejects-peeve-ml-researchers/) and other problematic aspects of its [review process](https://syncedreview.com/2020/08/13/neurips-paper-reviews-released-controversies-resurface/), the 34th Conference on Neural Information Processing Systems (NeurIPS 2020) has finally released its [list](https://neurips.cc/Conferences/2020/AcceptedPapersInitial) of accepted papers.

With 38 percent more paper submissions than 2019, this has been another record-breaking year for NeurIPS. A total of 1,903 papers were accepted, compared to 1,428 last year.

The NeurIPS 2020 Program Chairs report that 12,115 paper abstracts were submitted, leading to 9,467 full submissions. After 184 submissions were withdrawn by authors or rejected for violations such as being non-anonymous or exceeding the maximum page count, 11 percent were desk-rejected, leaving 8,186 papers assigned to reviewers. **The NeurIPS 2020 paper acceptance rate is 20.1 percent — slightly lower than last year’s 21 percent.**

Here is a quick read: [Google, Stanford, &amp; MIT Top NeurIPS 2020 Accepted Papers List](https://syncedreview.com/2020/10/08/google-stanford-mit-top-neurips-2020-accepted-papers-list/)",32,deeplearning,2020-10-13
j7hxb4,VScode environment or Colab Environment for Deep Learning,"Hey, I’m currently a student who uses google colab for my deep learning projects. However, I recently installed python in visual studio code as well. Would you guys recommend I stay away from doing deep learning on vscode and staying on colab just because colab gives you the option of a GPU?",0,deeplearning,2020-10-13
j7hjff,"Think it's a simple question, but... how do you read "".geno"" files in Jupyter Notebook (Python)?","Title.

Recently I have been assigned to build a deep learning model with some genotype and phenotype data. I'm honestly pretty new to machine learning and do not have a clue when it comes to reading those "".geno"" files. Looked it up but no luck. People say that I would have to write it in R, but doesn't that make it not a deep learning model?

 Hopefully someone could help with my concerns. Thanks.",0,deeplearning,2020-10-13
j7gwf8,[P] Doing More with Less Using Bayesian Active Learning,"[https://product.hubspot.com/blog/bayesian-active-learning](https://product.hubspot.com/blog/bayesian-active-learning)

How we're using advances in Bayesian deep learning to extract reliable uncertainty estimates from neural networks.",9,deeplearning,2020-10-13
j7geyh,Correspondance between types of filters and Image,"Hi,

I am working on electrophysiological data (EEG). I have to do the classification based on some images created from the EEG data visual and signal processing. I have around 3100 images/class. Training on pre-trained model like Xception doesn't give good results. I have trained with my simple architecture as I though due to lack of data the Xception model (Block-1 and Block-2) might be underfitting but with no avail. As my data is different from normal object related data like imagenet. I am wondering if anyone knows about any reference where some correspondance between types of images and hyper-parameter (eg. filter size, activation function and others) is mentioned.

&amp;#x200B;

Thanks for your reply.",1,deeplearning,2020-10-13
j7f1c9,"[D] When I try to train the VGG16 model without batch normalization and with no pre-trained weights (i.e. training from scratch) on the CIFAR-100, the accuracy on the validation set is stuck at 1% and is not improving.","I am using SGD and CrossEntropy for training. Also, when I use the pre-trained weights the accuracy seems to increase and work fine. Please suggest how I can rectify this issue. Thanks.

&amp;#x200B;

Edit: 

Code Link: [https://colab.research.google.com/drive/1MJ5sBuUeirh1XQTshZi1amw\_j5cZ0syV?usp=sharing](https://colab.research.google.com/drive/1MJ5sBuUeirh1XQTshZi1amw_j5cZ0syV?usp=sharing)",7,deeplearning,2020-10-13
j7drox,The problem when writing paper,"I have solved a problem with deep learning (CycleGAN + Pix2Pix + some preprocessing techniques) and I'm writing a paper about it. I know it needs a section that describes some advantages / higher accuracies with another paper or solution. The disadvantage I am facing is that my problem belongs to a narrow discipline and no one seems to have touched it. When building the model, I had to create the dataset myself when I couldn't find any available sources. How do I have to solve it?",11,deeplearning,2020-10-13
j7d6bd,Supreme Commander: Forged Alliance - All Cinematics (Remastered 8K 60FPS) Resolution increased using neural networks to 8K 60FPS,,1,deeplearning,2020-10-13
j7anng,Solving Web Accessibility with AI,,4,deeplearning,2020-10-13
j7a1rx,Laptop Suggestion for a beginner in Deep Learning and Computer and Computer Vision,"Hi everyone, 

I am currently looking to buy a laptop (in India) majorly for personal use and Deep learning tasks. I am currently a beginner in Deep Learning for Computer Vision (been learning it for the past 4 months) and I plan on pursuing it further as a career and it would be great if you could help me in figuring out one. After doing a fair bit of research, I have narrowed it down to these specifications and available options under 1100 USD:

**RAM:** 8GB or more

**Storage:** 512 SSD or 1TB HDD+128/256GB SSD

**CPU:** Intel i5/i7

**Graphics Card:** 4GB NVIDIA GTX 1050/1660Ti (I am a complete noob when it comes to select which GPU  is better and which one to choose in this case)

**Available options as of now:** HP Omen 15 2020 Model, Lenovo Legion 5i, Dell G3.

I prefer one with a bigger battery life and all of the mentioned above ones have mixed reviews online. I hope I could use some of your help. Kindly do suggest if there are any other options in the mentioned price range.

&amp;#x200B;

Thank you!",5,deeplearning,2020-10-13
j7941f,Thesis Suggestion in Deep Learning,"
Please suggest me some thesis ideas in the domain of deep learning.",0,deeplearning,2020-10-13
j77790,How Do I Start Learning Deep Learning?,,0,deeplearning,2020-10-13
j6z32g,Addinng an lstm decreases model performance,"So extending an image segmentation model to the task of video by adding an LSTM decreases the model performance. What could be possible reasons for this? 
Some details/possible reasons I've sort of ruled out:
1. mIoU drops a good 10% over training just the same architecture on the same inputs for image level sequences.
2. Already played around with learning rate, weight decay, lstm position( after the encoder/before the softmax). This is probably not the issue?

Any guesses/hidden secrets to training lstms that could help?",6,deeplearning,2020-10-13
j6tdlw,"A new way to discover top trending papers in Deep Learning, ML and CS.",,41,deeplearning,2020-10-13
j6rur5,Retrieval-Augmented Generation Explained!,[https://youtu.be/dzChvuZI6D4](https://youtu.be/dzChvuZI6D4),1,deeplearning,2020-10-13
j6nvba,[R] Explaining Deep Neural Networks,"**Abstract**:  Deep neural networks are becoming more and more popular due to their revolutionary success in diverse areas, such as computer vision, natural language processing, and speech recognition. However, the decision-making processes of these models are generally not interpretable to users. In various domains, such as healthcare, finance, or law, it is critical to know the reasons behind a decision made by an artificial intelligence system. Therefore, several directions for explaining neural models have recently been explored.

  
In this thesis, a researcher with Oxford University investigates two major directions for explaining deep neural networks. The first direction consists of feature-based post-hoc explanatory methods, that is, methods that aim to explain an already trained and fixed model (post-hoc), and that provide explanations in terms of input features, such as tokens for text and superpixels for images (feature-based). The second direction consists of self-explanatory neural models that generate natural language explanations, that is, models that have a built-in module that generates explanations for the predictions of the model. 

Full paper:  [https://arxiv.org/pdf/2010.01496v1.pdf](https://arxiv.org/pdf/2010.01496v1.pdf)",2,deeplearning,2020-10-13
j6lkrd,NVIDIA Releases Imaginaire: A Universal PyTorch Library Designed For Various GAN-Based Tasks And Methods,"NVIDIA has developed a universal PyTorch library, **Imaginaire,** with an optimized implementation of various GAN images and video synthesis. 

The **Imaginaire** library currently covers three types of models, providing tutorials for each of them:

* Supervised Image-to-image translation
* Unsupervised Image-to-image translation
* Video-to-video translation 

Summary: https://www.marktechpost.com/2020/10/06/nvidia-releases-imaginaire-a-universal-pytorch-library-designed-for-various-gan-based-tasks-and-methods/

Github: [https://github.com/NVlabs/imaginaire#supervised-image-to-image-translation](https://github.com/NVlabs/imaginaire#supervised-image-to-image-translation)

&amp;#x200B;

https://i.redd.it/99wdtefy3mr51.gif",59,deeplearning,2020-10-13
j6j9zc,Wanting to contribute to projects or research,"Hi everyone, I hope you're safe and healthy.

I recently graduated and I worked on deep learning for my graduation project (arrhythmia classification using raw ECG signal and LSTM) And it was fun. I would like to continue on the domain of ML/DL and since borders are closed on my country (no AI related jobs here) I have plenty of time  before I start applying for jobs.

So if you have any projects or research you need help with or you know any great open source project that I can contribute to, please let me know. Thanks in advance 😊.",1,deeplearning,2020-10-13
j6g2cj,How to make model train faster?,"I have been working on a CNN brain tumor image classifier, and my model is taking a disgusting amount of time to train. My train set has about 2000 images and 400 for validation, and 300 for testing. I have 3 layers of convolutions, followed each by a max pool with a filter size of 3. And my batch size is 150 followed by the number of epochs being 80. Does anyone know what I can do to allow it to train faster?",7,deeplearning,2020-10-13
j6ff3b,Latest from Microsoft and Samsung researchers: State of the art in Face Attribute Editing with GANs,,1,deeplearning,2020-10-13
j6cxo3,"Blob Detection Using OpenCV ( Python, C++ )","In today's post, we will discuss a kind of detector that helps us where even edge detectors or corner detectors might fail. We will discuss a simple (literally!) Blob detector example.  


Dive in to [https://www.learnopencv.com/blob-detection-using-opencv-python-c/](https://www.learnopencv.com/blob-detection-using-opencv-python-c/) for more details and both the CPP and Python code!

https://i.redd.it/ujvko3ewajr51.gif",1,deeplearning,2020-10-13
j68z87,Top 10 Machine Learning Courses(Theory and Practical in 2020),,6,deeplearning,2020-10-13
j68320,"I just graduated college and I am fascinated with the recent findings in GANs. I have no coding background, where should I start if I wanted to go headfirst into deep learning?","Hey guys,

Sorry about the newbie question. I love this stuff. I'm studying Social with Math but I will graduate and be eligable to apply for computer science next semester. I was going to begin Andrew NGs online Python class for a head start. I am interested in learning.

Does anyone have any suggestions on how I could optimize my route with respect to learning GAN, and generating interesting animation, digital effects and musical products from data? I am a UK House Producer with 6+ years of experience in sound design and production engineering. Cheers.",1,deeplearning,2020-10-13
j67ssh,A Simple Neural Network Upgrade Boosts AI Performance,,1,deeplearning,2020-10-13
j67r95,Does this mean my model is overfitting!? FYI - I'm trying to make a text generator using LSTM RNN.,,34,deeplearning,2020-10-13
j66m30,RMSprop or Adam?,"I have a problem where I've found that RMSprop optimises but Adam does not - Adam just stays around the starting loss. For the record, I am using quite a high lr (0.01). Does Adam generally require a smaller lr than RMSprop? 

Can anyone provide an explanation for why this might be the case?",2,deeplearning,2020-10-13
j65h41,Style transfer is an interesting problem in machine learning where one image's style is imposed on another. This concept can be pushed even further to work on videos as well.,,0,deeplearning,2020-10-13
j62a1l,Inventing Virtual Meetings of Tomorrow with NVIDIA AI Research,"[https://www.youtube.com/watch?v=NqmMnjJ6GEg](https://www.youtube.com/watch?v=NqmMnjJ6GEg)

Epic work by Nvidia for compressing video calls 😍 

the idea of sending a single keyframe then sending keypoints and using a GAN to reconstruct the subsequent frames is really elegant! 

The face alignment feature is also great - it always feels a little weird when people are looking behind you during a video call 😅",2,deeplearning,2020-10-13
j5x9nb,Training A Neural Network To Write Eminem Lyrics,,2,deeplearning,2020-10-13
j5vebc,Intel vs AMD CPU for Deep Learning?,,3,deeplearning,2020-10-13
j5va2k,Possible to get a job with only a BSc as a deep learning engineer?,"Hi all,

I've really fallen for deep learning since graduating with a BSc in mathematics but have never had a job in data/ML. I am studying to become an actuary out of neccessity, but my heart is just not in. Is it possible to get a job in deep learning with only a BSc? I have three projects on my github of applying DL to kaggle competitions, but no one ever calls me back for an interview. What more can I do? Playing around with models on data sets is my passion that I wish could turn into my day time job.",4,deeplearning,2020-10-13
j5ttvg,How can I apply reinforcement learning in a Javascript environment?,"Hi everyone! I'm working on a project about creating an agent that plays a Mortal Kombat game written in Javascript. 
My problem is that I want to train a deep learning model in Google Colab (Python + tensorflow) so my first idea is to ""migrate"" the project from JS to Python to train the model in a ""similar"" game environment, but surely there are better solutions, any advice?

Thank You!",0,deeplearning,2020-10-13
j5ra9g,[R] Google AI Helps Sign Language ‘Take the Floor’ in Video Conferences,"To enable signers to “take the floor” in such video meetings, a team of researchers from Google, Bar-Ilan University, and the University of Zurich recently developed a sign language detection model for video conferencing applications that can perform real-time identification of a person signing as an active speaker.

Here is a quick read: [Google AI Helps Sign Language ‘Take the Floor’ in Video Conferences](https://syncedreview.com/2020/10/05/google-ai-helps-sign-language-take-the-floor-in-video-conferences/)

Google AI has open-sourced the training code and models for [web demo](https://sign-language-detector.web.app/) on [GitHub](https://github.com/AmitMY/sign-language-detector). The paper Real-Time Sign Language Detection using Human Pose Estimation is available on the Google Research [website](https://research.google/pubs/pub49425/). The model will be presented at [SLRTP2020](https://www.slrtp.com/) and demoed at [ECCV2020](https://eccv2020.eu/).",0,deeplearning,2020-10-13
j5np4f,Convolutional Neural Network Champions — Part 2: AlexNet (TensorFlow 2.x + Python),"Hello All,

Part 2 of my article on Convolutional Neural Networks is published on Medium (link: [https://towardsdatascience.com/convolutional-neural-network-champions-part-2-alexnet-tensorflow-2-x-de7e0076f3ff](https://towardsdatascience.com/convolutional-neural-network-champions-part-2-alexnet-tensorflow-2-x-de7e0076f3ff) ). This section is dedicated to AlexNet with reproducible result in Tensorflow 2.0 and Python.

Cheers",2,deeplearning,2020-10-13
j5n787,GANs,,290,deeplearning,2020-10-13
j5n0kf,Pied Piper Compression,,0,deeplearning,2020-10-13
j5lwwr,What is the easiest software to create deepfakes for beginners,"So I want to learn how to create deepfakes but deeplab is hard for me
So can anyone suggest a software that is easy
And not complicated and a bit realistic",0,deeplearning,2020-10-13
j5imvv,Going faster than TensorFlow with Clojure,,3,deeplearning,2020-10-13
j5icny,"A complete guide on how to start learning deep learning in 2020. Without any background in the field, and for free.",,16,deeplearning,2020-10-13
j5hcdy,Knowledge Transfer in Self Supervised Learning,,0,deeplearning,2020-10-13
j5gn81,Top Papers from the Premier European ML Conference ECML-PKDD,"It's time to update your reading lists.

Recently participated in ECML-PKDD conference (**top European ML and data mining venue**). It was very diverse on topics with both research and applied tracks.

Thought it would be useful to update reading list not only for myself.

To make searching/skimming easy, lists are divided into **two groups: ""Applied Data Science"" and ""Research"".** I followed the conference theme regarding topics.

Below are selected papers for sample topics (conference featured 20+ topics!):

**Research track**

Transfer and multi-task learning

* Graph Diffusion Wasserstein Distances
* Towards Interpretable Multi Task Learning using bi-level programming

Graph neural networks

* A Self-Attention Network based Node Embedding Model
* GRAM-SMOT: Top-N Personalized Bundle Recommendation via Graph Attention Mechanism and Sub-Modular Optimization

NLP

* Early Detection of Fake News with Multi-Source Weak Social Supervision

CV / image processing

* Information-Bottleneck Approach to Salient Region Discovery

**Applied Data Science track**

Advertisement

* Think out of the package: Recommending package types for e-commerce shipments
* Social Influence Attentive Neural Network for Friend-Enhanced Recommendation

Transportation

* Automation of Leasing Vehicle Return Assessment Using Deep Learning Models

Anomaly detection

* Self-Supervised Log Parsing

Web mining

* Neural User Embedding From Browsing Events

Much more topics are covered in the articles w/ links to slideslive and papers. Hope this is helpful!

[Research Papers](https://neptune.ai/blog/ecml-pkdd-2020-research?utm_source=reddit&amp;utm_medium=post&amp;utm_campaign=blog-ecml-pkdd-2020-research)

[Applied Data Science](https://neptune.ai/blog/ecml-pkdd-2020-applied-data-science?utm_source=reddit&amp;utm_medium=post&amp;utm_campaign=blog-ecml-pkdd-2020-applied-data-science)",2,deeplearning,2020-10-13
j5gml8,[Research] Exploring target driven image classification,,1,deeplearning,2020-10-13
j5f3c0,Back to Machine Learning Basics - Clustering,,0,deeplearning,2020-10-13
j5ehuo,Bringing Old Photos Back to life in just a second using google colab step by step tutorial,,10,deeplearning,2020-10-13
j5deli,Advantages of CNN over K-nearest neighbors algorithm for image recognition?,"I know why KNN might not be feasible here, but why are CNNs so popular for image recognition?",3,deeplearning,2020-10-13
j5dahl,How to decide the values of hidden_dim and n_layers for LSTMs in Pytorch?,"I started learning and implementing LSTMs using [this tutorial](https://www.google.co.in/amp/s/blog.floydhub.com/long-short-term-memory-from-zero-to-hero-with-pytorch/amp/)

How do we decide the values for the parameters of nn.LSTM()?",2,deeplearning,2020-10-13
j5aowx,Supreme Commander - All Cinematics (Remastered 8K 60FPS) Resolution increased using neural networks to 8K 60FPS,,0,deeplearning,2020-10-13
j5adzo,Did any body try one if these? Do they worth the cost vs the usefulness?,,4,deeplearning,2020-10-13
j56pke,[Project] VOC Formatted Dataset Generation for DL Frameworks,,1,deeplearning,2020-10-13
j55g1l,Deep learning for computer vision,"I wanted to learn computer vision with deep learning but before that I want to learn deep learning, I have to start from the beginning. So can anyone please help me with this, where do I start learning. Is there any good source for absolute beginners.

Thank you :)",0,deeplearning,2020-10-13
j549ut,Poker + AI + AR,,47,deeplearning,2020-10-13
j53s7v,Building a DL machine: CUDA 11 or downgrade to 10.1? (on Ubuntu 18.04),"Edit: **Ubuntu 20.04**, not 18.04.

I'm setting up a machine for training networks. I'm interested in building a system that matches 'popular usage' as closely as possible.

Many tutorials seem to be split between using Conda to handle the environment vs. setting it up manually. The reasoning for choosing to set up the environment manually is unclear to me. Can anyone comment on  why they prefer not to use Conda?

Also: it appears that we're in an awkward time between releases. My Ubuntu machine has nvidia 450.66 as the driver, and CUDA version 11.0, which seems to require PyTorch to be compiled from source. Most guides seem to recommend downgrading to CUDA 10.1 but I'm wondering if this will cause future headaches, for example Ubuntu may try to auto-upgrade and bring me back to 11. I don't want to have to fight with the Ubuntu package manager any more than I have to.

So - what's the popular approach here? Compile against CUDA 11 or downgrade to 10.1?",1,deeplearning,2020-10-13
j52rdx,Educational Robot,Hi guys! Our team has made such an educational robot. We will soon make training courses for him. And we want to release it on Product Hunt. Does someone know a top hunter who is ready to place our project on Product Hunt? We will give a 70% discount on the robot for this. [https://turtlebro.com](https://turtlebro.com),0,deeplearning,2020-10-13
j52awj,Adversarial sticker proposal,"Hi,

Im generally interested if there is already an algorithm/model that can propose adversarial stickers(where to put them on an image, with what size)  based on supervised data aka already generated adversarial sticker samples. I have a few idea on wherw to go, but would be intrested if any of you have stumbled across the same problem, and can give me some sources to study on the topic.

Cheers",2,deeplearning,2020-10-13
j4ykk7,Anyone deployed Detectron2 in AWS?,"Hi! First time posting here, I'm a bit sad is just to ask a question thought! 

I'm currently trying to deploy a custom trained Detectron2 model in AWS. I've a local docker container that serves the model as a flask api endpoint which already works. 

I tried to deploy this docker container into Amazon Elastic Beanstalk, it does deploy and the environment is created without any issues, but when trying to reach the endpoint at the given URL and port the response fails due to a timeout. 

The model is running on CPU, so it's true that in my local laptop it takes about 12 secs to predict. 

Any suggestions, tips, options?  I would greatly appreciate any advice!",1,deeplearning,2020-10-13
j4xnxj,You don't have money $ to buy a fancy deep learning PC? Here is how you should start.,,0,deeplearning,2020-10-13
j4wad3,Python library to classify dialogue tag.,"Hi folks,

I made a dialogue text classification library in python as part of my side project. I started with NLP a few weeks back and decided to make something so as to get some practical knowledge about NLP. The learning curve was really great.

Since I'm still a novice in this field, I'm looking for some feedback, opinions about how this library is and how can I improve it further. Any help would be appreciated. Thanks!

Github link: [https://github.com/bhavitvyamalik/DialogTag](https://github.com/bhavitvyamalik/DialogTag)",4,deeplearning,2020-10-13
j4w2p1,Where to begin 3D deep learning from?,"Greetings,

Im in interested in 3d deep learning but don't know where to start.
I'm fairly good at simple deep learning (at least I think so)

Any recommendations where to start from

Thanks.",6,deeplearning,2020-10-13
j4v9rh,Can you recommend a capture card that's compatible with Ubuntu and provides API/SDK to access frames/buffer etc.?,"I'd like to be able to do real-time inference on the frames of an iPad Pro screen. I don't want to build an app and run the inference on the iPad itself, because I want to have the full power of a PC to be able to manipulate the frame and run multiple inferences per frame etc.

&amp;#x200B;

Can you recommend a capture card that is compatible with Ubuntu and is developer-friendly?",3,deeplearning,2020-10-13
j4ulw3,Is there some good course on Coursera or any other platform that uses Pytorch ? I was able to find all courses had only Tensorfloow/Keras in them.,"Although I did the [deeplearning.ai](https://deeplearning.ai)'s specialisation, I do not feel very confident over the skills. I feel like having the knowledge, but get stuck while building projects. I feel building more projects might help on this, but  wasn't able to find some resources on Pytorch.",24,deeplearning,2020-10-13
j4p0f6,"Latest from USC researchers: Given a single neutral scan, researchers generate a complete set of dynamic face model assets, including personalized blendshapes and physically-based dynamic facial skin textures of the input individual!",,0,deeplearning,2020-10-13
j4kuun,How to Speed Up Deep Learning Inference Using OpenVINO Toolkit,"Imagine you have trained an awesome neural network model using PyTorch and now want to use it for inference. You don't have the same computational power as you had during training and re-architecting and rewriting source code is not a feasible solution for speeding up inference. Fortunately, this is all possible using the Inference Engine provided Intel's OpenVINO Toolkit. 

In many cases, you get a considerable performance increase without hugely scarifying the inference accuracy. Additionally, the model conversion procedure is simple and fast.

In today's post, we walk you through the process step by step with code. **In our example, we have accelerated the inference step by approximately 2.2 times!** Click on the link below for a detailed tutorial with code

[How to speed up Deep Learning Inference Using OpenVINO Toolkit](https://click.convertkit-mail.com/5qukmnm54ks7h3x6xzc6/g3hnh5hzvqwrkmsr/aHR0cHM6Ly9vcGVuY3Yub3JnL2hvdy10by1zcGVlZC11cC1kZWVwLWxlYXJuaW5nLWluZmVyZW5jZS11c2luZy1vcGVudmluby10b29sa2l0LTIv)

https://preview.redd.it/wu6wsmteixq51.jpg?width=256&amp;format=pjpg&amp;auto=webp&amp;s=2c423cf09f415b613ae439bba7aa6b046c33093b",1,deeplearning,2020-10-13
j4isza,Pitfalls of using Google Colab for Data Collection,,5,deeplearning,2020-10-13
j4gwnf,Id like to get into GANs,"I have some experience with machine learning and i know how deep learning works , im really interested in GANs , can anyone please help me find something beginner friendly so i could get started.

 Thanks in advance :)",1,deeplearning,2020-10-13
j4f7da,This computer vision algorithm removes the water from underwater images!,,40,deeplearning,2020-10-13
j4ei3j,How 2 or more keras model outputs can be integrated?,"Hello, I've been thinking if I were to build multiple keras models that have different objectives, I will illustrate with an example to explain what I mean. Let's assume the main objective is to predict the price for a stock sign, let's say there will be 2 models, the first model is for sentiment analysis and its main objective is to process news articles and predict whether the stock price will go up or down. The second model would be an LSTM that predicts the next period (which can be a minute, a day, a month ...) price. Let's say I want the LSTM model to consider as well the outcome of sentiment analysis and possibly the output of other models that predict different metrics in the same fashion, is this possible? and how is it usually done? I think the same logic might apply on many other examples (recommender systems, retail inventory prediction ...)",1,deeplearning,2020-10-13
j42da6,Tips and methods to diagnose StyleganV2 training,"I'm trying to train using the StyleganV2, but I'm having a hard time being able to interpret the training.

I'm looking if there are resources or rules that allow me to diagnose the status of the training through the plots or the generated images, but I can't find many references. As well as not finding a great description of the training parameters of the StyleganV2.

For example, I am currently in the following situation:

&amp;#x200B;

[Training curves of StyleganV2](https://preview.redd.it/yefmvwe9qqq51.png?width=1395&amp;format=png&amp;auto=webp&amp;s=5c2047b17238f09e7bd0e954c66bd0c1ae9436c5)

In my case, I spent a few days training and I think the discriminator is learning his job much better than  the generator (although the FID keeps going down). Losing the balance, to make the discriminator learn slower than the generator or, on the contrary, the generator more efficient, the following occurs to me:

* Lower the RL in both in case the noise is affecting the training and in a higher way to the generator.
* Lower the RL only to the discriminator.
* Do N steps of the generator for each step of the discriminator.

Can someone give me some tips or ideas to know How to act in certain cases? As well as the one I currently have? 

It would be very helpful, thank you.",14,deeplearning,2020-10-13
j40byg,Working with Mediapipe’s pre-made Calculators in their Hand Tracking example. A guide for those with an intermediate knowledge of Mediapipe.,,9,deeplearning,2020-10-13
j3tlsz,"Are the eternal compatability issues with CUDA, CUDNN, NVIDIA drivers etc. with different (new) releases of tensorflow/keras a good reason for switcing to pytorch.",Basically as the title says. I'm getting tired of running in to these issues again and again? Is it the same with pytorch?,24,deeplearning,2020-10-13
j3q6j6,Tensorflow object detection API,"Can someone shed some light on the following parameters:

1. fine\_tune\_checkpoint

2. fine\_tune\_checkpoint\_type

3. from\_detection\_checkpoint

4. load\_all\_detection\_checkpoint\_vars

I'm trying to train a model on [http://download.tensorflow.org/models/object\_detection/ssd\_mobilenet\_v3\_large\_coco\_2020\_01\_14.tar.gz](http://download.tensorflow.org/models/object_detection/ssd_mobilenet_v3_large_coco_2020_01_14.tar.gz)",4,deeplearning,2020-10-13
j3ia72,Implemented the linear algebra in Deep Learning by Goodfellow,"I implemented the linear algebra in the book Deep Learning by Goodfellow.

It may help you understand the book by creating matrices and vectors and applying operators.

Operators include:

\- get-norm

\- multiplying-matrices

\- transpose(of two matrices)

\- combination(linear combination).

Here is the [github repo](https://github.com/Jobhdez/Linear-algebra-interpreter/blob/master/interp-linear.rkt).",0,deeplearning,2020-10-13
j3fle0,The first CI workflow (that I know of) for Data Pipelines available directly from PRs on GitHub using Great Expectations in Github Actions,[https://twitter.com/HamelHusain/status/1311699555243552769?s=20](https://twitter.com/HamelHusain/status/1311699555243552769?s=20),0,deeplearning,2020-10-13
j3em4v,[R] EvolGAN Boosts Image Quality for Small or Difficult Datasets,"GAN models however require massive amounts of training data to reach decent performance. In an effort to make GANs more effective and reliable when only small, difficult, or multimodal datasets are available, a group of researchers from Facebook AI, University of the Littoral Opal Coast, University of Grenoble and University of Konstanz have proposed Evolutionary Generative Adversarial Networks (EvolGAN).

Here is a quick read: [EvolGAN Boosts Image Quality for Small or Difficult Datasets](https://syncedreview.com/2020/10/01/evolgan-boosts-image-quality-for-small-or-difficult-datasets/)

The paper *EvolGAN: Evolutionary Generative Adversarial Networks* is on [arXiv](https://arxiv.org/pdf/2009.13311.pdf).",2,deeplearning,2020-10-13
j3drd8,Archai from Microsoft Research can design your neural network with state-of-the-art neural architecture search (NAS),,6,deeplearning,2020-10-13
j3cgun,Development in General Adversarial Networks (GANs) has showed us the possibility for AI to take inspiration from some data to make something new.,,18,deeplearning,2020-10-13
j331xa,Bag of Tricks for Image Classification,"What do you do when your image classification model fails to produce the results you want?  


Today, we are going to learn a bag of tricks you can use to improve the accuracy of your network. Here is what you will learn.  


Trick #1: Large Batch Training  
Trick #2: LR Warm-up  
Trick #3: Mixed Precision operations  
Trick #4: Cosine LR Decay  
Trick #5: Label Smoothing  
Trick #6: Knowledge Distillation  
Trick #7: Mix-up Augmentation 

[https://www.learnopencv.com/bag-of-tricks-for-image-classification/](https://www.learnopencv.com/bag-of-tricks-for-image-classification/)

https://preview.redd.it/79f7khkgcfq51.jpg?width=600&amp;format=pjpg&amp;auto=webp&amp;s=aff48b7e87359a1c05d6a4302f294094695a24c5",2,deeplearning,2020-10-13
j32efv,Creating Calculators in Mediapipe — Beyond The Documentation,,8,deeplearning,2020-10-13
j31vy4,Propagate the style from a few selected keyframes to the rest of the sequence!,,1,deeplearning,2020-10-13
j2zzs8,Sonnet (2.0),Has anybody here used sonnet 2.0. How does it compare with keras.,2,deeplearning,2020-10-13
j2twsf,Build Your Own Artificial Neural Network. It’s Easy!,,0,deeplearning,2020-10-13
j2s82z,Google Colab Drive Quota exceeded,"Hi all,

I don't know if this is the best sub to ask this question, so please direct me if you know a better place to ask this question.

I am running a segmentation model using Keras. My images and masks are stored as \`\`\`np.memmap\`\`\` with dtype uint8. I load them using a batch generator function that converts the dtype to float16 and yields batches to model.fit(). When approximately 650 images have been read, I get the message that ""Google Drive quota has exceeded"" and the run time crashes abruptly.

Is there another way I can convert dtype on the fly without exceeding the Drive Quota? Can I shift the memmap from Drive to the Colab's VM disk, so that Colab doesn't have to access drive so much?

Thanks.",2,deeplearning,2020-10-13
j2rde3,"Joint demo of Swaayatt's DGN-I and LDG algorithms. Again, fastest in the world, in either individual or joint operation modes, for #autonomousdriving perception. Computations: - DGN-I: 15 GFlops - LDG: 12.5 GFlops - Joint (merged in one network): 17.5 GFlops",,25,deeplearning,2020-10-13
j2nutb,Identifying GAN Generated Images,"**Paper:**  [Detection, Attribution and Localization of GAN Generated Images](https://arxiv.org/pdf/2007.10466.pdf)

**Basic Idea:** Pixel Statistics of GAN generated images are different from those of natural images. A network is trained on pixel co-occurrence matrices generated from images of 5 GANs.

**Some results:**

[Localization Heatmaps](https://preview.redd.it/gypyvj17iaq51.png?width=1170&amp;format=png&amp;auto=webp&amp;s=8bfb3ee4ef1e34e0bb2e2adf94bca39b622be3b8)

&amp;#x200B;

[t-SNE Visualization on 6 classes \(5 GANs and 1 Non-GAN\)](https://preview.redd.it/hnuqwpfuuaq51.png?width=800&amp;format=png&amp;auto=webp&amp;s=7a0f0c00a69e3b0acb9a37d7908a319c11f31d10)",3,deeplearning,2020-10-13
j2nda3,ONNX in the wild,is anyone using ONNX in deployment? Most of the people I know use tensorflow for production but I mostly dwell in pytorch for research. has anyone developed a model in torch and ran it for production? through ONNX?,18,deeplearning,2020-10-13
j2mxsz,Run Neural Networks on GPU Phones,"I've developed and launched Neural Networks using Core ML on iOS devices a few years back.  I don't know much about the GPU processors, and looks like they've even been getting better.

If I was looking to buy bulk unlocked devices, would iPhone or Android be better bet?  I'm looking to do video stream classification.  

Looks like iPhone X unlocks can buy around $500, but wondering if better options out there.  Or even better processors that make sense for this.",0,deeplearning,2020-10-13
j2mm8q,DL to cursive handwritting in historical documents,"Hi,  I have a historian friend working on a project on the restoration of historical documents of Brazilian colonial period. Those documents are quite old and I have basic knowledge of deep learning but haven't jumped into characters recognition. After browsing online, I realized that there are some real challenges to overcome to get a working model for so old cursive and somewhat alien writting.   
Do you have any resource that could me put in the right direction to learn this? Thanks!",0,deeplearning,2020-10-13
j2kx4k,Deep Learning to Diagnose Dystonia in Milliseconds,,6,deeplearning,2020-10-13
j2kl3b,"Want to get started with Deep Learning? In this tutorial by OdinSchool, you will learn more about what is deep learning, libraries, and tools used in deep learning, and more about Keras as well as Tensorflow.",,1,deeplearning,2020-10-13
j2jtzm,"The YOLOv4 algorithm: Introduction to You Only Look Once, version 4. Real-Time Object Detection. What do you think about re-using the ""YOLO"" trademark from different authors?",,1,deeplearning,2020-10-13
j2g9st,Extractive &amp; Abstractive Summarization with Transformer Language Models | Research Paper Walkthrough,,12,deeplearning,2020-10-13
j2fx69,Signal to signal processing,,1,deeplearning,2020-10-13
j28o0h,How can I see the accuracy of a model?,"**history =** [**model.fit**](https://model.fit)**(X\_train, y\_train,epochs=50, validation\_data=(X\_test, y\_test))**

For example with that line, I know that the results are stored in ""history"" and that I can access each of the accuracies obtained in each epoch. How can I get the ""final"" accuracy of my model? For example say that my model after having been trained for 50 epochs obtained an accuracy of 98%. 

Can I just take all the accuracies and calculate the average? or is there some other way to do it? Something like this:

**acc\_train = history.history\['accuracy'\]**

**np.mean(acc\_train) # acc\_train = 0.9935808491706848** 

&amp;#x200B;

Thank you !",5,deeplearning,2020-10-13
j27697,Does anyone here work in healthcare? How are you using deep learning?,I am trying to learn more applications.,1,deeplearning,2020-10-13
j25i16,Facebook scraping,"I am looking for Facebook scraping for learning, need tutorial links or assistance.

[Datasmartness](https://datasmartness.com)",0,deeplearning,2020-10-13
j257mz,DL project,"Although I have a decent amount of knowledge of ML, i am extremely new to DL (especially CNNs and their practical implementations). My college expects me to make a project and submit it very soon. For that I have chosen the topic ""Live video feed object detection"". Comind to the real doubt, could anyone here please guide me as to how do i go about it ? I found an implementation on GitHub but im struggling to keep up with whats going on there ! Thank you",1,deeplearning,2020-10-13
j21vnv,[News] Introducing ML News (mln.dev),"[ML News](https://mln.dev/top/1) (MLN for short) is a community for sharing and discussing all things related to machine learning, deep learning, AI, data science, and the like. (You can join now using the code ***convergence***).

Inspired by Hacker News, Lobste.rs, Reddit, and the original Slashdot, we decided to create a dedicated place for experts and enthusiasts to engage in open learning, discussion, and occasional whimsy.

There are many different channels for tech-related news. In our experience, these are often flooded with not-so-relevant posts which somehow fall under the ""tech"" umbrella. We've had a longstanding habit of sharing interesting ML-related articles and field-defining research with friends and peers, and know that we are by far not the only ones. That's why we decided to build a community dedicated to the field of ML. We hope that by narrowing the scope, we can build a space where ML people like ourselves can easily find interesting news, breakthroughs, and updates in the field, or essentially anything which could pique our interest.

From ML experts to AI enthusiasts, this is a community that values honest debate, curiosity, positivity, and good humor. Please help us maintain these core values as the community grows.

[Join the community](https://mln.dev/) using the code ***convergence***.",1,deeplearning,2020-10-13
j1y86h,How To - Ditching Ubuntu in favor of Arch Linux for a Deep Learning Workstation,"Hey guys, I wrote about my experiences with Arch as a Deep Learning workstation on my blog, and I really love it compared to the ""classic"" Ubuntu setup. Curious about your thoughts, and the OS you are using!

[https://www.datafortress.cloud/blog/howto-arch-linux-deeplearning-workstation/](https://www.datafortress.cloud/blog/howto-arch-linux-deeplearning-workstation/)

**Abstract**

## Why should I ditch Ubuntu?

Most of you might be using Ubuntu for their workstations, and that is fine for the more inexperienced users. One of the issues I had with Ubuntu and the Tensorflow/CUDA though, has been that handling the different drivers and versions of CUDA, cudnn, TensorFlow, and so on has been quite a struggle. I’m not sure about you, but once I had a working Tensorflow 1.15 or 2.0 environment, I usually did not touch it anymore being scared to mess up this holy configuration.

Working with different programs it would be nice to have a way of switching between the two most used TensorFlow versions of 1.15 and 2.0 like you can do with Google Colab in a single command, but installing a different TensorFlow version usually messed up my system again.

Additionally, Arch has always been on my To-Do list, as it is the most “barebone” Linux distro you can get, meaning you are working way closer on the hardware compared to “higher abstractions” like Ubuntu. In their own words, Ubuntu is built to “work out of the box and make the installation process as easy as possible for new users”, whilst the motto of Arch Linux is “customize everything”. Being way closer to the hardware Arch is insanely faster compared to Ubuntu (and miles ahead of Windows), for the cost of more Terminal usage.

When I have been using Arch in the past weeks, RAM usage usually halved compared to Ubuntu, and installing Machine Learning packages is a breeze. I can have both TensorFlow 1.15 and 2.0 working together, switching the versions with Anaconda environments. Also, the system works quite stable, as I am using the LTS (long term support) kernels of Linux, and usually updates to the famous AUR (user-made packages in Arch) are coming out a month ahead of the Debian (Ubuntu) packages.

All in all, I can only recommend setting up an Arch Linux Deep Learning station as it is:

1. Faster, like packages will install super fast, deep learning is supercharged, …
2. More stable
3. Easier to switch between TensorFlow versions compared to Ubuntu.

I will split the how-to in two parts, the first one being “How to I install Arch Linux” and the second one being “How to install the Deep Learning workstation packages”.",10,deeplearning,2020-10-13
j1x3d0,Deep Learning in Clojure with Fewer Parentheses than Keras and Python,,4,deeplearning,2020-10-13
j1wsud,[100% OFF] Machine Learning &amp; Deep Learning in Python &amp; R - United Academy,,3,deeplearning,2020-10-13
j1wboy,Interesting phenomenon about the size of training dataset,"Hi,

I have a project to recognize captcha codes with a CNN model. The captcha is 8 characters of the combination of number and alphabets. I have a training dataset about 50k samples. If I feed the model with all the records in the dataset, the model finally converge to a point that it actually remembers the possibility of the appearance of every character on each position. For example, if 'e' appears mostly at the first position in the training dataset, the model just predicates 'e' for the first character for any input. That means it always predicates a fixed result for any testing data.

But if I feed the data gradually to the model, the test result is quite reasonable and acceptable. What I do is like this:

1. Feed the model with 100 samples, train the model until the error is small enough
2. Feed another 100 samples, train the model with all 200 samples  until the error is small enough
3. Feed another 200 samples, train the model with all 400 samples  until the error is small enough
4. Do the same until all the samples are used.

The result is quite good with the approach above. But I don't understand what happened behind this. Why couldn't I just feed all the samples at once. Anyone can explain this?",1,deeplearning,2020-10-13
j1w3mj,Learn CNNs Free - LIVE and Online with Harvard faculty,"Learn Convolutional Neural Networks LIVE online with Harvard's Dr. Protopapas - FREE. The program begins November 3, 2020 and acceptance is through a test. Applications are open till October 20, 2020. Program pre-requisites are basic knowledge of Python programming and Machine Learning  (Regression and Classification)

Apply at [https://univ.ai/learn-cnns-free](https://univ.ai/learn-cnns-free)",1,deeplearning,2020-10-13
j1vzny,Need help with a problem,"Hello everyone,

I have lurked on this sub for quite some time abs absorbed so much knowledge. I thank you all for that. I am fairly new to deep learning and I am working on a project and needed some direction as I feel stuck.

I am working on meta learning / transfer learning for making performance predictions. For that I am looking g at the final validation accuracy as a simple metric. (I know we can also use more complicated metrics but since this is my first project in this area I'd like to go easy) The data was generated by running funnel shaped mlps on 6 different datasets/tasks 2000 times each and the following metrics were logged.

1. Epoch wise training, validation and test losses + accuracy (time series data) 
2. Learning rates, batch sizes,  momentum, weight decay, number of units per layer and number of layers.
3. I also have the meta features of each of the six data sets.

My source of confusion is that there are these different types of data which I wish to use to make an accurate predictor of performance but I am not sure how. Can someone please point me in the right direction.",6,deeplearning,2020-10-13
j1rhjn,Deep Learning &amp; How It's Work - Every Thing You Should Know,"# What is Deep Learning

Deep Learning is a machine learning technique that constructs artificial neural networks to mimic the structure and function of the human brain. In practice, deep learning, also called deep structured learning or hierarchical learning, uses a huge number of hidden layers -typically more than 6 but often much higher - of nonlinear processing to extract features from data and transform the data into different levels of abstraction (representations).  
As an example, assume the input data is a matrix of pixels. the first layer typically abstracts the pixels and recognizes the edges of features in the image. The next layer might build simple features from the edges like leaves and branches. The subsequent layer could then recognize a tree and so on. The data passing from one layer to the next is considered a transformation, turning the output of 1 layer into the input for the next. Each layer corresponds with a unique level of abstraction and the machine can learn which features of the data to place in which layer/level on its own. Deep learning is differentiated from traditional “shallow learning” because it learns much deeper levels of hierarchical abstraction and representations.

# Evolution of Deep Learning

It’s the most valuable development in the world of AI in the present time. But rather than trying to understand the details of the field which could lengthen this article a little too much. Let’s just take a look at some of the main developments in the evolution of deep learning.

Although the study of the human brain is thousands of years old. the first step towards neural networks took place in 1943.

In 1943

When Warren McCulloch, a neurophysiologist, and a young mathematician, Walter Pitts, wrote a paper on how neurons might work. They modeled an easy neural network with electrical circuits.

In 1958

Frank Rosenblatt creates the perceptron, an algorithm for pattern recognition based on a two-layer computer neural network using simple addition and subtraction. The perceptron computes a weighted sum of the inputs, subtracts a threshold, and passes one of two possible values out as the result.

In 1980

Kunihiko Fukushima proposes the Neocognitron which is a hierarchical, multilayered artificial neural network. It's been used for handwriting recognition and other pattern recognition problems.

In the 1980s-1990s

John Hopfield presented a paper to the National Academy of Sciences. His approach to making useful devices.  
Joint Conference on Cooperative/ Competitive Neural Networks at which Japan announced their Fifth-Generation effort resulted in the US worrying about being left behind. Soon funding was flowing once again.  
Deep Learning was introduced to the machine learning community by Rina Dechter in 1986.  
Yann LeCun’s invented the machine that could read handwritten digits. This invention felled beneath the wider world’s radar. While the algorithm worked and it required training for 3 days.  
This time when the second AI winter kicked in, which also effected research for neural networks and Deep Learning. Various overly-optimistic individuals had exaggerated the “immediate” potential of AI, breaking expectations, and angering investors. Luckily, some people continued to figure on AI and DL, and some significant advances were made. In 1995, Dana Cortes and Vladimir Vapnik developed the support vector machine.  
Sepp Hochreiter and Jürgen Schmidhuber publish a milestone paper on “Long Short-Term Memory” (LSTM). It’s a kind of RNN architecture that will persist to revolutionize deep learning in decades to come.

In 2006

Geoffrey Hinton, Ruslan Salakhutdinov, Osindero, and the altogether published the paper a fast learning algorithm for deep belief nets. in which they stacked multiple databases together in layers and called them Deep Belief Networks. The training process is much more efficient for a large amount of data.

In 2008

Andrew NG’s group at Stanford started advocating for the utilization of GPUs. So, that they can train Deep Neural Networks to hurry up the training time by many folds. this could bring practicality in the field of Deep Learning for training on a large volume of data efficiently.

In 2009

Finding enough labeled data has always been a challenge for the Deep Learning community. In 2009 Fei-Fei Li, an AI professor at Stanford launched ImageNet, assembled a free database of more than 14 million labeled images. it would serve as a benchmark for the deep learning researchers who would participate in ImageNet competitions (ILSVRC) each year.

In 2012

AlexNet, a GPU implemented the CNN model designed by Alex Krizhevsky. AlexNet won Imagenet’s image classification contest with an accuracy of 84%. It's a huge jump over 75% accuracy that earlier models had achieved. This win triggers a new deep learning boom globally.

In 2014

Ian Goodfellow created GAN also known as Generative Adversarial Neural Network. GANs open an entirely new door of application of deep learning in fashion, art, science, etc.

In 2016

Deepmind’s deep reinforcement learning model beats the human champion in the complex game of Go. the game is much more complex than chess. As a result, this feat captures the imagination of everyone. Also, it takes the promise of deep learning to an entirely new level. Self-learning computer eclipses human ability at complex game Go In 2019  
Yoshua Bengio, Geoffrey Hinton, and Yann LeCun won Turing Award 2018. they had immensely contributed to advancements in the area of deep learning and AI. This was a defining moment for those who had worked relentlessly on neural networks.2018 Turing Award

By 2012, deep learning had already been used to help people turn left at Albuquerque (Google Street View). It inquired about the estimated average airspeed velocity of an unladen swallow (Apple’s Siri). In June of the year 2012, Google linked 16,000 computer processors, gave them Internet access, and watched as the machines taught themselves how to identify…cats. What may seem laughably simplistic, though, was quite earth-shattering as scientific progress goes.

# Advantages of Deep Learning

The following are the benefits or advantages of Deep Learning:

**➾**  Features are automatically deduced and optimally tuned for the desired outcome. Features are not required to be extracted ahead of time. This avoids time-consuming machine learning techniques.  
**➾**  Robustness to natural variations in the data is automatically learned.  
**➾**  The same neural network-based approach can be applied to many different applications and data types.  
**➾**  Massive parallel computations can be performed using GPUs and are scalable for large volumes of data. Moreover, it delivers better performance results when the amount of data are huge.  
**➾**  The deep learning architecture is flexible to be adapted to new problems in the future.

# Disadvantages of Deep Learning

The following are the drawbacks or disadvantages of Deep Learning:

**➾** It requires a very large amount of data to perform better than other techniques.  
**➾** It is extremely expensive to train due to complex data models. Moreover, deep learning requires expensive GPUs and hundreds of machines. This increases the cost to the users.  
**➾** There is no standard theory to guide you in selecting the right deep learning tools as it requires knowledge of topology, training method, and other parameters. As a result, it is difficult to be adopted by less skilled people.  
**➾** It is not easy to comprehend output based on mere learning and requires classifiers to do so. Convolutional neural network-based algorithms perform such tasks.

&amp;#x200B;

If you find something interesting then read the full article - [Deep Learning](https://www.geeky4tech.com/2020/09/deep-learning.html)",0,deeplearning,2020-10-13
j1qr8p,PyTorch based deep generative model library has been installed more than 10k,,31,deeplearning,2020-10-13
j1ovsz,6D pose estimation of a known 3D CAD object with limited model training for a new object,"I'm working on a project where I need to estimate the 6DOF pose of a known 3D CAD object in a single RGB image - i.e. this task: [https://paperswithcode.com/task/6d-pose-estimation](https://paperswithcode.com/task/6d-pose-estimation). There are several constraints on the problem:

* Usable commercially (licensed under BSD, MIT, BOOST, etc.), not GPL.
* The CAD object is known and we do NOT aim for generality (i.e.recognize the class of all chairs).
* The CAD object can be uploaded by a user, so it may have symmetries and a range of textures.
* Inference step will be run on a smartphone, and should be able to run at &gt;30fps.
* The inference step can either be a) find the pose of the object once and then I can write code to continue to track it or b) find the pose of the object continuously. I.e. the model doesn't need to have any continuous refinement steps after the initial pose estimate is found.
* Can be anywhere on the scale of single instance of a single object to multiple instances of multiple objects (MiMo). MiMO is preferred, but not required.
* If a deep learning approach is used, the training time required for a new CAD object should be on the order of hours, not days.
* Can either 1) just find the initial pose of an object and not have any refinement steps after or 2) find the initial pose of the object and also have refinement steps after.

I am open to traditional approaches (i.e. 2D-&gt;3D correspondences then solving with PnP), but it seems like deep learning approaches outperform them (classical are too slow - [Real time 6D pose estimation of known 3D CAD objects from a single 2D image or point clouds from RGBD Camera when objects are one on top of the other?](https://stackoverflow.com/questions/62187435/real-time-6d-pose-estimation-of-known-3d-cad-objects-from-a-single-2d-image-or-p)). Looking at deep learning approaches (poseCNN, HybridPose, Pix2Pose, CosyPose), it seems most of them match these constraints, except that they require model training time. Though perhaps I can use a single pre-trained model and then specialize it for each new CAD object with a shorter training step. But I am not sure of this, and I think success probably relies on the specific model chosen. For example, this project says it requires 3 hours of training time: [https://github.com/DLR-RM/AugmentedAutoencoder](https://github.com/DLR-RM/AugmentedAutoencoder).

So, my question: would somebody know what the state of the art, commercially usable implementation that doesn't require extensive training time for a new CAD object is?

[https://stackoverflow.com/questions/64095121/6d-pose-estimation-of-a-known-3d-cad-object-with-limited-model-training-for-a-ne](https://stackoverflow.com/questions/64095121/6d-pose-estimation-of-a-known-3d-cad-object-with-limited-model-training-for-a-ne)",1,deeplearning,2020-10-13
j1kg3o,"[R] Google Introduces TensorFlow Recommenders, ‘Helping Users Find What They Love’","Google is one of the leading companies in recommender system research, development and deployment, and has been utilizing deep learning techniques such as multi-task learning, reinforcement learning and better user representations and fairness objectives to make its recommendations more personalized and effective. A group of researchers from Google Brain recently introduced a new open-sourced TensorFlow package, TensorFlow Recommenders (TFRS) designed to simplify the process of building, evaluating, and serving sophisticated recommender models.

Here is a quick read: [Google Introduces TensorFlow Recommenders, ‘Helping Users Find What They Love’](https://syncedreview.com/2020/09/28/google-introduces-tensorflow-recommenders-helping-users-find-what-they-love/)

TensorFlow Recommenders is now open-sourced on [GitHub](https://github.com/tensorflow/recommenders).",2,deeplearning,2020-10-13
j1jq5j,Dynamic hand gesture recognition,My team is planning to do a project on hand motion detection for college project such that we can control our browser using certain hand movements. But we are completely new to ML and don't know exactly how can this be done. We are not certain if we should use only opencv or cnn to build this. Can someone tell how can we do this. Will be great help.,1,deeplearning,2020-10-13
j1jb04,OPENCON,,1,deeplearning,2020-10-13
j1ja6w,"OpenCV Threshold ( Python, C++ )","Sometimes the easiest solution is the most suitable one. This is especially true in the Computer Vision domain. Thresholding is one of the most commonly used image processing techniques and despite its ease of use, it has proven to be highly effective even in advanced computer vision problems.  


In this blog, we will explore different thresholding techniques and implement them using OpenCV in Python and C++.  


[https://www.learnopencv.com/opencv-threshold-python-cpp/](https://www.learnopencv.com/opencv-threshold-python-cpp/) 

https://preview.redd.it/u3w0dmktzxp51.jpg?width=1024&amp;format=pjpg&amp;auto=webp&amp;s=cac8f3ab2b51e3428cc37614fef263042ae70a6d",1,deeplearning,2020-10-13
j1hq38,AI removes any object in the video.,,55,deeplearning,2020-10-13
j1h1v8,Solution to help stray street animals,,0,deeplearning,2020-10-13
j1ggz3,"Colorization Programs like: Deoldify, Interactive Deep Colorization","I always hear about Deoldify but I never see people use this one.  Is deoldify superior?

[https://github.com/junyanz/interactive-deep-colorization](https://github.com/junyanz/interactive-deep-colorization)

In this video the creator uses reference images of the subject to colorize the video.  What would allow the use of that?

[https://www.youtube.com/watch?v=ae3AbxP02zY](https://www.youtube.com/watch?v=ae3AbxP02zY)",1,deeplearning,2020-10-13
j1gdtr,Should I use DAIN before Upscaling or after?,It's much faster to do it before because of the lower resolution.  But have you guys found better results by doing it after?,1,deeplearning,2020-10-13
j1ff1z,What does the color mean in this network feature map?,,1,deeplearning,2020-10-13
j1dthk,Why data quality is key to successful ML Ops,,1,deeplearning,2020-10-13
j1bjye,Which research institutions can I apply to as a research assistant? (Profile given below),"I am currently a final year computer engineering student from India. My CGPA is 9.38/10 (as of 6 semesters).
I have done the deeplearning.ai specialisation and AI for Medicine courses from coursera, and done 3 projects listed below:
1. Segmentation of Eye scans (research internship with my college and an Ophthalmology institute in my city)
2. Deep learning intern at a research institute in my city.
3. Brain haemorrhage segmentation and detection using Mask - RCNN. (College project)
4. I am currently trying a medical image captioning project as my final year project.

I wish to work as a research assistant for deep learning before I apply for an MS in CS with Data science as a minor. I enjoy reading research papers and implementing it. I might be a little weak in advanced math for ML / DL, but I’m working on it. Any suggestions for professors / researchers / institutes that I can apply to with this profile?",0,deeplearning,2020-10-13
j19vax,Can you alter the label image too with STN?,"I just know that there's a method called Spatial Transformation Network for data augmentation. https://debuggercafe.com/spatial-transformer-network-using-pytorch/

If I train the data image with test images, given STN is just the spatial transformation, can I just transform the label image too using the same model?",2,deeplearning,2020-10-13
j17l7k,Back to Machine Learning Basics - Decision Tree &amp; Random Forest,,12,deeplearning,2020-10-13
j1035c,Sandwich Transformer: Improving Transformer Models by Reordering their Sublayers,,0,deeplearning,2020-10-13
j0wpsd,GANs for Improving Astronomical Images,,0,deeplearning,2020-10-13
j0uuu2,TorchRayLib++: A RayLib based UI for the Libtorch C++ Deep Learning Library.,,4,deeplearning,2020-10-13
j0rxcc,Deep learning generative models for time series?,"I was wondering what are some good deep learning generative models for time series generation.

Is there anything like PixelCNN, VQ-VAE-2 or even a GAN but specifically for time series generation?

Thanks! :)",30,deeplearning,2020-10-13
j0rum2,"Are you looking for a place where you can interact live, and talk over text and voice with many other machine learning enthusiasts?","**Are you looking for a place where you can interact live, and talk over text and voice with many other machine learning enthusiasts?**

Then come join our **Discord** server!  
*In short;  Discord is the easiest way to talk over voice, video, and text. Talk, chat, hang out, and stay close with your friends and communities.*

Then **join our community** right now! It's the best place to:   
\- Learn with other enthusiasts  
\- Share your projects, interesting research papers, amazing courses  
\- Ask your questions, anything related to the field of artificial intelligence, machine learning, and deep learning, NLP, computer vision, etc.  
\- Find Kaggle competition teammates, jobs, or just people to talk with!

We are excited to see you joining us! Just click the link below to join the ""Learn AI Together"" community.  
 [https://discord.gg/SVse4Sr](https://discord.gg/SVse4Sr?fbclid=IwAR277hJjB_V8PQgw4CY8ss6HN1o5Xq12r8E9HRWOdkOdLUvk_dheBGVxFtc)",0,deeplearning,2020-10-13
j0r6fg,Suggestion on improving facial expression recognition model,"Hi all,
Im currently building a facial expression recognition mainly through supervising learning using CNN with 4 hidden layers. Initially had an accuracy around 60%. Bought it to 65% after adding dropouts and data augmentation. Currently looking at adding batch normalization as it seems to be improving the test accuracy. However, I face two main issues currently: 
1. As for I heard the FER2013 dataset at most gives an accuracy of around 70% using traditional CNN route. 
2.GPU is a huge issue. Currently use kaggle notebook with an awesome GPU they provide. But, you easily hit there 37 hour usage limit as u experiment more. Google collab GPU's are really slow compared to kaggle. Do you have any suggestions to further improve my model. My two ideas for improving as of now is: 1. I am looking at CK+ dataset and thinking of combining both FER and CK+. 2.Remove emotions which are quite confusing for machine to learn such as disgust I am still new to deep learning, but its really been a fruitful experience to have came this much. Would love to know any technical suggestions from your side as well like ensemble and transfer learning perhaps?

Github Repo: https://github.com/unaveenj/Emotion_Recognition",0,deeplearning,2020-10-13
j0q7qs,Jump Rope + AI! Human Pose Estimation precisely. Link to the tutorial and code in the description there!,,5,deeplearning,2020-10-13
j0q5pw,[P] Hi! I'm happy to announce that I posted my first Towards Data Science post! In this case about virtual gamming using Tensorflow.js,,0,deeplearning,2020-10-13
j0q3jv,Fine-Tuning DistilBert for Multi-Class Text Classification using transformers and TensorFlow,,0,deeplearning,2020-10-13
j0bof8,Tesla GPU cloud rental from under 1$/hour (vast.ai) [D],,0,deeplearning,2020-10-13
j0akdm,Some deep learning project ideas! (Note: I've got all of these implemented on my GitHub),,27,deeplearning,2020-10-13
j0ahcc,What university department to choose for Deep Learning?,"Hello to everyone. So in the next year, I need to choose a department at the university. I want to study something about **Deep Learning** (main interest in **Computer Vision**) - for example, something that will help me to work in companies like Tesla and build Autonomous Vehicles (or something similar). What department do I need to choose for that? Is **Data Science** the right department? What is the job of Data Scientists?

Edit: Data Scientist are not like ordinary developers? Because I don't want to be a developer

Thanks in advance! :)",0,deeplearning,2020-10-13
j099jm,I did a project which combines output from different neural nets (3D object detector and panoptic segmentation) to do trajectory prediction.,,18,deeplearning,2020-10-13
j085xu,Deep Learning Project Suggestion,"Hello folks,
I am going to make a term project and I want to use deep learning in the project. Some of GAN applications seem nice to make but I need topic/project suggestions to make. Do you have any interesting one?",0,deeplearning,2020-10-13
j07y2p,Why High Performance Computing Could Become The Next Frontier For Enterprise AI,[https://analyticsindiamag.com/why-high-performance-computing-could-become-the-next-frontier-for-enterprise-ai/](https://analyticsindiamag.com/why-high-performance-computing-could-become-the-next-frontier-for-enterprise-ai/),0,deeplearning,2020-10-13
j06eo3,GPT-3: Is this the moment we've been waiting for? [Giveaway included],,0,deeplearning,2020-10-13
j04lgp,Old Photo Restoration Using Deep Learning | 2020 Novel Approach Explained &amp; Results,,3,deeplearning,2020-10-13
j04f5b,Computer Vision for Pictures and Videos,,0,deeplearning,2020-10-13
j03oz4,3090 memory pooling?,Will 3090 have memory pooling just like the quodros?,1,deeplearning,2020-10-13
j01y64,"If a video is basically many pictures, how about music?",How to break up an mp4 to feed into an RNN.,19,deeplearning,2020-10-13
iztuo1,What's your opinion regarding graph/node embeddings against graph convolutional networks?,"I've been researching about GCNs and found them very different from traditional machine learning approaches. Although they've shown outstanding performance in specific tasks, I'd like to know how they perform when comparing to node and graph embedding techniques (which to me are a lot more intuitive). Are graph embeddings able to carry the node and its neighbors' information as well as GCNs? And are there some sources comparing both approaches?",14,deeplearning,2020-10-13
izq97n,PC/Laptop for first job in industry as ML Engineer?,"For those of you who have elected to buy or build your own deep learning rig, what has your experience been? I finally landed my first job as a MLE contractor. Since I'm not an W2 employee, I'm told I'm responsible for my own equipment.

Rather than using the cloud, I would prefer purchasing my own rig. I blew through my 300.00 worth of free credits on GCP already (all used up teaching myself the stuff I needed to get hired).

I'm looking for other people's experiences and opinions. Again, the job is going to be full time, so I'm looking for high quality performance and reliability. I want whatever edge I can get in making sure my first job experience goes really well. I figure this is an investment, but I'm open to being told I'm wrong here.",6,deeplearning,2020-10-13
izney5,If anyone is interested in registering to ICIP conference as an attendee it is virtual and online,,0,deeplearning,2020-10-13
izle6k,Simple Background Estimation in Videos using OpenCV (C++/Python),"In today's post, we will go over a real-life application of OpenCV that is especially helpful when the processing power at your disposal is low or you have a static camera and moving object.  


https://reddit.com/link/izle6k/video/6cve7pny9bp51/player

Find details of the blog - Simple Background Estimation in Videos using OpenCV - with code at [https://www.learnopencv.com/simple-background-estimation-in-videos-using-opencv-c-python/](https://www.learnopencv.com/simple-background-estimation-in-videos-using-opencv-c-python/)",1,deeplearning,2020-10-13
izl2w3,[P] Quelling my fears about the future with fortune cookies and GPT-2,"With all that is happening in the world I think many worry about the future. To get some clarity I trained a GPT-2 to tell fortune cookie fortunes. The results were very wholesome and made me feel better, so I thought I should share. :)

&amp;#x200B;

[Github link](https://github.com/simon-larsson/fortune-cookie-gpt2)

&amp;#x200B;

The project itself is nothing noteworthy, it is just [huggingface](https://github.com/huggingface/transformers). But I think GPT-2 really nails the pseudo profundity of fortune cookies.

&amp;#x200B;

| Sample fortunes  |
|:-----------|
|It really does not matter which direction you are traveling from if you move ahead.|
|Life is short. Eat your cake! |
|A person who is not afraid of any, may be welcomed in safety.|
|An iron furnace will break if you ignore its own command.|
|A great change among people is upon us.|
|It's a beautiful day. Look around you.|
|Ask someone to hold your hand. You will feel happier today.|
|People can accomplish great things when they are given equal opportunities.|
|Do not hesitate to order a drink, it will fill you with high-quality energy.|
|Be not afraid to ask for more information. Stay alert! We've got to learn as much as we can today.|
|You will build strong friendships.|
|Stay aware of what you don't know.|
|In times when you are in the best position for what you dream, be open and honest.|
|Do not let fate judge us.|
|You will become a better man by not fighting past your obstacles.|
|All things must come about from below.|
|All will be right with you, no mistakes will happen. Everything will be fine.|
|You are the first to get the position you want to be.|
|The more you spend, the more you have.|
|Everyone who works for you seeks to achieve their own ends.|
|You will be surrounded by love.|
|Your loved ones will love you even more than they did before.|
|You will be happy in your lifetime.|
|The most beautiful thing in life is having a new adventure.|
|What is it like working for an entrepreneur?|
|If the best you can do is follow the rules of the market, what do you do then?|
|Try not to be taken by surprise.|
|You will receive a special medal for your efforts.|
|A happy new year brings a big reward for you.|
|A great idea may be waiting to become ingrained into your soul.|
|The moment your wish will come true should come true.|
|You will become a better person.|
|There are ways we can save others.|
|We need more people to fill the shoes of today.|
|You will become a better friend.|
|The great change taking place in the world will have a major impact on the way we look at ourselves.|
|Your life will change your life forever.|
|You can accomplish many things today.|
|Everything we do today will be great for you.|
|You will be welcomed into our world to become your personal hero.|
|It is you they are looking for.|
|It is a great day to be the happiest.|
|Your ability to be a better life will be honored by your accomplishments.|
|It is never too late to pursue the dream of a new career.|
|Today is a big day for you, but tomorrow will be a long day.|
|Good luck, you will be having a happy and successful day.|
|Try again tomorrow.|
|Now is your chance at success.|
|Tomorrow is about where you will be spending time today.|
|Don't worry about tomorrow just wait for it.|",21,deeplearning,2020-10-13
izhxmn,Which is the current state of the art model for Image Captioning?,I keep coming across Show and Tell which is a 2015 paper. Looking for newer methods.,18,deeplearning,2020-10-13
izhe76,"Talk: ""Using deep learning to count albatrosses from space"" (30th Sep 2020, free, online)","[https://www.meetup.com/PyData-Cambridge-Meetup/events/273366810/](https://www.meetup.com/PyData-Cambridge-Meetup/events/273366810/)

**Date:** Wednesday, September 30, 2020

**Time:** 7:00 PM to 9:00 PM GMT+1

**Agenda**

* 19:00 - Introduction
* 19:15 - ""Using deep learning to count albatrosses from space"" -- Ellie Bowler
* 19:45 - ""From Jupyter notebooks to production code, a Kedro introduction"" -- Lais Carvalho
* 20:15 - End

&amp;#x200B;

**Talk: ""Using deep learning to count albatrosses from space""**

*Speaker: Ellie Bowler*

Abstract: Wandering Albatrosses have seen dramatic declines in recent decades, leading to concern over their conservation. However due to their highly dispersed and inaccessible nesting locations, population surveys are expensive, infrequent, and often incomplete. In this work we address this issue by counting albatrosses directly from space, using 31-cm resolution WorldView-3 satellite imagery. We particularly focus on manual and automated methods for detecting the birds, and investigate how observer uncertainty in ground truth labels can impact supervised CNN training schemes.

Bio: Ellie Bowler is a PhD student under the supervision of Michal Mackiewicz at the University of East Anglia. Her background is in mathematics and computational ecology, with a particular interest in computer vision and deep learning. Her current research is on automated UAV and satellite image analysis for wildlife monitoring, working in collaboration with Peter Fretwell at the British Antarctic Survey.

&amp;#x200B;

**Talk: From Jupyter notebooks to production code, a Kedro introduction**

*Speaker: Lais Carvalho*

Kedro is an open-source Python library that helps data scientists write data pipelines following software engineering best practices from the start. Since our last visit to PyData Cambridge, we released several new features. In this talk, I will walk through some of those features and show you how to convert your Jupyter notebooks to a Kedro project, allowing you to scale your project and collaborate effectively on a team. Come and say hello. 😊

Bio: Lais Carvalho is a developer advocate for QuantumBlack. IT student, her background is on civil &amp; env. engineering and customer service. Board member of Python Ireland, Laís was part of the organisation of EuroPython 2020 and hosted the PyData Dublin Summer edition of same year.",0,deeplearning,2020-10-13
izfqkk,Learning Architecture from scratch for 11 classes,"Hi,

Can I go ahead with learning the deep learning architecture from scratch with \~10,000 samples being used to classify 11 classes?

&amp;#x200B;

Updated Question:

Adding Addition Information on this question. Below is my simple model. Earlier I had 11 classes which I clubed into two classes only. classes are not balanced and has the ration 1:4. Following the code is mentioned the output. The accuracy is stuck. Can anybody guide me through the issue here.

&amp;#x200B;

        model = Sequential()
        model.add(Conv2D(32, kernel_size=(3, 3), activation='relu',          input_shape=(150, 150, 3))) ## weight matrix - 1
        model.add(Conv2D(64, (3, 3), activation='relu'))
        model.add(MaxPooling2D(pool_size=(2, 2))) ## weight matrix - 2
        model.add(Dropout(0.25))
    
        model.add(Conv2D(64, (3, 3), activation='relu')) ## weight matrix - 3
        model.add(Conv2D(128, (3, 3), activation='relu'))
        model.add(MaxPooling2D(pool_size=(2, 2))) ## weight matrix - 4
        model.add(Dropout(0.25))
        #model.add(MaxPooling2D(pool_size=(2, 2)))
    
        model.add(Conv2D(128, (3, 3), activation='relu')) ## weight matrix - 5
        model.add(Conv2D(256, (3, 3), activation='relu')) ## weight matrix - 5
        #model.add(MaxPooling2D(pool_size=(2, 2))) ## weight matrix - 6
        model.add(GlobalAveragePooling2D())
        model.add(Dropout(0.25))
        #model.add(MaxPooling2D(pool_size=(2, 2)))
    
        model.add(Flatten())
        ## weight matrix - 7
    
        if node_number == '20':
            print(""node_number is %s"" %node_number)
            model.add(Dense(64, activation='relu')) 
            model.add(Dropout(0.25))
            #lr = 10**(-4*np.random.rand())
            model.add(Dense(num_classes, activation='softplus')) ## weight matrix - 8
    
        else:          
            print(""node_number is %s"" %node_number)
            model.add(Dense(64, activation='relu', input_dim=64, kernel_regularizer=regularizers.l2(0.01), activity_regularizer=regularizers.l1(0.01)))                    
            model.add(Dropout(0.25))
            #lr = 10**(-4*np.random.rand())
            model.add(Dense(num_classes, activation='softplus'))                    
    
        #adm = optimizers.Adam(lr=0.00001, beta_1=0.9, beta_2=0.999, epsilon=None, decay=0, amsgrad=False) Trained the earlier model with this learning rate.
        ## as per the lr_finder, I should use the learning rate between 0.0001 but close to 0.00001.
        adm = optimizers.Adam(lr=0.0001, beta_1=0.9, beta_2=0.999, epsilon=None, decay=0, amsgrad=False)
        model.summary()
    
    Output:
    
    (10337, 150, 150, 3)
    (3033, 150, 150, 3)
    Epoch 1/400
    162/162 [==============================] - 15s 91ms/step - loss: 1.2788 - accuracy: 0.7359 - val_loss: 0.9816 - val_accuracy: 0.6785
    Epoch 2/400
    162/162 [==============================] - 15s 91ms/step - loss: 0.8318 - accuracy: 0.7516 - val_loss: 0.8048 - val_accuracy: 0.6785
    Epoch 3/400
    162/162 [==============================] - 14s 86ms/step - loss: 0.7069 - accuracy: 0.7516 - val_loss: 0.7256 - val_accuracy: 0.6785
    Epoch 4/400
    162/162 [==============================] - 17s 103ms/step - loss: 0.6447 - accuracy: 0.7516 - val_loss: 0.6806 - val_accuracy: 0.6785
    Epoch 5/400
    162/162 [==============================] - 16s 101ms/step - loss: 0.6151 - accuracy: 0.7516 - val_loss: 0.6694 - val_accuracy: 0.6785
    Epoch 6/400
    162/162 [==============================] - 17s 104ms/step - loss: 0.5944 - accuracy: 0.7516 - val_loss: 0.6546 - val_accuracy: 0.6785
    Epoch 7/400
    162/162 [==============================] - 17s 106ms/step - loss: 0.5805 - accuracy: 0.7516 - val_loss: 0.6417 - val_accuracy: 0.6785
    Epoch 8/400
    162/162 [==============================] - 17s 104ms/step - loss: 0.5751 - accuracy: 0.7516 - val_loss: 0.6358 - val_accuracy: 0.6785
    Epoch 9/400
    162/162 [==============================] - 18s 113ms/step - loss: 0.5694 - accuracy: 0.7516 - val_loss: 0.6462 - val_accuracy: 0.6785
    Epoch 10/400
    162/162 [==============================] - 18s 109ms/step - loss: 0.5657 - accuracy: 0.7516 - val_loss: 0.6444 - val_accuracy: 0.6785
    Epoch 11/400
    162/162 [==============================] - 17s 106ms/step - loss: 0.5602 - accuracy: 0.7516 - val_loss: 0.6313 - val_accuracy: 0.6785
    Epoch 12/400
    162/162 [==============================] - 17s 105ms/step - loss: 0.5610 - accuracy: 0.7516 - val_loss: 0.6519 - val_accuracy: 0.6785
    Epoch 13/400
    162/162 [==============================] - 17s 102ms/step - loss: 0.5544 - accuracy: 0.7516 - val_loss: 0.6370 - val_accuracy: 0.6785
    Epoch 14/400
    162/162 [==============================] - 17s 104ms/step - loss: 0.5523 - accuracy: 0.7516 - val_loss: 0.6334 - val_accuracy: 0.6785
    Epoch 15/400
    162/162 [==============================] - 17s 105ms/step - loss: 0.5526 - accuracy: 0.7516 - val_loss: 0.6440 - val_accuracy: 0.6785
    Epoch 16/400
    162/162 [==============================] - 17s 105ms/step - loss: 0.5504 - accuracy: 0.7516 - val_loss: 0.6374 - val_accuracy: 0.6785
    Epoch 17/400
    162/162 [==============================] - 17s 105ms/step - loss: 0.5481 - accuracy: 0.7516 - val_loss: 0.6370 - val_accuracy: 0.6785
    Epoch 18/400
    162/162 [==============================] - 17s 103ms/step - loss: 0.5483 - accuracy: 0.7516 - val_loss: 0.6424 - val_accuracy: 0.6785
    Epoch 19/400
    162/162 [==============================] - 17s 105ms/step - loss: 0.5478 - accuracy: 0.7516 - val_loss: 0.6347 - val_accuracy: 0.6785
    Epoch 20/400
    162/162 [==============================] - 17s 104ms/step - loss: 0.5478 - accuracy: 0.7516 - val_loss: 0.6296 - val_accuracy: 0.6785
    Epoch 21/400
    162/162 [==============================] - 18s 113ms/step - loss: 0.5453 - accuracy: 0.7516 - val_loss: 0.6691 - val_accuracy: 0.6785
    Epoch 22/400
    162/162 [==============================] - 17s 103ms/step - loss: 0.5414 - accuracy: 0.7516 - val_loss: 0.6602 - val_accuracy: 0.6785
    Epoch 23/400
    162/162 [==============================] - 17s 103ms/step - loss: 0.5404 - accuracy: 0.7516 - val_loss: 0.6318 - val_accuracy: 0.6785
    Epoch 24/400
    162/162 [==============================] - 17s 105ms/step - loss: 0.5384 - accuracy: 0.7516 - val_loss: 0.6622 - val_accuracy: 0.6785
    Epoch 25/400
    162/162 [==============================] - 17s 105ms/step - loss: 0.5395 - accuracy: 0.7516 - val_loss: 0.6409 - val_accuracy: 0.6785
    Epoch 26/400
    162/162 [==============================] - 16s 102ms/step - loss: 0.5370 - accuracy: 0.7516 - val_loss: 0.6776 - val_accuracy: 0.6785
    Epoch 27/400
    162/162 [==============================] - 16s 101ms/step - loss: 0.5359 - accuracy: 0.7516 - val_loss: 0.6466 - val_accuracy: 0.6785
    Epoch 28/400
    162/162 [==============================] - 17s 107ms/step - loss: 0.5288 - accuracy: 0.7516 - val_loss: 0.6837 - val_accuracy: 0.6785
    Epoch 29/400
    162/162 [==============================] - 17s 104ms/step - loss: 0.5296 - accuracy: 0.7516 - val_loss: 0.6725 - val_accuracy: 0.6785
    Epoch 30/400
    162/162 [==============================] - 17s 102ms/step - loss: 0.5246 - accuracy: 0.7516 - val_loss: 0.6769 - val_accuracy: 0.6785
    Epoch 31/400
    162/162 [==============================] - 17s 106ms/step - loss: 0.5224 - accuracy: 0.7516 - val_loss: 0.6866 - val_accuracy: 0.6785
    Epoch 32/400
    162/162 [==============================] - 17s 102ms/step - loss: 0.5183 - accuracy: 0.7516 - val_loss: 0.6877 - val_accuracy: 0.6785
    Epoch 33/400
    162/162 [==============================] - 18s 109ms/step - loss: 0.5175 - accuracy: 0.7516 - val_loss: 0.6433 - val_accuracy: 0.6785
    Epoch 34/400
    162/162 [==============================] - 17s 103ms/step - loss: 0.5201 - accuracy: 0.7516 - val_loss: 0.6989 - val_accuracy: 0.6785
    Epoch 35/400
    162/162 [==============================] - 17s 106ms/step - loss: 0.5113 - accuracy: 0.7516 - val_loss: 0.7232 - val_accuracy: 0.6785
    Epoch 36/400
    162/162 [==============================] - 17s 106ms/step - loss: 0.5036 - accuracy: 0.7516 - val_loss: 0.6957 - val_accuracy: 0.6785
    Epoch 37/400
    162/162 [==============================] - 17s 105ms/step - loss: 0.5022 - accuracy: 0.7516 - val_loss: 0.7137 - val_accuracy: 0.6785
    Epoch 38/400
    162/162 [==============================] - 17s 106ms/step - loss: 0.5027 - accuracy: 0.7516 - val_loss: 0.6709 - val_accuracy: 0.6785
    Epoch 39/400
    162/162 [==============================] - 17s 104ms/step - loss: 0.4929 - accuracy: 0.7516 - val_loss: 0.6826 - val_accuracy: 0.6785
    Epoch 40/400
    162/162 [==============================] - 17s 105ms/step - loss: 0.4926 - accuracy: 0.7516 - val_loss: 0.7194 - val_accuracy: 0.6785
    Epoch 41/400
    162/162 [==============================] - 17s 104ms/step - loss: 0.4902 - accuracy: 0.7516 - val_loss: 0.7512 - val_accuracy: 0.6785
    Epoch 42/400
    162/162 [==============================] - 17s 106ms/step - loss: 0.4852 - accuracy: 0.7516 - val_loss: 0.6430 - val_accuracy: 0.6785
    
    
    

&amp;#x200B;",1,deeplearning,2020-10-13
izei4c,[P] Tutorial on how to train DETR model on custom dataset,"Video Tutorial
https://youtu.be/RkhXoj_Vvr4

Code
https://github.com/thedeepreader/detr_tutorial",3,deeplearning,2020-10-13
ize0ak,How neural network architectures like yolo are created?,"Hello, I need recommendations on what sources of knowledge (books, papers, ...) to look at if I am to create a new model architecture that is specific to a certain problem which is not necessarily a computer vision problem(ex: trading model). For those who are familiar with [yolo](https://pjreddie.com/yolo/) which is a very well crafted object detection model, it contains many convolutional, shortcut, bn, maxpool, .. you name it layers that fit all together to form a model. I'm wondering what might be proper resources to look at to learn how to design a neural network with the same level of sophistication.",1,deeplearning,2020-10-13
iz6k2e,Problem of keras/tf not utilising all cpu cores,"Hi, So I am running some deep learning models and noticed one thing, only one of the processor thread is at 100% the rest seem to be unaffected by the training process. I tried looking for a fix, but I did not find anything what works. 

Did someone else encountered this problem?",4,deeplearning,2020-10-13
iz60n7,"Solve Sudoku Puzzle Using Deep Learning, OpenCV And Backtracking",[https://analyticsindiamag.com/solve-sudoku-puzzle-using-deep-learning-opencv-and-backtracking/](https://analyticsindiamag.com/solve-sudoku-puzzle-using-deep-learning-opencv-and-backtracking/),1,deeplearning,2020-10-13
iz2nxc,Deep AI,,0,deeplearning,2020-10-13
iz2kps,Predict Next Sequence using Deep Learning in Python,,7,deeplearning,2020-10-13
iz27uc,How to Implement Linear Regression using Stochastic Gradient Descent in Python 👀,"[https://neuraspike.com/blog/linear-regression-stochastic-gradient-descent-python/](https://neuraspike.com/blog/linear-regression-stochastic-gradient-descent-python/)

&amp;#x200B;

\- The Basic Concept

\- Python Implementation

\- Benefits &amp; drawbacks behind the Algorithm

https://preview.redd.it/ze08b3y5x4p51.png?width=551&amp;format=png&amp;auto=webp&amp;s=201cc7256c4266b74ff4ebcf706bcbe6652abe89",0,deeplearning,2020-10-13
iz26mz,Grooking deep learning by Andrew Trask Chapter 11,"Hi all,

I'm reading Grooking deep learning and right now I'm at chapter 11 , there a line of code in the section 'fill in the blank' that I don't understand here's is the code :

weights\_1\_2 = np.random.rand(len(vocab),hidden\_size)\*0

This line means all weights are equal to 0 , is there a mistake here  ?

Thank You !",1,deeplearning,2020-10-13
iz0cd3,Search similar pictures of math problems?,"Hello everyone, recently I had use QandA app, this is an app solving math problem. I feel the application searches for pictures of math problems very quickly and accurately, how can it do that, can you explain? Thanks.",0,deeplearning,2020-10-13
iz09q0,Python and FastAI to Qualify at FallGuys,,88,deeplearning,2020-10-13
iyujyh,Anime Snapchat Filter | ANIME STYLE Filter on Snapchat,,3,deeplearning,2020-10-13
iyub9f,Computer Vision: how do I add a new class without retraining the entire model?,"Hi!

I am currently working on a model based on Inception V3 and performs binary classification, more specifically to determine if a product has a manufacturing error or not. It recognizes dents and scratches, but I want to quickly be able to retrain it to learn new kinds of errors, e.g. a wrong color.

Can I do this using transfer learning somehow? I have found methods which make some of the weights untrainable in order to add a new class in the output but I have yet to test its performance, but perhaps there is a way to keep it binary (faulty or not faulty).

In the end, it should be able to classify new kinds of defects by feeding it a series of examples of the new defect, without having to retrain the entire model.

All suggestions are welcome :)

EDIT: The exact model is Inception V3, followed by a GlobalAveragePooling2D layer and 2 Dense layers",17,deeplearning,2020-10-13
iyu7kz,What's the best detector to build a basketball detection model on a mobile phone.,"I'm building a basketball detection model and wanted that to be deployed on IOS. What is the best object detection model I can use for my problem?

I heard MobileNet SSD is good but I guess this doesn't have good accuracy on small objects.  


Training data sample: [https://drive.google.com/file/d/114fS0rbh487nemT7U0-JzrNJvaUOUXNy/view](https://drive.google.com/file/d/114fS0rbh487nemT7U0-JzrNJvaUOUXNy/view)",0,deeplearning,2020-10-13
iyscql,Video Transforms Pytorch,Can anyone refer to a good library for video transforms in pytorch ?,0,deeplearning,2020-10-13
iyqn7l,What are state of the art techniques in event detection in videos?,"For object detection EfficientDet, detectron2 are state of the art but what about event detection in videos. Can someone highlight the state of the art algorithms in video event detection.",1,deeplearning,2020-10-13
iyp33h,Flow Forecast: A deep learning for time library written in PyTorch,,11,deeplearning,2020-10-13
iyogwt,State of the art in 3D dense face alignment!,,1,deeplearning,2020-10-13
iyics7,Logistics regression image classification!!!,"I am new to this that's why needed lil guidelines. I wanna covert an image dataset into training, testing and classes dataset can someone provide me with a code or link to a code to do it without using any library such as keras or tensorflow?????
Like dividing them naturally like in Andrew NG course????",3,deeplearning,2020-10-13
iygqby,Intel® Edge AI for IoT Developers (Nanodegree Program),"Dev colleagues, this nanodegree program leverages the Intel® Distribution of OpenVINO™ Toolkit to fast-track development of high-performance computer vision and deep learning inference applications, and run pre-trained deep learning models for computer vision on-premise. You will identify key hardware specifications of CPU, VPU, FPGA, and Integrated GPU hardware types and utilize the Intel® DevCloud for the Edge to test model performance on the various hardware types. Use software tools to optimize deep learning models to improve performance of Edge AI systems. The three skill-based training modules(each with a hands-on project) include: 1) Edge AI Fundamentals with OpenVINO™
(Project: Deploy a People Counter at the Edge), 2) Hardware for Computer Vision &amp; Deep Learning Application Deployment .(Project: Design a Smart Queuing System)., and 3) Optimization Techniques and Tools for Computer Vision &amp; Deep Learning Applications (Project:Build a Computer Pointer Controller).  This program requires intermediate knowledge of Python, and experience with Deep Learning, Command Line, and OpenCV.

Enroll today at: https://fxo.co/9kvZ 

Much career success, Lawrence E. Wilson - Artificial Intelligence Academy (AIA)",0,deeplearning,2020-10-13
iyfop0,Twitter toxicity detector using Tensorflow.js,"Hi! I recently finished this project, I hope you find it interesting! :)

[https://github.com/MCarlomagno/TwitterToxicityDetector](https://github.com/MCarlomagno/TwitterToxicityDetector)",17,deeplearning,2020-10-13
iyf0a0,[D] Tracking Recent Topics &amp; Trends in 3D Photo Generation,"Today any smartphone can generate 3D Photos, but the popular AI-powered effect is actually fairly new. It was back in 2018 that Facebook first introduced a machine learning-based 3D photo feature that allowed users to generate an immersive 3D image from normal 2D pictures. Leveraging the **dual-lens “portrait mode” capabilities that had recently become available in smartphones**, the feature quickly gained traction and began evolving.

This June, a research team from Virginia Tech, National Tsing Hua University and Facebook designed an algorithm that generates even more immersive 3D photos from a single RGB-D (colour and depth) image. And in August, Facebook democratized the technique with a novel system able to generate 3D photos even on low-end mobile phones or without an Internet connection.

Facebook isn’t the only tech giant using AI to generate 3D photos — in recent months, Google has introduced its own AI techniques for generating 3D photos from 2D images. Computer vision (CV) has achieved remarkable progress across various subfields and real-world applications, but few bring the everyday user as visually appreciable an effect as the trending medium of 3D photo generation’s ability to deepen the immersive experience of a captured moment.

Another common use of 3D images is in AR and VR applications, where they can provide viewers a unique lifelike experience. Today’s smartphone authentication systems also rely on 3D image capability. The FaceID process for example employs an array of flood illuminators, sensors and an infrared camera to generate the 3D facial depth map it uses for verification and unlock.

[Synced](https://syncedreview.com/) has identified a few significant technical advancements in the 3D photo field that we believe may be of interest to our readers.

Read more: [Tracking Recent Topics &amp; Trends in 3D Photo Generation](https://syncedreview.com/2020/09/22/tracking-recent-topics-trends-in-3d-photo-generation/)",2,deeplearning,2020-10-13
iydct6,Pose Estimation using GTA 5,"This is how I play GTA 5 using the Pose estimation technique.

[https://www.youtube.com/watch?v=PfmoCA3MFW8](https://www.youtube.com/watch?v=PfmoCA3MFW8)",2,deeplearning,2020-10-13
iycssu,Editing Obama's Face with StyleGAN2,,0,deeplearning,2020-10-13
iyc3ik,Modern Google-level speech-to-text models released,,1,deeplearning,2020-10-13
iyauz0,Need some assistance in understanding a deep learning research paper,"I am having some trouble understanding a research paper on Auto Colorization. [Paper](https://drive.google.com/file/d/13_Xd8RfDZyQRGuF2-_b6lFx0v2wMhu6d/view?usp=sharing) This is the paper. In the paper , in the 3.6 **Final Classification Model** section on page 3, I am not getting how exactly the pixels are discretized. And how will be predict the pixel values as 50 classes? What will be the output shape of the mode?",2,deeplearning,2020-10-13
iyae7q,Validation accuracy is greater than Training accuracy !!!,"I have a problem when I train a model to classify dog breed.

I have used ResNet 50 V2 as a pre-trained model.

you can see my work: [Here!!!](https://colab.research.google.com/drive/1Ve8ItOLI-3MC5RIWH0m3RaaBbImDPXqk?usp=sharing)

Please i need help to prevent this underfitting!",3,deeplearning,2020-10-13
iy9x3e,LSTM Learns To Write Shakespeare Fanfiction,,1,deeplearning,2020-10-13
iy81uz,"With PULSE, you can construct a high-resolution image from a corresponding low-resolution input image in a self-supervised manner!",,2,deeplearning,2020-10-13
iy6ouq,Grad-CAM for EEG?,"What changes should I make to Grad-CAM to be able to visualize 1D signals, say EEG?",0,deeplearning,2020-10-13
iy684f,[P] Multimodal Emotion Recognition Competition 2020 (MERC 2020),,1,deeplearning,2020-10-13
iy6137,Has anybody tried to implement (or know how to) a depthwise transposed convolution?,"I’m currently working on an Encoder-Decoder network for some kind of regression problem and I try to achieve a real-time inference time on CPU (part of the research goal).

I figured a naive way to do it is by reducing the num. of network parameters and why not replacing the 2D convolution with 2D depthwise convolution? Like what they did in MobileNet.

Tensorflow has the 2D depthwise conv. implemented, but they don’t have the transposed version of it. Thus, we can’t have a depthwise transposed convolutions on the Decoder network.

So far, the only online forums that actually talking about this is [here](https://github.com/tensorflow/tensorflow/issues/12001) 

I wonder if any of you guys working about it as well and/or have a suggestion on how to implement it?",1,deeplearning,2020-10-13
iy4yw3,Why is softmax function the go to for probabilities calculation?,What I can't understand is why so many people use this as a go-to other than for its simplicity and ease to work with. Is this function infallible? Is there a reason why softmax is usually something you will always encounter in deep learning?,31,deeplearning,2020-10-13
ixzlgt,What is Deep neural network?,,0,deeplearning,2020-10-13
ixygnc,Plz help me with this error.......OS:Ubuntu 18.04. I am trying to load a image Dataset but getting this error again and again........plz guide me to a better solution!!!!!,,0,deeplearning,2020-10-13
ixvqf5,[R] Adobe’s DL-Based ‘HDMatt’ Handles Image Details Thinner Than Hair,"Image matting plays a key role in image and video editing and composition. Although existing deep learning approaches can produce acceptable image matting results, their performance suffers in real-world applications, where the input images are mostly high resolution. To address this, a group of researchers from UIUC, Adobe Research and the University of Oregon have proposed HDMatt, the first deep learning-based image matting approach for high-resolution image inputs.

Here is a quick read: [Adobe’s DL-Based ‘HDMatt’ Handles Image Details Thinner Than Hair](https://syncedreview.com/2020/09/22/adobes-dl-based-hdmatt-handles-image-details-thinner-than-hair/)

The paper *High-Resolution Deep Image Matting* is on [Arxiv](https://arxiv.org/pdf/2009.06613.pdf). Notably, second author Ning Xu from Adobe Research was first author on the 2017 paper [*Deep Image Matting*](https://arxiv.org/pdf/1703.03872.pdf).",3,deeplearning,2020-10-13
ixv4f2,Hardware required for speaker verification model,"I would like to do a speaker verification model, what hardware would I need to have an acceptable model?

Apply contrast learning on spectrograms

Will I be able to do it on a gtx1060, or will I need a better graphics card?",2,deeplearning,2020-10-13
ixu64k,Use keras model from c++,,0,deeplearning,2020-10-13
ixrggj,Bounding box prediction with Yolo,"Hello, 

I finally understood how Yolo is predicting bounding boxes but I still have one question. How does the neural network devide the last layer between a classifier and a regressor ? Is it after the fully connected layer ? How do I program such a ""split"" with keras / tf ?",1,deeplearning,2020-10-13
ixrb6k,Binary crossentropy with Jacobian penality term in AutoEncoders,"I have been working on AutoEncoders to generate embeddings for a custom image dataset, esp i built convolutional autoencoder and tested with both MSE (mean squared error) and BCE (binary corssentropy) and noticed that BCE works better. I am planning to include penalty term esp referring to Contractive loss which is typically MSE + Jacobian matrix. But as i have seen BCE is better, wanted to use BCE with Jacobian penalty term. Anybody has experimented some thing like this and seen any benefit with this combination?. And i have noticed that when i use MSE, i can find out the MSE with list of axis to shrink the dimensions and accumulate with Jacobian. But when i tried to use BCE, it gives complete four dimensions data as output and not able to concatenate with Jacobian as Jacobian is built using latent space which is lower dimension.",1,deeplearning,2020-10-13
ixo019,How to use LSTM with softmax in pytorch,Im new in deep learning how can i use lstm with softmax or crossentropyloss or nlloss im trying to do text classification,0,deeplearning,2020-10-13
ixngxv,Numpy Crash Course - Building Powerful n-D Arrays with NumPy,"Numpy is a python library for performing large scale numerical computations. It is extremely useful, especially in machine learning. Let's look at what Numpy has to offer. [https://medium.com/manishmshiva/numpy-crash-course-building-powerful-n-dimensional-arrays-810edc87dcc7](https://medium.com/manishmshiva/numpy-crash-course-building-powerful-n-dimensional-arrays-810edc87dcc7)",1,deeplearning,2020-10-13
ixmvpd,Residual Network Car Drive Game using Tensorflow.js,"Hi! I recently uploaded this github repo, please let me some feedback. I hope you'll find it useful :)

[https://github.com/MCarlomagno/CarDrivingResNet](https://github.com/MCarlomagno/CarDrivingResNet)",3,deeplearning,2020-10-13
ixmmuy,Deconstructing the GPT-3 economy,,1,deeplearning,2020-10-13
ixm6yu,OCR in the Wild: SOTA in Text Detection and Recognition,"Check out this post to learn more about the **SOTA in scene text detection and recognition**: [https://www.sicara.ai/blog/ocr-text-detection-recognition](https://www.sicara.ai/blog/ocr-text-detection-recognition)

Deep learning has enabled a breakthrough in the field of OCR, making it possible to read complex text instances ""in the wild"".

3 papers are reviewed:

* Textsnake \[Long et al., 2018\], a text detection algorithm with the specificity of handling very complex text shapes.
* MORAN \[Luo et al., 2019\], a text recognition algorithm using a rectification network and the attention mechanism to correct and read complicated textboxes.
* FOTS \[Liu et al., 2018\], an end-to-end approach sharing the convolutions between the detection step and the recognition step to improve robustness and efficiency.",34,deeplearning,2020-10-13
ixkp3w,Question related to segmentation with very thin mask,"Hi, 

I am trying to do segmentation from a given  image. It is a binary classification problem where I am only interested to segment a single object.  However, my mask is quite imbalance and have a very small area compare to entire image.. If I take a patch of 512 by 512 crop, on average I get a mask size about 1% to 5% of the entire image. If I want to resize, I might lose the information which is not an option. 

Now, my current situation, I have tried Attention-Res-Unet with jaccard coefficient loss function. no luck so far, each time after training I am getting black mask (not detected mask ) .. accuracy is 0.96 which is misleading and really it need to be at least 99% as my mask is 1%. jaccard coefficient is around 0.6. Any thought, solution or tricks to tackle the problem. Thanks in advance!",1,deeplearning,2020-10-13
ixkkn3,Deep convolutional neural network techniques,"Am i right?
Is Deep convolutional neural network techniques are (1) convolution (2) Relu (pooling) (3) FC",1,deeplearning,2020-10-13
ixkgkx,A Look Through Guide on Semantic Segmentation and its Types,,1,deeplearning,2020-10-13
ixj12c,Confused between the variety of tools available,"Note : A Deep Learning Newbie here

I've been researching deep learning and the various tools available for a while now but I don't entirely understand the functional difference between them namely, Tf, Keras, Google Cloud ML, Amazon Rekognition etc. I know that there are more but could someone break these down on a **highlevel** and explain the differences between these and any other tools available? I'm not particularly looking at the differences between **how** they work but rather **what** they are exactly and how do they differ from one another. Thanks",5,deeplearning,2020-10-13
ixf6u9,Latest: A browser extension that finds code implementations for machine learning papers anywhere on the web!,,1,deeplearning,2020-10-13
ixdnqr,[R] UC Berkeley Reward-Free RL Beats SOTA Reward-Based RL,"A new paper from researchers at the University of California, Berkeley addresses this issue with Augmented Temporal Contrast (ATC), a new unsupervised learning (UL) task for learning visual representations agnostic to rewards and without degrading the control policy.

Here is a quick read: [UC Berkeley Reward-Free RL Beats SOTA Reward-Based RL](https://syncedreview.com/2020/09/21/uc-berkeley-reward-free-rl-beats-sota-reward-based-rl/)

The paper *Decoupling Representation Learning from Reinforcement Learning* is on [arXiv](https://arxiv.org/pdf/2009.08319.pdf).",1,deeplearning,2020-10-13
ixbssf,Deep Learning Final Year Project Ideas,"Can anyone suggest me some project ideas in the realm of deep learning or deep reinforcement learning. I am looking for application kind of projects with regards to deep reinforcement learning where the application field is computer science. So solving a problem in computer science using deep reinforcement learning or male a better system using deep reinforcement learning.

Or, algorithmic projects in plain deep learning. Improving deep learning techniques or solving problems in deep learning related algorithms.

I need it for my final year project, and I want it to be something publishable once complete.",0,deeplearning,2020-10-13
ix6qiq,[HELP] SOTA algorithms or models to detect graphics from video?,"Hi 👋

I'm working on a CV problem where I've to detect graphics from sports videos, say cricket.

I'm taking this typical example of cricket, whenever a four is hit there's some random graphic which comes in the middle of the screen for a sec and then disappear.

I've been searching for it for sometime but couldn't find any proper way.

Are there any such methods, algorithms or sota models which could be applied for this problem domain?

Any help is appreciated.

Thanks",1,deeplearning,2020-10-13
ix4m8i,Smartphone Videos Produce Highly Realistic 3D Face Reconstructions,,66,deeplearning,2020-10-13
ix3olg,Open Source software meets Super Resolution,"Introducing an accurate and light-weight deep network for video  super-resolution upscaling, running on a completely open source software  stack using Panfrost, the free and open-source graphics driver for Mali  GPUs.

[https://www.collabora.com/news-and-blog/blog/2020/09/21/open-source-meets-super-resolution-part-1/](https://www.collabora.com/news-and-blog/blog/2020/09/21/open-source-meets-super-resolution-part-1/)",2,deeplearning,2020-10-13
ix2yv0,Google Introduces RigL Algorithm For Training Sparse Neural Networks (Paper &amp; Github link included),"Most of the AI models these days are based on Artificial Neural Networks. These neural networks consist of a system of Artificial Neurons linked together by software connections. These connections connect different inputs to different outputs by passing data, performing mathematical algorithms to generate the best possible result. There are many data pathways for the same, but only a fraction of those are used in many AI models, and the others are left unused, taking up a lot of space. This can cause the model to slow down.

To overcome this problem, Google recently released RigL, an algorithm that can make Artificial Intelligence models based on Neural Networks more efficient. It achieves it by eliminating the useless connections by making strategic tweaks to the neural network’s structure during the model’s training phase.

**Summary:** [https://www.marktechpost.com/2020/09/21/google-introduces-rigl-algorithm-for-training-sparse-neural-networks/](https://www.marktechpost.com/2020/09/21/google-introduces-rigl-algorithm-for-training-sparse-neural-networks/) 

**Paper:** [https://arxiv.org/pdf/1911.11134.pdf](https://arxiv.org/pdf/1911.11134.pdf) 

**Github:** [https://github.com/google-research/rigl](https://github.com/google-research/rigl) 

&amp;#x200B;

https://i.redd.it/8czhf9j1vio51.gif",6,deeplearning,2020-10-13
ix0wdm,"Asking for friend wishing to switch to Deep Learning: recent theoretical physics PhD, good but not advanced skills in python and statistics.","Some  data science work experience. Looking for suitable projects to build  resume. Also, where should one look for mentors? Thanks",1,deeplearning,2020-10-13
ix09hk,Is there a neural network which can represent both link and also location information of graph nodes?,"Hello,

I'm searching for neural networks which can represent paths on geographical maps.

For example, the inputs are as follows.

**Node location information**

|X-axis|Y-axis|Node name|
|:-|:-|:-|
|10|11|A|
|5|6|B|
|1|10|C|

**Edge information**

|Edge-type|Src|Dst|
|:-|:-|:-|
|1|A|B|
|2|A|C|
|3|B|C|

&amp;#x200B;

Typical graph neural networks which are based on either adjacency matrices or translation metrics do not incorporate the location information of nodes. Although location information can be represented as edge types by incorporating angles or distances, the number of types would become very large soon in the naive approach.

(not sure) It can be related to ""Unveiling the predictive power of static structure in glassy systems"", unfortunately, this paper is not available for me.

Could you introduce the research can represent both location and link information of nodes?",1,deeplearning,2020-10-13
iwznru,Something for the beginners and something for the enthusiasts,,2,deeplearning,2020-10-13
iwxfgc,[D] what does you data input pipeline look like?,,0,deeplearning,2020-10-13
iww40v,Google Introduces A New Algorithm For Training Sparse Neural Networks,,41,deeplearning,2020-10-13
iwv0f8,GPU for Deep Learning,"Which GPU should I go for to build a Deep Learning PC? 
* 3090 has almost everything better than Titan, but Titan has 576 tensor cores whereas 3090 has 328.

[View Poll](https://www.reddit.com/poll/iwv0f8)",6,deeplearning,2020-10-13
iwuo0a,Capsule Network in 75 lines,,2,deeplearning,2020-10-13
iwslx6,Learning to design neural network architectures.,"I want to learn how make my own neural nets. I have used mobilenet, inception resnet etc through transfer learning for projects however I would like to learn how to go about to design and build my own architectures and what to look for while designing one. I do know how to use keras as well as tensorflow to make a model and made them blindly to some degree of success  and also the basics of ML like the math and theory but I cant make a connection on how to use that to actually design my own.. please could you suggest some books or lectures to learn it properly",23,deeplearning,2020-10-13
iwnxux,Toward Efficient Learning: Model-Agnostic Meta-Learning for Fast Adaptation of Deep Networks,,1,deeplearning,2020-10-13
iwkrfm,Can deep learning algorithms be sped up with quantum computers?,"Hi, are there any ways to speed up deep learning model training algorithms such as backpropagation with quantum computers? Or is it just not a fit application of their capabilities?",6,deeplearning,2020-10-13
iwk50x,DCGAN 3d models training,,26,deeplearning,2020-10-13
iwfcm1,Interpolating between all American Presidents using Deep Learning StyleGAN2,,14,deeplearning,2020-10-13
iwebez,Using PyTorch to build neural network attacks,"Hey guys! I was recently working on neural network attacks and defenses, and will like to share with you an article I wrote on how to implement them in PyTorch. Feel free to have a look:

[https://towardsdatascience.com/adversarial-attack-and-defense-on-neural-networks-in-pytorch-82b5bcd9171](https://towardsdatascience.com/adversarial-attack-and-defense-on-neural-networks-in-pytorch-82b5bcd9171)",12,deeplearning,2020-10-13
iwczxf,VGG vs ResNet vs EfficientNet,"Hi, I'm just starting to learn about SOTA CNNs and I'm wondering which is the best model to use for training facial expression transfer. I can't seem to find any resources about the difference between these models in terms of performance",5,deeplearning,2020-10-13
iwcp5m,Creating 3D scenes of places using only photos from the internet!,,3,deeplearning,2020-10-13
iwbxqe,"What is the most simplest way to convert an ai program into a website, totally a simple one [D]","I need it for a simple ai application with very less amount of users a portfolio kind of thing. Program is written in python, tensorflow, scikit learn and is stored locally and currently I dont play to shift it to any cloud based options like azure, etc. Prefer the option to be cheapest",2,deeplearning,2020-10-13
iwbmpf,"New to deep learning, trying to understand how to approach a network I have in mind","Hey all! I've been fascinated with machine/deep learning for years now, and am finally taking my first steps into this world. I want to take a stab at creating a stock trading AI, and came across [this fantastic article](https://towardsdatascience.com/aifortrading-2edd6fac689d) that outlines one approach. The goal of the network described in the article is to predict the price on a day-to-day basis, which seems like an obvious starting point. It uses a LSTM network as the generator in a GAN. The first image in the article outlines how the approach is structured.

The thing is, I'm not very interested in predicting the stock price. My ideal system would instead output a ""conviction"" value for a variety of financial instruments. These would include holding cash, stocks, and options (both calls and puts, likely with a variety of strike prices and time horizons). A higher value would represent a stronger conviction that holding that financial instrument would be more profitable than not. The network would not be optimizing for raw numerical accuracy, but profitability. There would be non-machine learning based logic that translates the conviction values into actions (buy/sell/hold), with the outcome of those actions determining profitability.

An example of the conviction values it might return for a given day are as follows:

* Cash: 20%
* Stock: 50%
* Calls: 25%
* Puts: 10%

If I look at this, it tells me that the network thinks the stock is more likely to go up than not (stock and calls having higher percentages than cash and puts), but that it thinks there's enough of a chance it'll go down that buying some puts to hedge is worth their loss in value if it goes up instead. What to do with this information will depend on each person individually, but let's assume the action logic is pretty basic and allocates the funds proportionally based on the percentages. One note: the percentages don't have to add up to 100%. If it is 100% convinced the stock will go up, the conviction for both stock and calls would be 100%, while cash and puts would be 0%. In that case, with this super naive logic, it would split funds 50/50 between stocks and calls.

That leads me to my question: what would you use as the baseline-truth that the LSTM generator output gets compared to in the discriminator? With stock price it's obviously just the real stock price, but when we're talking about profitability across several financial instruments it's less so. My first thought is to use a 0/1 value based on whether or not holding that instrument through the next day was actually profitable, but it's important to me that the conviction value isn't just a binary YES/NO. I'm not familiar enough with GANs to know if it's possible to have it optimize towards an answer that doesn't necessarily match the baseline-truth it's being discriminated against. My gut reaction based on the little I know tells me it wouldn't be possible. I'm also not familiar enough with deep learning generally to know if another training methodology would be more appropriate in my situation.

How would you approach this?

EDIT: Been mulling this over a bit more and realized that I need to nail down what my ideal end result would be. I said I'd want it to optimize for profit, which means that I would need to calculate the maximum potential profit for each day and use that value as the baseline-truth that the results from the LSTM generator gets compared to. So, we can imagine a day where the stock went up 2%. If going all in on calls would result in $1 more in profit compared to going all in on stock, the maximum potential profit value for that day would be based on going 100% in on calls and 0% in on stocks. As a result, the perfectly optimal conviction values from the LSTM generator would be:

* Cash: 0%
* Stock: 0%
* Calls: 100%
* Puts: 0%

Now, the chance of making a model that predicts/matches this perfectly in a situation where you'd make $1 more going all in on calls is essentially 0. The next best case scenario is the generator acknowledging the fact that it can't predict it perfectly by giving calls a much lower weight and shares a higher weight (the reason being, calls generally lose value every single day you hold them if all else is equal and the price doesn't change). During training, it will run into situations like I described above where there's almost equal profit potential from holding stocks and calls. When it makes the wrong judgement call and says that going all in on calls is the way to go when stocks were actually better, the discrepancy in profit will be higher since the calls actually lost value. Over the training period, it should learn that it needs to be more conservative and allocate more funds to stocks in those situations. In other situations when it's REALLY sure the stock will go up, it will learn that it's safer/more profitable to prioritize calls over stock.

Actually, instead of calculating an actual dollar value and using that as the base-line truth, it should be enough to instead choose one financial instrument to have a conviction value of 1 for that day (representing that it's the most profitable instrument), while all the others get a value of 0. This is different to what I said in my original post, which was that I would set the conviction value for each instrument that would produce some profit to 1. In that situation the sum of the convictions could very well be over 100%; whereas, if only one instrument is given a value of 1 in the baseline-truth data, the sum of the conviction values should be close to 100%.

Now that I've written that out, I feel like I have a clearer path forward. If anything I said sounds wrong, please let me know. It's based off of assumptions I'm making about how GANs work, without having any real experience with them.",5,deeplearning,2020-10-13
iw9y4o,Keras and object detection,"Hello, 
I would like to build an object detection algorithm with Keras. I found the Yolo algorithm and I am really interested in implementing it. Do you have any advices on where to start , or should I look for other models ? I just want to avoid importing the model from a lib, I really want to do it myself !",1,deeplearning,2020-10-13
iw7uuy,Hello World!!! I built a Course on Udemy for applying cutting-edge Deep Learning Neural Networks to Flutter applications using Python &amp; Flutter. (FREE FOR LIMITED TIME),"In this course I will teach you 6 apps including:


· A simple Neural Network that can understand Sign Language

· A simple Neural Network that can detect Dogs and Cats

· How to build a Neural Network in Python that can detect Flowers and export it into Flutter Application with 92% accuracy

· How to build a Neural Network in Python that can detect 131 Fruits &amp; Vegetables and export into Flutter App!

· How to build an app that can perform Sentiment Analysis, aka an A.I. that can understand emotions behind a text!

· How to build an A.I. that can understand an image and generate a sentence that represents the image! (Image-To-Text, this app is very useful for blind people!)

· An app that can Generate a realistic looking shoe based off a Shoe Sketch the user draws in a Flutter Application! (Pix2Pix, Youtubers like PewDiePie have made videos on it! Really cool algorithm)


If you are passionate about deep learning and want to apply deep learning algorithms to mobile apps then this course is perfect for you!


https://www.udemy.com/course/flutter-deeplearning-course/?couponCode=DCE998986007C25EE77F",38,deeplearning,2020-10-13
ivzbug,"A new browser extension for finding code for ML research papers on the internet (on Google, Arxiv, Scholar, Twitter, Github)",,0,deeplearning,2020-10-13
ivrnoz,Follow r/GeometricDeepLearning for the latest and greatest in ML for Graphs and Manifolds!,,7,deeplearning,2020-10-13
ivqssg,I've been struggling,I've been struggling to use LSTM with softmax or crossentropyloss in pytorch anyone has a good tutorial or example?,1,deeplearning,2020-10-13
ivp8y0,Beginner-friendly ML projects for 2020 (By Current Microsoft Engineer - NOT an ex-Google engineer),,49,deeplearning,2020-10-13
ivnq4m,SUPERNOVA: A Deep Learning Based Image/Video Quality Enhancement Platform,"Both demand and accessibility for image and video media services is increasing day-by-day. Several IPTV/OTT based media services are becoming available through the internet. Media content quality is an essential topic of concern as there is still a lot of low-quality media content that needs to be enhanced. 

Degradation of image/ video content is mainly due to the quantization during the lengthy coding process. This degradation becomes significantly worse as customers are located where the transmission bandwidth becomes narrower because the bitrate for the encoded media contents’ bitstream becomes lower in this environment. Another degradation case is when the spatial resolution for the delivered image/video is too small for customers to watch with their FHD or 4-K display. When this resolution degradation occurs due to instantaneous bandwidth constraints, the image/video will soon regain its original resolution. Still, the resolution degradation continues if the whole content in a CDN (Contents Delivery Network) or H/E Server are only stored with low resolution or low bitrate. 

Full Paper Summary: [https://www.marktechpost.com/2020/09/18/supernova-a-deep-learning-based-image-video-quality-enhancement-platform/](https://www.marktechpost.com/2020/09/18/supernova-a-deep-learning-based-image-video-quality-enhancement-platform/)

Paper Download: https://www.ibc.org/download?ac=14555",9,deeplearning,2020-10-13
ivn79x,Image Recognition Model,"Neural Network Newbie but need advice.

Background - I'm looking to develop an Object Detection and Image Recognition model which would identify the product in the image. I'm not going to do any of the coding/technical bits of developing this model myself and would have to hire someone to do so. I have a large dataset (1 million + photos) of photos for training as well. I understand that I cannot use pre-trained networks because my need is custom (pls correct me if I'm wrong)

My question here is, how long would it take for an engineer with a ML background to create this model? Does the coding need to be done from scratch or is there an alternative? Does anyone suggest using open source development tools like Tensorflow/Keras or should I use AWS/Google ML for end to end development.

Thank you.",3,deeplearning,2020-10-13
ivjuv5,Should one treat bike rider and pedestrian as the same class for traffic datasets?,"I am working on classified vehicle count. I have multiple vehicles and a pedestrian class in my dataset. Merging bike riders and pedestrian class concerns me because of different orientations. But on the other hand, if don't merge them I encounter multiple false positives of bike riders as pedestrians. Also, if I annotate bike riders as pedestrians or bike riders. It almost takes some part of bike detection and accuracy for bike detection drops.Â 

There are 30000 instances for pedestrians and 28000 for bike riders.

If someone has encountered such inter-class dependency. I would love an opinion on this matter regarding how should I annotate bikes, bike riders, and pedestrians to get the most efficient results.",0,deeplearning,2020-10-13
ivc8qu,"Chrome/Firefox Extension for showing *code* for ML/AI research papers directly on Google, Arxiv, Scholar, Twitter, Github, and more!!",,2,deeplearning,2020-10-13
ivbxsl,Protobuf errors when building Caffe?,"I am using Ubuntu 16, Python 3, CUDA 10.1, and Tensorflow 2.3. I used git clone on the Caffe github repo, then did

    cd build
    cmake ..
    make all

I got a bunch of protobuf errors:

	~/Downloads/caffe/build$ make clean
	~/Downloads/caffe/build$ make all
	[  1%] Running C++/Python protocol buffer compiler on /home/me/Downloads/caffe/src/caffe/proto/caffe.proto
	Scanning dependencies of target caffeproto
	[  1%] Building CXX object src/caffe/CMakeFiles/caffeproto.dir/__/__/include/caffe/proto/caffe.pb.cc.o
	In file included from /usr/include/c++/5/atomic:38:0,
	               from /home/me/anaconda3/include/google/protobuf/io/coded_stream.h:115,
	               from /home/me/Downloads/caffe/build/include/caffe/proto/caffe.pb.h:23,
	               from /home/me/Downloads/caffe/build/include/caffe/proto/caffe.pb.cc:4:
	/usr/include/c++/5/bits/c++0x_warning.h:32:2: error: #error This file requires compiler and library support for the ISO C++ 2011 standard. This support must be enabled with the -std=c++11 or -std=gnu++11 compiler options.
	#error This file requires compiler and library support \
	^
	In file included from /home/me/anaconda3/include/google/protobuf/stubs/macros.h:34:0,
	               from /home/me/anaconda3/include/google/protobuf/stubs/common.h:46,
	               from /home/me/anaconda3/include/google/protobuf/io/coded_stream.h:141,
	               from /home/me/Downloads/caffe/build/include/caffe/proto/caffe.pb.h:23,
	               from /home/me/Downloads/caffe/build/include/caffe/proto/caffe.pb.cc:4:
	/home/me/anaconda3/include/google/protobuf/stubs/port.h:114:2: error: #error ""Protobuf requires at least C++11.""
	#error ""Protobuf requires at least C++11.""
	^
	/home/me/anaconda3/include/google/protobuf/stubs/port.h:120:7: error: expected nested-name-specifier before ‘ConstStringParam’
	using ConstStringParam = const std::string &amp;;
	     ^
	/home/me/anaconda3/include/google/protobuf/stubs/port.h:129:9: error: ‘uint8_t’ does not name a type
	typedef uint8_t uint8;
	       ^
	/home/me/anaconda3/include/google/protobuf/stubs/port.h:130:9: error: ‘uint16_t’ does not name a type
	typedef uint16_t uint16;
	       ^
	/home/me/anaconda3/include/google/protobuf/stubs/port.h:131:9: error: ‘uint32_t’ does not name a type
	typedef uint32_t uint32;
	       ^
	/home/me/anaconda3/include/google/protobuf/stubs/port.h:132:9: error: ‘uint64_t’ does not name a type
	typedef uint64_t uint64;
	       ^
	/home/me/anaconda3/include/google/protobuf/stubs/port.h:138:14: error: ‘uint32’ does not name a type
	static const uint32 kuint32max = 0xFFFFFFFFu;
	            ^
	/home/me/anaconda3/include/google/protobuf/stubs/port.h:139:14: error: ‘uint64’ does not name a type
	static const uint64 kuint64max = PROTOBUF_ULONGLONG(0xFFFFFFFFFFFFFFFF);
	...
	        ^
	/home/me/anaconda3/include/google/protobuf/stubs/port.h:355:10: error: ‘uint64’ does not name a type
	 static uint64 ToHost64(uint64 x) { return bswap_64(x); }
	        ^
	/home/me/anaconda3/include/google/protobuf/stubs/port.h:375:10: error: ‘uint16’ does not name a type
	 static uint16 Load16(const void *p) {
	        ^
	/home/me/anaconda3/include/google/protobuf/stubs/port.h:379:32: error: ‘uint16’ has not been declared
	 static void Store16(void *p, uint16 v) {
	                              ^
	/home/me/anaconda3/include/google/protobuf/stubs/port.h:383:10: error: ‘uint32’ does not name a type
	 static uint32 Load32(const void *p) {
	        ^
	/home/me/anaconda3/include/google/protobuf/stubs/port.h:387:32: error: ‘uint32’ has not been declared
	 static void Store32(void *p, uint32 v) {
	                              ^
	/home/me/anaconda3/include/google/protobuf/stubs/port.h:391:10: error: ‘uint64’ does not name a type
	 static uint64 Load64(const void *p) {
	        ^
	/home/me/anaconda3/include/google/protobuf/stubs/port.h:395:32: error: ‘uint64’ has not been declared
	 static void Store64(void *p, uint64 v) {
	                              ^
	/home/me/anaconda3/include/google/protobuf/stubs/port.h: In static member function ‘static void google::protobuf::BigEndian::Store16(void*, int)’:
	/home/me/anaconda3/include/google/protobuf/stubs/port.h:380:45: error: ‘FromHost16’ was not declared in this scope
	   GOOGLE_UNALIGNED_STORE16(p, FromHost16(v));
	                                           ^
	/home/me/anaconda3/include/google/protobuf/stubs/port.h: In static member function ‘static void google::protobuf::BigEndian::Store32(void*, int)’:
	/home/me/anaconda3/include/google/protobuf/stubs/port.h:388:45: error: ‘FromHost32’ was not declared in this scope
	   GOOGLE_UNALIGNED_STORE32(p, FromHost32(v));
	                                           ^
	/home/me/anaconda3/include/google/protobuf/stubs/port.h: In static member function ‘static void google::protobuf::BigEndian::Store64(void*, int)’:
	/home/me/anaconda3/include/google/protobuf/stubs/port.h:396:45: error: ‘FromHost64’ was not declared in this scope
	   GOOGLE_UNALIGNED_STORE64(p, FromHost64(v));
	                                           ^
	In file included from /home/me/anaconda3/include/google/protobuf/stubs/stringpiece.h:151:0,
	               from /home/me/anaconda3/include/google/protobuf/stubs/common.h:49,
	               from /home/me/anaconda3/include/google/protobuf/io/coded_stream.h:141,
	               from /home/me/Downloads/caffe/build/include/caffe/proto/caffe.pb.h:23,
	               from /home/me/Downloads/caffe/build/include/caffe/proto/caffe.pb.cc:4:
	/home/me/anaconda3/include/google/protobuf/stubs/hash.h: At global scope:
	/home/me/anaconda3/include/google/protobuf/stubs/hash.h:50:31: error: expected template-name before ‘&lt;’ token
	struct hash : public std::hash&lt;Key&gt; {};
	                             ^
	/home/me/anaconda3/include/google/protobuf/stubs/hash.h:50:31: error: expected ‘{’ before ‘&lt;’ token
	/home/me/anaconda3/include/google/protobuf/stubs/hash.h:50:31: error: expected unqualified-id before ‘&lt;’ token
	In file included from /home/me/anaconda3/include/google/protobuf/stubs/common.h:49:0,
	               from /home/me/anaconda3/include/google/protobuf/io/coded_stream.h:141,
	               from /home/me/Downloads/caffe/build/include/caffe/proto/caffe.pb.h:23,
	               from /home/me/Downloads/caffe/build/include/caffe/proto/caffe.pb.cc:4:
	/home/me/anaconda3/include/google/protobuf/stubs/stringpiece.h: In constructor ‘google::protobuf::StringPiece::StringPiece()’:
	/home/me/anaconda3/include/google/protobuf/stubs/stringpiece.h:211:24: error: ‘nullptr’ was not declared in this scope
	 StringPiece() : ptr_(nullptr), length_(0) {}
	                      ^
	/home/me/anaconda3/include/google/protobuf/stubs/stringpiece.h: In constructor ‘google::protobuf::StringPiece::StringPiece(const char*)’:
	/home/me/anaconda3/include/google/protobuf/stubs/stringpiece.h:215:16: error: ‘nullptr’ was not declared in this scope
	   if (str != nullptr) {
	              ^
	/home/me/anaconda3/include/google/protobuf/stubs/stringpiece.h: In member function ‘void google::protobuf::StringPiece::clear()’:
	/home/me/anaconda3/include/google/protobuf/stubs/stringpiece.h:252:12: error: ‘nullptr’ was not declared in this scope
	   ptr_ = nullptr;
	          ^
	/home/me/anaconda3/include/google/protobuf/stubs/stringpiece.h: In member function ‘void google::protobuf::StringPiece::set(const char*)’:
	/home/me/anaconda3/include/google/protobuf/stubs/stringpiece.h:264:16: error: ‘nullptr’ was not declared in this scope
	   if (str != nullptr)
	              ^
	/home/me/anaconda3/include/google/protobuf/stubs/stringpiece.h: In member function ‘std::__cxx11::string google::protobuf::StringPiece::ToString() const’:
	/home/me/anaconda3/include/google/protobuf/stubs/stringpiece.h:311:17: error: ‘nullptr’ was not declared in this scope
	   if (ptr_ == nullptr) return """";
	               ^
	In file included from /home/me/anaconda3/include/google/protobuf/io/coded_stream.h:141:0,
	               from /home/me/Downloads/caffe/build/include/caffe/proto/caffe.pb.h:23,
	               from /home/me/Downloads/caffe/build/include/caffe/proto/caffe.pb.cc:4:
	/home/me/anaconda3/include/google/protobuf/stubs/common.h: In function ‘void google::protobuf::internal::StrongReference(const T&amp;)’:
	/home/me/anaconda3/include/google/protobuf/stubs/common.h:167:17: error: ‘unused’ does not name a type
	 auto volatile unused = &amp;var;
	               ^
	/home/me/anaconda3/include/google/protobuf/stubs/common.h:168:10: error: ‘unused’ was not declared in this scope
	 (void)&amp;unused;  // Use address to avoid an extra load of ""unused"".
	        ^
	In file included from /home/me/anaconda3/include/google/protobuf/io/coded_stream.h:142:0,
	               from /home/me/Downloads/caffe/build/include/caffe/proto/caffe.pb.h:23,
	               from /home/me/Downloads/caffe/build/include/caffe/proto/caffe.pb.cc:4:
	/home/me/anaconda3/include/google/protobuf/stubs/logging.h: In function ‘T* google::protobuf::internal::CheckNotNull(const char*, int, const char*, T*)’:
	/home/me/anaconda3/include/google/protobuf/stubs/logging.h:167:14: error: ‘nullptr’ was not declared in this scope
	 if (val == nullptr) {
	            ^
	In file included from /home/me/anaconda3/include/google/protobuf/io/coded_stream.h:143:0,
	               from /home/me/Downloads/caffe/build/include/caffe/proto/caffe.pb.h:23,
	               from /home/me/Downloads/caffe/build/include/caffe/proto/caffe.pb.cc:4:
	/home/me/anaconda3/include/google/protobuf/stubs/strutil.h: At global scope:
	/home/me/anaconda3/include/google/protobuf/stubs/strutil.h:354:17: error: ‘uint32’ does not name a type
	PROTOBUF_EXPORT uint32 strtou32_adaptor(const char* nptr, char** endptr,
	               ^
	/home/me/anaconda3/include/google/protobuf/stubs/strutil.h:364:8: error: ‘uint32’ does not name a type
	inline uint32 strtou32(const char *nptr, char **endptr, int base) {
	      ^
	In file included from /home/me/anaconda3/include/google/protobuf/stubs/common.h:46:0,
	               from /home/me/anaconda3/include/google/protobuf/io/coded_stream.h:141,
	               from /home/me/Downloads/caffe/build/include/caffe/proto/caffe.pb.h:23,
	               from /home/me/Downloads/caffe/build/include/caffe/proto/caffe.pb.cc:4:
	/home/me/anaconda3/include/google/protobuf/stubs/strutil.h: In function ‘google::protobuf::int64 google::protobuf::strto64(const char*, char**, int)’:
	...
	     ^
	/home/me/anaconda3/include/google/protobuf/stubs/strutil.h:519:33: error: ‘uint64’ was not declared in this scope
	inline char* FastUInt64ToBuffer(uint64 i, char* buffer) {
	                               ^
	/home/me/anaconda3/include/google/protobuf/stubs/strutil.h:519:43: error: expected primary-expression before ‘char’
	inline char* FastUInt64ToBuffer(uint64 i, char* buffer) {
	                                         ^
	/home/me/anaconda3/include/google/protobuf/stubs/strutil.h:594:3: error: ‘uint64’ does not name a type
	 uint64 value;
	 ^
	/home/me/anaconda3/include/google/protobuf/stubs/strutil.h: In constructor ‘google::protobuf::strings::Hex::Hex(Int, google::protobuf::strings::PadSpec)’:
	/home/me/anaconda3/include/google/protobuf/stubs/strutil.h:606:5: error: ‘value’ was not declared in this scope
	   value = sizeof(v) == 1 ? static_cast&lt;uint8&gt;(v)
	   ^
	/home/me/anaconda3/include/google/protobuf/stubs/strutil.h:606:42: error: ‘uint8’ does not name a type
	   value = sizeof(v) == 1 ? static_cast&lt;uint8&gt;(v)
	                                        ^
	/home/me/anaconda3/include/google/protobuf/stubs/strutil.h:607:42: error: ‘uint16’ does not name a type
	         : sizeof(v) == 2 ? static_cast&lt;uint16&gt;(v)
	                                        ^
	/home/me/anaconda3/include/google/protobuf/stubs/strutil.h:608:42: error: ‘uint32’ does not name a type
	         : sizeof(v) == 4 ? static_cast&lt;uint32&gt;(v)
	                                        ^
	/home/me/anaconda3/include/google/protobuf/stubs/strutil.h:609:25: error: ‘uint64’ does not name a type
	         : static_cast&lt;uint64&gt;(v);
	                       ^
	/home/me/anaconda3/include/google/protobuf/stubs/strutil.h: In constructor ‘google::protobuf::strings::AlphaNum::AlphaNum(unsigned int)’:
	/home/me/anaconda3/include/google/protobuf/stubs/strutil.h:627:55: error: ‘google::protobuf::FastUInt32ToBufferLeft’ cannot be used as a function
	       piece_size_(FastUInt32ToBufferLeft(u32, digits) - &amp;digits[0]) {}
	                                                     ^
	/home/me/anaconda3/include/google/protobuf/stubs/strutil.h: In constructor ‘google::protobuf::strings::AlphaNum::AlphaNum(long long unsigned int)’:
	/home/me/anaconda3/include/google/protobuf/stubs/strutil.h:633:55: error: ‘google::protobuf::FastUInt64ToBufferLeft’ cannot be used as a function
	       piece_size_(FastUInt64ToBufferLeft(u64, digits) - &amp;digits[0]) {}
	                                                     ^
	/home/me/anaconda3/include/google/protobuf/stubs/strutil.h: In constructor ‘google::protobuf::strings::AlphaNum::AlphaNum(long unsigned int)’:
	/home/me/anaconda3/include/google/protobuf/stubs/strutil.h:643:55: error: ‘google::protobuf::FastUInt64ToBufferLeft’ cannot be used as a function
	       piece_size_(FastUInt64ToBufferLeft(u64, digits) - &amp;digits[0]) {}
	                                                     ^
	/home/me/anaconda3/include/google/protobuf/stubs/strutil.h: At global scope:
	/home/me/anaconda3/include/google/protobuf/stubs/strutil.h:790:30: error: ‘uint64’ was not declared in this scope
	PROTOBUF_EXPORT string ToHex(uint64 num);
	                            ^
	/home/me/anaconda3/include/google/protobuf/stubs/strutil.h:864:30: error: ‘google::protobuf::IsValidCodePoint’ declared as an ‘inline’ variable
	inline bool IsValidCodePoint(uint32 code_point) {
	                            ^
	/home/me/anaconda3/include/google/protobuf/stubs/strutil.h:864:30: error: ‘uint32’ was not declared in this scope
	/home/me/anaconda3/include/google/protobuf/stubs/strutil.h:864:49: error: expected ‘,’ or ‘;’ before ‘{’ token
	inline bool IsValidCodePoint(uint32 code_point) {
	                                               ^
	/home/me/anaconda3/include/google/protobuf/stubs/strutil.h:876:38: error: ‘uint32’ was not declared in this scope
	PROTOBUF_EXPORT int EncodeAsUTF8Char(uint32 code_point, char* output);
	                                    ^
	/home/me/anaconda3/include/google/protobuf/stubs/strutil.h:876:57: error: expected primary-expression before ‘char’
	PROTOBUF_EXPORT int EncodeAsUTF8Char(uint32 code_point, char* output);
	                                                       ^
	/home/me/anaconda3/include/google/protobuf/stubs/strutil.h:876:69: error: expression list treated as compound expression in initializer [-fpermissive]
	PROTOBUF_EXPORT int EncodeAsUTF8Char(uint32 code_point, char* output);
	                                                                   ^
	In file included from /home/me/Downloads/caffe/build/include/caffe/proto/caffe.pb.h:23:0,
	               from /home/me/Downloads/caffe/build/include/caffe/proto/caffe.pb.cc:4:
	/home/me/anaconda3/include/google/protobuf/io/coded_stream.h:189:35: error: ‘uint8’ does not name a type
	 explicit CodedInputStream(const uint8* buffer, int size);
	                                 ^
	/home/me/anaconda3/include/google/protobuf/io/coded_stream.h:228:27: error: ‘uint32’ has not been declared
	 bool ReadLittleEndian32(uint32* value);
	                         ^
	/home/me/anaconda3/include/google/protobuf/io/coded_stream.h:230:27: error: ‘uint64’ has not been declared
	 bool ReadLittleEndian64(uint64* value);
	                         ^
	/home/me/anaconda3/include/google/protobuf/io/coded_stream.h:235:16: error: ‘uint8’ does not name a type
	 static const uint8* ReadLittleEndian32FromArray(const uint8* buffer,
	...
	error: ‘cur_’ was not declared in this scope
	 bool Skip(int count) { return impl_.Skip(count, &amp;cur_); }
	                                                  ^
	/home/me/anaconda3/include/google/protobuf/io/coded_stream.h: In member function ‘bool google::protobuf::io::CodedOutputStream::GetDirectBufferPointer(void**, int*)’:
	/home/me/anaconda3/include/google/protobuf/io/coded_stream.h:1090:54: error: ‘cur_’ was not declared in this scope
	   return impl_.GetDirectBufferPointer(data, size, &amp;cur_);
	...
	                                           ^
	/home/me/anaconda3/include/google/protobuf/io/coded_stream.h: In static member function ‘static bool google::protobuf::io::CodedOutputStream::IsDefaultSerializationDeterministic()’:
	/home/me/anaconda3/include/google/protobuf/io/coded_stream.h:1235:12: error: ‘default_serialization_deterministic_’ was not declared in this scope
	   return default_serialization_deterministic_.load(
	          ^
	/home/me/anaconda3/include/google/protobuf/io/coded_stream.h:1236:16: error: ‘memory_order_relaxed’ is not a member of ‘std’
	              std::memory_order_relaxed) != 0;
	              ^
	/home/me/anaconda3/include/google/protobuf/io/coded_stream.h: In member function ‘void google::protobuf::io::CodedOutputStream::SetCur(int*)’:
	/home/me/anaconda3/include/google/protobuf/io/coded_stream.h:1243:29: error: ‘cur_’ was not declared in this scope
	 void SetCur(uint8* ptr) { cur_ = ptr; }
	                           ^
	/home/me/anaconda3/include/google/protobuf/io/coded_stream.h: In static member function ‘static void google::protobuf::io::CodedOutputStream::SetDefaultSerializationDeterministic()’:
	/home/me/anaconda3/include/google/protobuf/io/coded_stream.h:1261:5: error: ‘default_serialization_deterministic_’ was not declared in this scope
	   default_serialization_deterministic_.store(true, std::memory_order_relaxe
	   ^
	/home/me/anaconda3/include/google/protobuf/io/coded_stream.h:1261:54: error: ‘memory_order_relaxed’ is not a member of ‘std’
	   default_serialization_deterministic_.store(true, std::memory_order_relaxe
	                                                    ^
	/home/me/anaconda3/include/google/protobuf/io/coded_stream.h: At global scope:
	/home/me/anaconda3/include/google/protobuf/io/coded_stream.h:1270:44: error: ‘google::protobuf::io::CodedInputStream::ReadVarint32’ declared as an ‘inline’ variable
	inline bool CodedInputStream::ReadVarint32(uint32* value) {
	                                          ^
	/home/me/anaconda3/include/google/protobuf/io/coded_stream.h:1270:44: error: ‘bool google::protobuf::io::CodedInputStream::ReadVarint32’ is not a static data member of ‘class google::protobuf::io::CodedInputStream’
	/home/me/anaconda3/include/google/protobuf/io/coded_stream.h:1270:44: error: ‘uint32’ was not declared in this scope
	/home/me/anaconda3/include/google/protobuf/io/coded_stream.h:1270:52: error: ‘value’ was not declared in this scope
	inline bool CodedInputStream::ReadVarint32(uint32* value) {
	                                                  ^
	/home/me/anaconda3/include/google/protobuf/io/coded_stream.h:1270:59: error: expected ‘,’ or ‘;’ before ‘{’ token
	inline bool CodedInputStream::ReadVarint32(uint32* value) {
	                                                         ^
	In file included from /home/me/anaconda3/include/google/protobuf/io/coded_stream.h:1712:0,
	               from /home/me/Downloads/caffe/build/include/caffe/proto/caffe.pb.h:23,
	               from /home/me/Downloads/caffe/build/include/caffe/proto/caffe.pb.cc:4:
	/home/me/anaconda3/include/google/protobuf/port_undef.inc:107:27: error: expected ‘}’ before end of line
	/home/me/anaconda3/include/google/protobuf/port_undef.inc:107:27: error: expected ‘}’ before end of line
	/home/me/anaconda3/include/google/protobuf/port_undef.inc:107:27: error: expected ‘}’ before end of line
	/home/me/anaconda3/include/google/protobuf/port_undef.inc:107:27: error: expected declaration before end of line
	src/caffe/CMakeFiles/caffeproto.dir/build.make:74: recipe for target 'src/caffe/CMakeFiles/caffeproto.dir/__/__/include/caffe/proto/caffe.pb.cc.o' failed
	make[2]: *** [src/caffe/CMakeFiles/caffeproto.dir/__/__/include/caffe/proto/caffe.pb.cc.o] Error 1
	CMakeFiles/Makefile2:304: recipe for target 'src/caffe/CMakeFiles/caffeproto.dir/all' failed
	make[1]: *** [src/caffe/CMakeFiles/caffeproto.dir/all] Error 2
	Makefile:127: recipe for target 'all' failed
	make: *** [all] Error 2


I also tried

    sudo apt-get remove libprotobuf-dev protofbuf-compiler
    sudo apt-get install libprotobuf-dev protofbuf-compiler

 and then:

    conda uninstall libprotobuf
    conda uninstall protobuf

But those didn't help. Can anyone help?",0,deeplearning,2020-10-13
iv9n0i,ML / DL Computer Build Help,"Hi All, 

I'm building a machine learning / deep learning  machine for work and would appreciate your help selecting components for it. 

This will be used on a number of projects, but almost all of our data is time series data from physical sensors. The data can be of higher dimensionality (e.g. 1000 dimensions per sample). And some of the datasets can be quite large e.g. \~ 2TB. 

I have a budget of about $3000 but I have some flexibility.

I'm a beginner in the ML/DL space but  we've used decision trees, and SVMs, and ensembles of learners in previous work. We're just starting to use DL techniques so I'm not as certain about what types of architectures we'll be using though I imagine it will mainly be feed forward networks and RNNs.

In the past we've often used a fair bit of signal processing work to prep data before providing it to learners so that might be something to keep in mind.

I expect the vast majority of my work will be done in python with scikit-learn and tensorflow. 

I have one specific question

	1) I've read that some traditional ML techniques benefit from Intel MKL . It this true / a good reason to go with an Intel chip?

Otherwise, any advice on cpu, gpu, mobo  choices and other caveats to watch out for would be much appreciated.

Thanks!  

P.S. 

I realize there is an argument for training in the cloud but this is a use it or loose it situation.",0,deeplearning,2020-10-13
iv9jq9,Machine Learning For Managers — What You Need To Know,Are you managing a tech team as a product/project manager? Here is what you need to know about machine learning. [https://medium.com/manishmshiva/machine-learning-for-managers-what-you-need-to-know-8cb9cf95c05b](https://medium.com/manishmshiva/machine-learning-for-managers-what-you-need-to-know-8cb9cf95c05b),0,deeplearning,2020-10-13
iv8kjl,Neuraxle - a Clean Machine Learning Framework,,0,deeplearning,2020-10-13
iv7xct,Getting Started with OpenCV CUDA Module,"In today's post, we are going to talk about a feature in OpenCV that is used by a lot of people in the industry for accelerating their Computer Vision pipeline - the **OpenCV CUDA Module -** a collection of utility functions, low-level vision primitives, and high-level algorithms enabling users to develop GPU accelerated vision algorithms.  
With the CUDA Module, you can accelerate all supported computer vision algorithms ( not just the Deep Learning models ) by running them on a CUDA compatible GPU.

We are sharing details of how to use the CUDA Module and show an example of using the CUDA-supported Optical Flow API.  


[https://www.learnopencv.com/getting-started-opencv-cuda-module/](https://click.convertkit-mail.com/qduv4mq6pvs7heodowug/6qhehou2qm7llxho/aHR0cHM6Ly93d3cubGVhcm5vcGVuY3YuY29tL2dldHRpbmctc3RhcnRlZC1vcGVuY3YtY3VkYS1tb2R1bGUv)  


You can find the **code** for trying out the CUDA-accelerated OpenCV module ( C++ / Python )  
[https://github.com/spmallick/learnopencv/tree/master/Getting-Started-OpenCV-CUDA-Module](https://click.convertkit-mail.com/qduv4mq6pvs7heodowug/kkhmh2u97klnnril/aHR0cHM6Ly9naXRodWIuY29tL3NwbWFsbGljay9sZWFybm9wZW5jdi90cmVlL21hc3Rlci9HZXR0aW5nLVN0YXJ0ZWQtT3BlbkNWLUNVREEtTW9kdWxl)

https://preview.redd.it/dz8bdgs8axn51.jpg?width=600&amp;format=pjpg&amp;auto=webp&amp;s=f69351b032fc881661a6a6bd2d450619d6bc4ddf",6,deeplearning,2020-10-13
iv5afy,Retiming and duplicating people in Video (using neural rendering),,7,deeplearning,2020-10-13
iv3rnz,GPT-3: new AI can write like a human but don't mistake that for thinking – neuroscientist,,40,deeplearning,2020-10-13
iv3jc4,Building deep learning machine for startup company,"Hello! I recently started working at a startup company (they have around 10 employees) and few of us are training deep learning models (mostly CNN based architectures). I've always trained on my laptop (RTX 2060), but those were more shallow models and the training time was reasonable. However, we are getting into more serious models and are planning to build a server. What I need help with is what GPUs should we go for? Obviously, Teslas are great, but our budget is limited. My question is, is it better to maybe go for e.g 5x RTX 3090 vs. 10x RTX 3080, or just 1 Tesla? I'm not sure how multiple cards work in synergy and if it makes sense. Basically, I wish to know is it better to go for bigger amount of cheaper cards, or just one really expensive? Thank you in advance! :)",0,deeplearning,2020-10-13
iv34y2,My first Convolutional Model that looks at X-Rays and detects - Covid19/Pneumonia/Normal with ~91-93% Accuracy. Do let me know what you think.,,0,deeplearning,2020-10-13
iv2daq,SuperAnnotate Desktop: A better alternative to free annotation tools,"In partnership with OpenCV, SuperAnnotate just launched a free-to-use annotation tool for desktop. Even though the user doesn't spend a dime to use the tool, he/she is equipped with all the functionalities designed to increase the speed, the accuracy and the efficiency of their annotation tasks.

[SuperAnnotate Desktop](https://blog.superannotate.com/superannotate-desktop-a-better-alternative-to-free-annotation-tools) closes the gap between free and commercial annotation tools making the fastest annotation software accessible to everyone from student to researchers and others in the industry.",13,deeplearning,2020-10-13
iuzayw,"Nvidia ASUS vs GIGABYTE vs other manufacturers Driver Support for Ubuntu, are there any problems?","Gigabyte and Asus seem to only list drivers for windows for their Nvidia RTX 30 Series GPUs and nothing regarding Ubuntu/Linux.

Can I get away by just installing the drivers of the Founder Edition GPU? Or are there any know problems for these manufacturers GPUs on Linux?

I will be using the GPU for deep/machine learning, so I'm not concerned with any gaming features.",1,deeplearning,2020-10-13
iuyw0c,Retiming and duplicating people in video (using neural rendering)!,,1,deeplearning,2020-10-13
iuxbmt,"Find code implementations for ML/AI research papers directly on Google, Arxiv, Scholar, Twitter, Github, and more!!",,1,deeplearning,2020-10-13
iuus3q,"[P] DeepTrain: Resumable, glass-box training (Lightning alternative)","If you value control and introspection of every stage of training, I've a library. TensorFlow/Keras lacks a train &amp; data automation framework like Pytorch Lightning (AFAIK), and this library is better (and worse) in several regards. Introducing [DeepTrain](https://github.com/OverLordGoldDragon/deeptrain) \- features summary below.

**Why another library? Don't we have enough?** You have nothing like this; if there was, I'd not build it. DeepTrain's tailored for the ""babysitting approach"" to training: train fewer models, but train them thoroughly. Closely monitor each stage to diagnose what's wrong and how to fix.

Inspiration came from my own use; I'd see ""validation spikes"" throughout a long epoch, and couldn't afford to pause as it'd restart the epoch or otherwise disrupt the train loop. And forget knowing which batch you were fitting, or how many remain.

**How's it compare to Pytorch Lightning?** Superior resumability and introspection, along unique train debug utilities - but Lightning fares better in other regards. I have a comprehensive list comparison in working, will post within a week.

**Pytorch support coming?** Maybe. If I convince the Lightning dev team to make up for its shortcomings relative to DeepTrain, then not - otherwise probably. In the meantime, explore the gallery of [Examples](https://deeptrain.readthedocs.io/en/latest/?badge=latest).

\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_

## Train Loop

* **Resumability**: interrupt-protection, can pause mid-training
* **Tracking &amp; reproducibility**: save &amp; load model, train state, random seeds, and hyperparameter info

## Data Pipeline

* **Flexible batch\_size**: can differ from that of loaded files, will split/combine
* **Faster SSD loading**: load larger batches to maximize read speed utility
* **Stateful timeseries**: splits up a batch into windows, and reset\_states()(RNNs) at end

## Introspection &amp; Utilities

* **Model**: auto descriptive naming; gradients, weights, activations visuals
* **Algorithms, preprocesing, calibration**: tools for inspecting &amp; manipulating data and models

[Complete list](https://deeptrain.readthedocs.io/en/latest/why_deeptrain.html)",1,deeplearning,2020-10-13
iutee6,Guide for the implementation of Neural Network accelerator on FPGA,,1,deeplearning,2020-10-13
iusv67,"[R] After 15 Long Years, a NumPy Paper Finally Appears!","Since[ NumPy](https://numpy.org/) was introduced to the world 15 years ago, the primary array programming library has grown into the **fundamental package for scientific computing with Python.** NumPy serves as an efficient multi-dimensional container of generic data and plays a leading role in scientific computing. It is an essential component in research analysis pipelines across fields as diverse as physics, chemistry, astronomy, geoscience, biology, psychology, materials science, engineering, finance and economics. NumPy is open-sourced and has myriad contributors.

But one thing has always been missing. A thorough review paper that is fully representative of the team behind Numpy’s genesis has never been published.

The missing chapter in the NumPy story was written yesterday — with the appearance of the paper *Array Programming with NumPy* in leading scientific journal *Nature.*

Here is a quick read: [After 15 Long Years, a NumPy Paper Finally Appears!](https://syncedreview.com/2020/09/17/after-15-long-years-a-numpy-paper-finally-appears/)

The paper *Array Programming with NumPy* is on [*Nature*](https://www.nature.com/articles/s41586-020-2649-2).",110,deeplearning,2020-10-13
iusk00,This question,,1,deeplearning,2020-10-13
iuqfna,What are the issues for a 1920X AMD in deep learning?," I wanted to buy one for my upcoming Deep-learning workstation (2-3x RTX 3080), 128-256GB RAM)

but at one point someone told me there would be issues. i didnt ask what specificly he meant.

So: what could he have meant + what are your experiences?",0,deeplearning,2020-10-13
iuop77,hardware configuration advice sought,"Basically I would like to emulate something similar to the lambda workstation but with one GPU slowly increasing upto 4 as my budget allows. Primary use would be to start my deep learning voyage but I am also interested in other applications that benefit from multiple GPU's such as hash/password cracking, 4K 120fps gaming, HD video editing, deep fake rendering, and possibly crypto mining to fund my expensive hobby. Can I DIY build a rig suitable for such varied tasks? If so I would love recommendations on a solid motherboard+CPU+GPU+RAM combination. Any advice regarding individual components and what to look out for (and what to avoid) would be also gladly received. Thanks in advance.",1,deeplearning,2020-10-13
iuog81,What is the role of neurology in Ai?,"I just grew a keen interest in reading books related to neurology and human psychology. I just want to know if it will be helpful to apply it's concepts in Ai?
I think that understanding the neurology would help me create a proper base of approaching the Ai concepts in a much more sophisticated way !",2,deeplearning,2020-10-13
iunpna,"[D] what are some best practices followed in training and experiments management in deepmind, microsoft and facebook?",,2,deeplearning,2020-10-13
iumvgf,Networks for Visual Question Answering on Image and Video (HCRN) - CVPR 2020 (link to free zoom lecture by the author in the comments),,20,deeplearning,2020-10-13
iuimzx,Transliteration pair mining from parallel corpus using Moses,"Hi Everyone,

Moses ([http://www.statmt.org/moses/](http://www.statmt.org/moses/)) can also be used for Transliteration pair mining from a parallel Translation corpus but I couldn't find much documentation on it and it was really hard to set up things from scratch. I have compiled all that I have learned and have put it in a git repository - [https://github.com/gv22ga/moses-transliteration-pair-mining](https://github.com/gv22ga/moses-transliteration-pair-mining)

It shows how to extract transliteration pairs from a sample dataset. Please share your comments/feedback.

Thanks",0,deeplearning,2020-10-13
iug9wi,Cntk 2.7 and windows server 2012r2,"Hi everyone.

Until recently I have used cntk 2.5.1 with windows server 2012r2. Now I would like to upgrade to cntk 2.7.

The installation went find, however when I use

    Import cntk

I get an error cntk is supported by windows 10 and above.

Microsoft doesn't mention anywhere that Windows server 2012r2 is not supported by that release (At least I couldn't find anything).

Is there something I can do? (Upgrading to 2016/2019 is not an option for now).

Thx.",0,deeplearning,2020-10-13
iug3xl,Collaboration with a German researcher/professor on AI project (NLP) funded by the gouverment,"Hello Dears,

I with my professor (from Morocco) looking for a Professor/Researcher from a german university that would collaborate with us on NLP project funded by the government for a period of 36 months. If you found yourself interested or you wish to recommend your professor, we would be happy to connect and see what we can do.",8,deeplearning,2020-10-13
iueyho,Euclidean distance transform of an image in Tensorflow 1,"I am trying to define a loss function for which I require to find the Euclidean distance transform of an image in TF1. Tensorflow 2 has a function image.euclidean\_dist\_transform in tensorflow addons. I need to do the same job in TF1.

I wish to use the loss function described in the paper - Interactive Image Segmentation with First Click Attention to define the loss function for my model.

[https://openaccess.thecvf.com/content\_CVPR\_2020/papers/Lin\_Interactive\_Image\_Segmentation\_With\_First\_Click\_Attention\_CVPR\_2020\_paper.pdf](https://openaccess.thecvf.com/content_CVPR_2020/papers/Lin_Interactive_Image_Segmentation_With_First_Click_Attention_CVPR_2020_paper.pdf)

Any pointers on this would be appreciated. Thanks!",8,deeplearning,2020-10-13
iubv8x,Introduction to Neural Network Basics,,0,deeplearning,2020-10-13
iu9sq9,New tool for DL students: Chrome/Firefox extension for finding CV/ML/AI Code Implementations!,,1,deeplearning,2020-10-13
iu9fwy,Why tensorflow versions installed in Ubuntu don't match?,,2,deeplearning,2020-10-13
iu84zu,Deep learning freameworks,"Has anyone tried all three deep learning frameworks tensorflow, pytorch and mxnet? What are the plus and minus on each?",2,deeplearning,2020-10-13
iu6nx5,Machine Learning Engineer Training ($130k+ average salary),"ML colleagues, according to ZipRecruiter Machine Learning Engineers earn $130,530 per year. Learn advanced machine learning techniques and algorithms -- including how to package and deploy your models to a production environment. Gain practical experience using Amazon SageMaker to deploy trained models to a web application, evaluate the performance of your models, A/B test models and update the models as you gather more data..Suggested prerequisites are intermediate knowledge of Python and Machine Learning algorithms. The four skill-based training modules (each with a unique training project) include: 1) Software  Engineering Fundamentals (Project: Build a Python Package), 2) Machine  Learning in Production with Amazon SageMaker (Project: Deploy a Sentiment Analysis Model), 3) Machine Learning Case Studies (Project: Plagiarism Detector), and 4) Machine Learning Capstone (Project: Select a machine learning challenge and propose a possible solution). 

Enroll today at: https://fxo.co/9glo 

Much career success, Lawrence E. Wilson - Artificial Intelligence Academy (AIA)",0,deeplearning,2020-10-13
iu400q,AI for Entrepreneurs Podcast- Adrian Rosebrock,"We have a new episode of our podcast series [AI for Entrepreneurs](https://click.convertkit-mail.com/68u9nlnm49f8hxnlwoco/qvh8h7h6x9r8xoul/aHR0cHM6Ly93d3cueW91dHViZS5jb20vcGxheWxpc3Q_bGlzdD1QTHg3TGVueHhpRXR2YWRjRUtTbjd0a0czeGV4RFphR3d6)! Today, we will talk to **Adrian Rosebrock,** a successful entrepreneur and the author of a popular computer vision and machine learning blog [PyImageSearch](https://click.convertkit-mail.com/68u9nlnm49f8hxnlwoco/g3hnh5hzv43evpcr/aHR0cHM6Ly93d3cucHlpbWFnZXNlYXJjaC5jb20v).   


Adrian shares his thoughts on how to build an audience, how to come up with product ideas, and how to manage time for maximum productivity. In addition, he gives advice to people who want to get started in AI.  


His story is one of tremendous grit, extreme discipline, and relentless execution and you can watch it at [https://www.youtube.com/watch?v=z5KWHMOb1H8](https://www.youtube.com/watch?v=z5KWHMOb1H8).",3,deeplearning,2020-10-13
iu3oh8,State of the art in Crop/Weed Segmentation!,,2,deeplearning,2020-10-13
iu0yz5,MacBook recommendation for University.,"Hi. My main academic interest is in deep learning. I'm looking to get a new MacBook for University and I'm wondering which model and specs to get. Now my thought process has been this: 

1) If I get a high-end MacBook Pro, it won't be powerful enough to train DL models right. So I am most likely going to default back to cloud solutions. In that case I would only need to maintain a connection so I could in fact consider just getting a MacBook Air?

2) Even if I get a non MacOS laptop thats built for training DL models, would it even be wise to be training on it. Are people even doing that.

3) I'm taking a Computer Science major so there may be classes that require more computing power beyond a MacBook Air?

4) I have a small hobby in Blender and might consider learning Adobe software as a past time but is this really a good reason to gun for better specs.

Any advice will be deeply appreciated.",0,deeplearning,2020-10-13
ityg5g,"Practical Natural Language Processing Book [Interview + Giveaway] | NLP, ML &amp; AI in the Industry | GPT-3 and more",,22,deeplearning,2020-10-13
itul2i,Can anybody explain this?,"deep learning algorithms scale with data, whereas shallow learning converges",0,deeplearning,2020-10-13
itt5al,"PiFuHD: A new method for high-fidelity 3d reconstruction. It only needs a single image of you to generate a 3D avatar that looks just like you, even from the back!",,36,deeplearning,2020-10-13
itskbs,Need help for Implementing a recommendation engine at Scale,"Hi Everyone,

**Long Post Ahead**

I'm a Data Scientist at a job portal. I need to build a recommender system for Users to connect them to jobs. My idea of going about it was to generate Embeddings from User Content (meaning that I input User content such as tags, interests, designation etc) as input, try to create a representation via embeddings for both entities (Jobs and Users) and then basically perform a Nearest neighbour search using Annoy (By spotify) Also, using User content to generate User embeddings would be easier to do in real time and would not suffer from the multiple drawbacks of collaborative filtering.

The part which baffles me is how to get obtain meaningful embeddings. Most places I've checked (Neural Collaborative Filtering, are basically implementations of the MovieLens Dataset (using embeddings) but that doesn't help me since :

* It doesn't account for changing user interests
* Cannot accommodate new users (Cold Start Problem)

In fact, most tutorials for recommenders are actually plagued by these issues. Another suggestion was to use Graph Embeddings, and I did look at PyTorch's Biggraph implementation but again the issue is I cannot introduce User Content in the vanilla implementation.

These would be my questions then :

* Can someone simply point out resources for generating content based Embedding from different entities so that they're in the same space?
* Is Neural Collaborative Filtering pragmatic to implement for a million users?

Any other suggestions would be welcome as well , thanks in advance",1,deeplearning,2020-10-13
itsizq,Text Summarization of COVID-19 Medical Articles using BERT and GPT-2 | Research Paper Walkthrough,,2,deeplearning,2020-10-13
its9y0,Anomaly detector task,"Hi All, I have task where I have to compare two images and find differences between two of them. I could use some traditional algorithms like SSIM or absDifference.

However, based on articles and my limited knowledge of DL area I have feeling that anomaly detection would be perfect solution for this problem. I thought of recording scene for 2-3 hours, slice video into frames and train anomaly detector only with that data as 'good' samples. I was thinking to use CNN with autoencoders.

Things that I am unsure about and would appreciate your help are:

1. Will anomaly detector still perfrom well if I provide very 'similar' images taken under same angle with maybe slight variation in the light. In some cases no even any movement in the camera scene.
2. Is 2-3 hours of video enough data? If not than how many would be enough and is number of data depends on the scene complexity or something else.
3. Is there publicly available network that could help me with this task or should I build it from scratch.
4. Any articles, videos or tutorials that could help with understanding of anomaly detection would be helpful.

Thanks!",3,deeplearning,2020-10-13
itoiev,Are there some websites or any platform where developers can collaborate to work on projects globally [D],"I need it for a simple ai application with very less amount of users a portfolio kind of thing. Program is written in python, tensorflow, scikit learn and is stored locally and currently I dont play to shift it to any cloud based options like azure, etc. Prefer the option to be cheapest",0,deeplearning,2020-10-13
itlw1l,"tsBNgen, a Python Library to Generate Synthetic Data From an Arbitrary Bayesian Network","When we think of machine learning, the first step is to acquire and train a large dataset. However, many times the data isn’t available due to confidentiality. This problem is faced by hundreds of developers, especially for projects which have no previous developments. Certain GAN (Generative Adversarial Network) models, specifically Recurrent GAN (RGAN) and Recurrent Conditional GAN (RCGAN), have been introduced to produce realistic real-valued multi-dimensional time-series data. 

This paper brings the solution to this problem via the introduction of tsBNgen, a Python library to generate time series and sequential data based on an arbitrary dynamic Bayesian network.

**Full Summary:** [https://www.marktechpost.com/2020/09/15/tsbngen-a-python-library-to-generate-synthetic-data-from-an-arbitrary-bayesian-network/](https://www.marktechpost.com/2020/09/15/tsbngen-a-python-library-to-generate-synthetic-data-from-an-arbitrary-bayesian-network/)

**Paper:** https://arxiv.org/pdf/2009.04595.pdf

**Github:** https://github.com/manitadayon/tsBNgen/blob/master/tsbngen.pdf",20,deeplearning,2020-10-13
itlejn,Role of BIAS in DCGANs,"Greetings!

Can someone help me understand the intuition behind not using BIAS in DCGAN(s) such as here

[https://pytorch.org/tutorials/beginner/dcgan\_faces\_tutorial.html](https://pytorch.org/tutorials/beginner/dcgan_faces_tutorial.html)

?",2,deeplearning,2020-10-13
itjlvk,Input graph size for graph neural nets (GNNs)?,"Some of the [popular approaches](https://github.com/rusty1s/pytorch_geometric) for GNNs may be useful/relevant for my datasets. 

Is there an (approximate) minimal dataset size to work with GNNs? In this case, the dataset consists of thousands of input graphs (an individual graph corresponds to an ""instance/sample""), each with \~50 nodes. Would those graph sizes be enough for GNNs?",0,deeplearning,2020-10-13
itjcfj,Free browser extension! AI/ML Code Implementation Finder,,0,deeplearning,2020-10-13
ithesd,Can an attacker extract private training data from a trained ml-model?,"And speaking of which - is it possible to steal an ml-model through simple query-access?

A fellow researcher and I are doing research on exactly these questions - namely on **private and secure machine learning**. If you employ machine learning techniques, whether you consider yourself a developer, practitioner or hobbyist and have 10-15 minutes of your time to spare, it would mean a lot to us if you would participate in our anonymous online survey [https://websites.fraunhofer.de/ML\_security/index.php/149369?Start1=A5](https://websites.fraunhofer.de/ML_security/index.php/149369?Start1=A5).

If you are interested in any additional information, please visit [https://www.sit.fraunhofer.de/mlsurvey/](https://www.sit.fraunhofer.de/mlsurvey/)

You are also highly welcome to share and repost the link.

Many thanks in advance!",3,deeplearning,2020-10-13
itgjpz,How do you like my Remaster? Resolution increased using neural networks to 8K,,0,deeplearning,2020-10-13
itfjx6,Self-Supervised Learning for Domain Adaptation on Point-Clouds,,1,deeplearning,2020-10-13
itezec,How to properly structure LSTM labels?,"I was looking up how to generate text with an LSTM, and the input shape of the LSTM appears to be a set of samples, each containing many timesteps, with each timestep having features representing an individual character. However, I'm confused about why the labels are two dimensional for LSTMs (one label of x features per sample).  Wouldn't labels be three dimensional, with one label representing the subsequent character for each timestep? 

So, for the sample:

\[""a"", ""b"", ""c""\]

wouldn't the label be:

\[""b"", ""c""\]?

How would you do it with a 2d label?

like:

\[""a"", ""b""\]

to 

""c""?",0,deeplearning,2020-10-13
ite8ym,[R] Human Feedback Improves OpenAI Model Summarizations,"In a new paper, a team of OpenAI researchers sets out to advance methods for training large-scale language models such as BERT on objectives that more closely capture human preferences — and does so by putting humans back into the loop. The work focuses on abstractive English text summarization — a subjective task that’s considered challenging because the notion of what makes a “good summary” is difficult to capture without human input.

Here is a quick read: [Human Feedback Improves OpenAI Model Summarizations](https://syncedreview.com/2020/09/15/human-feedback-improves-openai-model-summarizations/)

The paper *Learning to Summarize from Human Feedback* is on [arXiv](https://arxiv.org/pdf/2009.01325.pdf).",1,deeplearning,2020-10-13
itclo6,Latest from NVIDIA: State of the art in capturing the shape and spatially-varying appearance!,,9,deeplearning,2020-10-13
itcf71,Help with Caffe installation errors?,,0,deeplearning,2020-10-13
itaprw,Researching ML vs researching DL/Robot Learning?,&amp;#x200B;,2,deeplearning,2020-10-13
it7i4h,Design Compact Deep Learning Models: Small is the New Big,,1,deeplearning,2020-10-13
it69fl,Any research on keeping Weights linear independent during training?,"Any researching on keeping Weights linear independent during training? I am thinking that no matter how you transform features on high dimensional space, if these features are independent, the vector representation should also be linear independent and these vectors span the problem space.",5,deeplearning,2020-10-13
it4ao2,Creating model architectures from scratch for production,"Hello, 

I'm still fresh in the area of deep learning, recently graduated mathematics and now basically working alone on producing deep learning models for a  startup. I've always used transfer learning in TensorFlow to create models (MobileNet V2/V3 and SSD MobileNet V2 for classification and object detection on mobile devices). Since those architectures are tweaked for datasets like ImageNet and COCO I wonder if I could make my own model which will be faster for my purposes, and possibly also easily converted into TFLite format). Do you guys have experience with e.g. creating fast inference models, modifying existing model architectures and training from scratch, incorporating some layer blocks and tricks from papers into your own model? What approach works?",12,deeplearning,2020-10-13
isyu5y,Microsoft releases a new version of DeepSpeed tool to enable the creation of deep learning models with a trillion parameters,"[DeepSpeed](http://www.deepspeed.ai/), Microsoft’s deep learning optimization library, makes distributed training easy, effective, and efficient. It’s an essential part of Microsoft’s initiative, [AI at Scale](https://www.microsoft.com/en-us/research/project/ai-at-scale/), to enable the next-generation AI capabilities at scale.

DeepSpeed trains deep learning (DL) models with over a hundred billion parameters on GPU clusters’ current generation and offers ten times better performance than state-of-the-art. Early adopters of DeepSpeed have already produced Turing-NLG, a language model (LM) with over 17B parameters.

**Summary:** https://www.marktechpost.com/2020/09/14/microsoft-releases-a-new-version-of-deepspeed-tool-to-enable-the-creation-of-deep-learning-models-with-a-trillion-parameters/

**Github:** https://github.com/microsoft/DeepSpeed",5,deeplearning,2020-10-13
isxigo,[Discussion] Suggestions regarding deep learning solution deployment,"I have to deploy a solution where I need to process 135 camera streams in parallel. All streams are 16 hours long and should be processed within 24 hours. A single instance of my pipeline takes around 1.75 GB to process one stream with 2 deep learning models. All streams are independent and the output isn't related. I can process four streams in real-time on 2080 ti (11 GB). After four, the next instance starts lagging. That doesn't let me process more streams given the remaining memory (\~4GB) of the GPU.  


I am looking out for suggestions regarding how can this be done in the most efficient way. Keeping the cost and efficiency factor in mind. Would making a cluster benefit me in the current situation?",1,deeplearning,2020-10-13
isxemm,Tensorflow: libcublas.so.10: cannot open shared object file,"I was trying to run a Unet in Keras but got

    terminate called after throwing an instance of 'std::bad_alloc'

which doesn't make sense since I'm running the same Unet as before. I did make changes to CUDA, so I'm guessing that's the cause of this

Whenever I use tensorflow (I use version 2.3.0 in Ubuntu 16 with an NVIDIA GPU) and try
 
    gpus = tf.config.experimental.list_physical_devices('GPU')

it shows `gpus` as an empty list and says

	Successfully opened dynamic library libcudart.so.10.1
	2020-09-14 16:39:11.975096: W tensorflow/stream_executor/platform/default/dso_loader.cc:59] Could not load dynamic library 'libcublas.so.10'; dlerror: libcublas.so.10: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda-10.0/lib64:/usr/local/cuda-10.0/lib64::/usr/local/cuda-10.0/lib64::/usr/local/cuda-11.0/lib64::/usr/local/cuda-11.0/lib64
	2020-09-14 16:39:11.975158: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcufft.so.10
	2020-09-14 16:39:11.975197: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcurand.so.10
	2020-09-14 16:39:11.975232: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusolver.so.10
	2020-09-14 16:39:11.975380: W tensorflow/stream_executor/platform/default/dso_loader.cc:59] Could not load dynamic library 'libcusparse.so.10'; dlerror: libcusparse.so.10: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda-10.0/lib64:/usr/local/cuda-10.0/lib64::/usr/local/cuda-10.0/lib64::/usr/local/cuda-11.0/lib64::/usr/local/cuda-11.0/lib64
	2020-09-14 16:39:11.975436: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudnn.so.7

even though I set

	export PATH=/usr/local/cuda-10.0/bin${PATH:+:${PATH}}
	export PATH=/usr/local/cuda-10.0/bin:/usr/local/cuda-10.0/NsightCompute-1.0${PATH:+:${PATH}}
	export LD_LIBRARY_PATH=/usr/local/cuda-10.0/lib64:${LD_LIBRARY_PATH:+:${LD_LIBRARY_PATH}}

and `which nvcc` shows

    /usr/local/cuda-10.0/bin/nvcc

and `$LD_LIBRARY_PATH `

shows

	bash: /usr/local/cuda-10.0/lib64::/usr/local/cuda-11.0/lib64:/usr/local/cuda-11.0/extras/CUPTI/lib64:/usr/local/cuda/lib64:/usr/local/cuda-11.0/extras/CUPTI/lib64:/usr/local/cuda/lib64:/usr/local/cuda/extras/CUPTI/lib64:/usr/local/cuda-11.0/lib64: No such file or directory

and `~/.bashrc` shows

    export PATH=""$PATH:/usr/local/cuda-10.0/bin""
    export LD_LIBRARY_PATH=""/usr/local/cuda-10.0/lib64""${LD_LIBRARY_PATH:+:${LD_LIBRARY_PATH}}

can anyone help?",3,deeplearning,2020-10-13
isw6o1,[R] Microsoft Democratizes DeepSpeed With Four New Technologies,"In February, Microsoft [introduced](https://syncedreview.com/2020/02/12/17-billion-parameters-microsoft-deepspeed-breeds-worlds-largest-nlp-model/) its open-source deep learning training optimization library DeepSpeed with memory optimization technology ZeRO (Zero Redundancy Optimizer), which helped build the 17-billion-parameter Turing Natural Language Generation model (T-NLG). In step with its [AI at Scale](https://www.microsoft.com/en-us/research/project/ai-at-scale/) initiative, Microsoft has now released four additional DeepSpeed technologies to enable even faster training times, whether on supercomputers or a single GPU.

Here is a quick read: [Microsoft Democratizes DeepSpeed With Four New Technologies](https://syncedreview.com/2020/09/14/microsoft-democratizes-deepspeed-with-four-new-technologies/)

The codes, tutorials and documentations have been open-sourced on [GitHub](https://github.com/microsoft/DeepSpeed).",1,deeplearning,2020-10-13
isu4mj,How to build a model in keras with form a(x)u+b(x),"Hi, 

I got stuck in trying to create a model in Keras representing a function a(x)u+b(x) where a(x) and b(x) are 2 nonlinear functions that I want to do regression and u is a changing variable. Is there any way that we can build one network to represent this function without using 2 networks representing a(x) and b(x) separately? Thanks",0,deeplearning,2020-10-13
istrr5,"Stop posting stuff about 'AI does xyz ... ""","The term 'AI' and its definition is pretty broad, imprecise and up for discussion. Unless, you are posting a research paper or something which deals which the philosophy of AI itself, stop posting stuff like ""AI creates faces...., AI drives cars ...."" - its non-informative, and bait-captioning at its worst. Write down the problem title e.g. Domain transfer, Sparsity, etc, the general area is needed, the architecture etc. If you can't do it - just copy/paste the research paper's title.

Please stop with the titles that paparazzi journalists would jot down.",7,deeplearning,2020-10-13
ist7vf,[D] It's time for AI to perceive time.,"Deep learning with complex numbers as an alternative to Spiking Neural Networks (SNN)   


[https://medium.com/@nariman.mammadli/its-time-for-ai-to-perceive-time-9ffdecd2ce91?source=friends\_link&amp;sk=d5ab67ca11528f8b3372d3d579f77d63](https://medium.com/@nariman.mammadli/its-time-for-ai-to-perceive-time-9ffdecd2ce91?source=friends_link&amp;sk=d5ab67ca11528f8b3372d3d579f77d63)",0,deeplearning,2020-10-13
issv1z,A loss definition for that exploits affinity.,"I have a small dataset and limited resources. My task is a regression problem where I have to get my model to locate the corner points of quadrilateral objects. The current results show me that simply applying mean squared error on the corner points independently does not really help preserving the object shape so I want a method that really encourages the network to learn the points by forcing each point to work together. I thought anchor-like methods could work well, however, even such Yolo-like frameworks are too complex for this simple task. Therefore I wanted to ask if there's any paper so I could dive into such sort of methods. Or any coined popular methods which I apparently don't know. Thanks",1,deeplearning,2020-10-13
isrqi7,[Research] AI Creates Human Faces From Your Sketches,,6,deeplearning,2020-10-13
isrbcu,Everything About Dropouts And BatchNormalization in CNN,[https://analyticsindiamag.com/everything-you-should-know-about-dropouts-and-batchnormalization-in-cnn/](https://analyticsindiamag.com/everything-you-should-know-about-dropouts-and-batchnormalization-in-cnn/),1,deeplearning,2020-10-13
isqjgd,"RTX 3090, 3080, and 3070 Deep Learning Workstation Guide",,53,deeplearning,2020-10-13
islh0r,[Article] A deep dive into GhostNet (CVPR 2020) with code in PyTorch and TensorFlow,"This article covers feature maps in convolutional neural networks, a deep dive into GhostNet, and an analysis of its capabilities and shortcomings. More specifically, we’ll cover:

* Convolution, depthwise convolution, and feature map pattern redundancy 
* Ghost Convolution in PyTorch and TensorFlow, as well as the Ghost Bottleneck and full architecture in PyTorch
* Results of GhostNet on various tasks and datasets
* Limitations of the proposed model 

Link to the article: [https://blog.paperspace.com/ghostnet-cvpr-2020/](https://blog.paperspace.com/ghostnet-cvpr-2020/)",6,deeplearning,2020-10-13
islf3b,Jupiter extension which converts English queries into relevant python code,,4,deeplearning,2020-10-13
isleqt,How do usage/habit models work on such little data?,"Hi! I posted this on r/machinelearning but no response. I think the main point of my question might revolve more on deep learning. I watched this video on a new smart refrigerator which observes user patterns for 3 weeks to decide when to cool ([https://youtu.be/SNHJJSTtzsw?t=288](https://youtu.be/SNHJJSTtzsw?t=288)). I was wondering how this works from a machine learning perspective.

Capturing the overall trend with some crude heuristics seems easy enough, but what about a machine learning model? It looks like a great application of it from the little graph. The reason I ask is everything I read tells me models suited to time series sort of data require vast amounts of it for training, so how does it compensate?

As a secondary question, what about when patterns change, similar to concept drift? How can it account for this?",1,deeplearning,2020-10-13
isje34,Open-source - a data visualization tool (beta),"When we were looking for a solution for our web app building process, our priorities were to find a tool/platform that:

... Saves Time - by rapidly iterating with your team of Devs and SMEs using the collaborative visual builder

... Saves Money by lowering the skills required to contribute to the development process

... Saves Effort by using pre-built (custom or community) apps and components. 

So, we went one step further and we've built our own tool - Kelp - [https://kelp.app/](https://kelp.app/)! Now, we are working on sharing it with the world so that other data scientists and developers can use it. I'm looking forward to hearing your honest feedback - and thoughts on similar tools as well. Have you used any and would you recommend them to other data scientists?

Thank you",0,deeplearning,2020-10-13
isi3w8,Question to vanishing gradient problem in RNNs,"I am trying to understand Rnn's better but struggle with grasping the vanishing gradient effect completly.
I have read that it occurs because small gradients (&lt;1) are repeatedly multiplied with each other, causing them to be very small.
When looking at the example in this blog post: http://www.wildml.com/2015/10/recurrent-neural-networks-tutorial-part-3-backpropagation-through-time-and-vanishing-gradients/

In the formular just above the picture with the red gradients he calculates:

dE_3/dW, which is the sum of the gradients from state 0 to 3. Given this formular I don't get where the multiplication is happening? Are the multiplications of the derivatives within the sum the cause of the vanishing gradient?
Maybe someone can help me out :D
Cheers!",10,deeplearning,2020-10-13
ishcbp,[R] Feedbacks on Progressive Self Label Correction,,1,deeplearning,2020-10-13
isfxci,CNN accuracy,"Hey, why is it that when a CNN model is trained, the accuracy of a training_set batch(when purposefully tried to overfit) gives an accuracy of 100%. (Let's say the batch has 10 images) but it predicts wrong when only one image or a subset of images from the same batch is considered and forward propagated. 
How exactly should the derivative of filter weights be calculated?",5,deeplearning,2020-10-13
isfe27,SimPLe: Learning to play Atari with only 2 hours of gameplay | Paper Explained,,1,deeplearning,2020-10-13
isf7gq,Multimodal Emotion Recognition Competition 2020 (MERC 2020) - Challenges(EvalAI),,2,deeplearning,2020-10-13
is9vc3,"CNN beginner using a GTX 960 2GB, PCIe Gen 3.0 motherboard. Upgrade to RTX 2060 Super or RTX 3070?","Convnet novice that's currently using a GTX 960 2GB on a z170i motherboard which limits the GPU to a PCIe 3.0 slot. The 2GB on the 960 is a constraint that I have been bumping up against while learning about CNNs. 

Having reviewed Tim Dettmers article on GPUs, I was considering upgrading to the RTX 3070 but it appears to be a PCIe Gen 4.0 GPU which would be restricted by the Gen 3.0 slot on my motherboard. Both the 2060S and 3070 have 8GB GDDR6 which is a huge leap from the 2GB I currently am using.

Which would be the better option given the motherboard constraint?

Personally, I think the 2060S is a better immediate application that aligns with the motherboard, but in terms of potential future upgrades, the 3070 may be a better investment if I upgrade the rest of my hardware later on.

Budget is $800 canuck coins which translates to approx. $600 USD.",2,deeplearning,2020-10-13
is7u81,Well read Students Learn Better: On The Important Of Pre-training Compact Models,,1,deeplearning,2020-10-13
is6kxz,"Onepanel: open source, production scale deep learning for computer vision platform",,6,deeplearning,2020-10-13
is5zer,Convolutional network insensitive to the input data variations," Hi guys!

I have a 1 D convolutional network that is designed to predict time series data. It has 11 layers, as it is basically designed like an AutoEncoder, with a bottleneck in between. My normalized input comes from \[-3, 3\] normal distribution which outputs time series data scaled from 0 to 1.

After training and achieving desired prediction performance, I tried random noise (-0.1, 0.1) as input and observed that my network had a decent prediction. Furthermore, I created an input of all zeros (shaped like my original input), and run it thought the NN model - it again predicted something reasonable even though it had all zeros as input.

My first question is: how is that possible that the network does not react much to the input data variability?

&amp;#x200B;

DECODER:

 encoded\_d = Dense(10\*2, activation='linear')(\_) 

\_ = Dense(64\*2, activation='linear')(encoded\_d) 

\_ = tf.keras.layers.Dropout(0.10)(\_) # additional 

\_ = Reshape((8, 8\*2))(\_) 

\_ = Conv1D(8\*2, 6, activation=""linear"", padding=""same"")(\_) 

\_ = LeakyReLU(alpha=0.3)(\_) 

\_ = tf.keras.layers.Dropout(0.10)(\_) # additional 

\_ = UpSampling1D(2)(\_) \_ = Conv1D(16\*2, 3, activation='linear')(\_) 

\_ = LeakyReLU(alpha=0.3)(\_)  \_ = tf.keras.layers.Dropout(0.10)(\_) # additional  

\_ = UpSampling1D(2)(\_) 

output\_dt = Conv1D(25, 4, activation='linear', padding='valid')(\_)",1,deeplearning,2020-10-13
is52hi,Deep Learning based Human Pose Estimation using OpenCV,"Pose estimation is a well-known facet of Computer Vision. The idea is to predict the pose of an object or a person with the help of some keypoints. This information can then be used in various applications like posture examination while exercising. In today's post, we will discuss how to use a Deep Neural Net model for performing Human Pose Estimation in OpenCV. We will explain in detail how to use a pre-trained Caffe model and briefly go over the architecture. 

  
[https://www.learnopencv.com/deep-learning-based-human-pose-estimation-using-opencv-cpp-python/](https://www.learnopencv.com/deep-learning-based-human-pose-estimation-using-opencv-cpp-python/)

https://reddit.com/link/is52hi/video/v9u1ql5xwym51/player",10,deeplearning,2020-10-13
irznyg,"[P] Open-sourcing ""beginner-friendly"" PyTorch GANs repo (DCGAN, cGAN, vGAN for now)",,50,deeplearning,2020-10-13
irz2h8,Help needed - T5 Transformers,"I came upon a really interesting project that I would like to work on my own.   
I want to know how do I make [this](https://github.com/renatoviolin/Multiple-Choice-Question-Generation-T5-and-Text2Text) project.   
I have never used T5 transformers before. If anyone could brief me on how could I move forward, it would be a great help.   
Thank you.",1,deeplearning,2020-10-13
irvyae,Mona Lisa Teaches Artificial Intelligence.,,1,deeplearning,2020-10-13
irup88,Cool Deep learning projects 🙂 you must know before starting with deep learning 🔥,,0,deeplearning,2020-10-13
irtei7,Machine Learning and Deep Learning Frameworks every data scientist should know 🔥,,0,deeplearning,2020-10-13
irs8a8,Liner and Non linear in Activation Function,"I know AF converts Liner into non linear, but i am unable to understand (linear and non linear), can anybody give example.",11,deeplearning,2020-10-13
irrwcd,Output size after applying convolution,"for example if we have image size 32X32 than out put would be 32 similarly filter size 5X5 than output would be 5. Ok

What if we have 24X32 image size and 4X5 filter size that whats the output after convolution?",0,deeplearning,2020-10-13
irr85q,Annotation Tool,"Suggest good annotation tool, I want to label cavity from teeth radio graphic images.",3,deeplearning,2020-10-13
irk5mo,Is Gamification Useful to Create Labels?,"What are your thoughts on gamification to create labels for deep learning? Is it hopeless or are we just lacking the right ideas?  We looked into taking successful games and tried to use them for annotation. In this example, we used candy crush/zookeeper as basis and added labeling of ophthalmologic images on top. I really enjoy playing the game and think this might be a path towards successful gamification:

[https://www.youtube.com/watch?v=\_w2DW0GiBi0](https://www.youtube.com/watch?v=_w2DW0GiBi0)

The video contains an in-game demo video and the description has a link to the WebGL-based demo.  So, let me know your thoughts about labeling using games...",1,deeplearning,2020-10-13
iris97,"Oh, the age-old question (= 4 years old) which deep learning framework should I use? PyTorch or TensorFlow?",,0,deeplearning,2020-10-13
irh1lk,capsule network,"the  initial buzz seems to have died off, but the idea of capsules instead  of kernels is still interesting. are there any groups working in capsule  network still?",16,deeplearning,2020-10-13
ircgu4,Tune weights,,0,deeplearning,2020-10-13
irbp5k,Can GPT-3 really help you and your company? What can it really do? Real-World Applications Demo,,1,deeplearning,2020-10-13
ir9jsf,Considerations on the arithmetic of convolutional neural networks,,0,deeplearning,2020-10-13
ir200f,Buying a GPU for Deep Learning,"Hello, 

I want to perform various image recognition tasks that are very computationally demanding, however, instead of using Cloud GPUs, I would like to purchase a GPU and build an external environment for it. Though... I have some questions!

&amp;#x200B;

1. Should I wait for NVIDIA's new line of GPUs to come out? 
2. What are some GPU models out now that perform well for image recognition tasks? 
3. How much memory should? How does that vary?

I have tried to do research on my own, but I've seen so many different responses.",1,deeplearning,2020-10-13
iqy33c,How far can a 1060ti get me?,"Let me know please :) Researched it a bit, but found an array of answers.",2,deeplearning,2020-10-13
iqsv4b,Best Machine Learning Books for Beginners and Experts in 2020,"Hey friends, I have curated a list of **the best Machine learning books** out there to learn Machine Learning in 2020. 

You can view it on my blog - [https://thecodingpie.com/post/best-machine-learning-books-for-beginners-and-experts-in-2020/](https://thecodingpie.com/post/best-machine-learning-books-for-beginners-and-experts-in-2020/)

[banner](https://preview.redd.it/1ozsjhq6gjm51.png?width=800&amp;format=png&amp;auto=webp&amp;s=3f8da8bd2232a79b55ad0d8f861936c46c589f3d)

No matter if you are a beginner in machine learning or already an Intermediate/Expert in this field, there is an awesome book waiting for you!

I hope you will find this book suggestions helpful in your great Machine Learning Journey and beyond. If you think I have forgotten any great book then please let me know. Thank you ;)",5,deeplearning,2020-10-13
iqsul7,[R] OpenAI ‘GPT-f’ Delivers SOTA Performance in Automated Mathematical Theorem Proving,"San Francisco-based AI research laboratory OpenAI has added another member to its popular GPT (Generative Pre-trained Transformer) family. In a new paper, OpenAI researchers introduce GPT-f, an automated prover and proof assistant for the Metamath formalization language.

Here is a quick read: [OpenAI ‘GPT-f’ Delivers SOTA Performance in Automated Mathematical Theorem Proving](https://syncedreview.com/2020/09/10/openai-gpt-f-delivers-sota-performance-in-automated-mathematical-theorem-proving/)

The paper *Generative Language Modeling for Automated Theorem Proving* is on [arXiv](https://arxiv.org/pdf/2009.03393.pdf).",43,deeplearning,2020-10-13
iqsfel,Magically remove humans from videos with this AI,,1,deeplearning,2020-10-13
iqq71t,Bolts - a new deep learning research and production tool box from PyTorch,,2,deeplearning,2020-10-13
iqowvk,What would you like from a model that recommends pc components based on the purchasers usecase?,,2,deeplearning,2020-10-13
iqn485,Detect the object in the image and crop it from the edges?,Detect the object (fruits) in the image and crop it from the edges. I want .png image of the object.  How can I implement it using ML and OpenCV,2,deeplearning,2020-10-13
iqmfuo,"Beam Search is useful for Sequence-to-Sequence problems, But how does spacy utilizes beam search in NER task?","Hey Everyone, recently I have studied about Beam search from Andrew Ng's video and successfully used them for machine translation tasks. But when I was trying to use Spacy for the NER task they also provide a beam search option and this has confused me a lot.

Since beam search makes sense when we are about to generate the next sequence and previous sequence information is required and all of this happens in the decoder step.   


But in the NER task model will make the prediction in one go for the entire sequence in the encoder step itself so how does spacy utilizes beam search in the NER task.  
I don't know how internally spacy trains the model but since I have trained the model for the NER task using Flair and Stanza library they utilize CRF decoding which I know and have used previously.",5,deeplearning,2020-10-13
iql2nn,"ERCIM, the European Research Consortium for Informatics and Mathematics, offers fellowships for PhD holders from all over the world. Next Application deadline 30 Sep 2020",,3,deeplearning,2020-10-13
iqkzuj,Anyone who deployed a object detection model on an edge device. What is your experience.,I am working on a project where I need to run the object detection model on a edge device mostly on Jetson Nano. I would like to know the experience of that process.,2,deeplearning,2020-10-13
iqk97j,Animating .obj files from video to .fbx,"Hello,

Not sure if this is the correct subreddit for the post but hoping it would give me some direction. 

I have a sequence of .obj files generated for each frame of  video. I  know we can read the single .obj file in autodesk but I was  wondering  how to generate the animation. This is the format of my data  : 

pred\_cam (n\_frames, 3) # weak perspective camera parameters in cropped image space (s,tx,ty)  
orig\_cam (n\_frames, 4) # weak perspective camera parameters in original image space (sx,sy,tx,ty)  
verts (n\_frames, 6890, 3) # SMPL mesh vertices  
pose (n\_frames, 72) # SMPL pose parameters  
betas (n\_frames, 10) # SMPL body shape parameters  
joints3d (n\_frames, 49, 3) # SMPL 3D joints  
joints2d (n\_frames, 21, 3) # 2D keypoint detections by STAF if pose tracking enabled otherwise None  
bboxes (n\_frames, 4) # bbox detections (cx,cy,w,h)s  
frame\_ids (n\_frames,) # frame ids in which subject with tracking id #1 appears

Can you please help me in this regard ?",1,deeplearning,2020-10-13
iqioqt,"""DeepSpeed: Extreme-scale model training for everyone"" {MS} (1t-parameter models now trainable; able to use CPU+GPU RAM simultaneously; sparse attention for saving RAM; sparsified Adam gradients for saving bandwidth)",,27,deeplearning,2020-10-13
iqdy8t,Need help finding resources for a project,Can anyone direct me to any resources or papers that use deep learning for perception and motion planning using a camera data as input.,2,deeplearning,2020-10-13
iqb93w,AI For Entrepreneurs Episode 2 : Kwabena Agyeman,"In 2015, they did a Kickstarter campaign for a smart camera based on a microcontroller. The campaign was a huge success and they raised more than $100k. 

And then came a disaster they were not prepared for. One of the components in the camera failed leaving 80% of the cameras unusable. But they fought back hard and delivered the cameras against all odds. 

In this episode, we will learn about OpenMV, microcontrollers, why they matter, and the challenges of porting computer vision algorithms to microcontrollers. 

But above all, we will learn about the amazing journey of a resilient entrepreneur Kwabena Aygeman who is one of the co-founders of OpenMV. 

[https://youtu.be/EBiI627K8A8](https://youtu.be/EBiI627K8A8)",1,deeplearning,2020-10-13
iq939r,"Which GPU(s) to Get for Deep Learning (compares 3080, 3090, A100, V100, etc)",,12,deeplearning,2020-10-13
iq7sle,Inference on V100 vs T4 = Tensorflow vs Pytorch?,"Per NVidia's benchmarks of their own optimal implementation of ResNext and SE-ResNext here are the inference speeds for mixed precision 128-batch:

&amp;#x200B;

For SE-ResNext101-32x4d

V100 on Pytorch: 977.86 img/s  
V100 on TensorFlow: 1683.63 img/s  
T4 on Pytorch: 856.19 img/s  
T4 on TensorFlow: 244.45 img/s

&amp;#x200B;

For ResNext101-32x4d

V100 on Pytorch: 1079.10 img/s  
V100 on TensorFlow: 1892.97 img/s  
T4 on Pytorch: 948.27 img/s  
T4 on TensorFlow: 272.17 img/s

&amp;#x200B;

Pytorch leaps over TensorFlow in terms of inference speed since batch size 8. Might have to do with TensorFlow having a computationally suboptimal tensor structure with channels being the last dimension or with using Tensor Cores efficiently.  


No training time info was provided for T4. 

As for A100, TensorFlow wins in terms of SE-ResNext training speed coming at 140% PyTorch speed, though take this with a grain of salt, as they seem to have ran that test at 256 batch size for TensorFlow and at 128 for PyTorch.

&amp;#x200B;

[https://github.com/NVIDIA/DeepLearningExamples/tree/master/TensorFlow/Classification/ConvNets/resnext101-32x4d](https://github.com/NVIDIA/DeepLearningExamples/tree/master/TensorFlow/Classification/ConvNets/resnext101-32x4d) [https://github.com/NVIDIA/DeepLearningExamples/tree/master/PyTorch/Classification/ConvNets/resnext101-32x4d](https://github.com/NVIDIA/DeepLearningExamples/tree/master/PyTorch/Classification/ConvNets/resnext101-32x4d) 

&amp;#x200B;

[https://github.com/NVIDIA/DeepLearningExamples/tree/master/PyTorch/Classification/ConvNets/se-resnext101-32x4d](https://github.com/NVIDIA/DeepLearningExamples/tree/master/PyTorch/Classification/ConvNets/se-resnext101-32x4d)

[https://github.com/NVIDIA/DeepLearningExamples/tree/master/TensorFlow/Classification/ConvNets/se-resnext101-32x4d](https://github.com/NVIDIA/DeepLearningExamples/tree/master/TensorFlow/Classification/ConvNets/se-resnext101-32x4d)",1,deeplearning,2020-10-13
iq7skr,[SIGKDD 2020 Paper] BusTr: predicting bus travel times from real-time traffic,,1,deeplearning,2020-10-13
iq548t,I created a collection of notebooks related to Machine Learning.,,2,deeplearning,2020-10-13
iq1sia,Speed up image labeling using transfer learning (no code required),"Transfer learning is one of the new hot solutions to automate image annotation. 

[This article](https://blog.superannotate.com/speed-up-labeling-process-using-transfer-learning) goes into detail on how transfer learning works and how to do it without a single line of coding.  

Here's the outline of the article:

* *What is transfer learning and how it can be applied to the annotation process*
* *Training new neural networks using SuperAnnotate*
* *Testing newly trained network*
* *Conclusion*",2,deeplearning,2020-10-13
iq10sj,Council-GAN - Breaking the Cycle (CVPR 2020) - Free live zoom lecture by the author,,73,deeplearning,2020-10-13
iq0von,Machine Learning Researchers Spot Deep Fakes From Heartbeats,[https://analyticsindiamag.com/deepfake-heartbeat-machine-learning-detection/](https://analyticsindiamag.com/deepfake-heartbeat-machine-learning-detection/),1,deeplearning,2020-10-13
iq01sn,There is an object detection project that I am currently working on. The idea is to develop a product which can run on an edge device.,"In a standard way, I wanted to know, what is actually developing a product which caN run on edge means. How do people approach this problem. What are the steps. 

Let's say if I want to detect a pet detector on an edge using jetson nano. What is the pipeline.   


Any help is highly appreciated.",1,deeplearning,2020-10-13
ipxh5e,[Question] Hardware suggestion for Darknet and YOLO,"What hardware should I buy if I have a lot of video material and want to evaluate it as quickly and reliably as possible using OpenDataCam ([https://github.com/opendatacam/opendatacam](https://github.com/opendatacam/opendatacam))?

&amp;#x200B;

Since the RTX 3090 was just released, my first thought was to buy and use one or two of them. 

But I read that an A100 is a much more efficient GPU. 

&amp;#x200B;

Would anyone have any idea what kind of hardware I should buy for the Debian/Ubuntu system? At best including CPU and RAM.",0,deeplearning,2020-10-13
ipvgbu,Medical Science Deep Learning Study Suggestions,"What are some unrealized applications for deep learning in health sciences? I am a health sciences graduate student and I think there is a wealth of opportunity for machine learning in the field, but I am rather inexperienced in it. It can be as simple or complex as you can think of, just compiling a list of ideas.",1,deeplearning,2020-10-13
ipv0kf,Compression-aware Continual Learning using Singular Value Decomposition,"A simple paradigm to incorporate continual learning for incremental task scenarios using compression based methods and a novel sharing mechanism. Our method significantly outperforms prior continual learning approaches on three benchmark datasets, demonstrating accuracy improvements of 10.3%, 12.3%, 15.6% on 20-split CIFAR-100, miniImageNet and a 5-sequence dataset, respectively, over state-of-the-art. Further, our method yields compressed models that have ~3.64x, 2.88x, 5.91x fewer number of parameters respectively, on the above mentioned datasets in comparison to baseline individual task models.
You can check out the paper at https://arxiv.org/abs/2009.01956
Please feel free to reach out to me for any further information regarding the work. Any comments would be highly appreciated!
You can check out the paper at https://arxiv.org/abs/2009.01956",1,deeplearning,2020-10-13
ipsris,Learnable pooling weights for facial expression recognition,,1,deeplearning,2020-10-13
ipqqx7,State of the art in video completion from Facebook and Virginia Tech!,,1,deeplearning,2020-10-13
ipo9ck,Feature visualization and feature maps,"I'm currently working on an unsupervised feature extraction method of 3D Images based on stacked Independent subspace analysis. The filters obtained through this have dimensions different than that of the original image. I'm unable to visualize filters from layer 2 and above because the dimensions are reduced. I've done visualization of filter and feature maps in CNN and had no problem. But with this, I'm unable to figure it out. Anyone here has an idea on how to visualize filters in similar stacked networks?

I could provide more detail on stacked Independent subspace analysis if required.",2,deeplearning,2020-10-13
ipnoh4,[R] New Multitask Benchmark Suggests Even the Best Language Models Don’t Have a Clue What They’re Doing,"The recently published paper, *Measuring Massive Multitask Language Understanding,* introduces a test covering topics such as elementary mathematics, US history, computer science, law, etc., designed to measure language models’ multitask accuracy. The authors, from UC Berkeley, Columbia University, UChicago, and UIUC, conclude that even the top-tier 175-billion-parameter OpenAI GPT-3 language model is a bit daft when it comes to language understanding, especially when encountering topics in greater breadth and depth than explored by previous benchmarks.

Here is a quick read: [New Multitask Benchmark Suggests Even the Best Language Models Don’t Have a Clue What They’re Doing](https://syncedreview.com/2020/09/09/new-multitask-benchmark-suggests-even-the-best-language-models-dont-have-a-clue-what-theyre-doing/)

The paper *Measuring Massive Multitask Language Understanding* is on [arXiv](https://arxiv.org/pdf/2009.03300.pdf).",3,deeplearning,2020-10-13
iplg7h,Using Multi-Objective Deep Reinforcement Learning to Uncover a Pareto Front in Multi-Body Trajectory Design,,2,deeplearning,2020-10-13
ipg9yn,Introduction to Keras for Deep Learning in 60 Minutes,"[**In this tutorial**](https://youtu.be/dvVOdWeDgF0), our expert instructor Varun Rao will introduce you to Keras, the open-source neural-network library. Moreover, you will learn to install and test different versions of Keras as well. 

Besides being user-friendly, Keras supports different product deployment options and can be integrated with back-end engines like Theano and TensorFlow at ease.",1,deeplearning,2020-10-13
ipft1r,KL Divergence term in VAE behaving strangely while training,"So, I have a problem where I'm training a Convolutional VAE with the reconstruction and the latent loss (KL term).

Now the strange thing is that while training, the KL term is monotonically non decreasing while the reconstruction loss is monotonically non increasing. I'm calling this strange because usually the KL term decreases and then vanishes (from what I've read, and I saw this behaviour in my previous stint with VAEs).

Could someone point out a possible reason or point me towards a blog/paper which explains this?",1,deeplearning,2020-10-13
ipfe2l,Holy crap! Some guy shouted “Machine learning is just statistics!” and then this happened,,346,deeplearning,2020-10-13
ipf8aq,Project suggestions needed!,"Hello!

I've enrolled in a Deep Learning course at my university. I am supposed to submit a project by the end of the course. We have been advised to use PyTorch for it. I am a complete beginner in this field and would love to get your ideas for doing a project. Of course I can browse the internet for ideas (which I will anyway), but wanted to get some of your suggestions too. Thanks!",1,deeplearning,2020-10-13
ipemjp,AI Generates Real Faces From Sketches! DeepFaceDrawing Overview | Image-to-image translation in 2020,,3,deeplearning,2020-10-13
ipegj4,Neuromorphic Computing: The Next-Level Artificial Intelligence,,0,deeplearning,2020-10-13
ipd51g,Can anyone give me advice about my chances to get into MSc. program at MILA (Yoshua Bengio group)?,Should I even think about applying to MILA for M.Sc. if my graduate percentage is 70%? Although I  have many projects related to computer vision and machine learning on my profile and also a research paper based on image captioning which I've submitted to Springer and is currently under review. I'm interested in computer vision as an area of research. My GRE prep is going on well.,1,deeplearning,2020-10-13
ipcngp,SpanBERT: Improving Pre-training by Representing and Predicting Spans | Research Paper Walkthrough,,11,deeplearning,2020-10-13
ipbugk,How do I allocate memory percentage per GPU. Getting an memory error for 1050ti . But I also have 2070 super in the same machine.,I'm using Darknet to train yolov4 on detection of tomatoes. The training was done on 2070 super for a while. Then I realised I can put my other GPU in the machine too. So now I have 1050 to and 2070 Super both running. But darknet is throwing a memory error for 1050ti .. I don't want to decrease my batch size. That will be like I'm using two 1050ti s .. is there any way around this ? Or should I just stick to 2070 Super .,0,deeplearning,2020-10-13
ip4k03,Ising Models as Deep Learning Frameworks,,1,deeplearning,2020-10-13
ip2ji6,Registration and Segmentation of 3D volumes,"Is it possible to perform segmentation and registration using the convolutional and recurrent layers of a CRNN for 3D volumes that are segments of a larger volume? Can a CNN be applied for the segmentation, then TCN or RNN for registration in this case?",0,deeplearning,2020-10-13
ip1yby,Detect Pattern Changes In Images,"Hello guys,  


This is my first question in this sub-reddit. I would highly appreciate some response.   


I have image datasets available for PV panels. I've uploaded an example image. My project entails designing a model of a system that is able to detect the following from PV panel picture taken from one particular angle:  


1. Clean or dirty from soiling.  


2. Classify the type of soiling (it could be just one type of soiling, sand, or it could be multiple, say sand and snow)   


3. Predict the probable power-loss from it.  


I intend to follow the CNN method paired with Tensorflow and Keras. What other packages do I need that will allow me to achieve those tasks above?  


I would highly appreciate if you guys could point me out in the right direction. I'm a beginner, and I've a project to submit by 1st of October. Thank you very much for time. :)",0,deeplearning,2020-10-13
ip0bib,Training a Custom Object Detector with Dlib &amp; Making Gesture Controlled Applications,"In today's blog post, we will discuss how to build python-based gesture-controlled applications using AI. In the process, you will learn training a custom Hand Detector with Dlib, automating the data collection &amp; annotation step, controlling your computer using gestures through your webcam.

We will guide you all the way with step-by-step instructions. I’m sure you will have loads of fun following the tutorial!

[https://www.learnopencv.com/training-a-custom-object-detector-with-dlib-making-gesture-controlled-applications/](https://el2.convertkit-mail.com/c/27uzm7dogztohl7e8vu8/x0hph3u7gv857qb5/aHR0cHM6Ly93d3cubGVhcm5vcGVuY3YuY29tL3RyYWluaW5nLWEtY3VzdG9tLW9iamVjdC1kZXRlY3Rvci13aXRoLWRsaWItbWFraW5nLWdlc3R1cmUtY29udHJvbGxlZC1hcHBsaWNhdGlvbnMv)

and you can find the **code** at [https://github.com/spmallick/learnopencv/tree/master/Training\_a\_custom\_hand\_detector\_with\_dlib](https://el2.convertkit-mail.com/c/27uzm7dogztohl7e8vu8/6qhehou2q8vm23to/aHR0cHM6Ly9naXRodWIuY29tL3NwbWFsbGljay9sZWFybm9wZW5jdi90cmVlL21hc3Rlci9UcmFpbmluZ19hX2N1c3RvbV9oYW5kX2RldGVjdG9yX3dpdGhfZGxpYg==)",0,deeplearning,2020-10-13
ip09ls,[D] Why Anchor Boxes in Object Detection,"What I understand from the anchor boxes is that they are predefined set of boxes of different sizes and shapes. A model like YOLO predicts offsets of the coordinates for each anchor box along with confidence and class scores. Please Correct me If I am wrong here.

What is the purpose of anchor boxes? why don't we just make the model predict multiple bounding boxes per cell or grid instead of predicting offsets for each predefined anchor box?

Also how these anchor boxes are used in loss functions of detection models?

This might be a beginner question but I am really not getting this. Any help or explanation will really be appreciated. Thanks",11,deeplearning,2020-10-13
iozr85,"Gradient Descent Algorithm, Clearly Explained 👀","[https://neuraspike.com/blog/gradient-descent-algorithm/](https://neuraspike.com/blog/gradient-descent-algorithm/) 😉

\#NeuraSpike #DeepLearning #MachineLearning #ArtificialIntelligence #DataScience

https://i.redd.it/kea7pmzp1zl51.gif",0,deeplearning,2020-10-13
iozlqu,"I feel like something is definitely wrong with the curve. It's too bumpy .. yolov4 with 64 batchsize and sub batches with 1000 iterations. Lr at 0.005 and steps at 800,900.",,0,deeplearning,2020-10-13
ioxlxq,Conditional Face Generation with PyTorch (kaggle kernel),,0,deeplearning,2020-10-13
ioxkih,Baka Mitai meme template error,"Hello, I am using [This Python code script](https://colab.research.google.com/github/AliaksandrSiarohin/first-order-model/blob/master/demo.ipynb) to make a Baka Mitai (Dame Da Ne) meme with an image, but everytime I get this error 

 FileNotFoundError: No such file: '/content/gdrive/My Drive/first-order-motion-model/02.png' 

I have a folder named first-order-motion-model and a png file called ""02"", I don't know why I get the error. Any fixes?",0,deeplearning,2020-10-13
ioxahq,Adversarial attacks and defenses on neural networks in PyTorch,"I recently started doing research on adversarial attacks and defenses of neural networks. I thought it would be interesting to share with you one of the earliest yet effective attacks (FGSM) and how to defend it through adversarial training, implemented in PyTorch:

[https://medium.com/@taying.cheng/adversarial-attack-and-defense-on-neural-networks-in-pytorch-82b5bcd9171](https://medium.com/@taying.cheng/adversarial-attack-and-defense-on-neural-networks-in-pytorch-82b5bcd9171)",0,deeplearning,2020-10-13
iowfgp,Suggestions for deeplearning on linux.,"I am starting my masters degree and planning to buy a laptop(PC is out of option). I have heard nvidia drivers have poor support on linux. If that is the case, I would be better off without a GPU. I also don't know how economically feasible it is to use cloud for training.",6,deeplearning,2020-10-13
iov9qy,Proper use of Tensorflow dataset prefetch and cache options,"I have read TF pages and some posts and about the use of prefetch() and cache() to speed up model input pipeline and tried to implement it on my data. Cache() worked for me as expected, i.e. reading data from the dist in the first epoch, and in the all subsequent epochs it is just reading data from memory. But I have many difficulties using prefetch() and I really don't understand when and how to use it. Can anybody help me with it? I really need some help.

My application is like this: I have a set of large TFRecord files, each includes some raw records to be processed before feeding my net. They are going to be mixed (different sample streams) so what I do is:

    def read_datasets(pattern, numFiles, numEpochs=125, batchSize=1024, take=dataLength):
    
        files = tf.data.Dataset.list_files(pattern)
    
        def _parse(x):
            x = tf.data.TFRecordDataset(x, compression_type='GZIP')
        return x
    
        np = 4 # half of the number of CPU cores
        dataset = files.interleave(_parse, cycle_length=numFiles, block_length=1, num_parallel_calls=np)\
        .map(lambda x: parse_tfrecord(x), num_parallel_calls=np)
        dataset = dataset.take(take)
        dataset = dataset.batch(batchSize)
        dataset = dataset.cache()
        dataset = dataset.prefetch(buffer_size=10)
        dataset = dataset.repeat(numEpochs)
        return dataset

parse\_tfrecord(x) function in interleave function is the required preprocessing of data before it applies to the model, and my guess is that the preprocesing time is comparable to the batch processing time by network. My whole dataset (including all input files) contains about 500 batch of 1024 samples. My questions are:

1- If I do caching, do I really need prefetching?

2- Is it the right sequence to do mapping, batching, caching, prefetching, and repeating?

3- Tensorflow documentation says that the buffer size of prefetch refers to the dataset elements and if it is batched, to the number of batches. So in this case I will read 10 batches of 1024 examples, right? My problem is that I don't see any difference in run time by changing prefetching buffer size and the memory consumption is not changed much even by setting buffer size to 1000 or bigger.

I appreciate any help.",2,deeplearning,2020-10-13
iouioz,Has anyone had experience training with EEG data?,"I'm currently struggling with an EEG classification task and am finding it very challenging to make progress. I have a large high quality dataset and even using models in published research in the field I am unable make progress.

Anyway, has anyone here had success training on EEG data? I should note that this is end-to-end training on raw (artifacted) EEG and not on features derived from the EEG. 

Happy to clarify further in comments.",2,deeplearning,2020-10-13
iotqco,Way to Deep learning,"I completed the machine learning course by IBM on Coursera. Before that, I learned the basics of python, NumPy and pandas. And in that course, the lab projects have been done using scikit-learn. But for some reason, It feels relatively easy doing it not in a good way using scikit learn because it is really simple to understand and implement for me that is something anyone can do. So I tried to use python only to implement those ML models that I learned in that course. As I am not that good with python, I ran into errors all the time and it consumes a whole lot of time. My main aim is to learn deep learning so I started with ML to grasp the basic concepts of it. Now should I go straight to deep learning or should I continue doing the ml models in python only and read the academic papers? And is the time that I try to use those ml models using python without any libraries worth it? Like will it make a difference when I go into deep learning or deep learning also depends on libraries? I want to be someone who researches in AI and not just sit behind a desk working a 9 to 5 job.",14,deeplearning,2020-10-13
iopwr3,"How long RTX 3080 will last, if used for deeplearning?","I'm a beginner at DL and thinking of getting an RTX 3080. 3080 will be used for gaming as well as deep learning, do you think my GPU will last 5 years if I put so much load on it?

and is one RTX 3080 sufficient for DL or multiple GPUs are required?",13,deeplearning,2020-10-13
iopqr4,"generated texture like the skin of a snake, when training cartoonGAN used the dataset of Celea-HQ and DANBOORU2018 face, anyone could tell me why,thanks",,7,deeplearning,2020-10-13
iom41l,Latest in drones! Efficient trajectory generation for chasing a dynamic target,,4,deeplearning,2020-10-13
ioikrw,Artificial Intelligence Academy (AIA),"Our mission is to Train and Certify the next generation of software developers and engineers worldwide in artificial intelligence and machine learning. Niches: Artificial Intelligence, Machine Learning, Data Science, Python, TensorFlow, PyTorch, Convolutional Neural Networks.. Top Partners: Google, Microsoft, IBM, DeepLearning.ai, MIT, Johns Hopkins, Stanford University, University of Michigan, UC Berkeley, Coursera, Pearson IT, EDx and Edureka.

Visit us today at:  https://aimlacademy.blogspot.com/    
  
Lawrence E. Wilson",0,deeplearning,2020-10-13
ioiiyz,Artificial Intelligence Academy (AIA),"Our mission is to Train and Certify the next generation of software developers and engineers worldwide in artificial intelligence and machine learning. Niches: Artificial Intelligence, Machine Learning, Data Science, Python, TensorFlow, PyTorch, Convolutional Neural Networks.. Top Partners: Google, Microsoft, IBM, DeepLearning.ai, MIT, Johns Hopkins, Stanford University, University of Michigan, UC Berkeley, Coursera, Pearson IT, EDx and Edureka.

Visit us today at:  https://aimlacademy.blogspot.com/    
  
Lawrence E. Wilson",0,deeplearning,2020-10-13
iof8wd,"Please, advise on 3090 vs 3080 for training GANs",How much does RAM and NVlink count? Is 20-25% more performant (for same batch size) 3090 worth the 2x price and much sharper depreciation? What potential training speed difference do you foresee.,0,deeplearning,2020-10-13
ioernz,[P] Open-sourcing beginner-friendly PyTorch GANs project,"This repo is geared towards learning. For those of you who don't have any experience with GANs I'd recommend you go through this code. It's heavily commented and I've added useful links around the README and in the code as well: [https://github.com/gordicaleksa/pytorch-gans](https://github.com/gordicaleksa/pytorch-gans)

But also those of you with more experience might find it useful!

I'll add conditional GANs and DCGAN in a couple of days but wanted to share this immediately with you. In the future, I'll potentially add new GAN architectures - if I can't find one myself.

There are already a couple of awesome PyTorch GAN repos out there but none of them as clean as this one I dare say.

Anyways, enjoy it! Any feedback is welcome!

Note: This repo will best work as a supplement to some theory, blogs, videos you find on the internetz.",0,deeplearning,2020-10-13
iobuf5,[D] Which GPU(s) to get for Deep Learning (Updated for RTX 3000 Series),"Tim Dettmers just updated his legendary blogpost to include advice for the RTX 3000 series

Blog: [https://timdettmers.com/2020/09/07/which-gpu-for-deep-learning/](https://timdettmers.com/2020/09/07/which-gpu-for-deep-learning/)

PS: I had a chance to interview him earlier last year, this interview also has some very general PC Building advice (among other topics): [https://www.youtube.com/watch?v=8Fp9m4fNDQ4](https://www.youtube.com/watch?v=8Fp9m4fNDQ4)",32,deeplearning,2020-10-13
ioagzc,Data Interpolation using deep learning,"Hello community , I was wondering if it was some technique to interpolate real time data .
I have 1 HZ data , I want to upsample it to 10Hz data .

I tried cubic spline and other techniques 
I heard that VAE was used to generate data.

What do you think about using Variational AUTOENCODER for this purpose ? 

Thank you",1,deeplearning,2020-10-13
ioa6gy,Transformer Architecture Explained,,0,deeplearning,2020-10-13
io884w,[D] The latest scope of ML news,"When the time comes to select a machine learning platform, do you favor the consistency of end-to-end machine learning platforms like Azure ML or SageMaker? Or the fast innovation of best-of-breed startups? What do you base your choice on? 

We discuss this topic in our free weekly newsletter about developments in AI industry.

Please share your opinion here or in the comment section of the newsletter.

Also in this edition:

\+ML Research Papers: Reasoning About Abstract Concepts by Massachusetts Institute of Technology; Quantum Chemistry Simulations by GoogleAI; Traffic Predictions with Graph Neural Networks by DeepMind and Google; DeepFakes’ heartbeats by Binghampton University and Intel AI.

\+Cool Tech Releases: Opacus by Facebook AI, PSI by MicrosoftResearch, AllenAct by Allen Institute.

\+Our very popular section 'Money in AI' that covers recent investments injected into **AI** industry.

Please sign up for this free weekly Scope of the most relevant ML news.

https://thesequence.substack.com/p/-end-to-end-vs-best-of-breed-machine",0,deeplearning,2020-10-13
io7wz5,[D] The latest scope of ML news,"When the time comes to select a machine learning platform, do you favor the consistency of end-to-end machine learning platforms like Azure ML or SageMaker? Or the fast innovation of best-of-breed startups? What do you base your choice on? 

We discuss this topic in our free weekly newsletter about developments in AI industry.

Please share your opinion here or in the comment section of the newsletter.

Also in this edition:

\+ML Research Papers: Reasoning About Abstract Concepts by Massachusetts Institute of Technology; Quantum Chemistry Simulations by GoogleAI; Traffic Predictions with Graph Neural Networks by DeepMind and Google; DeepFakes’ heartbeats by Binghampton University and Intel AI.

\+Cool Tech Releases: Opacus by Facebook AI, PSI by MicrosoftResearch, AllenAct by Allen Institute.

\+Our very popular section 'Money in AI' that covers recent investments injected into **AI** industry.

Please sign up for this free weekly Scope of the most relevant ML news.

https://thesequence.substack.com/p/-end-to-end-vs-best-of-breed-machine",0,deeplearning,2020-10-13
io7wkt,[D] The latest scope of ML news,"When the time comes to select a machine learning platform, do you favor the consistency of end-to-end machine learning platforms like Azure ML or SageMaker? Or the fast innovation of best-of-breed startups? What do you base your choice on? 

We discuss this topic in our free weekly newsletter about developments in AI industry.

Please share your opinion here or in the comment section of the newsletter.

Also in this edition:

\+ML Research Papers: Reasoning About Abstract Concepts by Massachusetts Institute of Technology; Quantum Chemistry Simulations by GoogleAI; Traffic Predictions with Graph Neural Networks by DeepMind and Google; DeepFakes’ heartbeats by Binghampton University and Intel AI.

\+Cool Tech Releases: Opacus by Facebook AI, PSI by MicrosoftResearch, AllenAct by Allen Institute.

\+Our very popular section 'Money in AI' that covers recent investments injected into **AI** industry.

Please sign up for this free weekly Scope of the most relevant ML news.

https://thesequence.substack.com/p/-end-to-end-vs-best-of-breed-machine",0,deeplearning,2020-10-13
io6dmu,What are the scenarios when early stopping should NOT be used when training a NN?,All in title.,3,deeplearning,2020-10-13
io5sn1,General Guidance,I've completed the deep learning specialization on coursers (the one by Andrew NG) and a few other minor courses (i know there's still a long way to go) and projects but I still don't feel as confident about just going out there and practically implementing a project by myself 😅 Any tips on what i should do now or how I should get a bit more comfortable in the field ? I know its a vary vague question but any help would be appreciated !,0,deeplearning,2020-10-13
io5htw,AI Portrait : What kind of architecture to use to convert an image to a portrait using Deep Learning,,3,deeplearning,2020-10-13
io5b0a,AI Portrait : What kind of architecture to use to convert an image to a portrait using Deep Learning,,86,deeplearning,2020-10-13
io4fgj,[Discussion] How to limit Volatile GPU Util in Pytorch on NVIDIA P5000?,"I'm trying to run two Pytorch Model in an application on Nvidia P5000 using Docker . One is YOLO V5 &amp; another one is a pose estimation model .

First Situation: I loaded two model in a single script, these are supposed to be runsequentially, YOLO V5 followed by Pose Estimator. In this case, GPU Memory
usage is around 1.5GB out of 16 GB and Volatile GPU Util is max up to 35%.

Second Situation: Since YOLO V5 is quite faster, I thought of separating it inanother container to parallelize the inference. Now, GPU Memory is around 1.5-2GB out of 16 GB for both the container but GPU Util around 70-80% with muchfluctuations.

In the first case, yolov5 was taking around 2030 ms and pose estimation wastaking upto 180ms/frame. While in the second case YOLO V5 optimised to19ms/frame and pose estimation started taking 300-350 ms/frame.

I believe, this could be because of YOLO V5 container started taking upto 50%Volatile GPU Util.

I'm new to this, could anyone suggest the possible way to reduce/customise thevolatile GPU Until so that inference of pose estimate could be faster.

Any suggestions are highly appreciated.
Thanks in advance.",0,deeplearning,2020-10-13
io2mfc,Plan2Explore: Planning to Explore via Self-Supervised World Models | Paper Explained,,1,deeplearning,2020-10-13
io1u8o,When to stop training YOLO,"I am training a (slightly) customized YOLO for detecting a single class object. I have around 9k annoated images and split them 80/20 for training/validation. I apply a good amount of augmentation.

When would you stop training? See plot below. around 600 epocs the validation error stops decreasing while the training error keeps descreasing. 

&amp;#x200B;

https://preview.redd.it/ax6sop4txnl51.png?width=649&amp;format=png&amp;auto=webp&amp;s=a61df0ab95a775bec9ad9ffcacf797b32906163c",7,deeplearning,2020-10-13
inu5du,"Facebook AI open-sources Opacus, a new high-speed library for training PyTorch models with differential privacy (DP)","With the growing interest in machine learning (ML), the use of differential privacy is trending in analytics. It’s a mathematical rigorous framework for quantifying the anonymization of sensitive data. Keeping in mind this growing interest, Facebook AI launched Opacus.

Opacus is the new high-speed library for training PyTorch models with differential privacy. With minimal required code modifications, this library supports training and has minimal impact on training performance. Thus, It provides an easier path to adopt differential privacy in machine learning and boost research. Compared to the existing state-of-the-art methods, Opacus has a significant advantage of being more scalable.

Blog: [https://www.marktechpost.com/2020/09/06/facebook-ai-open-sources-opacus-a-new-high-speed-library-for-training-pytorch-models-with-differential-privacy-dp/](https://www.marktechpost.com/2020/09/06/facebook-ai-open-sources-opacus-a-new-high-speed-library-for-training-pytorch-models-with-differential-privacy-dp/)

Github: [https://github.com/pytorch/opacus?](https://github.com/pytorch/opacus?)",39,deeplearning,2020-10-13
insgub,"Multi-GPU (seven) RTX 3090 workstation, possible? - build critique request",,0,deeplearning,2020-10-13
ins6v6,"Neural Networks: A 30,000 Feet View for Beginners","Most of our blogs have a generous amount of maths and demonstrations with a sprinkling of theory.  
So we decided to go back to a short, sweet and math-free blog. 

  
[https://www.learnopencv.com/neural-networks-a-30000-feet-view-for-beginners/](https://www.learnopencv.com/neural-networks-a-30000-feet-view-for-beginners/)  
The post is written for absolute beginners who are trying to dip their toes in Machine Learning and Deep Learning and is aptly titled Neural Networks: A 30,000 Feet View for Beginners 

https://preview.redd.it/3o5blsg2wkl51.jpg?width=768&amp;format=pjpg&amp;auto=webp&amp;s=eecd1de1b69ff71d23856f3f065adef9ec25b916",0,deeplearning,2020-10-13
inrj0g,An intuitive and visual explanation of the derivative of the sigmoid and softmax functions,,5,deeplearning,2020-10-13
innfcf,Train Multi-Class Classifier for Multi-Label Classifier (on Image),"Hello, I’ve stepped into the world of deep learning for months. I have finished the simple DNN for binary classification on image, or multi-class classification with CNN. 

Currently, I want to try another project, but I encountered some problem. 

I want to implement “face detection” with deep learning. After searching, I found that YOLO will be a good choice because I can train neural network for face or object detection. After reading the YOLO1 Paper, I thought I can do some easier first...
(Hope someone can give me some advice, I think detection = localization + classification. But I discovered that “localization” is very difficult!!!)

Hence, I want to simply implement “multi-label” classification. That is, an image including three people/faces is the input of model, model will output the labels representing three people. 

My question is that I train my model for multi-class classification (1000 images for person A, 1000 images for person B and 1000 images for person C), and testing my model for multi-label classification (input an image including three people, model should output three class all with high value). But the test result is bad.

I’m so confused about this result. I think if the model is trained on multi-class classification, it means that the model can “classify” these three people. However, why the testing result is still bad?

Thank you for your reading and comment.",2,deeplearning,2020-10-13
inne7y,Looking for a book to dive deeper into deeplearning.,"I've completed the deep learning specialization by Andrew Ng and so I know the basics of deeplearning. However when I try to read and understand the latest papers, I am not able to understand a thing. Maybe my intuition is not that great about how a neural network works. So I was in search of a good book on deep learning to  further crystallize my intuition and understanding of why and how neural networks work. 

Thank you !",3,deeplearning,2020-10-13
inlkpd,We present CARLA Car Chasing dataset - open sourced dataset for autonomous driving research,,26,deeplearning,2020-10-13
inlcod,Please share a recent Multi Object Tracking code for Person tracking that they had good experience with,"Edit: Title has a typo.   


Here's the SOTA list that I am following [https://paperswithcode.com/task/multiple-object-tracking](https://paperswithcode.com/task/multiple-object-tracking) I have tried [Towards Real-Time Multi-Object Tracking](https://paperswithcode.com/paper/towards-real-time-multi-object-tracking) and [FairMOT](https://github.com/ifzhang/FairMOT) but I am not getting the desired speed on a single GTX 1060 6Gb GPUand off course I tried DeepSort in the recent past but it has it's own issues and I need something more recent and close to SOTA",0,deeplearning,2020-10-13
inkx7p,Deep Learning PDF short Notes,,2,deeplearning,2020-10-13
inhrjj,Deep learning FastAI study partner,"Hi,

&amp;#x200B;

&amp;#x200B;

However as many of you are interested, why don;t you all form a group?

I have created a Studygroup in Discord, link: [https://discord.gg/WtK4h6](https://discord.gg/WtK4h6) 

this link is valid till 14 Sep, 7PM India time 

&amp;#x200B;

FastAI v2  (2020) is course is out and available. Link: [https://course.fast.ai](https://course.fast.ai)

I have tried this a few times but never completed it. This time I want to:

1. complete and practice the 8 video chapters
2. complete the FastAI book "" *Practical Deep Learning for Coders* "", 20 chapters in 2020 (3.5 months)

&amp;#x200B;

I had mixed success with my earlier study groups. If you want to join, please post below or message me all the below details, failing which I will not consider you for the group. Am looking for only 2 people so this will be a small group. May not respond once slots are filled

&amp;#x200B;

What i need:

1. Willingness to commit to 1 hours each every Saturday and Sunday for remainder of 2020

&amp;#x200B;

\#NOTE: I have got details over personal email, as as I wanted to limit group size, sorry .. not looking to add more

&amp;#x200B;

&amp;#x200B;",13,deeplearning,2020-10-13
in7wb5,Does anyone know this text editor?,"Maybe it's only a concept art... 

https://preview.redd.it/3in4rmf9ydl51.jpg?width=2020&amp;format=pjpg&amp;auto=webp&amp;s=7adf152cae6789a8106c6e685c6b2f71ec158170",0,deeplearning,2020-10-13
in4yu2,Deep Diamond - Deep Learning in Clojure is Fast and Simpler than Keras,,0,deeplearning,2020-10-13
in4f8s,RTX 3090 vs RTX 3080 for Deep Learning,"I have delayed building a Deep Learning rig in anticipation for the release of RTX 3000 series and after the reveal, my first thought was 3090 but I am not so sure after seeing specs. Below is 3090 compared to 3080. I would like to get an opinion on what would work best for a DL rig, 1x RTX 3090 or 2x 3080. I am thinking dual 3080 would be better value even though the performance isn't going to scale linearly.

 

**GeForce RTX 3090 specs:**

* 8K 60-fps gameplay with DLSS
* 24GB GDDR6X memory
* 3-slot dual axial push/pull design
* 30 degrees cooler than RTX Titan
* 36 shader teraflops
* 69 ray tracing TFLOPS
* 285 tensor TFLOPS
* $1,499
* Launching September 24

**GeForce RTX 3080 specs:**

* 2X performance of RTX 2080
* 10GB GDDR6X memory
* 30 shader TFLOPS
* 58 RT TFLOPS
* 238 tensor TFLOPS
* $700
* Launching September 17",10,deeplearning,2020-10-13
in34o5,NLP papers,,1,deeplearning,2020-10-13
imzl8f,"ECCV 2020's Best Paper Award! A new architecture for Optical Flow, with code publicly available! (Video cover and demo)",,39,deeplearning,2020-10-13
imvy1v,Multi Matrix Deep Learning with GPUs : A brief history,,8,deeplearning,2020-10-13
imtulb,"What do you call a field where you optimize use of deep learning and image processing on small systems( Raspberry pi, etc)",Is there a call to this particular field? I heard it in a lecture but i kind of forgot what it was. Im kind of interested in them. Thank you very much.!!!,0,deeplearning,2020-10-13
imqtpj,ML/AI Code Implementation Finder (free browser extension),,2,deeplearning,2020-10-13
imqa78,[D] Is OpenAI’s GPT-3 API Beta Pricing Too Rich for Researchers?,"OpenAI’s 175 billion parameter language model GPT-3 (Generative Pre-trained Transformer 3) turned heads in the NLP community when it was released in June, and now it’s back in the spotlight. A Reddit [post](https://www.reddit.com/r/GPT3/comments/ikorgs/oa_api_preliminary_beta_pricing_announced/) this week by independent writer and researcher Gwern Branwen detailed the pricing plan OpenAI has provided to GPT-3 Beta API users. The scheme, which goes into effect on October 1, has already raised as many questions as it has answered.

Here is a quick read: [Is OpenAI’s GPT-3 API Beta Pricing Too Rich for Researchers?](https://syncedreview.com/2020/09/04/is-openais-gpt-3-api-beta-pricing-too-rich-for-researchers/)",1,deeplearning,2020-10-13
immp3d,Improving Deep Learning For Airbnb Search [SIGKDD 2020],,1,deeplearning,2020-10-13
imju7v,How TF-Coder Works? (Explained),"How  does TF-Coder synthesize the answers to TensorFlow questions in   StackOverflow at the ‘superhuman’ level? What are the technologies   behind it?

Check out my new blog post.

[https://us.github.io/how-tf-coder-works](https://us.github.io/how-tf-coder-works)",1,deeplearning,2020-10-13
imjlrh,Artificial Intelligence in Retail : Benefits &amp; Use Cases,,2,deeplearning,2020-10-13
imib62,Anyone Have: Google Cloud Platform Account W/ GPU Access,"Hello, 

I have been trying to get my Google Cloud Platform GPU quota increased from 0 to 1 for

almost a month now. I really need the GPU, however, support has done nothing but be vague and brief...

&amp;#x200B;

If anyone have a Google Cloud Platform Account W/ a GPU quota of at least one, could you please message me. I will deposit my own money into the account, you can remove billing, etc. 

=( Please",0,deeplearning,2020-10-13
imgbbc,Driving Cars with Augmented Reality,,0,deeplearning,2020-10-13
img84u,Deep Learning With TensorFlow Mini-project in 20 Minutes,,1,deeplearning,2020-10-13
imfb72,[P] vedaseg: An open source semantic segmentation toolbox based on PyTorch,,0,deeplearning,2020-10-13
imevme,Learn Maths Inside a Game,,0,deeplearning,2020-10-13
imd41p,Accurately Lip-syncing Videos,,61,deeplearning,2020-10-13
im7vza,Any tips/advice for training ImageNet on private cloud services?,"I’ve never used any private cloud services. I’m considering, say, renting some TPUs. I have no experience with this. Before I proceed, with the hopes of training a model on ImageNet from scratch, does anyone have any words of warning, caution, advice, or wisdom that might prepare me? 

I would appreciate any suggestions, down even to the simplest most rudimentary details and advice such as about how to begin.",1,deeplearning,2020-10-13
im5l5j,Pls vote!,,0,deeplearning,2020-10-13
im4xc6,Embedding a virtual Network on to a physical network using deep learning,"My masters thesis problem is to take a Virtual Network Embedding request (basically a graph) and map it to physical network ( another graph).

It is done in 2 stages ( **Node Embedding** and **Link Embedding**).

My main focus is on node embedding, which means choosing an appropriate node on physical network for each virtual node in Virtual Network Request. I am taking the choices made by an existing state of the art deterministic algorithm as the training data.

**Physical Network Description:**

A graph of 10 nodes where each node has a compute resource value and each link has bandwidth value

**Virtual Network Request  Description:**

A graph where each node has a compute resource request value and each link has bandwidth request value

**Input to Deep learning model:**

* Physical network current state
* Virtual Network Request State
* Virtual Node I want to embed

**Output :**

A softmax output of 10 nodes where each value represents the probability of hosting the virtual node onto the corresponding physical node.

&amp;#x200B;

My question is how do i model the input ?

**Current Model of Input :**

Physical network: \[adjacency matrix\] \[node matrix\]

Virtual Network : \[adjacency matrix\] \[node matrix\] \[ node selection vector\]

In node selection vector, the node i want to embed will be given a value of 1 and rest will have zero",3,deeplearning,2020-10-13
im49hp,Towards physics-informed deep learning for turbulent flow prediction [SIGKDD 2020],,21,deeplearning,2020-10-13
im3liq,Faders network,"Hello!
I have observed this paper https://arxiv.org/abs/1706.00409 and wrote tensorflow 2 implementation. My task is to generate multi-view images, so my attribute is an angle of point of view. Instead of classifier as a discriminator I use a regression network which tries to guess the angle from the latent code (I use MSE as loss for discriminator). I tried to overfit the model on one object with 72 images (photos of rotating object from 0 degrees to 355), but I wasn't able to disentangle the view point from the latent code. The results are very poor, however I see that network tries to disentangle.

Has anyone tried faders network? Did you manage to train it? What can be the problem with my approach? Is it possible to overfit this model?",7,deeplearning,2020-10-13
im2q7w,Bumblekite Online – a 6 week programme on Healthcare data and AI Policy from October 26th to December 6th 2020,"**Bumblekite Online – a 6 week programme on Healthcare data and AI Policy from October 26th to December 6th 2020**

[https://bumblekite.four-corp.com/bumblekite-online](https://bumblekite.four-corp.com/bumblekite-online)

**What is Bumblekite?**

Bumblekite is four’s experimental learning space at the intercession of health, care, and technology, and Bumblekite Online is our programme focusing on “Healthcare data and AI policy”. We chose policy as the topic of our first module because we want to equip participants for discussing these issues, by exposing them to different opinions and ways of thinking, so they can understand everyday implications of AI, and apply this knowledge in their chosen field.

**Quick Facts**

* 6 weeks, 50 participants, 5 closely mentored groups
* Synchronous and asynchronous online learning - direct mentor contact, as well as group, and independent work
* Time commitment around 30hrs totals, distributed over the 6 weeks
* Customized projects curated to recent advancements in the field
* 10+ internationally acclaimed guest speakers

**Course Description** 

This six week programme focuses on healthcare policy with an emphasis on how it can serve to foster interdisciplinary ways of thinking, and thus promote cross-disciplinary collaboration at the intersection of healthcare and data science.The programme will be split into three modules: “effective communication”, “refining the issue”, and “creating the pitch”.

The programme will involve each participant being placed in a group of up to 10 people under the guidance of an assigned mentor. Participants will work both independently and collaboratively to complete text and/or discussion based assignments that will be evaluated primarily by the mentor.  Weekly sessions will be held featuring guest speakers with expertise at the intersection of policy with healthcare and data science.

**Course Objectives**

Upon successful completion of the programme participants will be able to:

* Provide verbal and oral critiques of short policy briefs
* Identify and communicate policy issues to a variety of audiences
* Work collaboratively to complete a policy report related to healthcare + data science 

**Application**

While this is a policy focused program, we don’t expect high levels of policy experience from each participant. We want to help teach people from different backgrounds how to critically think about policy, which means that we don’t expect a universal level of familiarity with the topic in our cohort, nor do we have a set expectation about your level, or field of education, what you do in your day to day life, or your professional experience in policy related disciplines. However, we do expect you to have experience with evidence based research, as this will be a heavily emphasized skill in the programme. 

Our application is centered around writing because we see it as an opportunity for you to tell us your story. Tell us about the project you would like to do, a project that you want Bumblekite to help you do, or a project that you’ve done in your other areas of interest and particularly enjoyed, let us know about your best learning, and teaching experiences. We always look for curious, open-minded, communicative, dedicated people, willing to both work with a team, but also take initiative and carve out their own educational experience. 

**Registration**

The registration fee covers access to the entirety of the programme, including the lectures and group work, one-on-one mentoring, as well as complementary social events, access to our extended network of members,  partners and collaborators, and personalized care packages delivered to your home. We offer a limited number of full and partial scholarships,  that you can apply for by filling out the scholarship supplement in the application form. This year’s fees are as follows: USD 500 for undergraduate, graduate and other students, USD 1,500 for industry attendees, postdoctoral and other researchers affiliated to non-profit institutions. 

**Application deadline: October 11th 2020**",0,deeplearning,2020-10-13
ilzpk7,RTX3090 vs 2x RTX 3080 for LSTM Deeplearning?,"After being able to see the price specs, im not sure what makes more sense for my task.

    RTX 3080:
    Cores MemoryInterfaceWidth MemoryBandwidth GB/sec ClockSpeed -&gt; Boosted  VRAM    8704               320-bit                ???   ???            1.71 GHz  10 GB 
    
    
    RTX 3090:
    Cores MemoryInterfaceWidth MemoryBandwidth GB/sec ClockSpeed -&gt; Boosted  VRAM    10496               384 Bit             1024 GB/s     ???       1.70 GHz   24 GB 

&amp;#x200B;

**My Purpose:**

Need to train 6-20 models, keras LSTMs:

Data: Float /double Sequences (\~1.000-15.000 rows, \~ 10-100 columns)

    [ # 1st samples
      [ 89.319787 1.329743 99.234670    ...    52.329743 0.319787 2.319787 ] 
      [ 84.319787 1.329743 49.329743    ...    52.329743 0.319    2.319787 ] 
      [ 12.319787 1.329743 33.329743    ...    52.329743 0.319787 2.319787 ] 
      [ 33.319787 1.329743 23.329743    ...    52.329743 0.319787 2.319787 ] 
    
            ...       ...       ...    ...          ...       ...     ...  
            ...       ...       ...    ...          ...       ...     ... 
    
      [ 23.319787 1.329743 45.234670    ...    52.329743 0.32721  2.319787 ] 
      [ 89.319787 1.329743 99.234670    ...    52.329743 0.319787 2.319787 ] 
      [ 84.319787 1.329743 49.329743    ...    52.329743 0.319    2.319787 ] 
      [ 12.319787 1.329743 33.329743    ...    52.329743 0.319787 2.319787 ] 
      [ 33.319787 1.329743 23.329743    ...    52.329743 0.319787 2.319787 ]   ],
    
    ...
    
    [ # n'th sample          (n = 500k or 2 million samples)
      [       ...       ...       ...    ...          ...       ...     ... ]
              ...       ...       ...    ...          ...       ...     ... 
      [       ...       ...       ...    ...          ...       ...     ... ]  ],

Questions:

1. What makes more sense **in your experience**?
2. what makes more sense **on the sample data**?
3. more VRAM vs more Cores (but in 2 seperate GPUs)?

EDIT: forgot to mention: my script is going to train 6-20 models which are interdependent to one another (datawise and predictionwise), so my guess is, that it would take around 30-100 days without pause, to run my full script.

EDIT2: every model around 10-30 EPOCHs",2,deeplearning,2020-10-13
ilzf57,"A Step-By-Step Guide to Becoming an AI Expert (R, Python, Statistics, Kaggle)",,1,deeplearning,2020-10-13
ilxpy1,We asked some AI experts to predict the next 'AI Hub' location,,0,deeplearning,2020-10-13
ilwsv2,What ways to Cool down GPU DURING training?,"I plan to train 6-20 LSTM models of which each probably takes 5 days (preprocessing takes about 5 hours each).

My script does that automatically (preprocessing, training, saving, next), because the models depend on each other ( the first 3-10 are crossvalidationwise on different data, the latter 2-10 models train as a stack on the prediction of the former 3-10 models).

Since the training and the preprocessing tasks are highly resource intensive. I need to find a way to cool down my gpu, since i cant reboot the workstation and then start where i stopped. ( yep more than 30 days consisting of training and preprocessing). 

I already plan on implementing a ""backup-like"" saving of the data into a csv in the case the machine crashes. I also thought of putting a ""sleep()"" after every model is finished, but what am i going to do **during** the process**?**

My setup is not yet bought but im thinking of t least a  3070 with an AMD 1920X (12 cores). No watercooling because im afraid something could run out. Workstation will be in a relatively cool basement.

Are there ways to handle **CPU** and **GPU** heat during training? (like interupting training every 60 minutes for around 5 minutes and then going on insided the .fit() function)

Every experience and useful tip is welcome.",0,deeplearning,2020-10-13
ilwgoh,[Tutorial] Training a Double Deep Q-Network to Play Super Mario Bros,"This post covers an introduction to reinforcement learning, Q-learning, and double Q-learning, followed by a tutorial with full Python code for building our model and training our agent to navigate the Super Mario Bros environment. 

Article link: [https://blog.paperspace.com/building-double-deep-q-network-super-mario-bros/](https://blog.paperspace.com/building-double-deep-q-network-super-mario-bros/) 

Run the code for free on Gradient:  [https://ml-showcase.paperspace.com/projects/super-mario-bros-double-deep-q-network](https://ml-showcase.paperspace.com/projects/super-mario-bros-double-deep-q-network)",2,deeplearning,2020-10-13
ilu0zo,Feel Virtual Objects.,,0,deeplearning,2020-10-13
iltyq5,Is planning a rig with 4x Nvidia RTX 3090 feasible and worth the money for the following use cases?,"Hello DL Redditors,

I'd like to build a rig that starts small but can scale if my following use-cases require more resource:

* Train Computer Vision and Deep Reinforcement Learning models
* The end project will be running multi-model CV inference (for each frame) of 3 - 4 video sources with at least 60fps and then running DRL model inference for 3 - 4 states. (which could run 24/7)

I don't know much GPUs, but I found out that for CV and DRL the following specs are important (CUDA Cores, vRAM, Memory Bandwidth, and PCIe lanes).  (vRAM is especially important for CV)

Budget isn't that much of a problem, so I just thought that going with a cutting edge card would be an easier solution (especially for the number of CUDA Cores in the RTX 3090). My idea is to plan a Rig with specs of 4x GPUs of these, only start with 1 GPU (same for ram) and scale as needed. What are your thoughts on this?

I also have the following questions:

1. Is there already hardware available to handle 4x RTX 3090 in one machine (MotherBoard, CPU, total size/count of RAMs)
2. I read a lot about the PCIe lanes required, and that x16 lanes for GPU do not provide that much speed over x8 lanes. But how can I verify a MotherBoard and CPU can support x8/x8/x8/x8 of PCIe lanes?
3. Should I even care about features like Amber considering my use cases (see below)?",3,deeplearning,2020-10-13
iltok9,Top Deep Learning Projects,,0,deeplearning,2020-10-13
iltgb3,How to Train and Deploy Custom Models with Amazon SageMaker - Part 1,"Hi everyone,

Here’s a tutorial on training models on Amazon SageMaker using Docker images, written by my coworker.She showcases an image classifier, but it can be extended for many other applications, so I figured that many of you might find it interesting.

[https://www.sicara.ai/blog/amazon-sagemaker-model-training](https://www.sicara.ai/blog/amazon-sagemaker-model-training)

Which stack do you use to deploy your own models ?",3,deeplearning,2020-10-13
ilqqdy,Tutorial: Convolutional layers implementations under the hood,"Hi /r/deeplearning, I made a video:

https://www.youtube.com/watch?v=-Y4ST8eNySI

Convolutional layers are at the heart of deep learning, taking up most resources (both in terms of memory and resources) in most models. In this video, I will talk about actual implementations in common deep learning frameworks under the hood.

OUTLINE:

0:00 - Intro &amp; Overview

1:33 - Types of convolution implementations 5:30 - Implementation Naive Conv2D

9:15 - Implementation PyTorch Conv2D

14:11 - Implementation Im2Col Conv2D

16:40 - Implementation MemStrided Im2Col Conv2D

23:13 - Links to PyTorch, Tensorflow, cuDNN implementations

24:47 - Strengs and Weaknesses of implementations

26:24 - Ending

I am new to YouTube, so I would be happy if anyone subscribed. :)",0,deeplearning,2020-10-13
ilqdh4,A Look into Uber’s Futuristic Self-Driving Cars Technology,,1,deeplearning,2020-10-13
ilq1hd,Wav2Lip: Accurately Lip-syncing Videos In The Wild to Any Speech,"Watch the demo video: [https://www.youtube.com/watch?v=0fXaDCZNOJc](https://www.youtube.com/watch?v=0fXaDCZNOJc)  
Read the paper: [https://arxiv.org/abs/2008.10010](https://arxiv.org/abs/2008.10010)

Try out the interactive demo: [https://bhaasha.iiit.ac.in/lipsync](https://bhaasha.iiit.ac.in/lipsync)

Explore the code and models: [https://github.com/Rudrabha/Wav2Lip](https://github.com/Rudrabha/Wav2Lip)",23,deeplearning,2020-10-13
iln1bk,Automatically remove bias from layers that are inputs of batch normalization layers,,3,deeplearning,2020-10-13
ilisnv,Recovering multi-person 3D poses from a single RGB image!,,2,deeplearning,2020-10-13
ili7ls,Can someone give me step by step instructions for renting TPUs or GPUs and training ImageNet from scratch with Pytorch?,"As the title says, could someone break down the procedure for training and evaluating a Pytorch model on ImageNet using private servers like AWS or Google Cloud or any other service that could help me train on ImageNet efficiently? That would include the Pytorch code as well because I’m not sure if just any ImageNet training repository would be compatible with those services. Expert help would be appreciated — thank you.",0,deeplearning,2020-10-13
ilc5p1,"Dive into Deep Learning! An interactive deep learning book with code, math, and discussions","Dive into Deep Learning

An **interactive** deep learning book with code, math, and discussions

Provides **NumPy/MXNet**, **PyTorch**, and **TensorFlow** implementations

[https://d2l.ai/](https://d2l.ai/)

&amp;#x200B;

https://preview.redd.it/igiahhi90sk51.png?width=709&amp;format=png&amp;auto=webp&amp;s=80d6341d318367758f6657a66a93b6a95da3553f",8,deeplearning,2020-10-13
ilbgyu,TensorFlow 2.0 RNN Tutorials,,0,deeplearning,2020-10-13
ilawt2,Autonomous Car Chasing - wanted to share my bachelor thesis accepted into ECCV workshop :) Hope that's ok,,0,deeplearning,2020-10-13
ilaw36,"Podcast - LearnOpenCV, OpenCV 20th anniversary celebrations, AI courses","Podcast alert!

Recently, I was invited on a podcast run by [**Ritesh K**](https://www.linkedin.com/feed/#) of Augmented Startups. We discussed my journey as an entrepreneur and educator, why I started the blog - LearnOpenCV, OpenCV 20th anniversary celebrations, the AI courses and what we plan for the future.

You can find the full video at [https://youtu.be/SbnByehgxps](https://youtu.be/SbnByehgxps).

https://preview.redd.it/4f5o8m1fork51.png?width=1280&amp;format=png&amp;auto=webp&amp;s=05c3f8127b3b06df5f99992718c2ddf23b3a8f9f",0,deeplearning,2020-10-13
il9m2j,What is the best way to detect tomatoes using Deep learning.,"We also have to consider they grow in bunches. 
I was thinking to use YOLO v3 but still not sure .
I have personally clicked 600 pictures of tomatoes from a farm. 
Please advice me on the architecture and the method because I need to be sure about this.",0,deeplearning,2020-10-13
il94tc,ECCV 2020: paper summaries and highlights (blog post),"Hi;

I thought I write a blog post where I highlight some of the things that caught my attention while browsing this year's ECCV conference. The blog post contains summaries of some papers (and the mention of some) that I thought were nice (note: this is just a sample, I certainly missed a lot of cool ones).

The post might be helpful to get a general feel of this year's conference quickly since the number of papers (&gt;1.3K) can be overwhelming at times. Check it out!

Blog post: https://yassouali.github.io/ml-blog/eccv2020/",34,deeplearning,2020-10-13
il7syg,"Introduction to Artificial Intelligence vs Machine Learning vs Deep Learning With a real world application, the Tesla Autopilot example",,5,deeplearning,2020-10-13
il64qc,[R] We really need to rethink robust losses and optimisation in deep learning!,,0,deeplearning,2020-10-13
il4sxj,The optimal way to evaluate the inference speed of DL models!,"*I'm working on DL models where the inference time is crucial, and it's about the real-time application. so, the question is what's the optimal way to measure the inference time for the trained models.* 

*I personally use the time library to know the exact time used by my model. example:* 

    start = time.time()
    # predictions functions 
    end = time.time()
    # the time used by the prediction dunctions is (start-end)

*I used this based on published codes of well-known frameworks.  but, I don't know whether it's the correct way to do that or not!!*",1,deeplearning,2020-10-13
il4jak,Fast Supernovae Detection using Neural Networks,,2,deeplearning,2020-10-13
il3uil,Can we count on hardware resources given by Colab? are they real resources??,"I'm working on Colab and I've purchased a pro subscription. The resources available include high-Ram and Tesla P100 or V100 accelerators. After working for quite a long time, I came across a problem where I need to measure the inference time of my DeepLearning models. So, is these resources are real hardware architectures, so that I can say that I used a GPU ""P100 for example"", and here is the resulted inference time ?? 

let's assume that I have the same hardware architecture installed on my workstation, will I get the same performance ??",12,deeplearning,2020-10-13
ikw35r,Purpose of Convolutions in CNN,I don't understand why why need to filter the images in a convolutional neural network. Won't the pooling layer alone do a good enough job in extracting the features of the image. Or is the filtering done to diversify.,1,deeplearning,2020-10-13
ikqekq,[R] AMBERT: BERT with Multi-Grained Tokenization Achieves SOTA Results on English and Chinese NLU Tasks,"Researchers from ByteDance AI Lab have proposed a novel pretrained language model, AMBERT (A Multigrained BERT), which leverages both fine-grained and coarse-grained tokenizations to achieve SOTA performance on English and Chinese language tasks.

Here is a quick read: [AMBERT: BERT with Multi-Grained Tokenization Achieves SOTA Results on English and Chinese NLU Tasks](https://syncedreview.com/2020/09/01/ambert-bert-with-multi-grained-tokenization-achieves-sota-results-on-english-and-chinese-nlu-tasks/) 

The paper *AMBERT: A Pre-Training Language Model with Multi-grained Tokenization* is on [arXiv](https://arxiv.org/pdf/2008.11869.pdf).",2,deeplearning,2020-10-13
ikp04e,Age and Gender Classification,"Hello Reddit,

it's my first time posting here. I created a new account because of my lame(r) username created a long time ago.  

I'm trying to build a model that will classify gender and age groups from face images. I chose to train a  MobileNet model in TensorFlow because I need it to be in tflite format and fast. I'm posting here because I'm basically desperate and in need of advice, after a month of training and training... At least I learned a lot about TensorFlow, I haven't used it before. I don't want to waste too much time trying to improve it.

I tried transfer learning, where I removed the top classification layers and added two new ones, which classify age and gender simultaneously (the model has two outputs). I trained it on the IMDB-WIKI dataset (just the top layers and then some fine-tuning of the whole model). The model is used on images from mobile camera phones with low quality and very different perspectives so I added many augmentations to the train dataset like artificial noise, blur etc. Whatever I do, I'm not satisfied with its performance, seeing many reports of 95%, 99% even on GitHub and papers. I got it to be 90% accurate on the validation dataset (gender). However, it doesn't seem so accurate on new images. It tends to predict males more often. Then I tried two approaches; oversampling female images and adding class weights, but it seems to hurt its performance. I realise that the IMDB-WIKI is not really representative, but I expected it to be better anyway. I'm looking into new datasets such as FairFace and plan to try it. Also, I will try to retrain a model such as ResNet to see how much better it performs.   
I used a learning rate finder and picked a learning rate of 1e-4, then 1e-5 for fine-tuning the whole dataset.   


I guess my question is whether am I missing something here? Should I try simpler nets, avoid transfer learning? Is it already the best it can be?",2,deeplearning,2020-10-13
ikohsd,"NVIDIA Launches RTX 3070, 3080 and 3090 for $499, $699 and $1,499: Based on Samsung's 8nm Process | Hardware Times",,69,deeplearning,2020-10-13
iknun3,Discussion slightly specific for DL engineers from India,"I understand that Machine Learning in Finance related areas has shoot up, a lot of companies now hire ML engineers. But as a Deep Learning engineer what is your view on the scene of this field in India?

You can answer with respect to:

1. How's the research scene? Do we have enough resources/ budget/support from government for example? How competent are we in competing against new State of the Art models according to you?

2. Are companies looking for Deep Learning engineers? If they are how do you expect the scope in a few years from now?

3. Do you see a reason for DL jobs to explode as the classical ML jobs in future years?

4. How well are new/emerging startups coming up with DL applications?",0,deeplearning,2020-10-13
ikjke4,Do we need regularizer when using Batch normalisation ?,,1,deeplearning,2020-10-13
ikic3b,"Free live zoom lecture about image Generation using Semantic Pyramid and GANs (Google Research - CVPR 2020), lecture by the author",,2,deeplearning,2020-10-13
iki3vi,Let’s Learn Dabl: A Python Tool for Data Analysis and ML Automation - Analytics India Magazine,[https://analyticsindiamag.com/lets-learn-dabl-a-python-tool-for-data-analysis-and-ml-automation/](https://analyticsindiamag.com/lets-learn-dabl-a-python-tool-for-data-analysis-and-ml-automation/),0,deeplearning,2020-10-13
ikfc9f,How To Run Inference Using TensorRT C++ API,"In today's blog post, we continue our discussion on how to get a 4 to 6 times inference speed-up using TensorRT.

In our previous post on [Using TensorRT for inference speed-up](https://el2.convertkit-mail.com/c/75ugmp32ogi8hdpmlkh9/kkhmh2u97w9z4gfl/aHR0cHM6Ly93d3cubGVhcm5vcGVuY3YuY29tL2hvdy10by1jb252ZXJ0LWEtbW9kZWwtZnJvbS1weXRvcmNoLXRvLXRlbnNvcnJ0LWFuZC1zcGVlZC11cC1pbmZlcmVuY2Uv) ([https://www.learnopencv.com/how-to-convert-a-model-from-pytorch-to-tensorrt-and-speed-up-inference/?ck\_subscriber\_id=371373457](https://www.learnopencv.com/how-to-convert-a-model-from-pytorch-to-tensorrt-and-speed-up-inference/?ck_subscriber_id=371373457)), we discussed how to convert your PyTorch model to TensorRT FP16 (16-bit floating point) model using the Python API to achieve the speed-up.

In today's post, we learn how to do it using the C++ API. Python and C++ APIs have their own advantages and disadvantages. For example, Windows OS does not have support for the Python API, so if you are a Windows user, the C++ API is your only option. We are sharing step by step instructions and example code!

  
[https://www.learnopencv.com/how-to-run-inference-using-tensorrt-c-api/](https://el2.convertkit-mail.com/c/75ugmp32ogi8hdpmlkh9/58hvh8u9ex93lvt6/aHR0cHM6Ly93d3cubGVhcm5vcGVuY3YuY29tL2hvdy10by1ydW4taW5mZXJlbmNlLXVzaW5nLXRlbnNvcnJ0LWMtYXBpLw==)

https://preview.redd.it/iypqoaicehk51.png?width=1075&amp;format=png&amp;auto=webp&amp;s=96a1899f5dcdfcd5f8434ab6abe5bc5f7e6ce4e9",1,deeplearning,2020-10-13
ikev7g,Generating photo-realistic face images from hand-drawn sketches!,,1,deeplearning,2020-10-13
ikehds,Deep Learning for Data Comprehension,"Can someone help me in an idea on how DL works in pattern recognition used for data compression? I have seen CNNs extracting features from images which in turn help in classification/prediction/generation etc. Now instead of images, if I give a huge raw data file and ask the model to compress into a single vector and then retrieve the info back from the vector, will it be possible?",1,deeplearning,2020-10-13
ike808,Understanding the Importance of Generative Adversarial Networks (GANs),,23,deeplearning,2020-10-13
ikd3fm,GAN for multiple classes,"Hi all.

I'm working on novelty detection using GAN.

When I train the model on only 1 class as in-distribute data (For example, digit 1 in MNIST), the model performs well.

Yet, when I train the model on 2 classes as in-distribute data (For example, digit 1 and 2 in MNIST), the model does not converge.

Through some googling, I found 2 solutions:

1. One model for one class. It's simple but I prefer having an all-in-one model.
2. One discriminator for one class. I'm checking it.

Other than these 2 solutions, is there any other way that I could do to improve my model?",4,deeplearning,2020-10-13
ik9401,I created a collection of notebooks related to Computer Vision.,,14,deeplearning,2020-10-13
ijzszh,Generating meaningful gestures by autoregressive neural network. Code available,,1,deeplearning,2020-10-13
ijzs36,TinyML — How To Build Intelligent IoT Devices with Tensorflow Lite,"Intelligent IoT devices are all around us. In this article, we will see how you can combine machine learning and embedded systems to build intelligent IoT devices. [https://medium.com/manishmshiva/tinyml-how-to-build-intelligent-iot-devices-with-tensorflow-lite-8cbcd91592db](https://medium.com/manishmshiva/tinyml-how-to-build-intelligent-iot-devices-with-tensorflow-lite-8cbcd91592db)",1,deeplearning,2020-10-13
ijz245,Effective testing for machine learning systems.,,1,deeplearning,2020-10-13
ijyqyc,Should I use activation function for the last layer of a sparse Auto-Encoder ?,"Hello , as the title spoke of itself , I ´my thinking about the effective  way of building the last layer of my autoencoder.
In some scientific paper , they used activation function for the last layer as for all the layer. (""Tanh"")
But in the book "" Machine learning and Deep Learning with Keras and tensorflow "" the author ( who wrote so helpful code ) , doesn’t activate the last layer : Activation ="" None ""

As the loss is computed using the last and the first layer  and depends on, what do you think about the proper manner of handling this ?",2,deeplearning,2020-10-13
ijyibu,[Tutorial] A Guide to TensorFlow Callback Functions,"TensorFlow callbacks have become a basic and essential part of training deep learning models. For instance, the EarlyStopping callback is commonly used to prevent overfitting; ModelCheckpoint is critical to prevent losing progress from interrupted training, or being able to return to a previous point in time; and TensorBoard is commonly used to visualize the progression of your model training.

This article covers the 10 main callback functions in TensorFlow, with runnable Python code included.

Tutorial link:  [https://blog.paperspace.com/tensorflow-callbacks/](https://blog.paperspace.com/tensorflow-callbacks/) 

Run the code for free: [https://ml-showcase.paperspace.com/projects/tensorflow-callback-functions](https://ml-showcase.paperspace.com/projects/tensorflow-callback-functions)",0,deeplearning,2020-10-13
ijybhe,Retrieval problem loss,"Hi everyone.

It is the first time for me I work on retrieval tasks. I have to retrieve the correct candidate (only 1 for each sample) from a list of 100 candidates pool. The ground truth will be a vector containing a 1 in the first position followed by a series of 99 zeros (e.g., \[1, 0, 0, 0, ..., 0, 0\]). This ground truth represents that the true candidate to retrieve is the first one.

The proportion 1-0 is then 1:99 and my model always tries to predict 0's. This leads to a model that learns to assign low scores to all the candidates it has to rank in the candidates' pool. Actually I am using BCE with a sigmoid activation function.

&amp;#x200B;

Is there something I can do to fix this? Is weighting the loss the only way?

Additionally, if the set of candidates is always set to be 100, can I also use the softmax instead of sigmoid? I think it should be conceptually wrong since PyTorch CE will consider the problem as multiclass, which is not.

&amp;#x200B;

Thank you",0,deeplearning,2020-10-13
ijyanj,Learning more about ML,"Hey, we've worked hard on distilling the best format for 1) overviewing the developments of ML industry 2) creating a bite-sized educational format to build and reinforce ML and AI knowledge for data scientists and developers. I would love to share it with you. 

I believe that it's hugely important to spread knowledge about machine learning and AI, explaining the main concepts and offering the practical implementations of the frameworks and tools. I receive a lot of good feedback about this newsletter from the data scientists from Microsoft, Google, Snorkel, LinkedIn, Intel, and professors and researchers from many universities across the globe.

The Sunday edition of TheSequence Scope is free, you can check it out and sign up here. It's quite convenient to follow the recent developments with this newsletter without being overwhelmed with opinions/not relevant news. 

The educational part that comes Tuesday and Thursday is a paid subscription offering but you can follow what topics we cover without paying. 

[https://thesequence.substack.com/p/-the-difficult-economics-of-ai-companies](https://thesequence.substack.com/p/-the-difficult-economics-of-ai-companies)",0,deeplearning,2020-10-13
ijvxfl,Demystifying the Future Of Self-Supervised Deep Learning,,0,deeplearning,2020-10-13
ijvslr,PyTorch Performance Tuning Guide,,58,deeplearning,2020-10-13
ijv4k2,Top 3 Artificial Intelligence Research Papers,,2,deeplearning,2020-10-13
ijundc,Elon Musk’s Neuralink Promises Neurological Cure Using Computer Chips,,0,deeplearning,2020-10-13
ijtbfm,BERT on Video,,9,deeplearning,2020-10-13
ijt31i,Difference between the usage of Batch Normalization and Weights Initialization.,I am confused when I read about batch normalization and weights initialization. I know how they are working and whats the problem like vanishing gradients and exploding gradients etc w.r.t weights initialization but when we think about Objective it seems both are doing the same thing. Am i thinking it right ? Please clarify,5,deeplearning,2020-10-13
ijq9ig,Linear Regression from scratch,"If anyone wants to learn about Linear regression you can watch this video: 

[https://youtu.be/QhTt-Onwr7g](https://youtu.be/QhTt-Onwr7g)

It explains Linear Regression in depth and also shows a practical implementation.",0,deeplearning,2020-10-13
ijms5q,Test-Train Overlap Problem - Question and Answer Test-Train Overlap in Open Domain Question Answering Datasets,,1,deeplearning,2020-10-13
ijmk0s,Looking for significant deep learning project ideas,"Hi!

I've been studying deep learning since a while now (mostly about CNN), and made some toy projects, but I would like to start making bigger and more relevant projects related to CNN/Computer vision. I have no ideas of what projects to pick or how to get inspiration though. Any ideas about how to get the inspiration needed / projects ideas that would be good to put on a resume ?

Thanks!",7,deeplearning,2020-10-13
ijmjtc,Feature Selection for unlabeled data ?,I m looking for a feature selection algorithm for unlabeled data ( unsupervised learning ),1,deeplearning,2020-10-13
ijlqni,GTX 1080 Ti vs RTX 2070 Super,"Hello everyone!

Sorry for yet another ""which GPU to buy"" -post, but I have a hard time deciding and would like to hear your opinion. I am building a PC that will be used for deep learning. My GPU budget is 450€. In this price range the choice narrows down to either a second hand GTX 1080 Ti or a new RTX 2070 Super which I can buy for the same price (RTX 2070S is slightly cheaper). 

I am fairly new to deep learning and want to explore a range of different kinds of models. Therefore my focus is on a well-rounded GPU rather than optimizing for a specific type of networks.

What would you suggest?

 I'm happy to provide more info if that helps.",4,deeplearning,2020-10-13
ijjpg2,Object Tracking using OpenCV (C++/Python),"Object detection is one of the major applications of OpenCV but what do we do when we have found the desired object and still want to keep ""tracking"" it in other frames?

For the second post of the ""Revisit LearnOpenCV"" series, this is exactly what we will discuss - we will learn about the object tracking API offered by OpenCV.

https://www.learnopencv.com/object-tracking-using-opencv-cpp-python/

We will learn how and when to use the 8 different trackers available in OpenCV 4.2. This post was originally written for OpenCV 3.0 but has now been updated for OpenCV 4.2.

https://i.redd.it/nw1wj4wl77k51.gif",0,deeplearning,2020-10-13
ijhb5y,Augmented Reality is Getting More Realistic,,20,deeplearning,2020-10-13
ijgz6w,How much time do you get for yourself while being in this field and how do you cope up with the stress I really think about this a lot any opinions,,6,deeplearning,2020-10-13
ijcusl,How AI Learns To Read Lips,"Hello, In this article, we will examine a research that has been accepted to  CVPR’20 (Conference on Computer Vision and Pattern Recognition), which  examines not only the lips but also the other movements in their faces,  learning personal speech styles and synthesizing sounds.

[https://us.github.io/how-ai-learns-to-read-lips](https://us.github.io/how-ai-learns-to-read-lips)",2,deeplearning,2020-10-13
ij92yu,Deep Learning in Ad Tech,"Hi , I presume Deep Learning is used in Ad Tech area-where can I find applications/use cases of the same - any courses or books available?",9,deeplearning,2020-10-13
ij3fz2,State of the art in lip-syncing a talking face video!,,1,deeplearning,2020-10-13
iixqt1,Can I publish research paper on DL project?,Actually I am doing project which is based on deep learning. I want ask that is it possible to publish paper on my project or their must be some deep research. As a beginner I don't know eligibility and criteria for publication. I have used existing algorithm but the application of project is unique. In application point of view it's a very good and unique project .,15,deeplearning,2020-10-13
iiwh6j,Wrong output shape from Conv2DTranspose,"Hello guys, I have little experience with machine learning and in particular deep learning and I would like to show you a problem that has occurred to me: I am building a GAN, and I have implemented the generator as an encoder-decoder network. The problem, however, is that the decoder, through Conv2DTranspose levels, gives me a different shape than the corresponding level in the encoder, in particular in the Conv2D level of the encoder the output has shape (7, 7, 128) while in the Conv2DTranspose level of the decoder the output has shape (8, 8, 128), and this thing prevents me from concatenating tensors in a Concatenate layer. Has this ever happened to you? Do you have any advice?  If necessary, however, I can post code snippets. Thanks in advance!",0,deeplearning,2020-10-13
iiuygi,Apps or websites that demontrate the power of neural networks,"I often try to convey to lay people how amazing neural networks are. I find that experiencing it directly is most effective, so I've been trying to find websites or apps that showcase strong applications. I haven't found much that can be tested by the general public though. 

I know of ""iDetection""/""Object detector"" on iOS/Android and  [https://talktotransformer.com/](https://talktotransformer.com/)  ( text generation). Anything else you'd recommend checking out?",0,deeplearning,2020-10-13
iisxua,Language-Guided Navigation in 3D Environment. ECCV2020 paper By Facebook AI Research (with code publicly available!) Video introduction &amp; demo,,7,deeplearning,2020-10-13
iis7vp,How to clone anyone's voice using Deep fake.,"I am blown away with the voice quality of the cloned voice it is hardly distinguishable from the original sound. I cloned Adele voice and it sounds damn real.  I used the code from GitHub repo of the implementation of ""Transfer learning from speaker verification to multi speaker text to speech synthesis"" by CorentinJ and ran the code in Google Colab.

[Here is the YouTube video I made on how to run the code.](https://youtu.be/SmsEHNaI77o)

&amp;#x200B;",0,deeplearning,2020-10-13
iiqds2,Want Your Machine Learning Algorithm To Be Fair? Check These 8 Tools,[https://analyticsindiamag.com/top-tools-for-machine-learning-algorithm-fairness/](https://analyticsindiamag.com/top-tools-for-machine-learning-algorithm-fairness/),3,deeplearning,2020-10-13
iioi92,Deep learning frameworks,,0,deeplearning,2020-10-13
iim9gm,Noob: where to begin to start playing with NN’s?,"I learn best by diving straight in with with working examples (get frustrated relatively easily) and then backing out and fine tuning and learning details as I need them to customize the tech for my purposes. 

I am really interested in playing with neural networks. 

As a first project I want to try image recognition of patterns in 2D data charts (and would love in the future to end up with a digital assistant that can actually help me do many tedious tasks on the computer as I get older and less capable) 

I can get around, albeit clumsily, in Python and JavaScript , and used to be an old school C programmer, have a Computer Science degree. 
Very comfortable with Linux, macOS, Windows etc 

With that in mind:
-Which tech stack/product should I start with that will have a good example to play around with to quickly give me results for Pattern recognition in 2D Data charts
-has a strong future
-prefer free open source
-Docker Image for development environment would be great too

Thx",8,deeplearning,2020-10-13
iifdhl,CV project request,,0,deeplearning,2020-10-13
iiay3d,Questions regarding Nvidia tesla k80 on a desktop/workstation,"Hey everyone! I'm guessing this may be the right place to ask this question, if not please feel free to remove the post. 

I'm planning on getting a K80 to accompany my now dated gtx960 on a desktop to be used for rendering, CAD, CAM and CAE and some deep learning. 

From what I've read so far I can tell that it is possible to run K80 on a desktop and get a video out from another card (in my case it's gtx960)? 

I'm planning on connecting my screens to gtx960 and run the renders on K80. Is this a possible/plausible setup?

Is it possible to run multiple K80s in an SLI or similar configuration? Would that be beneficial? If possible how do I do it?

Thanks in advance for answers. All and any help is appreciated. Feel free to point me in the right direction for me to read further on this.",4,deeplearning,2020-10-13
ii8rkp,[Tutorial] Build a VAE in Keras,"Variational autoencoders are one of the most fundamental neural network architectures, but many don’t know how they work, let alone how to build one. This tutorial covers how to build an end-to-end VAE to encode and decode images in Keras. Full code included.

Tutorial link: [https://blog.paperspace.com/how-to-build-variational-autoencoder-keras/](https://blog.paperspace.com/how-to-build-variational-autoencoder-keras/) 

Run the code for free:  [https://ml-showcase.paperspace.com/projects/build-an-autoencoder-from-scratch-in-keras](https://ml-showcase.paperspace.com/projects/build-an-autoencoder-from-scratch-in-keras)",6,deeplearning,2020-10-13
ii5h4f,Linear learning rate warmup,"Hey,  I have to implement a linear learning rate warmup which linearly  increases the learning rate from 0 to 0.1 over k iterations for a neural  network using TensorFLow 2 and Python 3.8. For example, k = 10000  training iterations/steps. Also, I am training a neural network model  using tf.GradientTape. Any help for a tutorial or code demo is  appreciated!

Thanks",1,deeplearning,2020-10-13
ii37d1,What should I learn to go about this project?,"I want to build a data extractor for images of medical reports. It should store field labels such as name, age, and labels in tables like blood pressure, glucose levels and the corresponding values of these labels in JSON output. I have tried PyTesseract for OCR but I don't how to proceed with the OCR output, as I don't know what to do to group the individual field label and it's field value. Please suggest techniques or existing packages to go about this problem.

[Sample](https://imgur.com/a/G26zxYN)",9,deeplearning,2020-10-13
ii30iu,Robot play jenga,,0,deeplearning,2020-10-13
ii0b8t,Short Description Tax Group Classifier,"Hello, I am new to machine learning. I am building a text classifier for tax account where the positive case is only 4% of the data. My two fields are a text field and a binary field indicating if the balance on the tax account is positive or negative. I use word embedding on my text field and write the model as follows:

nlp_input = Input(shape=(length_long_sentence,))

nlp_out = Embedding(len(VOCAB)+1, 50, input_length=length_long_sentence)(nlp_input)

lstm_out = LSTM(100)(nlp_out)

sign_input = Input(shape=(X_train_sign.shape[1],))

concat = concatenation([lstm_out, sign_input])

classifier = Dense(32, activation=‘relu’)(concat)

output=Dense(1, activation=‘sigmoid’)

The text field is very short; typical 2 words in each instance. The vocabulary is quite large though. My model works decent enough without the LSTM layer at about 70% recall and 70% precision. I added the LSTM layer to try to get even better results as there is noise in the data with some exact matching instances of the text field lending to different classes. I added the LSTM layer because I’ve seen it used after the Embedding layer in text classification models and figured it may help my model. But with the LSTM layer, the model does not learn and precision and recall remain at 0 each through training. Why could this be the case or is my model set up wrong? The model compiles and runs through training...  any ideas or tips?

EDIT: By the way, I tried TFIDF at first but word embeddings proved better. I think the vocabulary is so large TFIDF was not good. And the text field is both similar and different enough between classes for the stark imbalance to effect TFIDF negatively. I also use unigrams and bigrams in my model.

EDIT: I change my LSTM to two bidirectional LSTM layers as follows

lstm_out1 = Bidirection(LSTM(64, return_sequences=True))(nlp_out)
lstm_out = Bidirectional(LSTM(32))(lstm_out)

Now during training my precision and recall are changing—no longer sitting at 0 the whole time but rather increasing as the model did with just an Embedding layer and no LSTM. What’s going on here?

EDIT: I have about 2 million rows of data. I use the standard idea of word embeddings, at least as I’ve come to learn over the past day. I use a label encoder to encode each word in the vocabulary, transform each description with this encoder, then pad each description to the length of the longest description. I saw two BiLSTMs in an example online so I went forward with trying that. Perhaps it is overkill. My vocabulary is about 200,000 words. The descriptions are very short. There are reoccurring missspellings and abbreviations in the data. The descriptions are very domain specific like “prepaid expenses”, “payroll tax”, “accrued vacation”, etc. So I felt a pretrained embedding would be nonsensical but again I am so new to this that I could be wrong about everything. With this said, any further tips?

EDIT: I am using class weights to address the imbalance. I tried random over sampling with no luck.",2,deeplearning,2020-10-13
ihzmxt,Create 3d photos from old photos as well!,,3,deeplearning,2020-10-13
ihyhyl,Performance drop in distributed training,"I have access to a computer cluster and do an LSTM-based neural network training on it under keras/tensorflow. The node that I am working with on the cluster have 2x18-core cpus and 8 gpus. I tried training my network in two ways:

\- Using one gpu and normal training,

\- Using all 8 gpus in a MirroredStrategy setting of Tensorflow.

(the training data batch size  in the second case is 8 times the first case as instructed in Tensorflow help pages)

I train my network with the same data for 50 epochs under both of the above conditions and do it for some repetitions. The second case is always much faster for sure, but the training/validation/test accuracy of the distributed training is constantly lower than non-distributed training.

Is it typical of distributed training? What can be the cause?",2,deeplearning,2020-10-13
ihtt5f,Thinking about doing the deep learning Coursera specialization. Can I take this course if I have no prior programming experience?,,0,deeplearning,2020-10-13
ihstzn,Using Facial Landmarks for Overlaying Faces with Masks,"Imagine you want to create a classifier that detects whether a person is wearing a mask or not. To build such a classifier you first need to gather thousands of pictures of people wearing a mask, and thousands of pictures of people not wearing a mask. With this data, you train a classifier.  


While you can easily get pictures of people with no mask, it is not easy to obtain thousands of pictures of people wearing different kinds of masks.  


In some machine learning applications, we get lucky, and there is a way to create synthetic data. Generating images of people with masks also happens to be one such lucky case.   


In today's post, we will show how to overlay masks using facial landmark detection.  


[https://www.learnopencv.com/using-facial-landmarks-for-overlaying-faces-with-masks/](https://el2.convertkit-mail.com/c/o8ud4238rdfqhx6kp7cq/7qh7h2u4g35grw/aHR0cHM6Ly93d3cubGVhcm5vcGVuY3YuY29tL3VzaW5nLWZhY2lhbC1sYW5kbWFya3MtZm9yLW92ZXJsYXlpbmctZmFjZXMtd2l0aC1tYXNrcy8=)  


and the code is at  
[https://github.com/spmallick/learnopencv/tree/master/FaceMaskOverlay](https://el2.convertkit-mail.com/c/o8ud4238rdfqhx6kp7cq/owhkhwu8z5dz2o/aHR0cHM6Ly9naXRodWIuY29tL3NwbWFsbGljay9sZWFybm9wZW5jdi90cmVlL21hc3Rlci9GYWNlTWFza092ZXJsYXk=)  


https://preview.redd.it/syvax9ebtlj51.jpg?width=600&amp;format=pjpg&amp;auto=webp&amp;s=184a51befbc709b55096b72b31b6b3505f585cc7",3,deeplearning,2020-10-13
ihrny8,A 2020 review of Handwritten Character Recognition," [https://nanonets.com/blog/handwritten-character-recognition/](https://nanonets.com/blog/handwritten-character-recognition/)

OCR is considered a solved problem in general but not in entirety 🎯

A key component of it, **Handwriting Text Recognition** is still a challenging problem.

Handwriting Text Recognition(HTR) is the task of recognizing handwritten human text 🎫

**Solving Handwriting Text Recognition involves using both Computer Vision and NLP**

Every person has a different style of handwriting 💃, thus solving HTR is much more difficult than OCR

In this article I cover the progress of techniques in solving HTR and various SOTA models

In addition I have discussed the way to train your own HTR model on your own dataset

Happy to discuss more if you interested more to learn more about handwritten text recognition",0,deeplearning,2020-10-13
ihr3a6,Releasing keras session resources in Tensorflow 2,"I have a keras model running on Tensorflow 1.x, in which I have some datasets defined and then applied to a keras model. The code structure is as follows:

        import tensorflow as tf
        from tensorflow.keras import backend as K
        config = tf.ConfigProto()
        config.gpu_options.allow_growth = True
        
        def doWork(args):
        
            sess = tf.Session(config=config)
            K.set_session(sess)
        
            ... generate datasets, create keras model, run training loop, etc.
        
            K.clear_session()
            sess.close()
        
        if __name__ == '__main__':
            
            ... set some global variables
            doWork(first set of arguments)
            doWork(second set of arguments)
            ...
    

I wanted to limit gpu memory usage at the start (configProto line) so I needed to define a session with my desired gpu config. I have also cached my datasets in computer main memory to speed the training process, and wanted it to be released after finishing training. Therefore I put the training loop in the doWork() function to be able to assign and release resources each time I run it. I found unless I close the session, memory will not be freed. I also found a clear\_session with keras and added it (but I am not sure if it helps for my purpose or not).

The above code works fine with TF 1.x, but I don't know how to port it to TF 2, as the sessions are removed from ordinary use there. How can I do that and have both configProto and main memory release done in TF 2? Should I define sessions again? I think there should be more straightforward method.",2,deeplearning,2020-10-13
ihot87,"MLmodels , cross-framework model zoo for machine/deep learning.",,1,deeplearning,2020-10-13
ihmjy9,[R] Skyline: Interactive In-Editor Computational Performance Profiling for Deep Neural Network Training,"This paper introduces SKYLINE: a new interactive tool for DNN training that supports in-editor performance profiling, visualization, and debugging.

SKYLINE leverages special properties of DNN training including repetitiveness, predictability, and structured code to offer interactive performance visualizations tied to the code. According to the research, the main takeaways from this paper are 

* DNN training computational performance debugging is an important problem faced by deep learning developers.
* DNN training computation has useful properties that can enable new interactive features

SKYLINE is open-sourced to help deep learning developers and to hopefully facilitate future research in this area. [Here’s the Github link.](https://github.com/skylineprof/skyline) 

Read the full paper:   [https://arxiv.org/pdf/2008.06798v2.pdf](https://arxiv.org/pdf/2008.06798v2.pdf)",2,deeplearning,2020-10-13
ihlimj,Are Neural Turing Machines even being used for any purpose?,,2,deeplearning,2020-10-13
ihk8or,"Check out this very well laid out, detailed guide on artificial neural networks and how they work.", [https://datamahadev.com/artificial-neural-networks-detailed-explanation/](https://datamahadev.com/artificial-neural-networks-detailed-explanation/),4,deeplearning,2020-10-13
ihk6zm,Meet Silq- The First Intuitive High-Level Language for Quantum Computers,,1,deeplearning,2020-10-13
ihk6z7,11 Must-Know Machine Learning Algorithms for AI Professionals,,0,deeplearning,2020-10-13
ihjgpw,OSError: Google Drive quota exceeded when using StyleGAN, Hello Im trying to use styleGAN on my custom datasets and it is training  but i think after iteration 140 there seem some error about google  drive quota exceeding. How do you solve this?? Im not sure but it seems  like theres not much info about this error I tried it on two different  accounts.,0,deeplearning,2020-10-13
ihj4kl,3D view menu before ordering |Augmented reality,,3,deeplearning,2020-10-13
ihii3i,GenRL: PyTorch-First Reinforcement Learning library,"Github: [https://github.com/SforAiDl/genrl](https://github.com/SforAiDl/genrl)

Reinforcement learning research is moving faster than ever before. In order to keep up with the growing trend and ensure that RL research remains reproducible, GenRL aims to aid faster paper reproduction and benchmarking by providing the following main features:

* **PyTorch-first**: Modular, Extensible and Idiomatic Python
* **Tutorials and Documentation:** *We have over 20 tutorials assuming no knowledge of RL concepts. Basic explanations of algorithms in Bandits, Contextual Bandits, RL, Deep RL, etc.*
* **Unified Trainer and Logging class**: code reusability and high-level UI
* **Ready-made algorithm implementations**: ready-made implementations of popular RL algorithms.
* **Faster Benchmarking**: automated hyperparameter tuning, environment implementations, etc.

The core of our library is centered around RL, having policies, values, actor critics, etc. And with trainers and loggers, the only part to care about is to have the right functions implemented and everything else is taken care of!

By integrating these features into GenRL, we aim to eventually support **any new algorithm implementation in less than 100 lines**. **We're also looking for more Open Source Contributors!**

Currently, the library has implementations of popular classical and Deep RL agents that ready to be deployed. Apart from these, various Bandit algorithms are a part of GenRL. It has various abstraction layers that make the addition of new algorithms easy for the user. Do give us a star!

&amp;#x200B;

[Vanilla DQN](https://preview.redd.it/d8rjc9zltij51.png?width=1548&amp;format=png&amp;auto=webp&amp;s=55adf6bef31c0e720867cc2628ac8ca29b5b6f6a)

[Training a DoubleDQN would only require changing a single function](https://preview.redd.it/cg4cua1ltij51.png?width=1784&amp;format=png&amp;auto=webp&amp;s=980f31b95ad3ea0e924065508043da3b2cbf6cba)

[Training a DuelingDQN would only require changing a single function](https://preview.redd.it/o97uu41ltij51.png?width=1682&amp;format=png&amp;auto=webp&amp;s=97db9c8f6eb0cd0664cd59f85ed20375aa9d4ab8)",45,deeplearning,2020-10-13
ihgww2,Discriminator loss(GANs),The discriminator loss should be around 0.5. So the total Discriminator loss is around 0.5 or the individual losses(fake and real loss)?,2,deeplearning,2020-10-13
ihfnrr,LinkedIn open-sources LiFT to enable the measurement of fairness in large-scale machine learning workflows,,6,deeplearning,2020-10-13
ihb8sv,A new NLP Project Idea,"I am thinking of implementing a deep learning model that learns to expand single variable polynomials, where the model takes the factorized sequence as input and predict the expanded sequence.   Each line of train.txt is an example, the model should take the factorized form as input, and predict the expanded form. E.g.

* n\*(n-11)=n\*\*2-11\*n
* n\*(n-11) is      the factorized input
* n\*\*2-11\*n is      the expanded target

The expanded expressions are commutable, but only the form provided is considered as correct.  
I don't know what type of model will be useful here. Also, if you know of a model which can do this please link me to the code. I understand stuff better when I read the code.",1,deeplearning,2020-10-13
ihb6e2,[R] Hyperparameter Tuning for Transformer Models,"Hi all!

Recently there’s been some discussion about how to efficiently tune hyperparameters for large transformer models where even running one iteration is pretty expensive. ([https://www.reddit.com/r/MachineLearning/comments/ibrlvt/d\_how\_do\_ml\_researchers\_make\_progress\_when/](https://www.reddit.com/r/MachineLearning/comments/ibrlvt/d_how_do_ml_researchers_make_progress_when/)). It seems like companies that can afford it use more sophisticated approaches but the vast majority of people end up just doing a naive grid search over a few different hyperparameters.

I tried out a couple hyperparameter algorithms and found that [Population Based Training](https://deepmind.com/blog/article/population-based-training-neural-networks) could sizably increase model accuracy without increasing the tuning budget (for certain tasks).

I wrote up my experiences and a couple tips in this [blog post](https://medium.com/distributed-computing-with-ray/hyperparameter-optimization-for-transformers-a-guide-c4e32c6c989b) leveraging [Hugging Face transformers](https://huggingface.co/transformers/) and [Ray Tune](https://docs.ray.io/en/latest/tune.html). You can check out the [code](https://colab.research.google.com/drive/1tQgAKgcKQzheoh503OzhS4N9NtfFgmjF?usp=sharing) as well!

Let me know if you have any questions or thoughts!",1,deeplearning,2020-10-13
iha6pa,Is the RTX 3090 worth it?,"I was actually planning to buy a 2080Ti to run LSTMs... Until Nvidia introduced the upcoming Ampere line. :( Now I dont know what to do and if it would be worth it...

&amp;#x200B;

**My Purpose:**

I need to train multiple keras LSTMs on datasets that look like this.

Float or double sequences (of around 1.000-15.000 rows &amp; around 10-100 columns)

    [ 
    [ 89.319787 1.329743 99.234670 ... 52.329743 0.319787 2.319787 ] 
    [ 84.319787 1.329743 49.329743 ... 52.329743 0.319    2.319787 ] 
    [ 12.319787 1.329743 33.329743 ... 52.329743 0.319787 2.319787 ] 
    [ 33.319787 1.329743 23.329743 ... 52.329743 0.319787 2.319787 ] 
    ... 
    [ 23.319787 1.329743 45.234670 ... 52.329743 0.32721  2.319787 ] 
    [ 89.319787 1.329743 99.234670 ... 52.329743 0.319787 2.319787 ] 
    [ 84.319787 1.329743 49.329743 ... 52.329743 0.319    2.319787 ] 
    [ 12.319787 1.329743 33.329743 ... 52.329743 0.319787 2.319787 ] 
    [ 33.319787 1.329743 23.329743 ... 52.329743 0.319787 2.319787 ] ]

my budget is limited, so: I can now either buy a 2080Ti around 1.2k€ or 2x 2070 super for 500€ each or wait for the 3090 if its less than 200-300€ more than the 2080Ti.

I read bandtwidth is important, so as the number of cores, so I  wonder, which of the options above would be better. I also found this  information:

    RTX-2070 Super:
    Cores MemoryInterfaceWidth MemoryBandwidth GB/sec ClockSpeed -&gt; Boosted  VRAM
     2560              256 bit               448 GB/s   1605MHz     1770MHz 8 GB 
    2x RTX-2070 Super`: 
    Cores MemoryInterfaceWidth MemoryBandwidth GB/sec ClockSpeed -&gt; Boosted  VRAM
    5120              256 bit                448 GB/s  2x1605MHz   2x1770MHz 2x8 GB  
    
    RTX-2080 Ti: 
    Cores MemoryInterfaceWidth MemoryBandwidth GB/sec ClockSpeed -&gt; Boosted  VRAM    4352               352 bit               616 GB/s    1350MHz    1545MHz  11 GB 
    
    
    
    RTX 3090:
    Cores MemoryInterfaceWidth MemoryBandwidth GB/sec ClockSpeed -&gt; Boosted  VRAM    5.376               384 Bit             1024 GB/s   1.410 MHz to 1.740 MHz  24 GB 

Questions:

&amp;#x200B;

1. What makes more sense in your experience?
2. what makes more sense due to the data sample i gave?

EDIT: forgot to mention above around 500.000 to 2mio of those samples",1,deeplearning,2020-10-13
ih1zru,How to improve a hand detector trained in SSD using Tensorflow API? Dataset? Hyperparameters?,I have been trying to train a hand detector in SSD Mobilenet V2 using Tensorflow API. My requirement is to detect hands while a person is eating. But my trained model is having difficulty in detecting the hands. My dataset has varied hand gestures yet it cannot detect hands properly. I tried egohands but it is not detecting the hands when they are near the mouth (unless I sit really close to the camera). So any help regarding hyper parameter tuning or maybe dataset improvement will be highly appreciated. Training longer does not help. The loss keeps fluctuating between 2 and 4 and sometimes goes upto 10.,1,deeplearning,2020-10-13
ih1c2r,"Inception net ""dimensionality reduction""","In ""GooglNet"", which is the first version of ""Inception Net"", there are 1x1 convolutions to reduce data dimensions. Maybe I am missing something but the output size of a convolution operation will be exact to the input if the stride is 1 and kernel is 1x1. If the stride isn't 1 then it is just skipping some pixels. The paper is ""Going Deeper with Convolutions"".

Any idea how the reduction scheme in GoogleNet actually works?",0,deeplearning,2020-10-13
igy6wb,A high level overview of 5 popular hyper parameter tuning approaches without math or code. Feel free to check it out! If you like it I'll publish another article soon.,,0,deeplearning,2020-10-13
igxn36,Free course for beginners on Deep Learning with TensorFlow!,"Want to implement deep learning with one of the best software libraries? Get Started with this free 4-part course for beginners on Deep Learning with TensorFlow!  

[**In this tutorial**](https://www.youtube.com/watch?v=w80lDhiNl7w), you will learn more about the foundational concepts of TensorFlow, a software library used for numerical computation. Moreover, you will gain insights into neural networks along with other deep learning platforms and hands-on TensorFlow training.",1,deeplearning,2020-10-13
igx12b,"10 Free eBooks on Artificial Intelligence, Machine Learning and Deep Learning to read in 2020",,0,deeplearning,2020-10-13
igwsel,Elon Musk has said he will demonstrate a functional brain-computer interface this week during a live presentation from his mysterious Neuralink startup.,,75,deeplearning,2020-10-13
igwllh,System built by USC researchers reconstructs a fully textured 3D human from each frame,,7,deeplearning,2020-10-13
igwgm6,[D] Tempered Sigmoid Activations for Deep Learning with Differential Privacy,,1,deeplearning,2020-10-13
igwe1w,Weakly Supervised Color Aware GAN for Controllable Makeup Transfer,,2,deeplearning,2020-10-13
igvy38,Revisit LearnOpenCV - Invisibility Cloak using Color Detection and Segmentation with OpenCV,"There are a plethora of posts on LearnOpenCV's blog and just like old treasures, these have slipped away with the onslaught of time. So we are starting a new series - it's time to ""Revisit LearnOpenCV""!  
We are starting this series with a fun application of OpenCV.  


[https://www.learnopencv.com/invisibility-cloak-using-color-detection-and-segmentation-with-opencv/](https://www.learnopencv.com/invisibility-cloak-using-color-detection-and-segmentation-with-opencv/)  


Remember the good old days of Harry Potter?  
Well at LearnOpenCV, we can't provide you with a Philosopher's stone (at least not in the near future) but we can definitely teach you how to make your own invisibility cloak!  


All you need is a basic idea of colour detection and segmentation. That, and a red cloth and you are all set. Mention reviews and what you want us to work on next, in the comments!

https://preview.redd.it/8h619t05ibj51.png?width=600&amp;format=png&amp;auto=webp&amp;s=5a56f4ed2f09f40d3b705afbfe5d0814a371535b",1,deeplearning,2020-10-13
igstaz,Theory of Deep Learning,"I'm looking for a brief overview on the theory of Deep Learning, from a research perspective. What are the different areas and what are the goals of each area. I see buzzwords like optimization and robustness on the profiles of researchers but don't know if there are other areas as well. Can anyone help me with this?",0,deeplearning,2020-10-13
igpofo,Master's Thesis,"Hi,
I am a Master's Student at University at Buffalo in CS department.
I'm opting opting for Master's Thesis, I'm pretty much confused what topic to chose.
My interest areas are- Graph Convolution, Computer Vision and Reinforcement Learning.",0,deeplearning,2020-10-13
igog6m,Are gamma and beta just for removing extra 1/(epsilon)^(½) when mu and sigma all equal zero? I don’t get why use z tilde in Andrew’s deep learning course?," [https://www.coursera.org/learn/deep-neural-network/lecture/4ptp2/normalizing-activations-in-a-network](https://www.coursera.org/learn/deep-neural-network/lecture/4ptp2/normalizing-activations-in-a-network) 

https://preview.redd.it/1e9pu4ofp8j51.png?width=924&amp;format=png&amp;auto=webp&amp;s=e9ba58b5643fdb3fbf50ecf8a3b89e5b3621a6d5",1,deeplearning,2020-10-13
igobay,How PyTorch hooks work (explained visually),,36,deeplearning,2020-10-13
ighup8,Deep learning algorithm to speed up materials discovery in emerging tech industries,,1,deeplearning,2020-10-13
iggx2p,Understanding Recurrent Neural Networks (RNNs),"Check out this amazing article on Recurrent Neural Networks (RNNs).   
A good introduction to the topic I believe.

 [https://medium.com/@nvsyashwanth/understanding-rnns-652b7d77500e](https://medium.com/@nvsyashwanth/understanding-rnns-652b7d77500e)",0,deeplearning,2020-10-13
ige3cd,Deep Learning Object Detection at the zoo,,26,deeplearning,2020-10-13
ig9ji8,Covid 19 Virtual Patient Created with A.I.,,7,deeplearning,2020-10-13
ig8his,Machine Learning In Just 5 Lines Of Code: Fast.ai's New Release,[https://analyticsindiamag.com/machine-learning-code-fastai-library/](https://analyticsindiamag.com/machine-learning-code-fastai-library/),0,deeplearning,2020-10-13
ig8ff0,Ideas for Project in the Field of Video Segmentation,"Hi guys, I am trying to think for project ideas for my master thesis in the field of video segmentation and I would love some help or pointers to where to start looking! Like hot topics, interesting papers, etc.

Some keywords: spatio-temporal constraints, exploiting redundancy, self-supervised learning, attention, realtime, multi-modal (e.g. depth, optical flow).",0,deeplearning,2020-10-13
ig8dim,Estimating the relative position and orientation based on reference picture,"Consider the problem of estimating the position and orientation of a robot provided with a camera, by taking a picture and comparing it with a reference one which was taken before. What are the existing deep-learning based methods to accomplish this task?",2,deeplearning,2020-10-13
ig75to,[D] Tractable or Intractable Log Partition Function,,0,deeplearning,2020-10-13
ig5byu,"One big model, or multiple smaller ones?","Would you rather train a larger model with a wide training distribution, or split out segments of the training distribution, and train several models on more narrow subsets of the total distribution?

**Examples:**

*  Language model encapsulating all aspects in language A vs. Language model per dialect subset of A
*  Autonomous Computer Vision for the United States vs. Autonomous CV per state

etc.

I've not seen research tackling this, and I'd love to hear your thoughts on this.",7,deeplearning,2020-10-13
ig524y,Need help for a biomedical project,"Hello folks, I am interested in some deep learning/machine learning new papers/ways for motion artefact removal in ambulatory ECG using Electrode tissue impedance and 3d acc/gyro. If you have come across any such paper/link/repo, please share. 
Thank you.",2,deeplearning,2020-10-13
ig2j59,"Join more than 2 000 DL enthusiasts on our discord server for everyone working / learning Al. Share your project, papers, ask questions, learn together, create Kaggle competition teams and more!",,1,deeplearning,2020-10-13
ig0u2e,Resources and topics to cover for entry level ML/DL Software Engineering Interviews,"Sharing my posts ([1](https://www.reddit.com/r/MachineLearning/comments/ie2bti/d_resources_and_topics_to_cover_for_entry_level/)) and ([2](https://www.reddit.com/r/MachineLearning/comments/ig0ig0/d_resources_and_topics_to_cover_for_entry_level/)) from r/MachineLearning for more reach. 

Thanks",1,deeplearning,2020-10-13
ifz1qo,Is Swift still a potential next big thing in Deep Learning?,"Over a year ago, Jeremy Howard wrote on [fasti.ai](https://fasti.ai) that his team will do research on [Swift for Tensorflow](https://www.fast.ai/2019/03/06/fastai-swift/). Later on the media generated a temporary hype about Swift for deep learning. I'm wondering if this is still an active thread for any of the stakeholders (fast.ai, Google, Swift, etc.)?",2,deeplearning,2020-10-13
ifwfs4,Good starting point?,"Hello, Where should I start for learning ML to DL? Preferably a free course (or cheap.) I know of Deep Lizzard on YouTube and Udemy. Are these good starting points? I want to eventually get into Transfer learning. If this has already been answered (within a relative time frame, not 8 years ago) could you please point me to the right direction. 
Thank you for helping.",1,deeplearning,2020-10-13
ifw7vh,Robots Play Football,,5,deeplearning,2020-10-13
ifvwjc,6 fingers in one hand with 3D printer.,,1,deeplearning,2020-10-13
ifvmtv,Easily Extract images from Video Feed to Annotate for Deep Learning model,"I'm working with a very boring security video feed, and looking to find the activity in the feed to annotate images, and then start working on my DL model.  I've found a number of annotation services out there, but i really just need to isolate those images when something is happening.  Ideas?  I suppose I could write a custom python script of some kind to detect changes?",1,deeplearning,2020-10-13
ifun56,Best Image Colorization AI as of 2020,,62,deeplearning,2020-10-13
ifsys3,"I'm new to coding, so Do I need to learn ML before I can learn DL?",,1,deeplearning,2020-10-13
ifsc1u,Image to Image GAN Survey,"Hi :) I'm doing small research where I want to compare 3 different GAN models and how people will rate them. If anyone have spare 10 mins, please fill my little survey. Thanks in advance :)  

[https://forms.office.com/Pages/ResponsePage.aspx?id=DQSIkWdsW0yxEjajBLZtrQAAAAAAAAAAAANAAaVXp19UQjJXRVlBWFQwQzVXM1Q5NTZaWTJJSE1PMC4u](https://forms.office.com/Pages/ResponsePage.aspx?id=DQSIkWdsW0yxEjajBLZtrQAAAAAAAAAAAANAAaVXp19UQjJXRVlBWFQwQzVXM1Q5NTZaWTJJSE1PMC4u)",0,deeplearning,2020-10-13
ifr3wq,6 fingers in one hand with 3D printer.,,3,deeplearning,2020-10-13
ifr2n4,Project ideas for ANN,I need some project ideas to try and implement ANNs. It has to be good enough so that I can add it to my resume. Even CNNs are fine but I'm a beginner at that so yes.,0,deeplearning,2020-10-13
ifr1h6,Future of Online Shopping,,0,deeplearning,2020-10-13
ifpx84,We've launched a course on Deep Learning based Time-Series Forecasting with TensorFlow 2.0 and Python. Please feel free to let us know what you feel about it!,,19,deeplearning,2020-10-13
ifobv3,Using A Fantasy Game World To Boost AI Performance,,0,deeplearning,2020-10-13
ifo36t,Using A Fantasy Game World To Boost AI Performance,,0,deeplearning,2020-10-13
ifnuy7,Latest papers on CycleGANs?,I am trying to develop a project which involves image to image (Colored) translation. Does anybody know any papers which uses latest principles applied over CycleGANs (or similar architectures) which are more preferred to be used for a project as mentioned above?,1,deeplearning,2020-10-13
ifkseo,Getting Up to Date with AI-Based Malware,,1,deeplearning,2020-10-13
ifjxww,How do I deploy a deep learning model and test out its function,"I found this deep learning model in Github that can remove shadow from photo and I'm thinking of building a small app that uses its function:  
 [https://github.com/google/portrait-shadow-manipulation](https://github.com/google/portrait-shadow-manipulation)   


I have some experience with programming and app development however I have no experience with deep learning and model deployment. Is there a step by step instruction anywhere for me to read more about deploying a model and how to incorporate its function through an API",3,deeplearning,2020-10-13
ifjqm9,Built a Sensor Glove to Translate Indian Sign Language to Speech,,2,deeplearning,2020-10-13
ifjbe4,Deep learning/ML journals,"Hey guys, I want to publish a paper related to Deep Learning. Can you suggest some journals where I can publish, where the submission dates are still open?

Thanks",1,deeplearning,2020-10-13
ifixi8,Fast.ai Course or Book,"How does the fast.ai book compare to the online courses? Is it lacking in content, if so where?",0,deeplearning,2020-10-13
ifgidf,How the softmax function transforms the input space (the logit space) visualized in 3D,,50,deeplearning,2020-10-13
ifggka,How to write a PDF to PNG script to make gathering training data easier,"I want to make a custom OCR for schematic diagrams and have thousands of PDF schematics, but need to write a script to quickly and uniformly convert them to PNGs to use for training data/input for an OCR.  Anyone know of any good open source libraries out there that I could use?",0,deeplearning,2020-10-13
ifdbqv,Linkedin's New Search Engine | DeText: A Deep Text Ranking Framework with BERT | Deep Ranking Model,,1,deeplearning,2020-10-13
ifcvxi,Python Spark Certification Training using PySpark (CCA175),"Big Data Architects, Engineers and Developers - PySpark Certification Training will equip you to become a successful Spark Developer using Python and pass the Cloudera Hadoop and Spark Developer Certification Exam (CCA175). Gain in-depth knowledge of Apache Spark and the Spark Ecosystem including Spark RDD, Spark SQL, Spark MLlib and Spark Streaming and acquire comprehensive knowledge of Python Programming language, HDFS, Sqoop, Flume, Spark GraphX and Messaging System such as Kafka. Skill-based training modules cover: 1) Big Data Hadoop and Spark, 2) Python for Apache Spark, 3) Functions, OOPs, and Modules in Python, 4) Apache Spark Framework, 5) Spark RDDs, 6) DataFrames and Spark SQL, 7) Machine Learning using Spark MLlib, 8) Spark MLlib - Deep Dive, 9) Apache Kafka and Apache Flume, 10) Apache Spark Streaming - Processing Multiple Batches and Data Sources, 11) Implementing an End-to-End Project, and 12) Spark GraphX. 

Enroll today at: https://fxo.co/9YCB  

Much career success, Lawrence E. Wilson - Artificial Intelligence Academy (AIA)",0,deeplearning,2020-10-13
ifb2su,Help find an algorithm to solve this problem,"I am looking for a way to implement the following scenario:

1. The user films a video of a drawing (10-15 secs footage). The video focus on the drawing, but the user can move around and film from different angles.

2. The user edit the first frame of the video. For example, he can draw over a line with a specific color, fill a portion of the drawing with another color etc.

3. Given the data from step 1 and 2, the algorithm applies the edits made in step 2 to the whole video.


I first thought about using simple AR image tracking based on a picture of the drawing, but I think that the results would not be precise enough.

Any suggestion on how to properly achieve that?",1,deeplearning,2020-10-13
if9ing,A new Github repo. The vision is an end to end Object Detection API that will run a search at every stage of the algorithmic process.,,0,deeplearning,2020-10-13
if7ko5,What is the Pipeline to learn computer vision in deep learning?,,1,deeplearning,2020-10-13
if6spr,Pre-requisite skills to learn before getting into ML?,"Hello,

I am thinking about getting into online ML classes. I have a college education but nothing related to tech. I want to know what foundation of skills I need to learn before committing my time and money for online education for ML. I have a basic knowledge of math and I know I will have to get better at algebra, geometry, trig, ect. What are other skills I need to know before studying ML full time? 

Thank you for your time",6,deeplearning,2020-10-13
if6kg6,How To Get Started With ML," 

Hello, I'm an intermediate programmer with experience writing programs and I want to get into developing applications that apply DL algorithms. I tried the first 9 chapters of ""Hands-On Machine Learning by Aurelien Geron"" as a guide but I found it dry and lacking when it comes to writing code for a project as most of the work was done on a notebook. It seems like more of a reference nook than teaching material. Does anyone have a better suggestion for a learning resource that covers ml for projects better? I'm interested in applying machine learning on edge devices. Also, would I need to learn hard theory, or is it fine understanding on a higher level? I am looking at these three books currently:

\- Deep Learning with Python by Francois Chollet

\- Deep Learning for Coders with [fast.ai](https://fast.ai/) and PyTorch

\- Python Deep Learning by Ivan Vasilev

I am thinking of supplementing one of these resources with Grokking Deeping Learning",0,deeplearning,2020-10-13
if484s,Removed background from training data for U-Net semantic segmentation model,"Hello, i have a pipeline that can automatically remove the background of the training images that i use when phenotype plants. Do you think that the model would perform better segmentation by removing the background of the training data(as well as the test data ).",0,deeplearning,2020-10-13
iew3yu,System built by USC researchers reconstructs a fully textured 3D human from each frame,,1,deeplearning,2020-10-13
ierh7q,[R] Sepp Hochreiter on Parallels Between Attention Mechanisms and Modern Hopfield Networks,"Transformer and BERT language models, powered by attention mechanisms, have pushed performance on NLP tasks to ever-higher levels. Esteemed German computer scientist and inventor of long short-term memory (LSTM) Sepp Hochreiter says his attempt to explain transformers’ attention mechanisms for a lecture produced the pithy statement “a word is most similar to itself and gets a high score.”

Here is a quick read:  [Sepp Hochreiter on Parallels Between Attention Mechanisms and Modern Hopfield Networks](https://syncedreview.com/2020/08/22/sepp-hochreiter-on-parallels-between-attention-mechanisms-and-modern-hopfield-networks/)

The paper *Hopfield Networks is All You Need* is on [arXiv](https://arxiv.org/pdf/2008.02217.pdf), and the source code is on [GitHub](https://github.com/ml-jku/hopfield-layers).",3,deeplearning,2020-10-13
ieqlwr,Questions regarding Data preparation for image segmentation in UNET,"Hello everyone, I am a beginner in regards to deep learning, but am currently working on a deep learning model with the goal of segmenting muscles. Our team has a custom dataset, in which we have already personally annotated, and the groundtruths have been approved by radiologists. My main issue now is in regards to data preparation. I am able to create masks for every individual muscle group by separating our annotations (NRRD) files by pixel intensities, but am unsure of how to set labels so that they would correspond to a certain muscle group. I have tried researching examples of semantic segmentations online, but almost all of the sources and code I have found, the articles/code either focus mainly on training rather than data preparation, or use pre-labeled data sets available online. I would greatly appreciate any help I can get, and if my post is confusing and needs further clarification I would be happy to ! Thanks!",1,deeplearning,2020-10-13
ieofwo,Fast.ai has made pytorch jupyter version notebook for free,,60,deeplearning,2020-10-13
ienq6q,[Project] KD_Lib: A PyTorch library for knowledge distillation,"GitHub - [https://github.com/SforAiDl/KD\_Lib](https://github.com/SforAiDl/KD_Lib)

Knowledge distillation has been used  primarily to compress deep learning models but recently has found  applications in tasks such as improving robustness of models as well.  
[KD\_Lib](https://github.com/SforAiDl/KD_Lib)  is a modular open-source PyTorch library to facilitate knowledge distillation (KD) for custom deep learning models.  The inspiration behind developing this library is the absence of any comprehensive framework that allows users to distill their models easily. KD\_Lib takes care of the entire distillation training process and has a very simple and intuitive API. It contains a variety of methods from a collection of prominent research papers which can be used with a few lines of code.

The library is still under development and we seek your suggestions and feedback to make it better.  
We hope KD\_Lib can help users in efficiently incorporating knowledge distillation in their work.

TIA :)",9,deeplearning,2020-10-13
iennxt,AI generates cars from teh movie (repost from 1 month ago),,0,deeplearning,2020-10-13
iemk1c,Can machine learning do data analysis?,Now we need to analyze the data from our software product and come up with a solution for improvement on the product. Is this deep learning capable of?,0,deeplearning,2020-10-13
iemg5y,Relation of ML techniques with DL. [1 - Less relevant : 5 - Very relevant] (Please vote only if you are into DL),"

[View Poll](https://www.reddit.com/poll/iemg5y)",1,deeplearning,2020-10-13
iemetv,"I am a Molecular Biologist and I want to learn Deep Learning, where do I beging?","Hi fellow redditors,

I am a Molecular biologist and I work in cancer research with a focus on automated image acquisition. The application of Deep Learning to my field are endless, and we are looking for collaborators to help us do the analysis. 

However I´d like to learn myself to it as well, so I was wondering whether there is any good maaterial from which to learn (online courses, textbooks). I went to EdX but I couldn´t find something that looked ""usefull"" (maybe I did not look deep enough), and I downloaded a bunch of textbook from 2017  (but I feel they are too old).

&amp;#x200B;

Any advice for good material to start? I know how to program in C, Java, R and a I have basics of Python",2,deeplearning,2020-10-13
iej5pb,Here's a new paper announced in the ECCV2020 where they proposed a new technique for 3D Human Pose and Mesh Estimation from a single RGB image (with code available). It's called it I2L-MeshNet and here's a video I made introducing it and showing some results!,,4,deeplearning,2020-10-13
ieip78,VGG-16 architecture,"Published a blog on VGG-16 architecture

&amp;#x200B;

[VGG-16\_architecture](https://medium.com/towards-artificial-intelligence/the-architecture-and-implementation-of-vgg-16-b050e5a5920b?source=friends_link&amp;sk=8dda7810f1b5fceaf0252ad8634b3cdf)",1,deeplearning,2020-10-13
ieigpj,Sound Classification using CNN by MFCC,"Hey guys ,just a newbie here.Recently I tried to learn sound classification and learnt some important stuff like spectogram and MFCC.

But I'm getting some problem in implementation.The problem is when I try to calculate the MFCC for each sample audio wav file I get a value which is in the shape
of =[n_mfcc,t] now t is different for each file.

I want to pass the data to a 1D convnet but it needs constant shape.so how can I make the t same for every output so I can pass it to a CNN ?

Am I doing it wrong or maybe there is a way ? Please help.

(Note:I'm using librosa library ,librosa load to load the wav files and also librosa.features.mfcc to get the mfcc of the audio file ) 

Thanks in advance.Also sorry for my bad English.",3,deeplearning,2020-10-13
iehsx0,So many linear memory transformers. Which to choose?,,1,deeplearning,2020-10-13
ieg2je,Resource Recommendations for advanced deeplearning concepts,"Hi all
Any resource Recommendations for introduction to  advanced deeplearning concepts like meta learning , adveserial learning , representation learning ,etc.
Thanks in advance",19,deeplearning,2020-10-13
ieci59,"ICYMI from Nvidia and UWaterloo researchers: Latest in synthesizing scenes for graphics, gaming, and to create (labeled) synthetic datasets for ML",,3,deeplearning,2020-10-13
iecdm3,Dockship Data Science Community,"Hey guys! I work at a company that's building a Data Science community by providing pre trained models and hosting hackathons with cash prizes. 

Please join the telegram group for updates and participate in ai contests at dockship.io . 

Dockship Community
Official Dockship data science community.
https://dockship.io
https://t.me/dockship",1,deeplearning,2020-10-13
iebjst,Questions about Google colab,"1. Is it okay to train my model even with my browser closed. I tried to google this and I cant seem to find a definite answer.
2. How do you save model from colab to gdrive? Ive been trying to use [torch.save](https://torch.save) and its working okay in pc but not in colab. It does not give na error but it acts as if the saving was done but when I check my gdrive folder it is not there.
3. And also they said that you disconnect after 12 hrs? Im training a GAN and it disconnects less than 12  hrs. If I buy premium will it be significantly longer and the ad say the GPU is also faster. Is this also true?

Please see my code below for model saving.

 torch.save({  
 'generator'    : generator.state\_dict(),  
 'discriminator': discriminator.state\_dict(),  
 'g\_optim'      : g\_optim.state\_dict(),  
 'd\_optim'      : d\_optim.state\_dict(),  
 'parameters'   : (step, i, used\_sample, alpha),  
 'd\_losses'     : d\_losses,  
 'g\_losses'     : g\_losses  
            }, f'/content/gdrive/My Drive/Checkpoint/')  
 print(f'Iteration {i} successfully saved.')",2,deeplearning,2020-10-13
ie9g8m,Help with lower CNN U-net model parameters to prevent overfitting," Hello I need some help with lowering the parameters in a CNN model using pre-trained weights from the CNN architecture provided in the link. I can't figure out how to decrease the parameters and still being able to use the weights from the pre-trained model.

CNN architecture: [https://stackoverflow.com/questions/63531538/pytorch-lower-the-parameters-in-u-net-model](https://stackoverflow.com/questions/63531538/pytorch-lower-the-parameters-in-u-net-model)",0,deeplearning,2020-10-13
ie3m4c,Predicting NBA upsets with GANs,,2,deeplearning,2020-10-13
ie39vc,Maximizing Computer Vision's Field of View (CVPR 2020) - Free live online lecture by the researcher,,47,deeplearning,2020-10-13
ie0aq4,can I train a model on a raspberry pi cluster?,I'm interested in building a cluster for fun. If anyone has tried this let me know. Thanks!,0,deeplearning,2020-10-13
idy5xj,[D] Regularisation of Neural Networks by Enforcing Lipschitz Continuity,,0,deeplearning,2020-10-13
idxoki,Learning the theory behind DL,"Hello, 

I am interested in DL, and I would like to learn the theory properly before starting with any projects, so I was wondering if the deep learning specialization by Prof.Andrew Ng goes into the theory in a rigorous manner not just in a hand-wavy way, or would it be better just to read from the deep learning book by Goodfellow, Bengio, and Courville?

Another idea is to do both in parallel, as in take the course and read from the book to fill in any gaps. 

If anybody has any other book suggestions from experience please let me know. 

any advice is very much appreciated, Thanks.",1,deeplearning,2020-10-13
idva3o,"Experts Predict The Next Roadblocks in AI - Hear from Jeff Clune, Andriy Burkov, Jane Wang, Alexia Jolicoeur-Martineau and more.",,1,deeplearning,2020-10-13
idugn0,Should I learn about computer vision when I want to work in NLP?,"Hi!

I'm going through the deep learning specialization of [deeplearning.ai](https://deep.ai/) in Coursera and I've finished the first three basic courses of it. Though right now I'm entering convolutional neural nets and it's all about image processing and computer vision. I know I want to continue NLP as my major field of research but I'm not sure whether I should learn about image processing or not? Do you think I should take the time and go through this course? Do these fields relate to each other?  
Thanks in advance!",3,deeplearning,2020-10-13
idsn7a,Is this project a good practice to show my familiarity with Tensorflow?,"Hi everyone, 

I'm a beginner in this field and after finishing Andrew Ng's course,  decided to code a simple CNN for myself. I was wondering if this project which is about detecting Malaria from cell images is considered a good example to show to my university professor because he asked me to show him how was my understanding of Tensorflow and Deep Learning.

The project's link is: [https://github.com/tavasolireza/CNN-Malaria-Detection](https://github.com/tavasolireza/CNN-Malaria-Detection)",16,deeplearning,2020-10-13
idrzv2,Why don't people use L0 for net pruning more?,I have only seen a couple of papers about it and mostly with older architectures. Is it purely because it is hard to optimize or am I missing something?,3,deeplearning,2020-10-13
idrcmo,[P] vedastr: An open source scene text recognition toolbox based on PyTorch,"## Introduction
[vedastr](https://github.com/Media-Smart/vedastr) is an open source scene text recognition toolbox based on PyTorch. It is designed to be flexible
in order to support rapid implementation and evaluation for scene text recognition task.  

## Features
- **Modular design**\
  We decompose the scene text recognition framework into different components and one can 
  easily construct a customized scene text recognition framework by combining different modules.
  
- **Flexibility**\
  vedastr is flexible enough to be able to easily change the components within a module.

- **Module expansibility**\
  It is easy to integrate a new module into the vedastr project. 

- **Support of multiple frameworks**\
  The toolbox supports several popular scene text recognition framework, e.g., [CRNN](https://arxiv.org/abs/1507.05717),
   [TPS-ResNet-BiLSTM-Attention](https://github.com/clovaai/deep-text-recognition-benchmark), Transformer, etc.

- **Good performance**\
  We re-implement the best model in  [deep-text-recognition-benchmark](https://github.com/clovaai/deep-text-recognition-benchmark)
  and get better average accuracy. What's more, we implement a simple baseline(ResNet-FC)
   and the performance is acceptable.",2,deeplearning,2020-10-13
idrb74,[P]vedaseg: An open source semantic segmentation toolbox based on PyTorch,"## Introduction
[vedaseg](https://github.com/Media-Smart/vedaseg) is an open source semantic segmentation toolbox based on PyTorch.

## Features

- **Modular Design**

  We decompose the semantic segmentation framework into different components. The flexible and extensible design make it easy to implement a customized semantic segmentation project by combining different modules like building Lego.

- **Support of several popular frameworks**

  The toolbox supports several popular and semantic segmentation frameworks out of box, *e.g.* DeepLabv3+, DeepLabv3, U-Net, PSPNet, FPN, etc.

- **Deployment and acceleration**

  The toolbox can automatically transform and accelerate PyTorch, Onnx and Tensorflow models with TensorRT, can also automatically generate benchmark with given model.

- **Different training modes**
    
  The toolbox supports both single-label training and multi-label training.",2,deeplearning,2020-10-13
idr0qa,"[P]volksdep: An open-source toolbox for deploying and accelerating PyTorch, Onnx and Tensorflow models with TensorRT","## Introduction
[volksdep](https://github.com/Media-Smart/volksdep) is an open-source toolbox for deploying and accelerating PyTorch, Onnx and Tensorflow models with TensorRT.

## Features
- **Auto transformation and acceleration**\
    volksdep can automatically transform and accelerate PyTorch, Onnx and Tensorflow models with TensorRT by writing 
    only some few codes.

- **Auto benchmark**\
    volksdep can automatically generate benchmark with given model.",5,deeplearning,2020-10-13
idpxwm,Best option to begin with Deep Learning?,"

[View Poll](https://www.reddit.com/poll/idpxwm)",1,deeplearning,2020-10-13
idp241,Super-Human Performance in car racing using Deep Reinforcement Learning!,,22,deeplearning,2020-10-13
idoq6g,Pls vote and contribute ideas in the live discussion. This will help newbies like me to organize our learning trajectory. Thank you!,,2,deeplearning,2020-10-13
idn6ve,Recommendations for books on CNNs with examples of Python code?,"Hello everybody, I am looking for some good books/textbooks covering Convolutional neural network networks (CNNs) for image classification. I’m new to this area, so I’m looking for some with good how-to tutorials and examples of Python code. Does anybody have any suggestions?

Thanks!",10,deeplearning,2020-10-13
idhw8n,Too many AI researchers think real-world problems are not relevant,,9,deeplearning,2020-10-13
idhlrx,Deep Learning PC Build 2020 (illustrating each part),,0,deeplearning,2020-10-13
idfa9s,[Tutorial] Deep Learning with scikit-learn,"PyTorch, TensorFlow and Caffe aren’t the only frameworks for Deep Learning. There is also a library with a scikit-learn like API, **scikit-neuralnetwork**.

scikit-neuralnetwork is a deep neural network implementation without the learning cliff! This library implements multi-layer perceptrons as a wrapper for the powerful pylearn2 library that’s compatible with scikit-learn for a more user-friendly and Pythonic interface.

[https://towardsdatascience.com/deep-learning-with-scikit-learn-1de142d96118](https://towardsdatascience.com/deep-learning-with-scikit-learn-1de142d96118)",3,deeplearning,2020-10-13
idc9sz,I have high CPU and low GPU usage when training a model. I installed CUDA and tensorflow-gpu,"I  have a low GPU and a high CPU usage on MNIST dataset with this model. I installed CUDA for the GPU, but nothing has changed. Can you help me? 

&amp;#x200B;

https://preview.redd.it/2yiqct6ed6i51.png?width=694&amp;format=png&amp;auto=webp&amp;s=ae3d11a98f8c290c1c32624fc9bbbc7c020aef2d

https://preview.redd.it/utl7lx6ed6i51.png?width=1002&amp;format=png&amp;auto=webp&amp;s=71e790deb83e18564d750582a14af3ac966137d9",0,deeplearning,2020-10-13
id8qkn,"Join more than 2 000 DL enthusiasts on our discord server! Share, Learn &amp; improve together!","**Join us**:  [https://discord.gg/SVse4Sr](https://discord.gg/SVse4Sr?fbclid=IwAR2__32H2RMxvARPjhKN2wd7C7yeiNAnsePH-5wu5E18SGS8IwhGCPBAKDI) 

[https:\/\/discord.gg\/SVse4Sr ](https://preview.redd.it/yckgb7yu95i51.png?width=1074&amp;format=png&amp;auto=webp&amp;s=f880e94d38037dd4647631bb9c02aa0421306513)",2,deeplearning,2020-10-13
id7xcd,Question regarding Lai et al. (2018) Learning Blind Video Temporal Consistency published in ECCV 2018,"Hi guys,

As I am currently working on enforcing time consistency on per-frame processed videos and I am thus reviewing the litterature dealing with this issue. The last notable paper that seems to display very satisfactory results is ***Learning Blind Video Temporal Consistency*** by Wei-Sheng Lai, Jia-Bin Huang, Oliver Wang, Eli Shechtman, Ersin Yumer and Ming-Hsuan Yang. (github :  [https://github.com/phoenix104104/fast\_blind\_video\_consistency](https://github.com/phoenix104104/fast_blind_video_consistency) )

However, I have trouble understanding the way they define the long term and short term losses they use to enforce time consistency. Most paper introducing such losses define it in a different way that seems to me more logical and more understandable.

For instance, the short term loss is defined as follows.

&amp;#x200B;

[Short Term Loss](https://preview.redd.it/cjeqbf5w76i51.png?width=412&amp;format=png&amp;auto=webp&amp;s=7b79bd1f580ad5479d72a5a31d50ee9bf7fc3517)

, where $\\hat{O}\_{t-1}\^{(i)}$ is defined as the frame $O\_{t-1}$ (which is the output frame of the recurrent model for the t-1th frame of the video sequence) warped by the optical **BACKWARD** flow (i.e. the flow estimated from the frame t to t-1)

This definition of the loss puzzles me quite a lot. For instance, the authors declare that the loss is defined based on the warping error between the output frames, however the way I understand their explanation (and their code) is that they apply the backward flow between t and t-1 to the frame in t-1, thus this is not the warping error. This does not make sens to me at all.

Moreover, all the papers that I have read so far that include such temporal losses (using the warping error) define it in the ""logical""way which is warping the t-1 frame using the **FORWARD** flow. (Ruder et al. 2016,  Huang et al. 2017).

Is there something critical that I do not understand from their paper which could account for such difference in the definition of the loss ?

This puzzles me and makes me think that it might be a typo or a change of convention since the way they define the metric which they use to evaluate the temporal consistency of the of a video is defined as follows

&amp;#x200B;

&amp;#x200B;

[Temporal Metric](https://preview.redd.it/dcv6ujks76i51.png?width=556&amp;format=png&amp;auto=webp&amp;s=b42e612b7c642459cd2676518c816de047a401d7)

where this time using the backward flow to warp $V\_{t+1}$ would make sense. Nonetheless, when defining the metric, the authors do not care to explicitly define what flow they use to warp the frame in t+1, thus we could only suppose that the backward flow is used and not the forward one.

HOWEVER, when looking at the code they use it seems that the metric uses the forward flow to warp the t+1 frame.

For those familiar with python :

`flow_dir = os.path.join(opts.data_dir, opts.phase, ""fw_flow"", opts.dataset, video)`

where you can see the 'fw\_flow' for forward flow is used to define the flow directory. You then fetch the frames and the flow

`for t in range(1, len(frame_list)):   ### load input images` 

`filename = os.path.join(frame_dir, ""%05d.jpg"" %(t - 1))`  frame t

`img1 = utils.read_img(filename)` 

`filename = os.path.join(frame_dir, ""%05d.jpg"" %(t))` frame t+1

`img2 = utils.read_img(filename)` 

You then fetch the precomputed forward flow 

`filename = os.path.join(flow_dir, ""%05d.flo"" %(t-1))`

`flow = utils.read_flo(filename)`

and then, few lines of code later, you warp the t+1 frame using such forward flow

`warp_img2 = flow_warping(img2, flow)`

Hence, if I understand correctly what they do here : they compute forward flow between frame t and t+1, then warp the t+1 frame using that flow, and then compare it as detailed in the metric. 

This is highly conter-intuitive for me. Has anyone any explanation to what is going on here exactly ?

Thanks for reading !

&amp;#x200B;

&amp;#x200B;",5,deeplearning,2020-10-13
id6mwc,From Facebook researchers: State of the art in 3D Hand and Body Motion Capture!,,1,deeplearning,2020-10-13
id5o4m,Help understanding weight decay,"In L2 regularization, we want to reduce variance and improve the model by punishing large weights. But I don't really understand the relation. Are large weights necessarily a bad thing? If not, when would they be correct? What's the intuition in relation to weights and input features that makes it a good idea to punish large weights?",14,deeplearning,2020-10-13
id11qf,A community for newbies to ask amateur questions regarding Deep Learning,,6,deeplearning,2020-10-13
id0mjx,Virtual project collaboration?,"If anyone wants to get together over discord and work on a machine learning project, DM me so we can all get together and make something cool! It’d be interesting to see what we can all come up with.",0,deeplearning,2020-10-13
icwo6v,How to combine two different embeddings in the best way possible?,"I have two models which are giving two books embedding 

&amp;#x200B;

`Ml_model_a =&gt; book1_embedding [ 1, 200 ]`

`Ml_model_b =&gt; book2_embedding [ 1, 200 ]`  

I am building a third model which will take these two different embeddings to tell me which book to choose.

Now my final layer is the classification between 0,1 ( which book to choose ). How to learn these embeddings best way possible to classify better?

&amp;#x200B;

What I have tried yet :

[Current Model](https://preview.redd.it/7uefwvc0z0i51.png?width=3636&amp;format=png&amp;auto=webp&amp;s=02183ad4db74fe74f54c01a4402f1c3bdb0f720a)

If I am averaging those embeddings and then sending to one model, then embeddings are losing a lot of information, so I am using concatenation method.

But it's not classifying well, Is there any other model, a technique I could use to enhance the capability of learning to book embedding and predict which book to take?",2,deeplearning,2020-10-13
icvjpa,Using the fastai library?,"I'm a beginner in DL, transitioning from ML. 
I've started out with the Fastai practical DL for coders course and the instructor is using Fastai as opposed to Keras used in the previous version of the course. 

I've always heard more about using tensorflow and keras and almost never about FastAI. 
So should I learn the other libraries before using fastai?",4,deeplearning,2020-10-13
icubem,Deeplearning.ai specialization study group,"I'm organizing a study group for the [deeplearning.ai](https://www.deeplearning.ai/deep-learning-specialization/) specialization on Coursera. 

If you're interested in participating, drop your info in [this form](https://forms.gle/U7MGXsACerWxM3eu6) and I'll invite you to the Slack channel + coordinate virtual meetups for the group.",6,deeplearning,2020-10-13
icu16p,[R] DeepMind &amp; McGill Employ Operations Generalization to Divide &amp; Conquer Complex RL Problems,"These days, combining reinforcement learning with deep learning is emerging as a promising approach for tackling challenging sequential decision-making problems. Such systems however require a huge amount of data for training. DeepMind and McGill University researchers believe the problem could be solved through a strategic “divide-and-conquer” approach.

Here is a quick read: [DeepMind &amp; McGill Employ Operations Generalization to Divide &amp; Conquer Complex RL Problems](https://syncedreview.com/2020/08/19/deepmind-mcgill-employ-operations-generalization-to-divide-conquer-complex-rl-problems/)

The paper *Fast Reinforcement Learning With Generalized Policy Updates* is on [PNAS](https://www.pnas.org/content/pnas/early/2020/08/13/1907370117.full.pdf), and the source code is on [GitHub](https://github.com/deepmind/deepmind-research/tree/master/option_keyboard/gpe_gpi_experiments).",4,deeplearning,2020-10-13
icoag8,Transfer clothes between photos using AI. From a single image!,,1,deeplearning,2020-10-13
icnqt6,[R] Example Weighting for Deep Representation Learning,,1,deeplearning,2020-10-13
icju7d,"I’ve finished Andrew’s Deep Learning course 1&amp;2, and I want to use the code I learned in his assignment to solve this classification problem form UCI. But how do I even load my dataset?","UCI dataset

[https://archive.ics.uci.edu/ml/datasets/2.4+GHZ+Indoor+Channel+Measurements](https://archive.ics.uci.edu/ml/datasets/2.4+GHZ+Indoor+Channel+Measurements)

default ways to load dataset in assignment:

[https://jdwameieoblqbiugtcixrm.coursera-apps.org/edit/week7/tf\_utils.py](https://jdwameieoblqbiugtcixrm.coursera-apps.org/edit/week7/tf_utils.py) 

[https://jdwameieoblqbiugtcixrm.coursera-apps.org/tree/week7/datasets](https://jdwameieoblqbiugtcixrm.coursera-apps.org/tree/week7/datasets) 

code:

[https://jdwameieoblqbiugtcixrm.coursera-apps.org/notebooks/week7/TensorFlow\_Tutorial\_v3b-Copy1.ipynb](https://jdwameieoblqbiugtcixrm.coursera-apps.org/notebooks/week7/TensorFlow_Tutorial_v3b-Copy1.ipynb)",3,deeplearning,2020-10-13
icjjor,Looking for advice regarding an investment into a co-working space focused on deep learning / ml / ai / autonomous machines,"Hello,

Like the title says I'd be very thankful for advice regarding the establishment of a co-working office / space which I plan to make mostly / partially free to use for students in my city. 

I have some money to throw around and I don't necessarily care about a return on my investment; I can buy a handful of 4x RTX 3080 Ti computers and one or two 4x Quadro 6000, once the gpus come out, and other nvidia jetson dev kits and some equipment for an electronics lab  


So I plan on beating gpu instance cloud prices and provide the best environment possible for a relatively small group of people to work together at a time and exchange ideas.  


So my questions would be  


1. If this was set up in your city would you be interested in becoming a member provided the cost of membership made it cheaper than cloud for you to train your models and gave you access to other equipment and data sets?
2. If 1. then what equipment would you like to see in the co-working office / lab?
3. Do you have any other advice which I can't think to formulate a question for?  


Thank you kindly everyone",0,deeplearning,2020-10-13
ichz5i,Now AI generates Python Code,,54,deeplearning,2020-10-13
ichpqw,Help with understanding something from deep learning course,"[This](https://prnt.sc/u20guo) is from an Andrew Ng deep learning course. I think I understand the concepts of ""overfitting"" and ""underfitting"" but I don't really get what the graphs are really conveying. Why do the different graphs look like they do? Why is the first graph portraying high bias, and the last one high variance? I think if I can understand that, I can feel more comfortable with these concepts. Thanks in advance.",3,deeplearning,2020-10-13
icgl0o,Capture 3D human motion from internet videos!,,1,deeplearning,2020-10-13
icfk0f,The turning point for AI transformation?,"AI is not one independent technology. We need more open source tools to speed up the process: 

[https://towardsdatascience.com/passing-the-turning-point-of-ai-transformation-4855bc9742a1](https://towardsdatascience.com/passing-the-turning-point-of-ai-transformation-4855bc9742a1)",0,deeplearning,2020-10-13
icdmm9,DO YOU LIKE CATS OR DOGS BETTER,"# I LOVE BOTH BUT IM GONNA HAVE TO GO WITH DOG I LOVE CATS TO 

&amp;#x200B;

[View Poll](https://www.reddit.com/poll/icdmm9)",0,deeplearning,2020-10-13
ic6o0b,ML generates ML model,,2,deeplearning,2020-10-13
ic4ucs,The new deep fake app goes viral…,,73,deeplearning,2020-10-13
ic1a44,Creating my First Deep Learning + Data Science Workstation,,8,deeplearning,2020-10-13
ic16at,Need help with an assignment,"Hello everyone,

I am noob and just getting into this field. I need some help with an assignment that I've been allotted. I need help with using a pretrained network (Resnet18 or VGG16) to perform K Means clustering on a custom data of 30 images. The framework I am using is PyTorch. Any  inputs and resources from y'all would be highly appreciated.

Thanks in advance!",1,deeplearning,2020-10-13
ibyn8l,Help with deep learning build,"I am sorry in advance if I have posted this in the wrong section of reddit. But  I am currently considering to upgrade my current deep learning pc with some new gpus. My plan would be to go from gtx 1050ti to two rtx 2060 gpus. What I wanted to know is if

1. Would a ryzen 1300X be able to handle two rtx gpus or would i need to upgrade my cpu
2. would the asus strix b450-f gaming motherboard be able to handle the rtx gpus
3. for performance. Is it better to use two gpus or just stick with one gpu
4. is the rtx gpus better for deep learning compared to the gtx gpus",1,deeplearning,2020-10-13
ibwep9,Future Of Healthcare Through Deep Learning &amp; 3D-Printed Organoids,,2,deeplearning,2020-10-13
ibvsgl,Leveraging Computer Vision In Drone Tech,[https://analyticsindiamag.com/leveraging-computer-vision-in-drone-tech/](https://analyticsindiamag.com/leveraging-computer-vision-in-drone-tech/),0,deeplearning,2020-10-13
ibv9no,[Need Help] Bounding Box Regression using VPGNET,"i am implementing VPGNET which is an overfeat based paper for lane and road marking detection. Its a multi task network with four tasks

1. Grid box regression
2. Grid mask
3. Multi class
4. Vanishing point prediction

Task 2,3,4 are classification tasks, so they are learning and inferring okay. But grid box regression task isn't learning.

It has a constant loss. I am using linear activation function on the last layer and using Mean Absolute error L1 loss function for bounding box regression task as per paper. I am not normalising any bounding box coordinates, so their range is 0-640 (width) and 0-480 height. The training MAE loss starts off really high, 17.5 to be exact and then stays there.  


https://preview.redd.it/7kgwbac8osh51.png?width=1328&amp;format=png&amp;auto=webp&amp;s=9a11b0435fe7d661971171eac5f9ab638e695cbc",1,deeplearning,2020-10-13
ibto90,Automated capture of animal pose!,,1,deeplearning,2020-10-13
ibqszt,Where to start,"I am interested in learning more about deep learning, more specifically DLRM, where should I start, is there something like a ""Hello World"" starting concept with deep learning?  Something to start with the basics and start advancing slowly?",2,deeplearning,2020-10-13
iblijs,[R] Google Introduces NLP Model Understanding Tool,"Artificial intelligence does a lot of things extremely well, but just *how* it does these things often remains unclear — shrouded by what’s come to be known as the “black box” problem. This is particularly true in NLP, where researchers can waste a lot of time trying to figure out what went wrong when their models don’t run as well as expected. Last week, Google Research released a paper tackling this issue with a new open-source analytic platform: the Language Interpretability Tool (LIT).

Here is a quick read: [Google Introduces NLP Model Understanding Tool](https://syncedreview.com/2020/08/17/google-introduces-nlp-model-understanding-tool/)

The paper *The Language Interpretability Tool: Extensible, Interactive Visualizations and Analysis for NLP Models* is on [arXiv](https://arxiv.org/pdf/2008.05122.pdf). The tool has been open-sourced on [Github](https://github.com/pair-code/lit).",6,deeplearning,2020-10-13
iblhzl,Personal GPT-3 project 🚀: Guess the movie! You can't recall the name of that movie you watched? You know what the movie's about but you just can't remember its name? I used the GPT-3 model to solve this problem! Just feed it a small description of the movie/tv show and it will do the rest.,,106,deeplearning,2020-10-13
ibk6ei,Generative Adversarial Network with two images in input,"Hi everyone, I am doing an internship project regarding deep learning, and it is a totally new topic for me as I have never studied machine learning in the bachelor's degree courses. I have to implement a GAN that generates a middle image starting from two images, the previous and the next. In particular, the network must work with TACs, therefore it must generate the middle TAC starting from two successive ones. I am studying the basic theory concerning deep learning, neural networks and in particular GANs, but I have not yet fully understood where the network takes in the two starting images. Does the generating network still have to take in only one noise vector or must it also know the two images? Can you recommend any architecture that I can use to get ideas? Do you have any advice? 

Thanks in advance",3,deeplearning,2020-10-13
ibk1az,How to apply for research internship in DL/NLP?,"I am a CSE Junior year undergrad from , Mumbai. I am very much interested in NLP/DL and want to try my hands around with a research based projects/research internship . I have done few projects which are over here : [www.github.com/talha1503](https://www.github.com/talha1503)  and I am currently working on a Nerual Question Generation project. I have worked previously as a Data Science intern at a risk management company and also have a paper in pre-print. Can anyone please suggest me where to apply and how to reach out to professors/labs?",2,deeplearning,2020-10-13
ibjhf5,Yet another computer vision slack channel - Join Us!,,2,deeplearning,2020-10-13
ibgnxj,Using Reinforcement Learning to Design Resilient Spacecraft Trajectories,,1,deeplearning,2020-10-13
ibeykt,"what is Tensor(""IteratorGetNext:1"", shape=(None, 3), dtype=float32)","hello, I have a simple code here. I was trying to make a custom loss but I got stuck. I have a function:

`def call(self, y_true, y_pred):`

`print(y_true)`

`print(y_pred)`

`return tf.math.reduce_mean(tf.square(y_true - y_pred))`

this function returns :

`Tensor(""IteratorGetNext:1"", shape=(None, 3), dtype=float32) Tensor(""functional_137/dense_137/Softmax:0"", shape=(None, 2), dtype=float32)`

followed by value error. i want to access y\_true tensor, it has 3 components and y\_pred tensor which has 2 component, so i need to make mse correctly. please help me to undestand what:

`Tensor(""IteratorGetNext:1"", shape=(None, 3), dtype=float32) Tensor(""functional_137/dense_137/Softmax:0"", shape=(None, 2), dtype=float32)`

these are and how to get infrmation from them.",0,deeplearning,2020-10-13
ibetgl,Neural net that plays tic tac toe,"[https://github.com/cpita/TicTacToeAI](https://github.com/cpita/TicTacToeAI)

I coded up a neural net from scratch that plays tic tac toe, along with a theoretical explanation. What do you guys think? I'm also thinking about including it in my CV when applying for internships.",0,deeplearning,2020-10-13
ibengm,Where is OpenCL?,"On deep learning field. I see that CUDA based gpu accelerators are more famous than OpenCL but I dont understand why there's no OpenCL library that be famous. Like I said ""Top for NVDIAs gpu? - TF"" but for OpenCL I don't see any but OpenCL have more advantage that it can support Radeon Graphic and another why they not develop this. I dont ask about RocM. (Or if it like CUDA for AMD please give me some advance please)",7,deeplearning,2020-10-13
ibej84,Can the model's output be taken as the seed to produce random numbers?,[https://www.reddit.com/r/MachineLearning/comments/ibd4o8/d_can_i_take_my_models_output_as_seed_to_my_prng/?utm_medium=android_app&amp;utm_source=share](https://www.reddit.com/r/MachineLearning/comments/ibd4o8/d_can_i_take_my_models_output_as_seed_to_my_prng/?utm_medium=android_app&amp;utm_source=share),0,deeplearning,2020-10-13
ibeduq,TensorBoard with PyTorch Lightning,"While training a deep learning model, it is very important to visualize various aspects of the training process. This visualization is best achieved using [Tensorboard](https://el2.convertkit-mail.com/c/gkuog7wr5ot5hxq4nmf3/n2hohquodgkl02/aHR0cHM6Ly93d3cudGVuc29yZmxvdy5vcmcvdGVuc29yYm9hcmQ=) which we will cover in today's post.  


A few weeks back we had shared a post on [PyTorch Lightning for beginners](https://el2.convertkit-mail.com/c/gkuog7wr5ot5hxq4nmf3/48hvh7u2o9n78v/aHR0cHM6Ly93d3cubGVhcm5vcGVuY3YuY29tL2dldHRpbmctc3RhcnRlZC13aXRoLXB5dG9yY2gtbGlnaHRuaW5nLw==) where we saw how using PyTorch Lightning simplifies the coding experience and removes a lot of grunt work.  
Today, we will show how to use Tensorboard with PyTorch Lightning.  


[https://www.learnopencv.com/tensorboard-with-pytorch-lightning/](https://el2.convertkit-mail.com/c/gkuog7wr5ot5hxq4nmf3/wnh2h6uoz43l67/aHR0cHM6Ly93d3cubGVhcm5vcGVuY3YuY29tL3RlbnNvcmJvYXJkLXdpdGgtcHl0b3JjaC1saWdodG5pbmcv)  


and the code is at  
[https://github.com/spmallick/learnopencv/tree/master/TensorBoard-With-Pytorch-Lightning](https://el2.convertkit-mail.com/c/gkuog7wr5ot5hxq4nmf3/reh8h9u587eozz/aHR0cHM6Ly9naXRodWIuY29tL3NwbWFsbGljay9sZWFybm9wZW5jdi90cmVlL21hc3Rlci9UZW5zb3JCb2FyZC1XaXRoLVB5dG9yY2gtTGlnaHRuaW5n)

https://preview.redd.it/zt9oatj2hkh51.png?width=600&amp;format=png&amp;auto=webp&amp;s=8437f427c00cf5309bec94f83cda993edd72821a",3,deeplearning,2020-10-13
ibaoi2,Data Science Skills Study 2020,[https://analyticsindiamag.com/aim-2020-data-science-skills-survey-aim-and-analytix-labs/](https://analyticsindiamag.com/aim-2020-data-science-skills-survey-aim-and-analytix-labs/),2,deeplearning,2020-10-13
ibaij2,Video feature extraction,"Hey guys! I'm currently doing a project to identify the complexity of the videos e.g: sport videos or action films, which contain lots of scence changes, motions etc., are more complex than news video. I'm only thinking of extracting the video motion of a video and get stuck so far to find other potential features. Could anyone give me a keyword about the promising features to indentify the complexity of a video? Thank you.",1,deeplearning,2020-10-13
ib8kxh,LangLfP: Grounding Language in Play | Paper Explained,,0,deeplearning,2020-10-13
ib7o2d,"Deep learning gods, I just completed the dl specialization on coursera by Andrew ng, as a beginner how do I start to implement deeplearning??",Can you guys please share some tips??,2,deeplearning,2020-10-13
ib7e6s,Machine Learning Practices And The Art of Research Management,[https://analyticsindiamag.com/machine-learning-research-management-dan-malowany/](https://analyticsindiamag.com/machine-learning-research-management-dan-malowany/),0,deeplearning,2020-10-13
ib791z,"CNN usually converging to zero, how to solve?","I am training a CNN on a novel problem, but the network design is similar to that shown below. However, my network takes an input image and predicts an output image of the same dimensions. So its similar to denoising, autoencoding, deblurring, sematic segmentation, etc.

However, I find that during training, my network usually converges very quickly to predict all zeros at the output. I believe this is because my input image and target image are sparse (96% zeros). So unfortunately, the network takes the easy way out, and just says *""Hell with it, I'll give you the trivial solution and still get a solid A on the test!""*

Assuming my diagnosis is correct, one solution would be to not use sparse images. But my images are naturally sparse. **In this situation, is there a technique (such as a regularization method), to prevent the network from converging to the trivial solution (output all zeros)?** 

[http:\/\/openaccess.thecvf.com\/content\_cvpr\_2017\/papers\/Gong\_From\_Motion\_Blur\_CVPR\_2017\_paper.pdf](https://preview.redd.it/fjgnux1lmhh51.png?width=1012&amp;format=png&amp;auto=webp&amp;s=5512d6a979c5cbd672e0422aa2a07ad42920860d)",1,deeplearning,2020-10-13
ib70mq,Is deep learning for stock prediction a huge scam?,"The insane amount of papers and articles regarding people using LSTMs, GRUs, CNNs and whatnot for predicting stock prices is driving me mad. At the end of the day all their fancy models just replicate the previous day values. Some papers just conclude with having better RMSE (or some other metric) and don't even bother to acknowledge that their models mean shit when the goal was having a prediction model. Is their anyone out there who can share a decent implementation where there's some sort of trend prediction being done?",43,deeplearning,2020-10-13
iaw492,Huber loss vs MAE loss in DQN,"I am Implementing DQN on Space invaders environment. I have tried using Huber loss, MSE loss and MAE loss (Pytorch). I get maximum average reward (627) using MSE loss but the average loss is 48.61 at the end. Whereas, MAE and Huber loss gave the average reward around 500 but average loss was 1.22. 

Most of the resources suggest that Huber loss is used only with reward clipping and I have not clipped my rewards. 

Am I going wrong somewhere or the results given by the 3 loss functions are correct (specially the average loss value of 48.61)?",2,deeplearning,2020-10-13
iaw09m,A Supervised Approach to Extractive Summarisation of Scientific Papers | Research Paper Walkthrough,,2,deeplearning,2020-10-13
iau7s7,Difference between OpenCV &amp; Deep Learning,I am really getting confused regarding the difference :(,1,deeplearning,2020-10-13
iasyct,Why are EfficientNets not more popular?,"Pytorch and Tensorflow don't ship them by default(?) but from what I can gather they do a pretty good job accuracy-wise and use way less memory, so why are they not more popular than ResNets or SqueezeNets?",4,deeplearning,2020-10-13
iaruid,Freezing TensorFlow2 layers,"I have a LeNet-300-100 dense neural network for MNIST dataset where I want to freeze the first two layers having 300 and 100 hidden neurons in the first two hidden layers. I just want to train the output layer. The code I have to do this is as follows:

        from tensorflow import keras
        inner_model = keras.Sequential(
            [
                keras.Input(shape=(1024,)),
                keras.layers.Dense(300, activation=""relu"", kernel_initializer = tf.initializers.GlorotNormal()),
                keras.layers.Dense(100, activation=""relu"", kernel_initializer = tf.initializers.GlorotNormal()),
            ]
        )
        model_mnist = keras.Sequential(
            [keras.Input(shape=(1024,)), inner_model, keras.layers.Dense(10, activation=""softmax""),]
        )
        
        # model_mnist.trainable = True  # Freeze the outer model
        # Freeze the inner model-
        inner_model.trainable = False
        
        
        # Sanity check-
        inner_model.trainable, model_mnist.trainable
        # (False, True)
        
        # Compile NN-
        model_mnist.compile(
            loss=tf.keras.losses.categorical_crossentropy,
            # optimizer='adam',
            optimizer=tf.keras.optimizers.Adam(lr = 0.0012),
            metrics=['accuracy'])

However, this code doesn't seem to be freezing the first two hidden layers and they are also learning. What am I doing wrong?

&amp;#x200B;

Thanks!",1,deeplearning,2020-10-13
iaqukc,How is the job market for a computer vision engineer in Europe?,"I just graduated and signed my first contract, doing R&amp;D in computer vision for a company. It's great experience IMO, but I'm badly underpaid. I might have to move if I want that to change. I'm okay with most European countries.

How hard is it to find good entry-level deep learning R&amp;D jobs in Europe? Is a PhD a hard requirement for all the interesting positions? (I plan to do one, but only after getting on-the-job experience for some time.)

EDIT to clarify: I *am* European, and trying to get a picture of the opportunities and salaries abroad in this field. I'm mostly immune to visa and tax problems, as long as the destination country is in the European Union. I'm specifically interested in the state of the job market.",30,deeplearning,2020-10-13
iaqgiy,"Researchers use Separated Channel Attention Convolutional Neural Network (SC-CNN-Attention) to Identify ADHD in fMRI Dataset with 68.6% accuracy, higher than any modern model.",,5,deeplearning,2020-10-13
iaq9ku,"Batch Normalization, A different perspective from Quantized inference Model",,1,deeplearning,2020-10-13
iapaqp,What is AP medium value of YOLOv4 tiny Darknet?,I can't able to find it anywhere. The author has only shown for AP50.,0,deeplearning,2020-10-13
iame2m,StyleGAN implementation tutorial,"Hey guys! Do you know any website or place where there is a step by step code and explanation tutorial for styleGAN? I want to try to understand it but I want to study it by reading a code and explanation side by side. I would like to understand how this works and write my own implementation in the future.

 I understood DCGAN through this pytorch tutorial: [https://pytorch.org/tutorials/beginner/dcgan\_faces\_tutorial.html](https://pytorch.org/tutorials/beginner/dcgan_faces_tutorial.html)

. I only know pytorch so a pytorch tutorial would help.

Or even just a source code with comments of what is happening. Thank you very mcuh!

THank you very much!",5,deeplearning,2020-10-13
iaddbx,"From Adobe, Stanford, &amp; UWashington: A new framework can predict a full head portrait for ages 0-70 from a single photo, modifying both texture and shape of the head",,19,deeplearning,2020-10-13
iaa86c,REALM: Retrieval-Augmented Language Model Pre-training | Qpen Question Answering State-of-the-art,,0,deeplearning,2020-10-13
ia8fec,Survey on Loss for Heatmap Regression,"I am trying to work out which loss function is better for Heatmap regression, for face keypoint detection project. I am looking for losses that are compatible with other domains like Human pose estimation which also use heatmaps. 

I currently am using MSE as loss, and want to implement either Adaptive Wing loss, focal tversky loss or OHEM(online hard example mining) + MSE next. Which should I test first?",0,deeplearning,2020-10-13
ia806y,"FreezeG, a Face Generating Model by the GitHub user Bryandlee, Transfers Real Face Photographs Into Distinctive Cartoon Styles",,14,deeplearning,2020-10-13
ia7uge,StarGANS,"
I'm looking to implement this code: https://github.com/albertpumarola/GANimation

With a single animation (similar to: https://media.istockphoto.com/videos/beauty-fashion-woman-face-with-perfect-smile-closeup-of-beautiful-video-id1026603470)

The code will take any picture (containing a single face) as an input, and animate it within seconds. The result must be close to reality.

This can be implemented using stargans. Has anyone implemented this before. If yes, then please guide me!",0,deeplearning,2020-10-13
ia5m92,DataScience 1 year project idea," 

Hello Guys/Girls, I am currently in my final year in BSCS. We have to develop a project as our final year project. Our team members are interested in developing data science projects. We had an idea which was developing a model that intelligently give cloud resources to the developers that avail cloud services. But problem with this idea is that no company is ready to give us their cloud resources usage data(because of privacy issues) which is necessary for our model to train.

As the previous idea is not applicable, we are now in shortage of project ideas. Most project ideas we found on internet are toy projects which can be done in like a month or 2 weeks. Moreover, the projects on internet does not solve real life problems, or provide solution of already solved problems.

So, if you have any one year project ideas in the field of either data science or ML with dateset publicly available kindly share it.",0,deeplearning,2020-10-13
ia3sco,[R] Progressive Self Label Correction (ProSelfLC) for Robust Deep Learning,,1,deeplearning,2020-10-13
ia2zju,Advanced Speech Analytics for Better Customer Experience,,1,deeplearning,2020-10-13
ia0mz5,How to create a neural network that will generate variations of a 2d texture?,"Hello, I have some experience programming in Python and Javascript, I understand the basics of neural networks and how they work at a high level but I haven't done any project regarding deep learning algorithms.

I would like to be able to create multiple variations from a 2d texture image source.The source file would be something like this:[https://thumbs.dreamstime.com/b/white-marble-texture-background-design-white-marble-texture-background-marble-natural-patterned-design-110892783.jpg](https://thumbs.dreamstime.com/b/white-marble-texture-background-design-white-marble-texture-background-marble-natural-patterned-design-110892783.jpg)

Or any other texture could for example: Rock, wood, marble, metal, dirt, etc.

The idea is to get similar images but the patterns inside to be randomized in position size, etc.

Can anyone give me some guidance around where could I start and/or what should I start learning?

Many thanks!",3,deeplearning,2020-10-13
i9ynn8,[D] (Paper Overview) Informative Dropout for Robust Representation Learning: A Shape-bias Perspective,"**Video**

[https://youtu.be/GPHlRwyqVwo](https://youtu.be/GPHlRwyqVwo)

**Paper**

 [https://arxiv.org/abs/2008.04254](https://arxiv.org/abs/2008.04254) 

Code

 [https://github.com/bfshi/InfoDrop](https://github.com/bfshi/InfoDrop) 

**Abstract**

Convolutional Neural Networks (CNNs) are known to rely more on local texture rather than global shape when making decisions. Recent work also indicates a close relationship between CNN's texture-bias and its robustness against distribution shift, adversarial perturbation, random corruption, etc. In this work, we attempt at improving various kinds of robustness universally by alleviating CNN's texture bias. With inspiration from the human visual system, we propose a light-weight model-agnostic method, namely Informative Dropout (InfoDrop), to improve interpretability and reduce texture bias. Specifically, we discriminate texture from shape based on local self-information in an image, and adopt a Dropout-like algorithm to decorrelate the model output from the local texture. Through extensive experiments, we observe enhanced robustness under various scenarios (domain generalization, few-shot classification, image corruption, and adversarial perturbation). To the best of our knowledge, this work is one of the earliest attempts to improve different kinds of robustness in a unified model, shedding new light on the relationship between shape-bias and robustness, also on new approaches to trustworthy machine learning algorithms.",1,deeplearning,2020-10-13
i9xxvu,Trajectory Prediction using Deep Learning With Steering &amp; Speed Recommendation (part of my Master Thesis),,22,deeplearning,2020-10-13
i9tkix,What does non-euclidean data mean in machine learning?,I am studying about graph structures and learning from the structure data.  Then I found that people are saying ***graph structures are in non-euclidean space and the non-euclidean data***. I search it on the web but I did not find any satisfactory answer about non-euclidean data and why graphs are in a non-euclidean space. Can anyone please help me to understand the concept of non-euclidean data and why graphs are not in a euclidean space?,0,deeplearning,2020-10-13
i9soid,Deep Compression (Han et. al.) model size,"Hello, I was reading [Deep Compression (Han et al.)](https://arxiv.org/abs/1510.00149) research paper and came across Table-1 (mentioned on page 6) which is as follows:

&amp;#x200B;

[Table-1 \(Deep Compression paper\)](https://preview.redd.it/xxzjyg6ns0h51.png?width=702&amp;format=png&amp;auto=webp&amp;s=97f979d6801b1b97e9e05d6a24757d96032e2549)

&amp;#x200B;

My question is: If I am using TensorFlow-2.0 and Python3 (in Linux OS), how do I find out the size of ""Parameters"" which is the 3 column of this table? Because I need to implement this pipeline to see the compression working. And as of now, I don't know how to see the size of the parameters for a given model.

Help?",0,deeplearning,2020-10-13
i9oeug,[Tutorial] Neural Architecture Search: Using REINFORCE Gradient,"This tutorial covers how to use custom loss functions and the REINFORCE gradient for training in neural architecture search (full Python code included). Topics covered include training the generated models and logging metrics, preparing data for the controller, REINFORCE gradient, training the controller, and evaluating model metrics. 

Tutorial link: [https://blog.paperspace.com/neural-architecture-search-reinforce-gradient/](https://blog.paperspace.com/neural-architecture-search-reinforce-gradient/) 

This is part of a series covering end-to-end neural architecture search. The other parts cover [an overview of neural architecture search](https://blog.paperspace.com/overview-of-neural-architecture-search/) as a whole, designing the [search space, architecture design, and one-shot training](https://blog.paperspace.com/neural-architecture-search-one-shot-training/), and [building controllers and accuracy predictors](https://blog.paperspace.com/neural-architecture-search-controllers/).",1,deeplearning,2020-10-13
i9nbwb,Neural Light Transport for Relighting and View Synthesis,,0,deeplearning,2020-10-13
i9mzer,"80+ Jupyter Notebook tutorials on image classification, object detection and image segmentation",,18,deeplearning,2020-10-13
i9mlil,Accurate 3D Human Pose and Mesh Estimation from a Single RGB Image,,0,deeplearning,2020-10-13
i9m8s5,Transfer clothes between photos using AI,,72,deeplearning,2020-10-13
i9kx9b,3 Common Challenges That Deep Learning Faces In Medical Imaging,[https://analyticsindiamag.com/3-common-challenges-that-deep-learning-faces-in-medical-imaging/](https://analyticsindiamag.com/3-common-challenges-that-deep-learning-faces-in-medical-imaging/),0,deeplearning,2020-10-13
i9joun,[Question] How to use transfer learning for autoencoder based anomaly detection?,,0,deeplearning,2020-10-13
i9j96q,10 most popular activation functions. Advantages and Disdvantages of Activation Functions.,,0,deeplearning,2020-10-13
i9euj7,"Latest from Facebook researchers: Codec Avatars! A class of learned, photorealistic face models that accurately represent the geometry and texture of a person in 3D (i.e., for virtual reality), and are almost indistinguishable from video",,17,deeplearning,2020-10-13
i9ec3c,[P] RepNet CLI implementation,"Google Research and DeepMind released a very interesting Deep learning model called ""RepNet"". [https://sites.google.com/view/repnet](https://sites.google.com/view/repnet)

It counts any repetitive frequency on video. I was really fascinated when it got released because I've been working on a related topic, automatic workout recognition which workout consists of repetitive motion.

So I had a chance to do some code work and converted an official Colab Notebook code into a python command-line interface so that I can experiment easier. You can find this repository below link. I hope this helps those who interested in this topic!

[https://github.com/JeiKeiLim/repnet-cli](https://github.com/JeiKeiLim/repnet-cli)

P.S. My original goal was to convert this model into the TFJS model so I can make a website using it but unfortunately, TFJS does not support the 5-D operation where RepNet requires 5-dimensional input :/",0,deeplearning,2020-10-13
i96m40,NER for Document Digitization,"Full disclaimer: I work at nanonets.

The problem is quite simple to define. How do we automate (or make faster) the process of document Digitization with Deep Learning? We've explored quite a few techniques on this topic previously using CNNs, GCNs.

In this blog specifically, we look the effectiveness, caveats of using NER to tackle this problem.

[https://nanonets.com/blog/information-extraction-with-nlp-and-deep-learning/](https://nanonets.com/blog/information-extraction-with-nlp-and-deep-learning/)",0,deeplearning,2020-10-13
i95jmc,Deeplearning custom pc. Would love some suggestions as this will be my first custom build.(or should I wait for nvidia release?),,0,deeplearning,2020-10-13
i92bmh,"Must Read AI Papers As Suggested by Experts Pt 2 (Includes Jane Wang, Alexia Jolicoeur-Martineau and more)",,20,deeplearning,2020-10-13
i91gdy,"[D] NeurIPS Paper Reviews Released, Controversies Resurface","The NeurIPS 2020 paper reviews were sent out last Friday, starting the author response phase. While many researchers are pondering how to draft their rebuttals, others are decrying what they see as problematic or even “terrible” reviews. It’s that time of year, and controversies are again swirling around the prestigious machine learning conference’s review process.

Here is a quick read: [NeurIPS Paper Reviews Released, Controversies Resurface](https://syncedreview.com/2020/08/13/neurips-paper-reviews-released-controversies-resurface/)",14,deeplearning,2020-10-13
i90zbw,[Video Analysis] Well-Read Students Learn Better,https://youtu.be/yEhwRsuaPQs,0,deeplearning,2020-10-13
i8yxns,How to make DeepFake in 10 mins - Tutorial,,0,deeplearning,2020-10-13
i8yu2l,YOLO v3 TensorFlow Lite iOS GPU acceleration,,0,deeplearning,2020-10-13
i8wrdk,"Data Augmentation using Pre-trained Transformer Model (BERT, GPT2, etc) | Research Paper Walkthrough",,26,deeplearning,2020-10-13
i8vbnp,"From MIT, Google, UCSD researchers: Neural rendering--&gt;relight the scene photorealistically!",,0,deeplearning,2020-10-13
i8tlru,Machine Learning For Managers — What You Need To Know,Are you managing a tech team as a product/project manager? Here is what you need to know about machine learning. [https://medium.com/manishmshiva/machine-learning-for-managers-what-you-need-to-know-8cb9cf95c05b](https://medium.com/manishmshiva/machine-learning-for-managers-what-you-need-to-know-8cb9cf95c05b),0,deeplearning,2020-10-13
i8sai8,How do you feel if your colleagues think you have “basic” knowledge on ML/DL?,"Hey guys, recently i just joined a company as an intern and was perceived as someone having a “basic” knowledge on ML. I have worked in the research field for DL, published a paper, have done a lot stuff with ML for the past years and to be looked as someone who knows “basic” ML is insulting!

I’ve been getting this similar shitty response from my colleagues from these past few days. Idk if it’s because they don’t know me well or because they don’t know what I’m capable of doing. Even though I’m just an intern doesn’t mean i only know “basic” ML. Should I clarify things w my colleagues or should I swallow my pride and just move on. I know this post looks like I’m having an ego problem but having this kind of insult is not justifiable.",7,deeplearning,2020-10-13
i8naln,[R] How Smart is BERT? Evaluating the Language Model’s Commonsense Knowledge,"In the new paper *Does BERT Solve Commonsense Task via Commonsense Knowledge?*, a team of researchers from Westlake University, Fudan University and Microsoft Research Asia dive deep into the large language model to discover how it encodes the structured commonsense knowledge it leverages on downstream commonsense tasks.

Here is a quick read: [How Smart is BERT? Evaluating the Language Model’s Commonsense Knowledge](https://syncedreview.com/2020/08/12/how-smart-is-bert-evaluating-the-language-models-commonsense-knowledge/)

The paper *Does BERT Solve Commonsense Task via Commonsense Knowledge?* is on [arXiv](https://arxiv.org/pdf/2008.03945.pdf).",3,deeplearning,2020-10-13
i8mne1,Building a very basic Deep Neural Network to classify clothing items. (Fashion-MNIST) (great for beginners),,10,deeplearning,2020-10-13
i8kltq,Have anyone used Oracle GPU cloud servers?,"Hi everyone!
I'm training a TTS system using Nvidia's implementation of tacotron2 and Waveglow, however training times are huge! Around 6 days on a 8 Nvidia V100 AWS instance, so I'm looking for cheaper alternatives!
I stumbled across Oracle cloud GPU offerings and they sound too good to be true! Less than 3 USD/hour for the same 8 V100 config.
I'm afraid there must be some hidden costs or some other reason Oracle is giving so good prices
Have anyone used Oracle GPU servers before? Could you please share your experience with that?",1,deeplearning,2020-10-13
i8fkmi,How to calculate the total number of parameters w in CNN?,"I have been trying to solve the below question, but I couldn't get to the answer of it. Could this community help to understand how to calculate it?

&amp;#x200B;

&gt;Consider a CNN of 3 convolutional layers, each with 5 x 5 filters, a stride of 2, and SAME padding. The lowest layer outputs 50 feature maps, the middle one 150 and the top one 500. The input images are RGB images of 120 x 100 pixels. What is the total number of parameters w in the CNN?   
&gt;  
&gt;HINT: do not forget the biases.

Apparently, we need to use this formula, not sure how the above values goes in to get the correct answer

https://preview.redd.it/id8swfhv8lg51.png?width=517&amp;format=png&amp;auto=webp&amp;s=a49a9192d1db75d71b12ad144981e945edef9456

The correct answer for this question is 2066950",1,deeplearning,2020-10-13
i8fbdo,Lio - The Versatile Personal Assistant Robot Assist People in COVID-19 Times,,0,deeplearning,2020-10-13
i8f30q,object detection in a research paper,"I am doing research and I want to use the object detection in my paper but due to controversy is it good to cite the yolov5 or not.

 Please tell me what should I do?yolov5 medium model is taking less than 1 second for inference while yolov4 (checked ONNX and darknet) is taking 5-8 sec for inference on CPU which is not feasible for my research and I do not want to go for tiny version. Also using opencv dnn for yolov4 might also take 3-4 sec on CPU and I think that yolov4 is slow on CPU than the yolov3 due to the use of mish activation function.

 Please tell what should I do?

 any help is highly appreciated.",1,deeplearning,2020-10-13
i8afru,Workstations for Deep learning,"I need to procure five  workstations for my research lab, does any of you have any suggestions?Which GPU would be better a Nvidia Quadro or ti series, as well cpu core i7 or Xeon?We will use it for the training of small to medium scale (a few million learnable parameters) convnets, rnns etc.",26,deeplearning,2020-10-13
i88rm2,A curated list of egocentric and related area resources!,,2,deeplearning,2020-10-13
i88b7x,Game Bot,"I want to make or find a ai that learns by watching you or videos play any game and then it plays the game and learns. I do have a coding background but I am really confused about where I can find on or how I can make one. I have tried ardamavi/Game-Bot on GitHub but can't get it to work. Any help is appreciated, Thank You.",1,deeplearning,2020-10-13
i87e5i,Accurate 3D Human Pose and Mesh Estimation from a Single RGB Image!,,1,deeplearning,2020-10-13
i86y6v,How to start implementing papers,"Hi.

I believe that a very important skill for a Deep Learning Engineer is to know how to implement research papers in code.  I've found a video by ""Machine Learning with Phil"" where he implements a paper on Deep Q Learning but it seemed a little too advanced to follow.  How can I begin learning how to implement papers?  Or am I biting off too much?    


Thank you",6,deeplearning,2020-10-13
i7ymfb,FPN: Downsampling Notation,"I got a question concerning notation.

Presentation: [http://presentations.cocodataset.org/COCO17-Stuff-FAIR.pdf](http://presentations.cocodataset.org/COCO17-Stuff-FAIR.pdf)  
Slide: 11  


[Encoder of an FPN](https://preview.redd.it/jdrxw62dffg51.png?width=268&amp;format=png&amp;auto=webp&amp;s=17962d59c175492a0003f445275bbe3876457583)

&amp;#x200B;

The scale annotations of 1 and 1/4 make sense to me. Obviously, we start at full scale and after one pooling step, we have a scale of 1/4, because we downsized by a factor of 2 in both directions. But as far as I understand, following the same logic, at the next stage (i.e. after the next pooling), we should have a scale of 1/16. What am I missing?",1,deeplearning,2020-10-13
i7vq1r,We built an interactive learning tool to help people ace their machine learning and data science interviews,,67,deeplearning,2020-10-13
i7t1zo,Why do we reduce the learning rate on a plateau?,"Intuitively I feel, to escape a flat region learning rate should be increased.",1,deeplearning,2020-10-13
i7suj5,Facebook uses AI to create ultra-realistic visuals in varifocal headsets,,5,deeplearning,2020-10-13
i7sqxp,[Video Analysis] Easy Data Augmentation for Text Classification,[https://youtu.be/3w92peJtYNQ](https://youtu.be/3w92peJtYNQ),1,deeplearning,2020-10-13
i7s4qw,Mona Lisa’s eyes follow you as you move around the room,,1,deeplearning,2020-10-13
i7qfsp,Regarding Inter Class Confusion for a Classification Model,"I am considering 5 classes that is Sleep, yawn, neutral, Fear and Fatigue/Tired . I am using Alexnet model  for classification. we have collected around 10 k images for all classes except Fatigue class. Scraping method wasn't that successful with fatigue or tired keyword search as most of the images were sleep and yawn, which will cause inter class confusion to the model. I have seen drowsy detection datsets but did not find images which were much different from yawn or sleep. I did not come across much papers regarding fatigue etc. Is there any other way i can tackle this problem, that is collect Fatigue images without affecting sleep or yawn class. Any leads/ideas/datasets?? thank you.",1,deeplearning,2020-10-13
i7q4wl,"TransCoder from Facebook Reserchers translates code from a programming language to another. Check some examples at 3:10 in the video, or in the paper itself linked in the video description!",,16,deeplearning,2020-10-13
i7p5gr,[R]Dual In-painting Model for Unsupervised Gaze Correction and Animation in the Wild,,1,deeplearning,2020-10-13
i7o7jn,Study Group!!,"I've been studying and working on Deep Learning and Computer Vision for the last 3-4 months. Interested on the lines of Object Detection and Generative Modelling. Wanted to form a study group with people having similar interests so that we can learn together and get better at this. If you're up for it, send me a message! Cheers!",0,deeplearning,2020-10-13
i7nzvy,[R] Deep Learning for Deepfakes Creation and Detection: A Survey," **Abstract**—  This paper presents a survey of algorithms used to create deepfakes and, more importantly, methods proposed to detect deepfakes in the literature to date. We present extensive discussions on challenges, research trends, and directions related to deepfake technologies. 

By reviewing the background of deepfakes and state-of-the-art deepfake detection methods, this study provides a comprehensive overview of deepfake techniques and facilitates the development of new and more robust methods to deal with the increasingly challenging deepfakes. 

Get paper:  [https://arxiv.org/pdf/1909.11573v2.pdf](https://arxiv.org/pdf/1909.11573v2.pdf)",3,deeplearning,2020-10-13
i7nzvp,"Kornia v0.4: 3D augmentations, local features matching, homographies and epipolar geometry","https://preview.redd.it/3gxar7ha2cg51.png?width=960&amp;format=png&amp;auto=webp&amp;s=b33b2346b49505b6ad78de6aeec6ce8f7ab2daad

Today we are releasing a new version for Kornia that includes different functionalities to work with **3D augmentations** and **volumetric data**, **local features matching**, **homographies** and **epipolar geometry**.

In short, we list the following new features:

* Support to PyTorch v1.6.0.
* Local descriptors matching, homography and epipolar geometry API.
* 3D augmentations and low level API to work with volumetric data.

## Local features matching

We include an [kornia.feature.matching](https://kornia.readthedocs.io/en/latest/feature.html#matching) API to perform local descriptors matching such classical and derived version of the nearest neighbor (NN).

https://preview.redd.it/vlbgkkqm2cg51.png?width=594&amp;format=png&amp;auto=webp&amp;s=1ad28373cafc7eaf461505170067904b453fcf05

https://preview.redd.it/bbjfrufn2cg51.png?width=658&amp;format=png&amp;auto=webp&amp;s=2740426536c731ebb34e176c6102c3f9109ce75f

## Homography and epipolar geometry

We also introduce [kornia.geometry.homography](https://kornia.readthedocs.io/en/latest/geometry.homography.html) including different functionalities to work with homographies and differentiable estimators based on the DLT formulation and the iteratively-reweighted least squares (IRWLS).

https://preview.redd.it/a56wn7yn2cg51.png?width=1200&amp;format=png&amp;auto=webp&amp;s=d249cc1c62f60e4231200f95179ff59265be2bc1

https://preview.redd.it/uak2rvmo2cg51.png?width=657&amp;format=png&amp;auto=webp&amp;s=c1c87dc4cf63cc788bfe6a4c9e9c256982c87036

In addition, we have ported some of the existing algorithms from [opencv.sfm](https://docs.opencv.org/master/d8/d8c/group__sfm.html) to PyTorch under [kornia.geometry.epipolar](https://kornia.readthedocs.io/en/latest/geometry.epipolar.html) that includes different functionalities to work with **Fundamental**, **Essential** or **Projection** matrices, and **Triangulation** methods useful for Structure from Motion problems.

## 3D augmentations and volumetric

We expand the [kornia.augmentaion](https://kornia.readthedocs.io/en/latest/augmentation.html) with a series of operators to perform 3D augmentations for volumetric data.

https://i.redd.it/oj177lzo2cg51.gif

In this release, we include the following first set of geometric 3D augmentations methods:

* RandomDepthicalFlip3D (along depth axis)
* RandomVerticalFlip3D (along height axis)
* RandomHorizontalFlip3D (along width axis)
* RandomRotation3D
* RandomAffine3D

Finally, we introduce also a low level API to perform 4D features transformations [kornia.warp\_projective](https://kornia.readthedocs.io/en/latest/geometry.transform.html#kornia.geometry.transform.warp_projective) and extending the filtering operators to support 3D kernels [kornia.filter3D](https://kornia.readthedocs.io/en/latest/filters.html#kornia.filters.filter3D).

&amp;#x200B;

Happy coding day - **The Kornia team.**",0,deeplearning,2020-10-13
i7notd,Estimating Eigenvalues with neural Networks,I am interested in inverting a matrix by estimating an Inverse with a neural network. This should potentially be faster for very large matrices than inverting them deterministically. Also it is probably cheap to check if the Inverse is good enough or if the error by the network is too big. Maybe the way to go is also to estimate Eigenvalues of the matrix. Can someone point me to a paper that works with that idea?,15,deeplearning,2020-10-13
i7ll19,How To Implement LSTM RNN Network For Sentiment Analysis,[https://analyticsindiamag.com/how-to-implement-lstm-rnn-network-for-sentiment-analysis/](https://analyticsindiamag.com/how-to-implement-lstm-rnn-network-for-sentiment-analysis/),3,deeplearning,2020-10-13
i7l5xv,Why loss curve seems like stairs on CBOW model?,"After, I training a simple CBOW model with PTB dataset. The loss curve looks like have different step of each epoch.But, I have no idea to explain this.

https://preview.redd.it/qy37xr1snag51.png?width=386&amp;format=png&amp;auto=webp&amp;s=b89aa124649b91dc5c7347e5f814bd51cea50b75

Tell me what are your thoughts.   
Thanks for your answer.",1,deeplearning,2020-10-13
i7k3f0,Denoise old music recordings with neural networks,,3,deeplearning,2020-10-13
i77hld,Convolution Neural Network visualiser. I have developed a python package for interpreting and visualizing cnns.,"The link for to this project :- https://github.com/rshah240/conv_visualiser

Please give me more suggestions for improving this and if you're facing any issues please feel free to reach out to me.",40,deeplearning,2020-10-13
i7420u,[R] Free Deep Learning Resources,"Free Deep Learning Resources

Link:  [https://lme.tf.fau.de/teaching/free-deep-learning-resources/?fbclid=IwAR2d0NM7tFV-bVdG6cq7z2XbuymVFoVS9Dvq1mZfG5eOdVmhc8pNoQpc4kk](https://lme.tf.fau.de/teaching/free-deep-learning-resources/?fbclid=IwAR2d0NM7tFV-bVdG6cq7z2XbuymVFoVS9Dvq1mZfG5eOdVmhc8pNoQpc4kk)",1,deeplearning,2020-10-13
i72boz,Keras vs PyTorch vs Caffe - Comparing the Implementation of CNN,[https://analyticsindiamag.com/keras-vs-pytorch-vs-caffe-comparing-the-implementation-of-cnn/](https://analyticsindiamag.com/keras-vs-pytorch-vs-caffe-comparing-the-implementation-of-cnn/),0,deeplearning,2020-10-13
i70m45,Why horizontal flipping do not work in face landmark detection?,"I'm trying to implement face landmarks detection.... Completed successfully. But a weird situation I've faced there, when I apply random horizontal flip to the faces... The model is not learning... almost at all.

&amp;#x200B;

[Model without random horizontal flip... Everything works just fine...](https://preview.redd.it/dus93dxjp4g51.png?width=720&amp;format=png&amp;auto=webp&amp;s=e6eeff415db8e97267015c40e46227d2ca4fd31f)

&amp;#x200B;

&amp;#x200B;

[Not so much in case of random horizontal flipping](https://preview.redd.it/lgqsrh3op4g51.png?width=720&amp;format=png&amp;auto=webp&amp;s=080bab69ac9270ada75e86782ee43c9c201d7560)

&amp;#x200B;

I have no clear explanation why this is happening.

But I think, let's say I have one image of same person, and I've created two images from it, one is itself, and another one is its flipped version. So on training, the model will see these two images of same person, now even though one image is flipped... but the higher level features would sill be same (I guess) for same person, for example textures in hairs, nose, lips.. etc... But the landmarks key points would be totally mirrored, so the model will get confused, because most of the higher level features are same, but the labels are completely different, thus the model will collapse to the points where the loss is minimum for both of these images... which in return will set the parameters so that the landmarks predicted lies between both of the labels (one of original image, another one from mirrored image), and therefore we see a centered drawn landmarks... 

Tell me what are your thoughts.

Thanks for your time.",1,deeplearning,2020-10-13
i6zske,Understanding Maths and Intuition for Multivariate Gaussian Distribution | Machine Learning Fundamentals,,25,deeplearning,2020-10-13
i6xwkz,Step By Step Guide To Stabilize Facial Landmarks In A Video Using Dlib,[https://analyticsindiamag.com/step-by-step-guide-to-stabilize-facial-landmarks-in-a-video-using-dlib/](https://analyticsindiamag.com/step-by-step-guide-to-stabilize-facial-landmarks-in-a-video-using-dlib/),1,deeplearning,2020-10-13
i6u942,Note-taking tips while reading papers!,"Hi All,

I read a lot of papers but forget the content very quickly, I do try to make notes but those don't help at a later stage. Can someone suggest some tips for note-taking while reading papers? Or method that you use?

TIA",3,deeplearning,2020-10-13
i6pwll,[P] We built an easy way to find image datasets,"Hi r/deeplearning!

My team and I recently launched a website to search for datasets for your machine learning projects. We’ve all experienced the pain of searching for that perfect dataset. The world's datasets are scattered across academic websites and Github repos. That’s why we came up with Bifrost Data Search.

Bifrost Data Search is an initiative to aggregate, analyse and deliver the world's image datasets straight into the hands of AI developers. You can search from over 1000 listings paired with rich information and in-depth analyses. It’s **100% free** and we’re always adding more datasets and features.

This is just a beta release, and we’d love to hear your feedback so we can make this a valuable resource for the community! We're currently live on [https://www.producthunt.com/posts/bifrost-data-search](https://www.producthunt.com/posts/bifrost-data-search).

We really hope you like it!",28,deeplearning,2020-10-13
i6ourt,Research topic: Reinforcement learning or Computer Vision or NLP,"Hello, I am a first year of PHD student in machine learning. And I am currently facing a dilemma of choosing the PHD research topic. My professor's research focuses on three areas (reinforcement learning, computer vision-supervised learning and NLP ) that I can choose from. Which area should I go into? In terms of job prospect, which area will have more opportunities after PHD?

In terms of interest, I am equally interested in all. So I am more concerned about the job prospect.

It seems that reinforcement learning doesn't have as many application as CV and NLP and a lot more tech company hires people with CV or NLP background, is it correct? Only very few specialized company (deepmind, openAI, maybe best scenario google brain) hire people with reinforcement learning background, right?

Can anyone shed some light on this. 

Thanks.",2,deeplearning,2020-10-13
i6oo23,Otsu’s Thresholding with OpenCV,"One of the most common pre-processing techniques used in traditional computer vision is called image thresholding. It simplifies the image for easy analysis. For example, you may use it in medical image processing to reveal tumor in a mammogram or localize a natural disaster in satellite images.  


https://preview.redd.it/nqkrz7lzv0g51.png?width=576&amp;format=png&amp;auto=webp&amp;s=5e3f7ba52b229ee447c8e60fb2b322f08c45aeae

A problem with simple thresholding is that you have to manually specify the threshold value. That requires a lot of trial and error. A threshold that works with one image may not work with another image. So, we need a way to automatically determine the threshold.  


This is where Nobuyuki Otsu's creation aptly named as Otsu's technique helps us with auto thresholding. Let's look at the post for more details.  


[https://www.learnopencv.com/otsu-thresholding-with-opencv/](https://el2.convertkit-mail.com/c/38uvxqr24vskhvex6zip/n2hohquo4p04eq/aHR0cHM6Ly93d3cubGVhcm5vcGVuY3YuY29tL290c3UtdGhyZXNob2xkaW5nLXdpdGgtb3BlbmN2Lw==)  


and the code is at the link below.  
[https://github.com/spmallick/learnopencv/tree/master/otsu-method](https://github.com/spmallick/learnopencv/tree/master/otsu-method?ck_subscriber_id=371373457).",0,deeplearning,2020-10-13
i6mybu,Anyone who got selected for the AI summer school by Google research India?,"They asked us to review a paper and critic it. 
Wanted to know what I could have done differently.

Paper: [Understanding deep learning requires rethinking generalisation](https://arxiv.org/abs/1611.03530)",0,deeplearning,2020-10-13
i6md8e,"Tutorial On Keras CallBacks, ModelCheckpoint and EarlyStopping in Deep Learning",[https://analyticsindiamag.com/tutorial-on-keras-callbacks-modelcheckpoint-and-earlystopping-in-deep-learning/](https://analyticsindiamag.com/tutorial-on-keras-callbacks-modelcheckpoint-and-earlystopping-in-deep-learning/),1,deeplearning,2020-10-13
i6kvyn,[D] Spectral Norm Regularization for Improving the Generalizability of Deep Learning,,6,deeplearning,2020-10-13
i6iqqm,"Tutorial On Keras CallBacks, ModelCheckpoint and EarlyStopping in Deep Learning",[https://analyticsindiamag.com/tutorial-on-keras-callbacks-modelcheckpoint-and-earlystopping-in-deep-learning/](https://analyticsindiamag.com/tutorial-on-keras-callbacks-modelcheckpoint-and-earlystopping-in-deep-learning/),0,deeplearning,2020-10-13
i6i092,"This AI can cartoonize any picture or video you feed it! Tune in the video in caption at 3:08 to see more awesome examples using it, they passed in on The Avengers movie and the results are impressive!",,0,deeplearning,2020-10-13
i6h67f,DEEP learning models deployment in edge devices,,0,deeplearning,2020-10-13
i6fbjz,Metrics to Use to Evaluate Deep Learning Object Detectors,,2,deeplearning,2020-10-13
i6f64b,Abstractive summarisation of non-fiction books,,1,deeplearning,2020-10-13
i6ce1r,"Make easy edits to high-quality, diverse, and photorealistic images on real images and those generated by GANs!",,1,deeplearning,2020-10-13
i6cat6,PettingZoo- Gym for multi-agent reinforcement learning- just hit it's 1.0 release!,,6,deeplearning,2020-10-13
i637nv,Testing the demo of DeepFaceDrawing: Deep Generation of Face Images from Sketches,,32,deeplearning,2020-10-13
i5zkx8,"Hi deep learning enthusiasts, If you are interested in new research papers in AI, I am sharing those in form of short informative video on YouTube. I look forward for some feedback to improve, here's the most recent I published today as an example",,0,deeplearning,2020-10-13
i5yrsq,Learning community for Machine Learning and Deep Learning. Feel free join our Discord server!!,,1,deeplearning,2020-10-13
i5ygd8,Morphological Operations | Computer Vision | Post Processing | DeepEigen | Swaayatt Robots,,11,deeplearning,2020-10-13
i5xtcp,Collection of Most important/influential Deep Learning papers,"How can I find the most important or influential Deep Learning papers  in say 2020, 2019 etc. Is there some kind of collection?",3,deeplearning,2020-10-13
i5vheb,Best Math Courses for Machine Learning," 

Hi Folks,

As we know, the Knowledge of **Mathematics** is very important in order to understand how machine learning and its algorithms work?.

Without knowledge of **maths and statistics**, it’s difficult to understand the concepts of machine learning. So, if you want to learn or brush up your math skills, then read this article- [https://www.mltut.com/best-math-courses-for-machine-learning/](https://mltut.us18.list-manage.com/track/click?u=daed40bf0a68af806ccb51607&amp;id=092413957b&amp;e=3d7f03b9f8)

In this article, I have listed some **great online courses for math** that are enough for Machine Learning. I hope your search will end after reading this article.

All the Best!

Happy Learning!",0,deeplearning,2020-10-13
i5vebn,What’s your thought on this,,5,deeplearning,2020-10-13
i5v2lq,Deep learning target problems,"What are some current target benchmark problems that is focused by the community of researchers? The kinda problems that haven’t been solved effectively or there’s considerable research to better the solution in that direction. 

Examples in the past could be achieving best results in ImageNet in 2012, TIMIT speech recognition in 2005, AlphaGo  etc. 

Could someone help me link to these massive problems that are currently relevant?

(I am less than 6 months old in my exposure to neural networks)",1,deeplearning,2020-10-13
i5uyxx,Implementation of Translatotron: End to End Speech Translation,"Hello, I was reading this paper by Google on DIrect End to End Speech Translation. Is there any official/unofficial or any whatsoever implementation of paper available. If it is please share the link.",9,deeplearning,2020-10-13
i5tgyg,Project idea,"Hi everyone, I have a intel realsense depth camera and a jetson tx2. What deep learning and computer vision project can I do with these parts? 
Thank you :)",0,deeplearning,2020-10-13
i5tcm6,"Manipulate novel images in realistic ways, such as changing lighting effects and scene geometry!",,2,deeplearning,2020-10-13
i5mvqm,Question about a particular type of loss function,"I'm writing a classifier network, but rather than only having one correct category for the network to pick, each training example has a number of correct possible categories. However I only care that the network pick one of the correct categories. Could anyone suggest what loss function would be suited to my problem?

 I have been looking at multi-class cross entropy, but I'm not certain it does what I want. I have read that it requires a one-hot vector, whereas my system is an N-hot vector. Does this render multi-class cross entropy useless? How does it behave in such a situation?

Anyway, I'm grateful for any pointers or tips you might have.

Cheers

Matt",9,deeplearning,2020-10-13
i5mehf,[R] Eyes on Me: Google AI ‘MediaPipe Iris’ Improves Iris Tracking and Distance Estimation,"A team of Google AI researchers has proposed a solution to this problem with MediaPipe Iris, a novel machine learning model designed to deliver accurate iris estimation without using depth sensors. Experiments show the approach can measure the distance from the camera lens to the user with a relative error rate comparable to methods that do use depth sensors.

Here is a quick read: [Eyes on Me: Google AI ‘MediaPipe Iris’ Improves Iris Tracking and Distance Estimation](https://syncedreview.com/2020/08/07/eyes-on-me-google-ai-mediapipe-iris-improves-iris-tracking-and-distance-estimation/)

The MediaPipe Iris project page is on [GitHub](https://google.github.io/mediapipe/solutions/iris).",2,deeplearning,2020-10-13
i5jt85,Any open source papers on image Frame Extension?,"I’m looking for a network for image frame extension, as in using AI to extend image bounds and predict what’s outside the image. Cre8tiveAI has one but it’s been on “Coming soon” for awhile, without any paper on it.",0,deeplearning,2020-10-13
i5iz5s,[R] Pixel2Style2Pixel: Novel Encoder Architecture Boosts Facial Image-To-Image Translation,"In the recently published paper *Encoding in Style: a StyleGAN Encoder for Image-to-Image Translation,* researchers from Penta-AI and Tel-Aviv University introduce a generic image-to-image translation framework dubbed Pixel2Style2Pixel (pSp).

Here is a quick read:  [Pixel2Style2Pixel: Novel Encoder Architecture Boosts Facial Image-To-Image Translation](https://syncedreview.com/2020/08/07/pixel2style2pixel-novel-encoder-architecture-boosts-facial-image-to-image-translation/)

The paper *Encoding in Style: a StyleGAN Encoder for Image-to-Image Translation* is available on [arXiv](https://arxiv.org/pdf/2008.00951.pdf).",3,deeplearning,2020-10-13
i5h8yr,Open Sourced Deep Reinforcement Learning algorithms,"Hey all,

I've been working over the past months on some state of the art Deep Reinforcement Learning algorithms revolving policy value methods such as PPO, A3C, DDPG, TD3, REINFORCE, ARS, and genetic algorithms such as Evolutionary Strategies.

I've implemented them in single file jupyter notebooks as well as in simple out of the box implementation using terminal based on python implementation. 

I'd really appreciate it if you could check out the [repository](https://github.com/QasimWani/policy-value-methods) and give it a star on github. It really means a lot to me. 

If you find any errors, do raise issues in the repos, will promptly fix them :D

Cheers!",0,deeplearning,2020-10-13
i5dnp5,Free R Programming Language Tutorial For Beginners,,0,deeplearning,2020-10-13
i5cet1,Emojify - My first Project with Deep Learning,,1,deeplearning,2020-10-13
i5afih,Object Detection,"Hi

I am trying to build an object detection application. Currently, I am working on a module that detects walls. Say my dataset has two images against each entry. 

I also have a text file against each, (part of the example text file at the bottom of post) mentioning attributes in the image.

Can someone suggest me ways I could utilize this to help train my model?

&amp;#x200B;

Example text file's part:

001 # 0 # 0 # wall # wall # """"

002 # 0 # 0 # wall # wall # """"

003 # 0 # 0 # floor, flooring # floor # ""tile""

004 # 0 # 0 # ceiling # ceiling # """"

005 # 0 # 0 # windowpane, window # window # """"

006 # 0 # 1 # door # door # """"

007 # 0 # 0 # windowpane, window # window # """"

008 # 0 # 0 # windowpane, window # window # """"

009 # 0 # 1 # armchair # armchair # """"

010 # 0 # 0 # armchair # armchair # """"

011 # 0 # 0 # stool # stool # """"

012 # 0 # 1 # candlestick, candle holder # candle holder # """"

013 # 0 # 0 # candlestick, candle holder # candle holder # """"

014 # 0 # 0 # glass, drinking glass # glass # ""wine""

015 # 0 # 0 # glass, drinking glass # glass # ""wine""

016 # 0 # 0 # bottle # bottle # """"

017 # 0 # 0 # coffee table, cocktail table # coffee table # """"

&amp;#x200B;

and so on.",1,deeplearning,2020-10-13
i5af28,Humanoid robot arm,,2,deeplearning,2020-10-13
i5a8ep,"Jupyter notebook tutorial for ""Indoor house room type recognition""",,43,deeplearning,2020-10-13
i5989h,This Week in AI - Issue #29 | Rubik's Code,,2,deeplearning,2020-10-13
i56rh0,ICYMI: State of the art in image-to-image translation!,,2,deeplearning,2020-10-13
i54vwz,Gradient descent In a nutshell,"Check out this article about gradient descent
https://link.medium.com/9m0RFTWcK8",1,deeplearning,2020-10-13
i50f0b,BPDA for Adversarial Patches - what attacks to use?,,0,deeplearning,2020-10-13
i4z7in,[N] ArXiv’s 1.7M+ Research Papers Now Available on Kaggle,"To help make world’s largest free scientific paper repository even more accessible, arXiv [announced yesterday](https://twitter.com/arxiv/status/1291007439953973249) that all of its research papers are now available on Kaggle.

Here is a quick read: [ArXiv’s 1.7M+ Research Papers Now Available on Kaggle](https://syncedreview.com/2020/08/06/arxivs-1-7m-research-papers-now-available-on-kaggle/)",5,deeplearning,2020-10-13
i4y7ul,PyTorch to CoreML model conversion,"We have been receiving requests to write posts on creating mobile applications using the Deep Learning models that we train in PyTorch or Tensorflow. So, we decided to start a series on deploying deep learning models to mobile devices!  


In today's post, we provide step by step instructions for converting a model trained in PyTorch to CoreML - a format identified by Apple's devices.  
The good news is this post isn't strictly for Apple users because in the first part of the post you will learn how to convert a PyTorch model to ONNX format and perform the required checks to ensure that the conversion was correct!  


[https://www.learnopencv.com/pytorch-to-coreml-model-conversion/](https://www.learnopencv.com/pytorch-to-coreml-model-conversion/)

&amp;#x200B;

and the code is at

[https://github.com/spmallick/learnopencv/tree/master/PyTorch-to-CoreML-model-conversion](https://el2.convertkit-mail.com/c/n4ukn4827ktvhe9qk4t0/8ghqh3u589rd6l/aHR0cHM6Ly9naXRodWIuY29tL3NwbWFsbGljay9sZWFybm9wZW5jdi90cmVlL21hc3Rlci9QeVRvcmNoLXRvLUNvcmVNTC1tb2RlbC1jb252ZXJzaW9u)

https://preview.redd.it/994hgcwemff51.jpg?width=600&amp;format=pjpg&amp;auto=webp&amp;s=447a0476087c86e82a566e69c7274697fdf207c1",5,deeplearning,2020-10-13
i4xffp,ML Newsletter,"In TheSequence Edge#10 – it's all about Features: 

\-we explain the difference between feature extraction and feature selection; 

\-we explore a feature visualization method known as Activation Atlases;  

\- we review the HopsWorks, feature store platform; 

and offer you an easy quiz to check your knowledge

[https://thesequence.substack.com/p/-edge10-feature-extraction-and-the](https://thesequence.substack.com/p/-edge10-feature-extraction-and-the?r=1cmcl&amp;utm_campaign=post&amp;utm_medium=web&amp;utm_source=twitter)",0,deeplearning,2020-10-13
i4wbvc,Pan &amp; zoom through all of ImageNet,,22,deeplearning,2020-10-13
i4w005,GAN BERT: Generative Adversarial Learning for Robust Text Classification (Paper Explained),,0,deeplearning,2020-10-13
i4vh5c,"How does YOLO object detection work and How can you use it to make your own custom object detection Model? Also, see its simple implementation in OpenCV. You can also find a Keras Implementation of YOLO linked in the article.",,4,deeplearning,2020-10-13
i4vgsr,Step-by-Step Building Block For Machine Learning Models,[https://analyticsindiamag.com/step-by-step-building-block-for-machine-learning-models/](https://analyticsindiamag.com/step-by-step-building-block-for-machine-learning-models/),0,deeplearning,2020-10-13
i4vdfv,In-depth tutorials on TensorFlow," hello I am really a beginner in TensorFlow, and I have a hard time to understand how computational graph works, so I made many mistakes while writing code, so can you suggest online tutorials or any resources that you think would be enough to really understand TensorFlow and also would help me to write code fluently(like people write python code)",7,deeplearning,2020-10-13
i4v955,A 2020 guide to Semantic Segmentation," Semantic segmentation is the task of classifying images on a pixel level 📷.

It has multiple use-cases in self-driving cars 🚓, medicine 🏥, makeup tools and photography etc.

In this article, I cover various techniques which can be used to implement semantic segmentation for images, videos, point clouds and also cover loss functions, metrics, datasets and annotation tools involved

[https://nanonets.com/blog/semantic-image-segmentation-2020/](https://nanonets.com/blog/semantic-image-segmentation-2020/)",1,deeplearning,2020-10-13
i4v2mh,[Q] Should I build my own DL rig or keep using a low to mid-range laptop(which are easily portable and not heavy gaming ones) or rely on cloud GPU storage providers?,"The laptop which I am using is an i5 processor with a 940MX graphics card. But It is getting harder and harder when I am training more and more models while learning and exploring. I also do gaming, video/photo editing on my laptop. And after completing my UG within a year, I'll get more free time to explore more and train more models from scratch.

So, could you please help me in deciding -

Whether I should buy a new heavily GPU enabled gaming laptop or rely on cloud GPU services?

Also, Should I build my own DL rig or keep using a low to mid-range laptop(which are easily portable and not heavy gaming ones) and rely on cloud GPU storage providers?

Thankyou",0,deeplearning,2020-10-13
i4sdk5,Don't regarding text classifications with metatags,"Can anyone let me know how can I build a classifier model that takes in sentences and few categorical tags and outputs a class?

P.S. I meant doubt",0,deeplearning,2020-10-13
i4r168,Project Fabula: finding video-fragment or person in a pile of video files,,0,deeplearning,2020-10-13
i4p7lo,"Despite The Breakthroughs, Why NLP Suffers From The Issue Of Underrepresented Languages",[https://analyticsindiamag.com/despite-the-breakthroughs-why-nlp-has-underrepresented-languages/](https://analyticsindiamag.com/despite-the-breakthroughs-why-nlp-has-underrepresented-languages/),0,deeplearning,2020-10-13
i4oy8o,Using Grad-CAM to Visually Verify the Performance of CNN Model,[https://analyticsindiamag.com/using-grad-cam-to-visually-verify-the-performance-of-cnn-model/](https://analyticsindiamag.com/using-grad-cam-to-visually-verify-the-performance-of-cnn-model/),1,deeplearning,2020-10-13
i4oo1c,Learn Deep Learning online with these 10 best deep learning courses,The best [Deep Learning courses](https://blog.coursesity.com/best-deep-learning-courses?utm_source=reddit&amp;utm_medium=social&amp;utm_campaign=redditPost&amp;utm_term=best-deep-learning) online &amp;  Tutorials to Learn Deep Learning courses for beginners to advanced level,1,deeplearning,2020-10-13
i4o8t0,Representation for MIMO Time Series ML's,"Hello, I am in need of some help. Does anyone have a link or resources or general advice on what tensor structure to use for time series machines (LSTM, RNN, etc) that deal with multi dimensional inputs and output. I.E: I got a \[t-5..t\] of data where t has 6 dimension and I want to predict t+1 also with 6 dimensions.

Additionally how does one cope with predictions with data on various sample scales. For instance I would like the macro series (trend) to inform the micro series.

I can't seem to find too much on this. Any help would be great.",1,deeplearning,2020-10-13
i4kxxk,What should I work on for a one month long DL project?,"Hi,

Pretty soon, I will have some months off in between jobs. I am planning to spend 1 month to form a team of 3-4 to do a DL project. What would be some good ideas that you think are well scoped for 1 month?

Here are a couple things that I hope that an ideal project should have:

1. Ideally there should be benchmarks and baselines that I look up.  
2. Ideally the dataset is readily available as well.
3. Ideally with some open ended components.
4. One project for members of 3-4 that fits for one month.

In particular, I am not interested in Kaggle or any other competition because I'd like the exploration to be unconstrained rather than particularly beating a metric or being goal heavy.

&amp;#x200B;

I do have some years of experience doing ML. Any idea is appreciative!",13,deeplearning,2020-10-13
i4koiq,[R] Hopfield Networks is All You Need,,7,deeplearning,2020-10-13
i4d189,"Facial Emotion dataset, for SPAFF classification?",I know of the \[Child Affective Facial Expression (CAFE) dataset\]([https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4285011/](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4285011/)). Any others? labeled?,1,deeplearning,2020-10-13
i4b12b,Need help with visualizing pyramidNet in pytorch/tensorflow?,"Hi, I trying to come up with a network based off pyramidNet for my project. I want to visualize the network so that I can understand it better. The [github repo](https://github.com/dyhan0920/PyramidNet-PyTorch) has hosted pytorch code and I've tried it via some [tutorials](https://pytorch.org/tutorials/intermediate/tensorboard_tutorial.html) on pytorch website. But it just outputs a blank image. So if you can provide me any suggestions, please do so.

Other way would be to use [tf2cv](https://pypi.org/project/tf2cv/), which provides pre-written networks, but I have no idea how to use them in tensorflow. I've tried the given example in gist but that just outputs an image with ""model"" written in it. I tried to save the image of the model using \`keras.utils.plot\_model()\` function.",2,deeplearning,2020-10-13
i49zqz,[N] YogaDL: a better approach to data loading for deep learning models,"[YogaDL](https://determined.ai/blog/yogadl-announcement/) is a new approach to data loading for deep learning models. It is essentially a caching layer that wraps your existing data loading code and provides random access to the data set in a high-performance way, which enables efficient data shuffling, sharding, and checkpoint/restart. We were inspired to build Yoga in part by the [challenges we encountered using tf.data](https://determined.ai/blog/tf-dataset-the-bad-parts/) to accomplish similar tasks.

YogaDL currently supports tf.data as an input API, and supports caching data sets on local storage, AWS, and GCS. Support for more input APIs and more storage types is on the roadmap. YogaDL is open source under the Apache 2.0 license. YogaDL is brought to you by the same team that is building the [Determined](https://github.com/determined-ai/determined) deep learning training platform, but it can be used outside of Determined.

For more, check out the [announcement blog post](https://determined.ai/blog/yogadl-announcement/), the [documentation](https://yogadl.readthedocs.io/en/latest/yogadl.html), or [GitHub](https://github.com/determined-ai/yogadl).",9,deeplearning,2020-10-13
i454t1,[D] Help Needed for performing Joint training of 2 models one which does Sentence Classification and other which does NER.,"Hey, Everyone on this subreddit, I have a problem where the task is, given an input sentence classify whether it comes from class\_0 or class\_1. If it comes from class\_1 then perform NER on the sentence if class\_0 then do nothing simply discard. 

class\_0 -&gt; data point which contains plain English sentence

class\_1 -&gt; Domain-specific small sentence with (50-80) characters within it.

I have solved this in two steps were the first model performs sentence classification, this step is easy because data in both the 2 classes are very different with a little overlap. 

In the second step, I trained a NER model from scratch on the Domain-specific sentence (can't use a pre-trained model one because the domain-data is very different from Normal English data on which various models(like Bert, ELMO) are trained)

Now what I want is how can I build a single model which can solve this using 1 model rather than 2 models.

so for the example given an input sentence, I pass the entire sentence as a character inputs to the model and the model does the classification whether class\_0 or class\_1, if class\_1 then performs NER.   


I know that for a single model to perform this I have to do a joint training and backpropagate by summing the loss of both the task but I am confused with the class\_0 as with class\_0 there is no NER thing it has to be simply discarded. Also, I am confused about the approach, whether I should solve this using 2 models or a single model.",0,deeplearning,2020-10-13
i43ztf,Intro to transfer learning,"I have come across this amazing blog on Transfer Learning for Deep Learning which talks about the working of Pre-Trained models such as BERT. 

https://www.theaisorcery.com/post/transfer-learning-for-deep-learning-pre-trained-models-to-save-training-time-and-cost",0,deeplearning,2020-10-13
i437pt,image-GPT from OpenAI can generate the pixels of half of a picture from nothing using a NLP model,,93,deeplearning,2020-10-13
i422xg,"Hey y'all, I need some help with my undergrad project. (Deep Learning /Neural Networking)",So for my project I was tasked with coming up with a way to visualize a basic Neural Network structure with basically cups and siphons. What are some ideas I could visualize the way a neural network works with flowing water between cups or containers to come to an end point? I honestly don't know if this is possible and really could use some help! Also some examples of a basic NN structure and how they work would also be helpful!,0,deeplearning,2020-10-13
i416za,Basic neural network structure,"1. Could the number of neurons be greater or smaller than the number of input features. If so, can the number of neurons present in each hidden layer vary?
2. Does each neuron in the hidden layer receive all the features as input or else random features are passed to each neuron?",3,deeplearning,2020-10-13
i3ycrz,An Introductory Reinforcement Learning Event Tmr,"Posting for my company...The event is free/online...The speaker is legit (company's co-founder). He's a real scholar in the field and he actually teaches RL courses at Columbia. You might need to get used to his accent tho...

Anyways, thx for letting me post this.

RSVP: [https://www.eventbrite.com/e/reinforcement-learning-explained-overview-and-applications-tickets-113849695504?aff=r](https://www.eventbrite.com/e/reinforcement-learning-explained-overview-and-applications-tickets-113849695504?aff=r)",0,deeplearning,2020-10-13
i3uup1,#FreeTheData - a tee I made to help us towards building a better AI,,0,deeplearning,2020-10-13
i3s7z0,Meta-learners’ learning dynamics are unlike learners’, [https://arxiv.org/pdf/1905.01320.pdf](https://arxiv.org/pdf/1905.01320.pdf),1,deeplearning,2020-10-13
i3psrc,Test-First Machine Learning,,1,deeplearning,2020-10-13
i3nk7j,"How Data Augmentation Impacts Performance Of Image Classification, With Codes",[https://analyticsindiamag.com/image-data-augmentation-impacts-performance-of-image-classification-with-codes/](https://analyticsindiamag.com/image-data-augmentation-impacts-performance-of-image-classification-with-codes/),4,deeplearning,2020-10-13
i3muc4,Pushing CIFAR10 SOTA with ResNets,"The goal of this project is to first replicate the ResNet SOTA results on CIFAR10 and use several recently published *updates* to push this state of the art as high as possible. Using such updates, I was able to achieve an error rate of **6.90%** on the CIFAR10 test set, using a **20-layer** ResNet that consists of mere **0.27M parameters**. For comparison, the original ResNet20 had an error rate of **8.75%**. The performance of this 20-layer model is comparable with that of the original ResNet56 which was reported to have an error rate of **6.97%**. 

&amp;#x200B;

|MODEL|TEST LOSS|TEST ACC|
|:-|:-|:-|
|ResNet20|8.75|91.25|
|SE-MXResNet20|**6.90**|**93.10**|

For full source code and project details, visit [this](https://github.com/iamVarunAnand/image_classification) link",2,deeplearning,2020-10-13
i3kxu1,Pre-training Is (Almost) All You Need: An Application to Commonsense Reasoning (Paper Explained),[https://youtu.be/Ijrdm0Nb\_k0](https://youtu.be/Ijrdm0Nb_k0),3,deeplearning,2020-10-13
i3khmu,Multiple losses ad inputs with tensorflow,I want to discuss a issue I am having with coding multiple loss in tensorflow version 1.x. The problem is that I have have trained a decoder network separately. The model then first takes in a encoded sequence and produces a future step which we calculate the loss on say loss one. Then I would like to pass this self.output obtained to my decoder model and find the loss on that too and incorporate it into my optimization too. Any suggestions?,0,deeplearning,2020-10-13
i3kci3,[R] - Deep Video Portraits - Photo-realistic re-animation of portrait videos using only an input video,,2,deeplearning,2020-10-13
i3kb0e,"What should be the Query Q, Key K, and Value V vectors/matrics in torch.nn.MultiheadAttention?","Following an amazing [blog](https://jalammar.github.io/illustrated-transformer/), I implemented my own self-attention module. However, I found PyTorch has already implemented a multi-head attention [module](https://pytorch.org/docs/master/_modules/torch/nn/modules/activation.html#MultiheadAttention). The input to the forward pass of the MultiheadAttention module includes Q (which is query vector), K (key vector), and V (value vector). It is strange that PyTorch wouldn't just take the input embedding and compute the Q, K, V vectors on the inside. In the self-attention module that I implemented, I compute this Q, K, V vectors from the input embeddings multiplied by the Q, K, V weights. At this point, I am not sure what the Q, K, and V vector inputs that the MultiheadAttention module requires. Should they be Q, K, and V weights or vectors and should these be normal vectors, or should these be Parameters?

Original question [here](https://stackoverflow.com/questions/63248948/what-should-be-the-query-q-key-k-and-value-v-vectors-matrics-in-torch-nn-multih).",1,deeplearning,2020-10-13
i3k59w,[Video Analysis] Contrastive Learning for Unpaired Image-to-Image Translation,[https://youtu.be/i7U646IiQOw](https://youtu.be/i7U646IiQOw),1,deeplearning,2020-10-13
i3jtic,Looking someone for image annotation task.,Looking someone with experience in labelling 10k semantic segmentation images. It is relatively simple. Please dm me to discuss details.,1,deeplearning,2020-10-13
i3ill5,Semantic Segmentation with a small dataset.,"I need advice on how to start semantic segmentation on a small dataset (around 1500 images) and get competitive results. 
I have done some research on the latest architectures in Semantic Segmentation and everything is done on a quiet large dataset.",1,deeplearning,2020-10-13
i3i1a5,What questions should I ask myself when I'm reading papers from fields of computer vision and robotics?,I'm working on autonomous drones and I was wondering if I could get a list of questions which researchers use to gain a good understanding of the paper?,3,deeplearning,2020-10-13
i3hs9f,Introduction to Anomaly Detection with a Convolutional Auto-Encoder on Time Series transformed into Images,,101,deeplearning,2020-10-13
i3en88,Top 15 AI Articles You Should Read This Month - July 2020,,0,deeplearning,2020-10-13
i3cy5b,I want to create a model that can detect signs of depression from social media posts. Is there any publically available dataset related to it?,,1,deeplearning,2020-10-13
i3c2vy,"Infer spatial arrangements and shapes of humans and objects from a 2-D image: Latest from Facebook, Berkeley, Carnegie Mellon, and Argo researchers:",,2,deeplearning,2020-10-13
i3agkp,signal/noise ratio,,254,deeplearning,2020-10-13
i36vqu,ML Newsletter to keep you up to date,"I'd like to introduce you to a new ML newsletter focused on practical ML things: impactful research papers, relevant frameworks to work with, important investments.  
**In recent TheSequence Scope we've covered:**  
\-Understanding the Success of Deep Learning  
\-Learning Poker from Scratch  
\-TF-Coder Robot face  
\-Model Card Toolkit for model transparency  
\-Introducing ScaNN  
\-PyTorch for Windows  
and a few investments in AI startups and companies.

**Please consider to subscribe and I will be thrilled to receive your feedback!**

Sunday free edition:   
[https://thesequence.substack.com/p/thesequence-scope-can-machine-learning](https://thesequence.substack.com/p/thesequence-scope-can-machine-learning)",1,deeplearning,2020-10-13
jagizr,Female Pioneers in Computer Science You May Not Know - Part 2,,1,deeplearning,2020-10-13
jafhtj,Calculate Optimum / Best Batch Size?,"Batch sizes are supposed to be proportional to the GPU/TPU memory size.

Experts recommend that we keep them as powers of 2. So, 8, 16, 32, etc.

There are useful [threads](https://stackoverflow.com/questions/46654424/how-to-calculate-optimal-batch-size) with partial answers,

&gt;*Max batch size= available GPU memory bytes / 4 / (size of tensors + trainable parameters)*

but I could not find a full calculation of how to get the perfect value for a given input image resolution.

&amp;#x200B;

Say, we have a colab TPU with RAM of 8 GB.

And we are training MNIST on it, with a ResNet50 model.

MNIST has 60,000 images of size 128x128.

Then how to estimate the optimum batch size?

Please show every step of the calculation.

&amp;#x200B;

Also, lets break it down into sub problems:

If we take the Keras ResNet50 model, how much memory does it occupy on the GPU/TPU? I guess this has to do with 16, 32 and 64 bit integer and float data types of the tensor.

What other things in the program take up considerable memory on the TPU?

&amp;#x200B;

Thanks in advance!",1,deeplearning,2020-10-13
jacdk8,PC and GPU recommendations,"I'm looking forward to buying a new PC to run my deep learning models. I´m relatively new to deep learning, so I don´t know which specific atributes I need to analyze for my PC. I'm asking for recommendatios for a specific PC or to which things I need to look into when deciding which PC I´m buying. I also want to buy a NVIDIA GPU, so recommendations for which one I should buy are also welcome.",0,deeplearning,2020-10-13
jacbs8,Mura Dataset,"Hello guys, how're you?
Guys I downloaded a dataset of bone fractures to build a CNN to classify if has or no fractures.
I downloaded a zip file with the images dataset and I can't put it in a variable to build a CNN, could you guys help me please?",1,deeplearning,2020-10-13
jabsdc,What layers to use for one hot encoded vectors,"Hello all, 
I have a dataset which contain sentences and context and other metadata related to  it. The metadata has to be one hot encoded. I was wondering is there any way we can include one hot encoded vectors in a deep learning model. Are there any special layers for it ?",1,deeplearning,2020-10-13
jaaza1,How do I gain confidence while coding models ?,"I am quite familiar with the theory and understand it well. Although I have been facing difficulties while building and coding the model. How can I get better at it ? I have been practicing by building models, but I usually get stuck at points in between.",1,deeplearning,2020-10-13
jaaeoo,Is any problem in the Cuda configuration in Nvidia GPU with an AMD CPU?,"

[View Poll](https://www.reddit.com/poll/jaaeoo)",0,deeplearning,2020-10-13
jaa1au,How to extract data from forms using deep learning,Time-consuming manual data entry of digitized forms is a bottleneck in numerous internal processes of any insurer. We wrote a blog to help you automate this step for a popular type of form - ACORD. Hope it's helpful! Link: [https://nanonets.com/blog/ocr-extract-data-from-acord-forms/](https://nanonets.com/blog/ocr-extract-data-from-acord-forms/),1,deeplearning,2020-10-13
ja91e2,Recruiting GPU Container Tester in goormIDE (https://ide.goorm.io),"Hi Everyone!

&amp;#x200B;

We provide Cloud IDE Service called goormIDE ([https://ide.goorm.io](https://ide.goorm.io)) like AWS Cloud9.

Free plan? Of course we provide.

&amp;#x200B;

This time, the GPU container support has been opened in goormIDE, but testers are being recruited because the actual performance and usability needs to be verified before opening as a paid model.

&amp;#x200B;

To those who have been selected as testers, we plan to deliver a GPU container with an NVIDIA Tesla V100 model connected to it free for two weeks and receive reviews. If you are interested in testing GPU containers, please go to [https://goor.me/gEuwP](https://goor.me/gEuwP) and apply!

&amp;#x200B;

The more detailed the purpose of use, the more likely it is to be selected, so please refer to this point :)

We ask for your interest!

Thank you!",0,deeplearning,2020-10-13
ja5sct,Understanding Deep Learning Theory Papers,"Could you recommend a good textbook or source that will help engineering majors (like me) understand deep learning theory papers?

I know somewhat about Bayesian inference, MLE/MAP, basics of Monte Carglo estimation of expectation, that we are trying to learn “good” representations, and also multivariate calculus.

Yet, when I meet terms such as point estimates, Lipschitz smoothness, universality, or Riemann manifolds, I need to consult Wikipedia, which often talks such gibberish that I am left thinking “I’d rather study a textbook than crawl through this”.

Thanks!",47,deeplearning,2020-10-13
ja1e1e,Let's say the circle nodes were empty. Does anyone know how to calculate the state value function for each node?,,17,deeplearning,2020-10-13
ja0ka0,Pytorch vs Tensorflow for freelancing in the future?,"I would like to dive in to deep learning for future freelancing projects, what would be the best bet for the future in work, pytorch or tensorflow? :)",0,deeplearning,2020-10-13
j9ysy8,HPC in the Cloud - Python Package Management - Thursday Evening Livestream,,1,deeplearning,2020-10-13
j9tf3x,Dealing with the Concept Drift. State of practice.,"For ML applications it comes difficult to manage some special kind of changes, that we call concept drift or covariate shift or data drift.

These can be detrimental to your model performance in prod as **most concept drift related methods are very subjective to the nature of the problem.**

So, how to prevent concept drift?

There are various strategies, including:

* Online learning
* Model re-training
* Re-sampling using instance selection
* Ensemble learning with model weighting
* Feature dropping

However, my question is – have you found any methods you personally use that might not be ""conventional"" but they work?

We dive deep into the topic in [this article](https://neptune.ai/blog/concept-drift-best-practices?utm_source=reddit&amp;utm_medium=post&amp;utm_campaign=blog-concept-drift-best-practices).",2,deeplearning,2020-10-13
j9taxk,Multi-View Transfer Learning,"Hello folks, need a little help.

I am working on a multi-view image classification problem. I have a small dataset of two classes with each class having 208 and 220 images respectively in the training set and 48 and 52 images in the validation set respectively. Each class has two images of the same object so it effectively reduces the number to 104 and 110 images effectively for each class. I can not train a full CNN on this. 

So, can anyone help me to figure out how can I use transfer learning to accomplish this task? Any good resources or advice will be very helpful.",1,deeplearning,2020-10-13
j9t5l6,Choosing between big cnn for object detection or smaller piped with image classification,"Hello everybody!  
 I'm pretty new to the field of deep learning and I'm working at a project involving a smart traffic assistance.  
 The first task involves object detection and recognition.  
 Objects can be divided in three main classes as follows: traffic lights,  traffic signs and other traffic participants (vehicles).

I have two possible approaches: 

* train a big dataset that contains every subclass element like: stop  sign, red traffic light left, truck, bike, and every other traffic  light/traffic sign from the data bases.
* train a smaller dataset capable of recognising fewer classes, crop the recognised element and then use a classifier.

Why I would use the second approach:

&amp;#x200B;

1. I have a uniform dataset containing all the main classes.
2. I have different number of samples in each dataset, different format and annotations.
3. There are some subclasses with small representation thus is harder to train object detection than classification.

Why I wouldn't use it:

&amp;#x200B;

1. It has to run real time ( I guess this approach would be more computational demanding ?).

What would you choose?  
 Thanks!",1,deeplearning,2020-10-13
j9r82n,An Image is Worth 16x16 Words:Transformers for Image Recognition at Scale (Paper Explained),,25,deeplearning,2020-10-13
j9r6jk,"[Article] Evaluating Deep Learning Models: The Confusion Matrix, Accuracy, Precision, and Recall","This article gives an intuitive and thorough explanation of deep learning metrics like accuracy, precision, recall, and the confusion matrix. Topics covered include the confusion matrix for binary and multi-class classification; how to calculate the confusion matrix with Scikit-learn; a discussion of accuracy, precision, and recall; and when to use either precision or recall. 

Article link: [https://blog.paperspace.com/deep-learning-metrics-precision-recall-accuracy/](https://blog.paperspace.com/deep-learning-metrics-precision-recall-accuracy/)",2,deeplearning,2020-10-13
j9pvnr,The `Hello World` of Deep Learning in fastai,,5,deeplearning,2020-10-13
j9pgn3,How To Use DeepCognition To Build Drag And Drop Deep Learning Models Without Coding?,,1,deeplearning,2020-10-13
j9o3f2,GPT3 inference,"Hi.

Does anybody knows or have there been a paper done on how GPT3 inference works.

I mean one can view GPT3 as very high dimensional auto-regressive model. I am curious if it is soo good because it has seen insane amount of data and have capacitibility to just remember everything, or it can actually infer (understand) input data. Understand is not the proper word, i hope you know what I mean... Does it like for example calculate some statistics of the inputs (very simply put) and then based on them return the output or its like, ha i ve seen this already, this is what follows...? 

I hope i express my question articulately enough, english is not my first language..",0,deeplearning,2020-10-13
j9mgs3,Back to Machine Learning Basics - Regularization,,2,deeplearning,2020-10-13
j9lfwd,Download Project Management Solutions,,0,deeplearning,2020-10-13
j9jvgl,Need Ideas For NLP based Machine Learning or Deep Learning Projects,"Actually, I am an NLP enthusiast. I was looking for some project ideas regarding NLP Based on either Machine learning or deep learning. Can someone give any ideas regarding Such Projects, or and new NLP based Module Launched recently for making interesting projects or What websites or resources you would suggest that you personally prefer for making NLP based Projects?  


Interested Developers and NLP Enthusiasts, we can even collab to discuss and work together on amazing NLP projects",1,deeplearning,2020-10-13
j9iwqz,Activation Function And Loss Function,"Hi,

Is there any one to one correspondece between activation function in the last layer and the loss function? For example using softmax with categorical\_crossentropy.

Thanks",10,deeplearning,2020-10-13
j9ivsw,Interview with Tim Dettmers: Which RTX 3000 GPU(s) to get for Deep Learning?,"Hi Everyone! 

I run a non-monetised, Ad-free interview series as a service to the ML Community where I interview my ML Heroes. 

I had interviewed Tim Dettmers about his GPU advice now that the 3000 series is released:

[Audio](https://anchor.fm/chaitimedatascience/episodes/Tim-Dettmers-Which-RTX-3000-GPU-to-get-for-DL--3090-FAQ--CTDS-Show-108-ekeue8), [Video](https://www.youtube.com/watch?v=CaoQLrSBk0o)

I hope you find this useful and if you've any feedback for me, or guest suggestions, I'd be very grateful. Thanks!",33,deeplearning,2020-10-13
j9hbho,Create new features from hierarchical clustering,"Is it normal to generate a new type of ""group"" feature on the training data by applying hierarchical clustering, to then use it as a feature in a deep learning model ?",1,deeplearning,2020-10-13
j9bi9v,Unpooling function keras," Hi everybody!

I  start by saying that I'm kinda new to deep learning. I'm trying to  write a segnet in keras that uses pooling indices to upsample. I'm using  this function with a Lambda Layer to perform a max pooling and save  pooling indices:

    def pool_argmax2D(x, pool_size=(2,2), strides=(2,2)):
        padding = 'SAME'
        pool_size = [1, pool_size[0], pool_size[1], 1]          
        strides = [1, strides[0], strides[1], 1]          
        ksize = [1, pool_size[0], pool_size[1], 1]          
        output, argmax = tf.nn.max_pool_with_argmax(                  
            x,                  
            ksize = ksize,                  
            strides = strides,                  
            padding = padding          
        )           
        return [output, argmax] 

It seems working. In my model summary it returns a tensor of shape **(None, h/2, w/2, channels)**. However I'm having some issues to find or write a working unpooling function. I'm unable to return a tensor of shape **(None, 2h,2w, channels)** (None for batch size)

I  have already tried some unpooling function but with no results. The  main issue is not the unpooling process itself but it's returning a  tensor with None as first axis. Any suggestions or help would be useful,  thank you!",7,deeplearning,2020-10-13
j9bgtl,Is there something like www.respeecher.com (dont have to be online website),,2,deeplearning,2020-10-13
j9av18,"GauGAN/SPADE UI, feel free to use","[https://github.com/deduble/gaugan-gui](https://github.com/deduble/gaugan-gui)

&amp;#x200B;

Hello everyone,

I created that GUI long ago before Nvidia published their demo. Now I see that theirs is down, so I decided to publish mine.

For people who don't know (really? Do you exist?), Nvidia SPADE creates photo realistic images from basic segmentation images. (basic drawings).

Feel free to implement this anywhere. Just mention my github. Most importantly, I don't have much place for now for testing. I am open to PR and fixing issues.

Have good day.",3,deeplearning,2020-10-13
j95938,Reason behind classification in one or two classes only?,"Hi,

Please observer following output for the given model.

base\_model = tf.keras.applications.Xception(

        include_top=False,
        weights=""imagenet"",
        input_shape=(150, 150, 3),
        classifier_activation='softmax',
    )
    
    base_model.summary()
    # Freeze the base_model
    base_model.trainable = False
    
    # Create new model on top
    inputs = tf.keras.Input(shape=(150, 150, 3))
    #x = data_augmentation(inputs)  # Apply random data augmentation
    x = inputs
    # Pre-trained Xception weights requires that input be normalized
    # from (0, 255) to a range (-1., +1.), the normalization layer
    # does the following, outputs = (inputs - mean) / sqrt(var)
    norm_layer = keras.layers.experimental.preprocessing.Normalization()
    mean = np.array([127.5] * 3)
    var = mean ** 2
    # Scale inputs to [-1, +1]
    x = norm_layer(x)
    norm_layer.set_weights([mean, var])
    
    model_1 = Model(inputs=base_model.input, outputs=base_model.get_layer('add').output)
    model_2 = Model(inputs=base_model.input, outputs=base_model.get_layer('add_1').output)
    model_3 = Model(inputs=base_model.input, outputs=base_model.get_layer('add_2').output)
    model_4 = Model(inputs=base_model.input, outputs=base_model.get_layer('add_3').output)
    model_5 = Model(inputs=base_model.input, outputs=base_model.get_layer('add_4').output)
    model_6 = Model(inputs=base_model.input, outputs=base_model.get_layer('add_5').output)
    model_7 = Model(inputs=base_model.input, outputs=base_model.get_layer('add_6').output)
    model_8 = Model(inputs=base_model.input, outputs=base_model.get_layer('add_7').output)
    model_9 = Model(inputs=base_model.input, outputs=base_model.get_layer('add_8').output)
    model_10 = Model(inputs=base_model.input, outputs=base_model.get_layer('add_9').output)
    model_11 = Model(inputs=base_model.input, outputs=base_model.get_layer('add_10').output)
    
    x = model_6(x, training=False)
    
    x = keras.layers.GlobalAveragePooling2D()(x)
    outputs = keras.layers.Dense(7, activation='softmax')(x)
    model = keras.Model(inputs, outputs)
    model.summary()
    
    epochs = 40
    
    model.compile(
        optimizer=keras.optimizers.Adam(),
        loss=keras.losses.CategoricalCrossentropy(from_logits=True),
        metrics=['accuracy'],
    )

https://preview.redd.it/i1a3vqlltgs51.png?width=515&amp;format=png&amp;auto=webp&amp;s=22b89ec6973a38b383f2c2d2ac49175bae83dbb7

    Class Dist For Train: [3996. 3770. 3878. 4426. 3880. 3656. 5382.]
    Class Dist For Valid: [432. 324. 646. 648. 108. 538. 972.]
    Class Dist For Test: [ 646.  108. 1124. 1126.  910.  864. 1331.]
    
    [[   0    0    0    0    0    0  646]
     [   0    0    0    0    0    0  108]
     [   0    0    0    0    0    0 1124]
     [   0    0    0    0    0    0 1126]
     [   0    0    0    0    0    0  910]
     [   0    0    0    0    0    0  864]
     [   0    0    0    0    0    0 1331]]
    
    Why everything is being classfied to one class only?",1,deeplearning,2020-10-13
j93gok,100-off-python-certification-training-beginner-to-expert/,,0,deeplearning,2020-10-13
j92tlz,"PCIe connections and riser cables for high performance workloads like RNDR / OctaneRender (Ribbon, USB, M.2, PLX, MSI, Splitters)",,4,deeplearning,2020-10-13
j927ey,Where to collect image datasets for classifier?,"Hi,

I am pretty new and don't know any resources to collect thousands of images required for my classifiers. 

I wanna collect mainly recyclable objects for my project.

Can you please tell me where to collect these images?",10,deeplearning,2020-10-13
j8zbbu,Hosting neural networks in one place," Hey guys, Is it possible to host many ml/dl models that do different tasks on one place and potentially create a network of classification and routing AIs that can narrow down the problem and route it to the appropriate specialized AI? in simple, how do i host many neural networks that do different tasks in one place and create a system that will classify the problem and route it to the specialized ai {ex: computer vision, nlp}?",5,deeplearning,2020-10-13
j8x0rp,Advice for a teen learning deep learning?,"I have finished the introduction to PyTorch by audacity last month, where I learned about linear neural networks, cnns, and rnns. I have since then stopped learning about deep learning and now I don't remember a lot of things I once knew.

I want to get back into deep learning, and get good enough to the point where I can make my own models that can be put to good use.

What courses, would you recommend to a person who has a good understanding of how deep learning works, but doesn't know how to make one for himself? thanks",0,deeplearning,2020-10-13
j8vc46,Should I return the Nvidia Jetson Nano 4GB for the 2GB,I'm trying to develop on the nano and will be using a GAN on it. Would it be smart for me to return the 4gb one that I just bought for 2gb. Is the extra ram going to be useful for inference?,0,deeplearning,2020-10-13
j8tb9y,Architecture for deploy custom models for multiples customers?,"Hi

I am confidente using ML, DL and NLP techniques, however I am new in cloud architecture design, what  I want to know is which one is the architecture for deploy custom models for multiples customers?, I mean a customer A has a trained model, a customer B has another one, 

Each customer own their own API to consume their model

Any Idea how to approach to the problem? thank you",0,deeplearning,2020-10-13
j8s3dn,Available pre-trained Super-Sampling Neural Networks,As per the question,0,deeplearning,2020-10-13
j8lk2h,Object Detection from 9 FPS to 650 FPS - on-GPU tuning case study,,27,deeplearning,2020-10-13
j8leeg,Best practices for handling large datasets,"Hello, since I got into deep learning, I've been working with small datasets to create models in `tensorflow` / `keras` functional api. What I'm used to do is to preprocess and clean / manipulate / visualize the data using `pandas` and later create a tfrecord that I use for training. Recently I started working with stock data (1min frequency) so, I currently have somewhere between 10,000 - 30,000 stock signs for 10+ years of data that I stored in the following fashion: I got the data from [polygon](https://polygon.io/) api and for each stock sign I create a separate `.parquet` file and I have the files in a `GCP` bucket. Now, if I'm going to create a dataset that will include most of the signs I have the following concerns:

* Variable length and frequency files which implies for example: `AAPL` df has 2,566,598 rows and `AMZN` has 1,928,479 rows for the same period, and some signs have fewer than 10,000 rows. What is a proper way of dealing with `NAN` values?
* For calculating technical indicators, lagged returns and many other computations efficiently, I was thinking maybe I could use Google BigQuery and store the data and perform necessary computations using `SQL` queries, is there a better way? should I store all signs in 1 table with multiple indices? or use one table for each sign?

And for those who worked with intraday stock data before:

* What frequency do you recommend to avoid overfitting and get good results?
* What technical indicators work best for data with this frequency(1min)? I'm asking because `moving averages`, `MACD` and many other indicators calculate over periods of days and I'm not sure whether this can be applied to this frequency as well.",8,deeplearning,2020-10-13
j8jfjn,DeepFakes in 5 minutes. Understand how deepfakes work and create your own!,,48,deeplearning,2020-10-13
j8gb26,Wrote a simple C# program to draw images on Paint (Source in the comments),,8,deeplearning,2020-10-13
j8g6on,"[P] Reproducible Pytorch Implementation of ""FixMatch"" with trained models.",,1,deeplearning,2020-10-13
j8cm5k,Unsupervised Multi-Document Summarization using Neural Document Model | Research Paper Walkthrough,,2,deeplearning,2020-10-13
j8a0gy,Next step on deep learning,"Hi folks
I have just finished Andrew Ng's neural network course on coursera. What should be the next step? I don't want to lose myself while I found my pace.
Have a nice day",9,deeplearning,2020-10-13
j87swm,DDPG in Stock. Looking for Teammates :),"Hi,

Hope this finds you well guys!

Recently I am trying to implement the paper  [""Adversarial Deep Reinforcement Learning in Portfolio Management""](https://arxiv.org/abs/1808.09940) with one of the methods mentioned in the paper -- Deep Deterministic Policy Gradient. The code of the paper can be found [here](https://github.com/liangzp/Reinforcement-learning-in-portfolio-management-). It also includes the dataset.  I am using TensorFlow 2.0 / Keras. I created a small network instead of a full network in the paper for debugging purposes. My code could be found [here](https://github.com/XimingFeng/ddpg-stock). You can open to Jupyter notebook ""[DDPGTest2.ipynp](https://github.com/XimingFeng/ddpg-stock/blob/master/DDPGTest2.ipynb)"" for the running result.

My issue right now:  somehow the actor starts to produce high confidence with only one class/stock after a few steps, then it stays that way forever unless I set the noise on the actor output to be really high. Even if I force the network to learn the same dataset for multiple episodes, still does not make any change. I tried different types of networks such as CNN, Fully-Connected. With that, I don't think the network type is the issue. I have also tried different sets of hyper-parameter. I feel stuck right now. Not sure what to check next. If you are interested in the project, please let me know. Any help is appreciated!",1,deeplearning,2020-10-13
j87evq,CUDA using AMD processor,"Hello everybody!

Currently I am setting up a new computer, I would like to train some DL models . I am deciding which processor should be buy between AMD or Intel together with a NVIDIA GPU. I want use the GPU to train some models using Pytorch, however I don't know if CUDA works with an AMD processors properly (I only used it with Intel + NVIDIA GPU). 

&amp;#x200B;

I would like to know if some of you have worked with AMD + NVIDIA to train models?  

Any recommendations?

Thank you very much!",0,deeplearning,2020-10-13
j855sv,PwC-Powered Code Tab Added to arXiv ML Papers,"Tired of searching for and copying GitHub links in arXiv papers to find the code? Papers with Code (PwC) is here to help! PwC and arXiv jointly announced their partnership yesterday, [unveiling](https://blog.arxiv.org/2020/10/08/new-arxivlabs-feature-provides-instant-access-to-code/) a convenient new Code tab on the abstract page of arXiv Machine Learning articles. PwC says the new feature will make it much easier for researchers and practitioners to access and build on the latest machine learning research.

Here is a quick read: [PwC-Powered Code Tab Added to arXiv ML Papers](https://syncedreview.com/2020/10/09/pwc-powered-code-tab-added-to-arxiv-ml-papers/)",27,deeplearning,2020-10-13
j846pf,Understanding gini index and information gain in decision tree,,1,deeplearning,2020-10-13
j7z0v0,"Image Matting with state-of-the-art Method “F, B, Alpha Matting”","Image matting has been traditionally done using a green or blue screens. With advances in AI, we can now get rid of the green screen and still create high quality outputs for images with natural backgrounds.  


Without further ado, let's go over the state of the art image matting algorithm in the post below.  


[https://www.learnopencv.com/image-matting-with-state-of-the-art-method-f-b-alpha-matting/](https://www.learnopencv.com/image-matting-with-state-of-the-art-method-f-b-alpha-matting/)  


We have also shared code.

https://preview.redd.it/pf0axi5jn2s51.jpg?width=600&amp;format=pjpg&amp;auto=webp&amp;s=5915a0bba2c27cb578b1d6bf3fcb960def784eac",3,deeplearning,2020-10-13
j7xf0x,Anyone have experience with yolov5. I'm facing an issue with coreml export.,[https://github.com/ultralytics/yolov5](https://github.com/ultralytics/yolov5),0,deeplearning,2020-10-13
j7wfme,Finally a storage benchmark tool to include GPUs (Feedback/suggestions welcome),,9,deeplearning,2020-10-13
j7v57i,Variational Autoencoders : which losses to use ?,"Hello community. I'm currently implementing a VAE solution . In TensorFlow 2.0 examples , I saw that they used `sigmoid_cross_entropy_with_logits` as the reconstruction loss.

I didn't understand this choice , I would instead use MSE or RMSE errors to reconstruct the loss ,and use the `KL Divergence` for the latent loss.

I want to precise that in my task ,images don't have classes ,they are just a bunch of images that cannot be classified . I can simply say that I have one class.,what loss should I use instead of `sigmoid_cross_entropy_with_logits` does `MSE` would do the job ?",13,deeplearning,2020-10-13
j7u34o,Filter learning with unsupervised learning,“Filter Learning with Unsupervised Learning” - Tekin Evrim Ozmermer tarafından https://link.medium.com/Vc07ppe7qab,1,deeplearning,2020-10-13
j7u327,Filter learning with unsupervised learning,“Filter Learning with Unsupervised Learning” - Tekin Evrim Ozmermer tarafından https://link.medium.com/Vc07ppe7qab,1,deeplearning,2020-10-13
j7tuft,Randomly changing weights of CNN in between training,"Hi,

Can I randomly change weights of CNN in between training in keras? It is for the case if there is no change in accuracy.

Thanks",0,deeplearning,2020-10-13
j7tijb,How to formulate custom learning rate pytorch?,"I'm working with transformer based model and want to schedule custom learning rate i.e.

```bash
lrate = d_model ^ 0.5 * min( step_num ^ 0.5, step_num * warmup_steps ^ -1.5)
```

How to formulate this in pytorch?",1,deeplearning,2020-10-13
j7nwje,Network Saliency Maps,"I would like to ask if there is a way to acquire network saliency maps for applications like object detection (aside from classification)? For example if we take the standard gradient-based saliency maps, how can we do this if our output is an image map and each pixel is classified rather than having a single predicted value?   
Thank you very much.",2,deeplearning,2020-10-13
j7nm83,Is Quantum Machine Learning the next thing?,,0,deeplearning,2020-10-13
j7nkby,Is Quantum Machine Learning the next thing?,,0,deeplearning,2020-10-13
j7mng0,[R] ‘Farewell Convolutions’ – ML Community Applauds Anonymous ICLR 2021 Paper That Uses Transformers for Image Recognition at Scale,"A new research paper, *An Image Is Worth 16×16 Words: Transformers for Image Recognition at Scale,* has the machine learning community both excited and curious. With Transformer architectures now being extended to the computer vision (CV) field, the paper suggests the direct application of Transformers to image recognition can outperform even the best convolutional neural networks when scaled appropriately. Unlike prior works using self-attention in CV, the scalable design does not introduce any image-specific inductive biases into the architecture.

Here is a quick read: [‘Farewell Convolutions’ – ML Community Applauds Anonymous ICLR 2021 Paper That Uses Transformers for Image Recognition at Scale](https://syncedreview.com/2020/10/08/farewell-convolutions-ml-community-applauds-anonymous-iclr-2021-paper-that-uses-transformers-for-image-recognition-at-scale/)

The paper *An Image Is Worth 16×16 Words: Transformers for Image Recognition at Scale* is available on[ OpenReview](https://openreview.net/pdf?id=YicbFdNTTy).",0,deeplearning,2020-10-13
j7liwh,Machine Vision Anomalous Spray Pattern Problem Detection Problem,"I'm hoping to get some direction on a problem I'd like to try to solve using deep learning. The problem is a machine vision problem. I need to detect anomalous spray patterns in a spray drying application.

Specifically, the spray dryer has multiple spray nozzles that atomize the product (concentrated milk) before it is introduced into a hot air stream. Occasionally, a build-up occurs on the nozzle body causing an anonymous spray pattern. The real danger here is the build-up, which has been termed ""bearding"". The ""beard"" can smolder and drop off of the nozzle and cause a dryer explosion. To help monitor and prevent this, the spray dryer is equipped with cameras that allow an operator to spot the issue and take action.

My hope is to utilize the camera footage to train a deep network to recognize an abnormal spray pattern and alert the operator (or take action). I have a PC equipped with an Nvidia 2080 GTX video card and is running the latest version of Ubuntu. The PC can be set up with various deep learning platforms, but my thought was to use Keras as well as TensorFlow and/or MxNet and whatever else is required to conduct training. 

I should mention that I'm almost quite inexperienced in deep learning. I've read a couple of books, followed along on some exercises, and tried a few small projects. With all of that said, I was wondering if this approach, [""Anomaly Detection in Videos using LSTM Convolutional Autoencoder""](https://github.com/hashemsellat/video-anomaly-detection) will work for this application? Here's the [GitHub link](https://github.com/hashemsellat/video-anomaly-detection) to the same. My thought is that this is not a difficult problem compared to other machine vision problems, but not sure what other more experienced practitioners think? Thanks in advance for any thoughts, comments, suggestions, etc...

# 

[Typical spray pattern](https://preview.redd.it/np10qfhrqxr51.jpg?width=898&amp;format=pjpg&amp;auto=webp&amp;s=8994cc8c6372ff71dfb4a35a95e83a613bb1ffbc)

&amp;#x200B;

[Build-up and slightly disturbed spray pattern](https://preview.redd.it/byieyj62rxr51.jpg?width=300&amp;format=pjpg&amp;auto=webp&amp;s=0ec67d8e0227af89148cd80c7dd730a831e6c6c3)",1,deeplearning,2020-10-13
j7k3dm,Is Attention a technique or an architecture ?,"I was recently reading articles and the original paper of Attention, where the paper defines Attention as

&gt;An attention function can be described as mapping a query and a set of key-value pairs to an output

This led me into confusion whether Attention is an architecture, a fixed layer by layer design, or a technique, which involves implementing a basic idea, to bring the model's attention to the important parts, as it is said for Attention models ? If it is a technique, what is the idea based on code that it tries to incorporate ?",8,deeplearning,2020-10-13
j7jvn3,Building a chatbot with google's universal sentence encoder (Open Source),"Hi everyone,

I recently built a simple chatbot with Google's universal sentence encoder using it as a sentence embedding and finding the best response with cosine similarity. I wrote about it a bit more in my [blog post](https://www.papercups.io/blog/chatbot). I tried to simplified some of the explanation since I had trouble understanding embeddings when I first learned it

You can also play around with the chatbot by feeding it your own questions and answers [https://app.papercups.io/bot/demo](https://app.papercups.io/bot/demo)

with the source code for the backend [https://github.com/papercups-io/papercups-simple-chatbot](https://github.com/papercups-io/papercups-simple-chatbot)

the source code of the client side is [https://github.com/papercups-io/papercups/blob/master/assets/src/components/demo/BotDemo.tsx](https://github.com/papercups-io/papercups/blob/master/assets/src/components/demo/BotDemo.tsx)

Would love any feedback!",5,deeplearning,2020-10-13
j7inbs,Handling matrix dimensions problem,"Hi folks,

I am a newbie and trying to implement neural network model from scratch. I am confusing dimension of matrix most of the time. I mean sometimes I need to take transpose a matrix while multiplying or doing element-wise multiplication instead of dot product, etc. One of the thing why I confuse is the convension in different courses or implementations I guess. Do you have any suggestion for placing this idea into mind clearly?

Thanks",0,deeplearning,2020-10-13
j7ig7y,"Google, Stanford, &amp; MIT Top NeurIPS 2020 Accepted Papers List","After months marred by controversies over poorly-explained [desk-rejects](https://syncedreview.com/2020/07/16/poorly-explained-neurips-2020-desk-rejects-peeve-ml-researchers/) and other problematic aspects of its [review process](https://syncedreview.com/2020/08/13/neurips-paper-reviews-released-controversies-resurface/), the 34th Conference on Neural Information Processing Systems (NeurIPS 2020) has finally released its [list](https://neurips.cc/Conferences/2020/AcceptedPapersInitial) of accepted papers.

With 38 percent more paper submissions than 2019, this has been another record-breaking year for NeurIPS. A total of 1,903 papers were accepted, compared to 1,428 last year.

The NeurIPS 2020 Program Chairs report that 12,115 paper abstracts were submitted, leading to 9,467 full submissions. After 184 submissions were withdrawn by authors or rejected for violations such as being non-anonymous or exceeding the maximum page count, 11 percent were desk-rejected, leaving 8,186 papers assigned to reviewers. **The NeurIPS 2020 paper acceptance rate is 20.1 percent — slightly lower than last year’s 21 percent.**

Here is a quick read: [Google, Stanford, &amp; MIT Top NeurIPS 2020 Accepted Papers List](https://syncedreview.com/2020/10/08/google-stanford-mit-top-neurips-2020-accepted-papers-list/)",29,deeplearning,2020-10-13
j7hxb4,VScode environment or Colab Environment for Deep Learning,"Hey, I’m currently a student who uses google colab for my deep learning projects. However, I recently installed python in visual studio code as well. Would you guys recommend I stay away from doing deep learning on vscode and staying on colab just because colab gives you the option of a GPU?",0,deeplearning,2020-10-13
j7hjff,"Think it's a simple question, but... how do you read "".geno"" files in Jupyter Notebook (Python)?","Title.

Recently I have been assigned to build a deep learning model with some genotype and phenotype data. I'm honestly pretty new to machine learning and do not have a clue when it comes to reading those "".geno"" files. Looked it up but no luck. People say that I would have to write it in R, but doesn't that make it not a deep learning model?

 Hopefully someone could help with my concerns. Thanks.",0,deeplearning,2020-10-13
j7gwf8,[P] Doing More with Less Using Bayesian Active Learning,"[https://product.hubspot.com/blog/bayesian-active-learning](https://product.hubspot.com/blog/bayesian-active-learning)

How we're using advances in Bayesian deep learning to extract reliable uncertainty estimates from neural networks.",12,deeplearning,2020-10-13
j7geyh,Correspondance between types of filters and Image,"Hi,

I am working on electrophysiological data (EEG). I have to do the classification based on some images created from the EEG data visual and signal processing. I have around 3100 images/class. Training on pre-trained model like Xception doesn't give good results. I have trained with my simple architecture as I though due to lack of data the Xception model (Block-1 and Block-2) might be underfitting but with no avail. As my data is different from normal object related data like imagenet. I am wondering if anyone knows about any reference where some correspondance between types of images and hyper-parameter (eg. filter size, activation function and others) is mentioned.

&amp;#x200B;

Thanks for your reply.",1,deeplearning,2020-10-13
j7f1c9,"[D] When I try to train the VGG16 model without batch normalization and with no pre-trained weights (i.e. training from scratch) on the CIFAR-100, the accuracy on the validation set is stuck at 1% and is not improving.","I am using SGD and CrossEntropy for training. Also, when I use the pre-trained weights the accuracy seems to increase and work fine. Please suggest how I can rectify this issue. Thanks.

&amp;#x200B;

Edit: 

Code Link: [https://colab.research.google.com/drive/1MJ5sBuUeirh1XQTshZi1amw\_j5cZ0syV?usp=sharing](https://colab.research.google.com/drive/1MJ5sBuUeirh1XQTshZi1amw_j5cZ0syV?usp=sharing)",7,deeplearning,2020-10-13
j7drox,The problem when writing paper,"I have solved a problem with deep learning (CycleGAN + Pix2Pix + some preprocessing techniques) and I'm writing a paper about it. I know it needs a section that describes some advantages / higher accuracies with another paper or solution. The disadvantage I am facing is that my problem belongs to a narrow discipline and no one seems to have touched it. When building the model, I had to create the dataset myself when I couldn't find any available sources. How do I have to solve it?",9,deeplearning,2020-10-13
j7d6bd,Supreme Commander: Forged Alliance - All Cinematics (Remastered 8K 60FPS) Resolution increased using neural networks to 8K 60FPS,,1,deeplearning,2020-10-13
j7anng,Solving Web Accessibility with AI,,4,deeplearning,2020-10-13
j7a1rx,Laptop Suggestion for a beginner in Deep Learning and Computer and Computer Vision,"Hi everyone, 

I am currently looking to buy a laptop (in India) majorly for personal use and Deep learning tasks. I am currently a beginner in Deep Learning for Computer Vision (been learning it for the past 4 months) and I plan on pursuing it further as a career and it would be great if you could help me in figuring out one. After doing a fair bit of research, I have narrowed it down to these specifications and available options under 1100 USD:

**RAM:** 8GB or more

**Storage:** 512 SSD or 1TB HDD+128/256GB SSD

**CPU:** Intel i5/i7

**Graphics Card:** 4GB NVIDIA GTX 1050/1660Ti (I am a complete noob when it comes to select which GPU  is better and which one to choose in this case)

**Available options as of now:** HP Omen 15 2020 Model, Lenovo Legion 5i, Dell G3.

I prefer one with a bigger battery life and all of the mentioned above ones have mixed reviews online. I hope I could use some of your help. Kindly do suggest if there are any other options in the mentioned price range.

&amp;#x200B;

Thank you!",4,deeplearning,2020-10-13
j7941f,Thesis Suggestion in Deep Learning,"
Please suggest me some thesis ideas in the domain of deep learning.",0,deeplearning,2020-10-13
j77790,How Do I Start Learning Deep Learning?,,0,deeplearning,2020-10-13
j6z32g,Addinng an lstm decreases model performance,"So extending an image segmentation model to the task of video by adding an LSTM decreases the model performance. What could be possible reasons for this? 
Some details/possible reasons I've sort of ruled out:
1. mIoU drops a good 10% over training just the same architecture on the same inputs for image level sequences.
2. Already played around with learning rate, weight decay, lstm position( after the encoder/before the softmax). This is probably not the issue?

Any guesses/hidden secrets to training lstms that could help?",5,deeplearning,2020-10-13
j6tdlw,"A new way to discover top trending papers in Deep Learning, ML and CS.",,42,deeplearning,2020-10-13
j6rur5,Retrieval-Augmented Generation Explained!,[https://youtu.be/dzChvuZI6D4](https://youtu.be/dzChvuZI6D4),1,deeplearning,2020-10-13
j6nvba,[R] Explaining Deep Neural Networks,"**Abstract**:  Deep neural networks are becoming more and more popular due to their revolutionary success in diverse areas, such as computer vision, natural language processing, and speech recognition. However, the decision-making processes of these models are generally not interpretable to users. In various domains, such as healthcare, finance, or law, it is critical to know the reasons behind a decision made by an artificial intelligence system. Therefore, several directions for explaining neural models have recently been explored.

  
In this thesis, a researcher with Oxford University investigates two major directions for explaining deep neural networks. The first direction consists of feature-based post-hoc explanatory methods, that is, methods that aim to explain an already trained and fixed model (post-hoc), and that provide explanations in terms of input features, such as tokens for text and superpixels for images (feature-based). The second direction consists of self-explanatory neural models that generate natural language explanations, that is, models that have a built-in module that generates explanations for the predictions of the model. 

Full paper:  [https://arxiv.org/pdf/2010.01496v1.pdf](https://arxiv.org/pdf/2010.01496v1.pdf)",2,deeplearning,2020-10-13
j6lkrd,NVIDIA Releases Imaginaire: A Universal PyTorch Library Designed For Various GAN-Based Tasks And Methods,"NVIDIA has developed a universal PyTorch library, **Imaginaire,** with an optimized implementation of various GAN images and video synthesis. 

The **Imaginaire** library currently covers three types of models, providing tutorials for each of them:

* Supervised Image-to-image translation
* Unsupervised Image-to-image translation
* Video-to-video translation 

Summary: https://www.marktechpost.com/2020/10/06/nvidia-releases-imaginaire-a-universal-pytorch-library-designed-for-various-gan-based-tasks-and-methods/

Github: [https://github.com/NVlabs/imaginaire#supervised-image-to-image-translation](https://github.com/NVlabs/imaginaire#supervised-image-to-image-translation)

&amp;#x200B;

https://i.redd.it/99wdtefy3mr51.gif",60,deeplearning,2020-10-13
j6j9zc,Wanting to contribute to projects or research,"Hi everyone, I hope you're safe and healthy.

I recently graduated and I worked on deep learning for my graduation project (arrhythmia classification using raw ECG signal and LSTM) And it was fun. I would like to continue on the domain of ML/DL and since borders are closed on my country (no AI related jobs here) I have plenty of time  before I start applying for jobs.

So if you have any projects or research you need help with or you know any great open source project that I can contribute to, please let me know. Thanks in advance 😊.",1,deeplearning,2020-10-13
j6g2cj,How to make model train faster?,"I have been working on a CNN brain tumor image classifier, and my model is taking a disgusting amount of time to train. My train set has about 2000 images and 400 for validation, and 300 for testing. I have 3 layers of convolutions, followed each by a max pool with a filter size of 3. And my batch size is 150 followed by the number of epochs being 80. Does anyone know what I can do to allow it to train faster?",6,deeplearning,2020-10-13
j6ff3b,Latest from Microsoft and Samsung researchers: State of the art in Face Attribute Editing with GANs,,1,deeplearning,2020-10-13
j6cxo3,"Blob Detection Using OpenCV ( Python, C++ )","In today's post, we will discuss a kind of detector that helps us where even edge detectors or corner detectors might fail. We will discuss a simple (literally!) Blob detector example.  


Dive in to [https://www.learnopencv.com/blob-detection-using-opencv-python-c/](https://www.learnopencv.com/blob-detection-using-opencv-python-c/) for more details and both the CPP and Python code!

https://i.redd.it/ujvko3ewajr51.gif",1,deeplearning,2020-10-13
j68z87,Top 10 Machine Learning Courses(Theory and Practical in 2020),,4,deeplearning,2020-10-13
j68320,"I just graduated college and I am fascinated with the recent findings in GANs. I have no coding background, where should I start if I wanted to go headfirst into deep learning?","Hey guys,

Sorry about the newbie question. I love this stuff. I'm studying Social with Math but I will graduate and be eligable to apply for computer science next semester. I was going to begin Andrew NGs online Python class for a head start. I am interested in learning.

Does anyone have any suggestions on how I could optimize my route with respect to learning GAN, and generating interesting animation, digital effects and musical products from data? I am a UK House Producer with 6+ years of experience in sound design and production engineering. Cheers.",3,deeplearning,2020-10-13
j67ssh,A Simple Neural Network Upgrade Boosts AI Performance,,1,deeplearning,2020-10-13
j67r95,Does this mean my model is overfitting!? FYI - I'm trying to make a text generator using LSTM RNN.,,36,deeplearning,2020-10-13
j66m30,RMSprop or Adam?,"I have a problem where I've found that RMSprop optimises but Adam does not - Adam just stays around the starting loss. For the record, I am using quite a high lr (0.01). Does Adam generally require a smaller lr than RMSprop? 

Can anyone provide an explanation for why this might be the case?",2,deeplearning,2020-10-13
j65h41,Style transfer is an interesting problem in machine learning where one image's style is imposed on another. This concept can be pushed even further to work on videos as well.,,0,deeplearning,2020-10-13
j62a1l,Inventing Virtual Meetings of Tomorrow with NVIDIA AI Research,"[https://www.youtube.com/watch?v=NqmMnjJ6GEg](https://www.youtube.com/watch?v=NqmMnjJ6GEg)

Epic work by Nvidia for compressing video calls 😍 

the idea of sending a single keyframe then sending keypoints and using a GAN to reconstruct the subsequent frames is really elegant! 

The face alignment feature is also great - it always feels a little weird when people are looking behind you during a video call 😅",3,deeplearning,2020-10-13
j5x9nb,Training A Neural Network To Write Eminem Lyrics,,2,deeplearning,2020-10-13
j5vebc,Intel vs AMD CPU for Deep Learning?,,3,deeplearning,2020-10-13
j5va2k,Possible to get a job with only a BSc as a deep learning engineer?,"Hi all,

I've really fallen for deep learning since graduating with a BSc in mathematics but have never had a job in data/ML. I am studying to become an actuary out of neccessity, but my heart is just not in. Is it possible to get a job in deep learning with only a BSc? I have three projects on my github of applying DL to kaggle competitions, but no one ever calls me back for an interview. What more can I do? Playing around with models on data sets is my passion that I wish could turn into my day time job.",5,deeplearning,2020-10-13
j5ttvg,How can I apply reinforcement learning in a Javascript environment?,"Hi everyone! I'm working on a project about creating an agent that plays a Mortal Kombat game written in Javascript. 
My problem is that I want to train a deep learning model in Google Colab (Python + tensorflow) so my first idea is to ""migrate"" the project from JS to Python to train the model in a ""similar"" game environment, but surely there are better solutions, any advice?

Thank You!",0,deeplearning,2020-10-13
j5ra9g,[R] Google AI Helps Sign Language ‘Take the Floor’ in Video Conferences,"To enable signers to “take the floor” in such video meetings, a team of researchers from Google, Bar-Ilan University, and the University of Zurich recently developed a sign language detection model for video conferencing applications that can perform real-time identification of a person signing as an active speaker.

Here is a quick read: [Google AI Helps Sign Language ‘Take the Floor’ in Video Conferences](https://syncedreview.com/2020/10/05/google-ai-helps-sign-language-take-the-floor-in-video-conferences/)

Google AI has open-sourced the training code and models for [web demo](https://sign-language-detector.web.app/) on [GitHub](https://github.com/AmitMY/sign-language-detector). The paper Real-Time Sign Language Detection using Human Pose Estimation is available on the Google Research [website](https://research.google/pubs/pub49425/). The model will be presented at [SLRTP2020](https://www.slrtp.com/) and demoed at [ECCV2020](https://eccv2020.eu/).",0,deeplearning,2020-10-13
j5np4f,Convolutional Neural Network Champions — Part 2: AlexNet (TensorFlow 2.x + Python),"Hello All,

Part 2 of my article on Convolutional Neural Networks is published on Medium (link: [https://towardsdatascience.com/convolutional-neural-network-champions-part-2-alexnet-tensorflow-2-x-de7e0076f3ff](https://towardsdatascience.com/convolutional-neural-network-champions-part-2-alexnet-tensorflow-2-x-de7e0076f3ff) ). This section is dedicated to AlexNet with reproducible result in Tensorflow 2.0 and Python.

Cheers",2,deeplearning,2020-10-13
